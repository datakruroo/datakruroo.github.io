---
title: "Week 4: Data Preprocessing I"
author: "ผศ.ดร.สิวะโชติ ศรีสุทธิยากร"
institute: "ภาควิชาวิจัยและจิตวิทยาการศึกษา <br> คณะครุศาสตร์ จุฬาลงกรณ์มหาวิทยาลัย"
format:
  revealjs:
    slide-number: c/t
    footer: "week 4: 2758623 Machine Learning Principles and Application<br>
            ผศ.ดร.สิวะโชติ ศรีสุทธิยากร"
    logo: https://github.com/ssiwacho/picture/blob/main/datakruroo.png?raw=true
    theme: theme.scss
    css: my_css.css
    scrollable: true
    transition: fade
    background-transition: fade
    highlight-style: atom-one
    title-slide-attributes:
      data-background-image: img/ML.jpg
      data-background-opacity: 8%
      data-background-size: full
code-link: true
execute:
  echo: true
---

```{r echo = F}
library(tidymodels)
library(tidyverse)
tidymodels_prefer()
```

## `learningdata.csv` {.smaller}

```{r}
data <- read_csv("learningdata.csv")
glimpse(data, 60)
```


# Feature Engineering {background-color="#FFD7C4"}

> Reformatting predictor values to make them easier for a model to use effectively.

- Encodings

- Transformations


## Encoding Categorical Data into Numerical Format {.smaller}

```{mermaid}
%%| echo: false
flowchart LR
A[factor]-->B[numeric]
C[character]-->B
```


<div style="font-size:80%;">


- `step_unknow()` -- กำหนด missing value ในตัวแปรแบบ factor ให้เป็น  "unknown".

- `step_novel()` -- กำหนดค่า factor level ที่ไม่เคยเห็นมาก่อนให้เป็น "new".

- `step_other(threshold)` -- รวม catergories ที่มีจำนวนความถี่น้อยให้เป็นกลุ่มเดียวกันเรียกว่า "other"

- `step_dummy(one_hot)`

</div>


## Interaction Terms (1) {.smaller}

อิทธิพลปฏิสัมพันธ์ (interaction effects) เกิดขึ้นเมื่อความสัมพันธ์/อิทธิพลของตัวแปรอิสระตัวหนึ่งที่มีต่อ y มีค่าที่แตกต่างกันไปคามค่าหรือระดับของตัวแปรอิสระอย่างน้อยอีกตัวหนึ่ง

```{r fig.height=5}
data |> 
  ggplot(aes(x=study.hr, y=ach))+
  geom_point(alpha = 0.5, shape = 1)+
  geom_smooth(method = "lm", se = F, aes(col = self.esteem > 16))+
  theme_light()+
  theme(panel.grid = element_blank(),
        text = element_text(size = 15))


data |> 
  mutate(
         acad_axiety = rowMeans(across(starts_with("acad.axiety")),na.rm=T),
         teach_sup = rowMeans(across(starts_with("teach")),na.rm=T),
         lrn_environ = rowMeans(across(starts_with("lrn.environ")), na.rm=T)
  ) |> 
  ggplot(aes(x=study.hr, y=ach))+
  geom_point(alpha = 0.5, shape = 1)+
  geom_smooth(method = "lm", se = F)+
  facet_wrap(~par.involv_ordinal)

```


## Interaction Terms (2) {.smaller}

ตัวอย่างการเขียน recipe สำหรับ interaction terms

```{r eval = F}
recipe(y ~ x1+x2+x3+x4+x5 , data = train_data) |> 
  step_interact(terms = ~ x1:x2) 

recipe(y ~ x1+x2+x3+x4+x5 , data = train_data) |> 
  step_interact(terms = ~ x1:starts_with("x")) 
```


## Interaction Terms (3) {.smaller}

- **Literature Review/Expert Knowledge** (Neter et al., 2004)

- **Principle of Interaction Search** (Wu and Hamada, 2011)

  - First Principle: Interaction Hierarchy -- higher order interaction มักมีความสัมพันธ์หรือมีผลกระทบต่อค่าทำนายน้อยกว่า lower order interaction และ main effects

  - Second Principle: Effect Sparsity -- มีเพียงส่วนหนึ่งของผลกระทบที่เป็นไปได้ทั้งหมดเท่านั้นที่สามารถอธิบายความแปรปรวน/ทำนายตัวแปรตามได้อย่างมีนัยสำคัญ

  - Third Principle: Effect Heredity -- ปฏิสัมพันธ์ของตัวแปรต่างๆ อาจพิจารณาได้ก็ต่อเมื่อผลกระทบของตัวแปรที่เกิดก่อนปฏิสัมพันธ์นั้นมีประสิทธิภาพในการอธิบายความแปรปรวน/ทำนายตัวแปรตาม



![](https://bookdown.org/max/FES/figures/interaction-effect-sparsity.png){fig-align="center"}

<div class="caption">figure1: Effect Sparsity</div>

<br>




![](https://bookdown.org/max/FES/figures/interaction-effect-heredity.png){fig-align="center"}

<div class="caption">figure2: Effect Heredity</div>


<div class="caption3">M. Kuhn and Johnson (2020)</div>

## Interaction Terms (4) {.smaller}

- **Simple Screening** -- ใช้การเปรียบเทียบโมเดลระหว่างโมเดลอย่างง่าย และโมเดลซับซ้อนด้วยค่าสถิติวัดความสอดคล้องเชิงประจักษ์ (fit indices) 

  - $R^2, adj-R^2$
  - Deviance-test
  - Partial F-test
  - AIC, BIC

การเปรียบเทียบความสอดคล้องของโมเดลบน training data มีแนวโน้มที่ผู้วิเคราะห์จะพบกับปัญหา overfitting วิธีการแก้ปัญหาหนึ่งคือใช้การทำ cross-validation


![](img/algo-model-compare.png)


## Interaction Terms (5) {.smaller}


- **Regularized/Penalized Regression**

  - lasso regression

  - ridge regression

  - elastic-net regression

<div class="caption3">M. Kuhn and Johnson (2020)</div>


## Workflow (1) {.smaller}

![](https://www.tmwr.org/premade/proper-workflow.svg){width="70%"}


## Workflow (2) {.smaller}

- รวมขั้นตอนการ preprocessing กับ การสร้างโมเดลไว้ในที่เดียว

- ช่วยให้การสร้างโมเดลสามารถทำซ้ำได้ง่ายขึ้น

```{r eval = F}
library(tidymodels)

# Model specification
model_spec <- logistic_reg() %>% 
  set_engine("glm")

# Recipe
recipe_spec <- recipe(Class ~ ., data = training_data) %>%
  step_normalize(all_numeric_predictors())

# สร้าง workflow
workflow <- workflow() %>%
  add_recipe(recipe_spec) %>%
  add_model(model_spec)

## model tuning
tuned_results <- workflow %>%
  tune_grid(
    resamples = vfold_cv(training_data, v = 5),
    grid = 10
  )

## show best
tuned_results %>%
  show_best(metric = "accuracy", n = 5)

## select best
best_params <- tuned_results %>%
  select_best(metric = "accuracy")

## finalizing
final_wf <- workflow %>%
  finalize_workflow(best_params)

## fitting the final model
final_fit <- final_wf %>%
  fit(data = training_data)

final_fit <- final_wf %>%
  last_fit(split)
```


## กิจกรรม {.smaller}

สร้าง workflow เพื่อ train regression model จากชุดข้อมูล `learningdata.csv`

```{r eval = T}
library(tidyverse)
library(tidymodels)
data <- read_csv("/Users/choat/Downloads/learningdata.csv")
glimpse(data)

## รวมคะแนนตัวแปร
data <- data |> 
  mutate(
         acad_axiety = rowMeans(across(starts_with("acad.axiety")),na.rm=T),
         teach_sup = rowMeans(across(starts_with("teach")),na.rm=T),
         lrn_environ = rowMeans(across(starts_with("lrn.environ")), na.rm=T)
  ) |> 
select(-starts_with("acad.axiety"), -starts_with("teach.sup"), -starts_with("lrn.environ")) 
```


วัตถุประสงค์ของกิจกรรมคือ train linear regression เพื่อทำนาย ach ของนักเรียน


```{r results = TRUE}
set.seed(123)
## 1. แบ่งชุดข้อมูลออกเป็น train กับ test set
split <- initial_split(data, prop = 0.8, strata = "ach", breaks = 5)
train_data <- training(split)
test_data <- testing(split)
```

<br>

<center>

```{r fig.width = 8, fig.height = 4}
## ตรวจสอบว่า dsitribution ของตัวแปรตามเหมือนกันมั้ยใน train กับ test
train_data |> 
    mutate(dataset = "train_data") |> 
    bind_rows(test_data |> mutate(dataset = "test_data")) |> 
    ggplot(aes(x = ach, col = dataset))+
    geom_density()
```

</center>

<br>

```{r}
## 2. กำหนด algorithm ที่จะใช้ในการ train regression model
lm_mod <- linear_reg() |> 
    set_engine("lm") |> 
    set_mode("regression")

glmnet_mod <- linear_reg(penalty = tune(), mixture = 1) |> 
    set_engine("glmnet") |> 
    set_mode("regression")

## 3. preprocessing model
lm_rec <- recipe(ach ~ ., data = train_data) |> 
    update_role(student.id, new_role = "id") |> 
    step_mutate(
        across(c(ends_with("ordinal"), "satisfac"), ~factor(.))
        )


glmnet_rec <- recipe(ach ~ ., data = train_data) |> 
    update_role(student.id, new_role = "id") |> 
    step_mutate(
        across(c(ends_with("ordinal"), "satisfac"), ~factor(.))
        ) |> 
    step_interact(terms = ~ all_predictors():all_predictors())  |> 
    step_dummy(all_nominal_predictors())
```

<br>

```{r}
## 4. สร้าง workflow จำนวน 2 ตัว
lm_wf <- workflow() |> 
    add_recipe(lm_rec) |> 
    add_model(lm_mod)

glmnet_wf <- workflow() |> 
    add_recipe(glmnet_rec) |> 
    add_model(glmnet_mod)
```


<br>

```{r}
## 5. Train model
### --- 1. Train linear reg (lm)
lm_fit <- lm_wf |> 
            fit(data = train_data)

### --- 2. Train glmnet
## cv dataset
folds <- vfold_cv(data = train_data, v=5, repeats =3)
## เลือกช่วงชอง penalty เป็น default ก่อน ใช้ grid แบบ regular จำนวน 50 grids

###-- ส่วนนี้เตรียมทำ parallel computing
library(future)
## ใช้ 10 cores เพื่อประมวลผลแบบ parallel 
plan(multisession, workers = 10) ### -- ถ้าจำไม่ผิด windows จะต้องใช้ multicores 
penalty_grid = grid_regular(penalty(), levels=50)
### tune glmnet
glmnet_tuned_results <- glmnet_wf |> 
    tune_grid(
        resamples = folds,
        grid = penalty_grid,
        control = control_grid(save_pred = TRUE)
    )
```


<br>

```{r}
library(patchwork)
## 6. ประเมินประสิทธิภาพของโมเดลเพื่อกำหนด hyperparaeter ที่ดีที่สุด
### เราดูเฉพาะ glmnet เพราะเป็นโมเดลเดียวที่มีการ tune hyperparameter
p1<- glmnet_tuned_results |> 
    collect_metrics() |> 
    filter(.metric == "rmse") |> 
    arrange(mean) |> 
    ggplot(aes(x = penalty , y= mean))+
    geom_line()+
    geom_point()+
    geom_errorbar(aes(ymin = mean-1.96*std_err, ymax = mean+1.96*std_err))+
    ylab("RMSE")

p2<-glmnet_tuned_results |> 
    collect_metrics() |> 
    filter(.metric == "rsq") |> 
    arrange(mean) |> 
    ggplot(aes(x = penalty , y= mean))+
    geom_line()+
    geom_point()+
    geom_errorbar(aes(ymin = mean-1.96*std_err, ymax = mean+1.96*std_err))+
    ylab("R-square")

p1/p2
```

ผลการ tune hyperparameter พบว่าเราน่าจะได้โมเดลที่ดีที่สุด ณ penalty ประมาณเกือบ 0.25 โดยมีค่า RMSE และ R2 ประมาณ 8 กับ 70% ตามลำดับ

<br>

```{r}
#### --- เลือก best ของ glmnet
best_glmnet <- glmnet_tuned_results |> 
    select_best(metric = "rmse")
### finalized workflow
##### -- เอา training data ทั้งหมดมา train แต่ละโมเดลใหม่ และเปรียบเทียบประสิทธิภาพบน test_data ทั้งหมดนี่สามารถทำได้พร้อมกันผ่าน `last_fit()`
### --- lastfit lm
last_lm <- lm_wf |> 
    last_fit(split)
### ----- lastfit glmnet
lm_perform <- last_lm |> collect_metrics()
last_glmnet <- glmnet_wf |> 
   finalize_workflow(best_glmnet) |> 
   last_fit(split)
```

```{r}
## performance in test data
glmnet_perform <- last_glmnet |> collect_metrics()
last_glmnet |> collect_predictions() |> 
    ggplot(aes(x= ach, y=.pred))+
    geom_point()
lm_perform |> 
    mutate(model = "lm") |> 
    bind_rows(glmnet_perform |> mutate(model = "glmnet")) |> 
    ggplot(aes(x=model, y=.estimate))+
    geom_col(aes(fill = model))+
    geom_text(aes(label = round(.estimate,4)), col = "white", vjust = 2)+
    facet_wrap(~.metric ,nrow = 2, scales = "free_y")+
    scale_fill_manual(values = c("steelblue","maroon"))+
    ylab("\n Estimated Performance \n")
```


## Feature Extraction {.smaller}

- create new features from the predictors that capture the information in the broader set as a whole.

  - Principal Component Regression (PCR)

  - Partial Least Squares Regression (PLS)

  - Kernel PCA (KPCA)

  - Isometric Mapping (ISOMAP)

  - uniform manifold approximation and projection (UMAP)


## Feature Extraction: PCR & PLS {.smaller}

  ![](img/PCR.png){width="90%"}

  ![](img/PLS.png){width="90%"}

  <div class="caption3">Boehmke, & Greenwell, 2020</div>


## `step_pca()` ใน tidymodels {.smaller}

`step_pca()` รวมทั้ง technique อื่น ๆ ในกลุ่มนี้สามารถใช้ได้ทั้งในงานแบบ supervised และ unsupervied learning 

**Unsupervised Task**

ลองทำ unsupervised เพื่อทำความเข้าใจตัวแปรในชุดข้อมูล `learningdata_csv`  โดยจะใช้ training data จากกิจกรรมก่อนหน้า

<div style="font-size: 80%;">


```{r}
glimpse(train_data)
```

<br>

```{r}
pca_trained <- recipe(ach ~ ., data = train_data) |> 
  update_role(student.id, new_role = "id") |> 
  step_mutate(
        across(c(ends_with("ordinal"), "satisfac"), ~factor(.))
        ) |> 
  step_normalize(all_numeric_predictors()) |> 
  step_pca(all_numeric_predictors(), threshold = 0.7) |> 
  prep()

## create scree plot to determine PCA
pca_trained |> 
  tidy(3, type = "variance") |> 
  filter(terms == "variance") |> 
  ggplot(aes(x=component, y=value))+
  geom_col()+
  ggtitle("scree plot")+
  scale_x_continuous(breaks = 1:10)
## create scree plot with cumulative percent variance
pca_trained |> 
  tidy(3, type = "variance") |> 
  filter(str_detect(terms, "percent")) |> 
  ggplot(aes(x=component, y=value,col = terms))+
  geom_line()+
  geom_point()+
  geom_hline(yintercept = 70, linetype = 2)+ ## สมมุติกำหนด cut-off (threshold) เท่ากับ 70%
  theme(legend.position = "top")+
  labs(col = "")+
  scale_x_continuous(breaks = 1:10)
```

จาก cut-off ที่กำหนดแสดงว่าควรมีองค์ประกอบหลัก 4 องค์ประกอบ เราสามารถตีความความหมายขององค์ประกอบหลักได้จาก loading ระหว่างตัวแปรต้นฉบับกับองค์ประกอบหลักของแต่ละองค์ประกอบ

```{r}
## create loading plot
pca_trained |> 
  tidy(3, type = "coef") |>
  filter(component %in% paste0("PC",1:4)) |> 
  ggplot(aes(x=value, y=terms))+
  geom_col(aes(fill = value))+
  geom_vline(xintercept = c(-0.3,0.3), linetype = 2)+
  facet_wrap(~component) +
  scale_fill_gradient2(low = "maroon", mid = "white", high = "steelblue")
```

องค์ประกอบทั้ง 4 ควรมีความหมายว่าอย่างไร?

หากเราพอใจความหมายขององค์ประกอบทั้ง 4 แล้ว เราสามารถสร้างคะแนนองค์ประกอบได้ง่าย ๆ โดยใช้ `juice()` หรือ `bake()` ขึ้นอยู่กับว่าเราจะสร้างคะแนนบน train หรือชุดข้อมูลอื่น ๆ 

ลองพิจารณาชุดข้อมูลด้านล่างจะเห็นว่าเมื่อ `juice()` หรือ `bake()` ตัวแปรเชิงปริมาณที่นำไปสร้าง scale องค์ประกอบจะหายไปหมด แทนที่ด้วยคะแนนองค์ประกอบ 4 ตัวที่เราเลือกมาแทน

```{r}
pca_trained |> 
  juice() |> 
  glimpse(60)
```


```{r}
pca_trained |> 
  juice() |> 
  ggplot(aes(x=PC1, y=PC2)) +
  geom_point(aes(col = ach),alpha = 0.9)+
  scale_color_gradient2(low = "maroon",mid = "white", high = "steelblue",
                        midpoint = 50)
```

</div>

**Supervised Task**

ใช้ syntax ที่ส่งให้ในคาบ




## Feature Extraction: Kernal PCA {.smaller}

1. แปลงข้อมูล: ใช้ kernel function เพื่อแปลงข้อมูลจากพื้นที่เดิมที่อาจมีความซับซ้อนไปสู่พื้นที่มิติสูงกว่า

2. ลดมิติและจำแนกข้อมูล: ดำเนินการ PCA ในพื้นที่ใหม่ที่แปลงแล้วเพื่อหาตัวแปรใหม่ (principal components) ที่สามารถอธิบายความแปรปรวนและจำแนกข้อมูลได้อย่างมีประสิทธิภาพ

![](img/1_mCwnu5kXot6buL7jeIafqQ.webp){fig-align="center"}


![](img/1_vqQK50YMY2kfPVvnS-3Iow.webp)

<div class="caption3">https://medium.com/@avicsebooks/part17-unsupervised-machine-learning-kernel-principal-component-analysis-and-multidimensional-5c9eec755bd3</div>


<div class="caption3">https://medium.com/@zxr.nju/what-is-the-kernel-trick-why-is-it-important-98a98db0961d</div>


![](img/0_pJ5MMOJIxuzCoCsQ.png){fig-align="center"}

<div class="caption3">https://medium.com/@zxr.nju/what-is-the-kernel-trick-why-is-it-important-98a98db0961d</div>





## Subsampling for Imbalance Class Problem {.smaller}

- ในปัญหา classification ปัญหาหนึ่งที่ผู้วิเคราะห์มักพบคือ imbalance class ซึ่งจะเกิดขึ้นเมื่อสัดส่วนของ category ในตัวแปรตามมีความแตกต่างกันอย่างมาก

- ปัญหาดังกล่าวจะทำให้อัลกอริทึมการเรียนรู้ มีต้นแบบการเรียนรู้จากกลุ่มที่เป็น majority มากเกินไปจนผลการเรียนรู้ที่ได้มีความลำเอียง

การแก้ปัญหาดังกล่าวสามารถทำได้ โดย

- **Downsampling** -- สุ่มข้อมูลออกจา majority class จนกระทั่งสมดุลกับ minority class

  - Random majority under-sampling with replacement	: `step_downsample()`

  - NearMiss-1: `step_nearmiss()`

  - Extraction of majority-minority Tomek links: `step_tomek()`


- **Upsampling** -- สร้างข้อมูลสังเคราะห์ (synthetic data) สำหรับ minority class เพื่อให้มีจำนวนข้อมูลมากขึ้นจนสมดุลกับ majority class

  - Random minority over-sampling with replacement: `step_upsample()`

  - Synthetic Minority Over-sampling Technique (SMOTE): `step_smote()`

  - Borderline SMOTE (B-SMOTE): `step_bsmote()`

  - Adaptive synthetic sampling approach for imbalanced learning (ADASYN): `step_adasyn()`

  - Generation of synthetic data by Randomly Over Sampling Examples (ROSE): `step_rose()`


- **Hybrid sampling** -- downsampling ใน majority class และ upsampling ใน minority class

  - SMOTE + Tomek

  - B-SMOTE + Tomek

  - ROSE + downsample

<div class="caption3">https://github.com/tidymodels/themis</div>


## SMOTE

![](img/the-basic-principle-of-the-synthetic-minority-oversample-technique-smote-algorithm-5452514.png.webp){fig-align="center"}

<div class="caption2">SMOTE Concept: https://rikunert.com/smote_explained></div>


![](img/Specific-groups-of-imbalanced-data-in-the-Borderline-SMOTE.png){fig-align="center"}

<div class="caption2">BSMOTE Concept: https://www.researchgate.net/figure/Specific-groups-of-imbalanced-data-in-the-Borderline-SMOTE_fig2_365584195</div>

## Tomek link {.smaller}

ลบ majority class ที่อยู่ใกล้กับ minority class มากที่สุดออก

1. ค้นหาคู่ข้อมูลที่เป็น tomek link

2. ลบข้อมูล

3. ประเมินผล


![](img/download.png){fig-align="center"}

<div class="caption2">https://www.kaggle.com/code/marcinrutecki/smote-and-tomek-links-for-imbalanced-data</div>



## Variable Transformation {.smaller}

ใน library-recipe มี `step_mutate()` ที่ทำงานเหมือนกับ `mutate()` ใน dplyr

**original**

```{r eval = F, echo = T}
data |> 
  mutate(
         acad_axiety = rowMeans(across(starts_with("acad.axiety")),na.rm=T),
         teach_sup = rowMeans(across(starts_with("teach")),na.rm=T),
         lrn_environ = rowMeans(across(starts_with("lrn.environ")), na.rm=T)
  )
```


**recipe**

```{r eval= F}
recipe(ach ~ . , data = data) |> 
step_mutate(
        acad_axiety = rowMeans(across(starts_with("acad.axiety")),na.rm=T),
         teach_sup = rowMeans(across(starts_with("teach")),na.rm=T),
         lrn_environ = rowMeans(across(starts_with("lrn.environ")), na.rm=T)
)
```
