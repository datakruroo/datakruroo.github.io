---
title: "Single Learning (cont.)"
format: html
toc: true
message: false
warning: false
editor: visual
---



# Linear Discriminant Analysis (LDA)

-   เป็นหนึ่งในเทคนิคการจำแนกประเภทที่ใช้ในการวิเคราะห์ข้อมูลที่มีลักษณะเป็นเชิงเส้น โดยมีจุดประสงค์เพื่อแยกแยะกลุ่มหรือคลาสของข้อมูลตามคุณลักษณะของข้อมูล (features)

-   หลักพื้นฐานของ LDA คือพยายามหาเส้นแบ่งข้อมูล ที่ทำให้ความแตกต่างของกลุ่มข้อมูลมากที่สุด ภายใต้ข้อตกลงเบื้องต้นว่าข้อมูลในแต่ละ class มีการแจกแจงแบบปกติที่มีคุณสมบัติ homogeneity of covariance matrices

-   การหาเส้นแบ่งข้อมูลด้วย LDA จะใช้หลักการลดมิติข้อมูล (เหมือน PCA) แต่แตกต่างกันตรงที่พยายามสกัดองค์ประกอบที่ทำให้ distribution ของข้อมูลแตกต่างกันมากที่สุด (maximize the ratio of between-class variance to within-class variance) เรียกสเกลองค์ประกอบที่สร้างขึ้นนี้ว่า discrimination function

-   จากนัั้นจะสร้างจุดแบ่ง class จาก discrimination function ที่ได้ โดยจุดแบ่งนี้จะเป็นเส้นตรงที่ทำให้ค่าเฉลี่ยของ discrimination score ระหว่างสองกลุ่มมีค่าสูงสุด

![](https://sebastianraschka.com/images/blog/2014/linear-discriminant-analysis/lda_1.png){width="90%"}

# Quadratic Discriminant Analysis (QDA) {.smaller}

-   Quadratic Discriminant Analysis (QDA) เป็นรูปแบบหนึ่งของ Discriminant Analysis ที่คล้ายกับ LDA แต่ ไม่สมมติว่าข้อมูลในแต่ละคลาสมี covariance matrix ที่เหมือนกัน ดังนั้น QDA จะสร้างเส้นแบ่งที่มีลักษณะเป็น quadratic (ไม่เชิงเส้น) เพื่อจำแนกข้อมูลระหว่างกลุ่มต่าง ๆ

-   QDA ยังสมมุติการแจกแจงแบบปกติของข้อมูลในแต่ละ class อยู่ แต่ไม่สมมุติว่า covariance matrix ของข้อมูลในแต่ละ class เหมือนกันแล้ว

-   เมื่อการแจกแจงมีการกระจายที่แตกต่างกันเส้นแบ่งระหว่าง class จึงมีลักษณะเป็นเส้นโค้ง

![](https://mathformachines.com/images/quadratic-linear.png)

-   QDA จะคำนวณ discriminant score สำหรับข้อมูลใหม่ในแต่ละคลาส โดยพิจารณาจาก covariance matrix และค่าเฉลี่ยของข้อมูลในแต่ละคลาส

-   เส้นแบ่งจะเกิดขึ้นเมื่อ discriminant score ของสองคลาสมีค่าเท่ากัน ซึ่งหมายถึงข้อมูลมีโอกาสที่จะอยู่ในทั้งสองคลาสเท่ากัน

# Example



```{r}
library(tidyverse)
library(tidymodels)
data <- read_csv("/Users/choat/Library/CloudStorage/OneDrive-ChulalongkornUniversity/Documents/เอกสารประกอบการสอน/2758615/EDA using R/learning_data.csv")
glimpse(data)
```



# Exploring data using PCA and PLS



```{r}
## compoent loading
data %>% 
  recipe(research_score ~.) %>% 
  update_role(student_id, new_role = "ID") %>%
  step_normalize(all_numeric_predictors()) %>%
  step_rm(gender, department) %>% 
  step_impute_knn(cheat_index) %>% 
  step_pca(all_numeric_predictors()) %>% 
  prep() %>% tidy(4) %>% 
  filter(component %in% paste0("PC",1:4)) %>% 
  ggplot(aes(x=value, y=terms))+
  geom_col(aes(fill = value))+
  facet_wrap(~component)

data %>% 
  recipe(research_score ~.) %>% 
  update_role(student_id, new_role = "ID") %>%
  step_normalize(all_numeric_predictors()) %>%
  step_rm(gender, department) %>% 
  step_impute_knn(cheat_index) %>% 
  step_pls(outcome = "research_score", all_numeric_predictors()) %>% 
  prep() %>% juice() %>% 
  ggplot(aes(x=PLS1, y=PLS2, col=research_score>80))+
  geom_point()+
  geom_vline(xintercept = 0,linetype = 2)+
  xlab("เด็กดีและเก่ง")+
  ylab("เด็กขี้โกง")+
  theme(text = element_text(family = "ChulaCharasNew"))
```

```{r}
new_data <- data |> 
  mutate(research_score = ifelse(research_score>80, 1,0)) %>% 
  mutate(research_score = factor(research_score, levels=c(1,0),
                                 labels=c("success","fail")))
```



## Data Spliting



```{r}
library(tidymodels)
library(MASS)
library(discrim)
set.seed(123)
split <- initial_split(new_data, prop = 0.8, strata = research_score)
train_data <- training(split)
test_data <- testing(split)
```



## Specifing model



```{r}
lda_spec_MASS <- discrim_linear() %>%
  set_engine("MASS") %>%
  set_mode("classification")

lda_spec_mda <- discrim_linear(penalty = tune()) %>%
  set_engine("mda") %>%
  set_mode("classification")

qda_spec_MASS <- discrim_quad() %>%
  set_engine("MASS") %>%
  set_mode("classification")
```



## Recipe



```{r}
train_data %>% count(research_score)
```

```{r}
library(themis)
lda_rec <- recipe(research_score ~. ,data=train_data) %>% 
  update_role(student_id, new_role = "ID") %>% 
  step_rm(gender, department) %>% 
  step_impute_knn(cheat_index) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_smote(research_score)

lda_rec %>% prep() %>% juice() %>% count(research_score)
```



## create workflowset



```{r}
lda_wfset <- 
   workflow_set(
      preproc = list(base_rec_lda = lda_rec), 
      models = list(lda_MASS = lda_spec_MASS, 
                    lda_mda = lda_spec_mda, 
                    qda_MASS = qda_spec_MASS),
      cross = FALSE
   )

lda_wfset %>% 
extract_workflow(id = "base_rec_lda_lda_mda")
```



## Tune hyperparameter



```{r}
library(future)
plan(multisession, workers = 10)
tidymodels_prefer()

tuned_results_wfset <- lda_wfset %>% 
  workflow_map(
      seed = 123,
      resamples = vfold_cv(train_data, v = 5, repeats = 3, strata = "research_score"),
      grid = 50,
     # metric = metric_set(roc_auc, f_meas, sens, spec, precision),
      control = control_grid(save_pred = TRUE, parallel_over = "everything")
    )

## -- explore lda

tuned_results_wfset %>% 
  extract_workflow_set_result(id = "base_rec_lda_lda_mda") %>% 
  collect_metrics() %>% 
  filter(.metric == "roc_auc") %>%
  arrange(desc(mean))


  
tuned_results_wfset %>% 
  extract_workflow_set_result(id = "base_rec_lda_lda_mda") %>% 
  collect_predictions() %>% 
  filter(.config == "Preprocessor1_Model01") %>% 
  sens(truth = research_score, estimate = .pred_class)

tuned_results_wfset %>% 
  extract_workflow_set_result(id = "base_rec_lda_lda_mda") %>% 
  collect_predictions() %>% 
  filter(.config == "Preprocessor1_Model01") %>% 
  spec(truth = research_score, estimate = .pred_class)


tuned_results_wfset %>% 
  extract_workflow_set_result(id = "base_rec_lda_lda_mda") %>% 
  collect_predictions() %>% 
  filter(.config == "Preprocessor1_Model01") %>% 
  precision(truth = research_score, estimate = .pred_class)

tuned_results_wfset %>% 
  extract_workflow_set_result(id = "base_rec_lda_lda_mda") %>% 
  collect_predictions() %>% 
  filter(.config == "Preprocessor1_Model01") %>% 
  conf_mat(truth = research_score, estimate = .pred_class)
```

```{r}
### explore qda

tuned_results_wfset %>% 
  extract_workflow_set_result(id = "base_rec_lda_qda_MASS") %>% 
  collect_metrics()


tuned_results_wfset %>% 
  extract_workflow_set_result(id = "base_rec_lda_qda_MASS") %>% 
  collect_predictions() %>% 
  sens(truth = research_score, estimate = .pred_class)

tuned_results_wfset %>% 
  extract_workflow_set_result(id = "base_rec_lda_qda_MASS") %>% 
  collect_predictions() %>% 
  spec(truth = research_score, estimate = .pred_class)


```



# Support Vector Machine (SVM)

การจำแนกข้อมูลแบบ SVM ใช้หลักการสร้าง เส้นแบ่งแยก (hyperplane) ที่สามารถแยกข้อมูลออกเป็นสองกลุ่มได้อย่างเหมาะสมมากที่สุด

การสร้างเส้นแบ่งดังกล่าวเป็นสิ่งที่โมเดลการเรียนรู้ต่าง ๆ ก็ทำเหมือนกัน ดังรูปด้านขวา จะเห็นเส้นแบ่งที่ดีที่สุดจากแต่ละอัลกอริทึม

![](img/HMC.png)

support vector machine มีหลักการเบื้องต้นคล้ายกับ classifier แบบ linear อย่างไรก็ตามการหาเส้นแบ่งของ SVM จะพิจารณาจาก support vector ที่เป็นข้อมูลที่อยู่ใกล้ขอบเขตการจำแนกข้อมูลมากที่สุดด้วย (มี contraint เพิ่มเติม) กล่าวคือ SVM จะพยายามหาเส้นแบ่งที่ทำให้ระยะห่างระหว่าง support vector กับเส้นแบ่งมีค่ามากที่สุด ดังรูป

![](img/SVM1.png){width="60%"}

การจำแนกข้อมูลด้วยอัลกอริทึมตามหลักข้างต้นจะเรียกว่า hard margin classification อย่างไรก็ตามอัลกอริทึมประเภทนี้มีข้อจำกัดในบางกรณี เช่น

-   มีค่าผิดปกติในข้อมูล

![](img/outlier.png){width="60%"}

การแก้ปัญหาดังกล่าวคือการปรับให้โมเดลมีความยืดหยุ่นมากขึ้น โดยใช้ soft margin classification ซึ่งจะให้ความผิดพลาดได้มากขึ้น แต่ก็จะลดความเสี่ยงที่เกิดจากข้อมูลผิดปกติ แนวคิดดังกล่าวคือการเพิ่ม hyperparameter อีกตัวหนึ่งขึ้นมาเขียนแทนด้วย C (penalty term) ที่ใช้ควบคุมระยะห่างระหว่าง hyperplan กับข้อมูลที่ใกล้ที่สุดจากทั้งสองกลุ่ม (support vector)

ลองพิจารณารูปด้านล่างจะเห็นว่าการปรับค่า C ที่เพิ่มมากขึ้นส่งผลอย่างไรต่อ classifier ของเรา

![](img/SMC.png)

-   ขอบเขตจำแนกที่ไม่ใช่เส้นตรง

หลายกรณีความสัมพันธ์ระหว่างตัวแปรอาจมีความซับซ้อนทำให้เส้นแบ่งที่เป็นเส้นตรงไม่สามารถจำแนกข้อมูลได้ดี กรณีเช่นนี้ linear classifier ทั้งหลายอาจจะให้ประสิทธิภาพที่ต่ำ

SVM แก้ปัญหานี้ด้วยการใช้ kernel trick ซึ่งเป็นการแปลงข้อมูลเป็นมิติสูงขึ้นเพื่อที่จะสามารถใช้เส้นตรง (hyperplane) แบ่งข้อมูลในมิติสูงอย่างมีประสิทธิภาพ

![](img/nonlinearSVM.png)

-   Linear Kernel

-   Polynomial Kernel

-   Radial Basis Function (RBF) Kernel (Gaussian Kernel)

-   Sigmoid Kernel

[parsnip](https://www.tidymodels.org/find/parsnip/)

## Example

## Specifing model



```{r}
svm_linear_spec <- svm_linear(cost = tune()) %>%
  set_engine("kernlab") %>%
  set_mode("classification")

svm_poly_spec <- svm_poly(degree = 2, cost = tune(), scale_factor = tune()) %>%
  set_engine("kernlab") %>%
  set_mode("classification")

svm_rbf_spec <- svm_rbf(rbf_sigma = tune(), cost = tune()) %>%
  set_engine("kernlab") %>%
  set_mode("classification")
```



## Recipe



```{r}
library(themis)
svm_rec <- recipe(research_score ~. ,data=train_data) %>% 
  update_role(student_id, new_role = "ID") %>% 
  step_rm(gender, department) %>% 
  step_impute_knn(cheat_index) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_adasyn(research_score)

svm_rec %>% prep() %>% juice() %>% count(research_score)
```



## create workflowset



```{r}
wfset_all <- 
   workflow_set(
      preproc = list(smote_rec = lda_rec , adasyn_rec = svm_rec),
      models = list(lda_MASS = lda_spec_MASS,
                    svm_linear = svm_linear_spec, 
                    svm_poly = svm_poly_spec, 
                    svm_rbf = svm_rbf_spec),
      cross = TRUE
   )
wfset_all
```

```{r}
library(future)
plan(multisession, workers = 10)
all_tuned_results_wfset <- wfset_all %>% 
  workflow_map(
      seed = 123,
      resamples = vfold_cv(train_data, v = 5, repeats = 3, strata = "research_score"),
      grid = 50,
      metrics = metric_set(roc_auc, f_meas, sens, spec, precision),
      control = control_grid(save_pred = TRUE, parallel_over = "everything")
    )
```

```{r}
## สามารถใช้ collect_metrics() กับ workflowset ได้เลย
all_tuned_results_wfset %>% collect_metrics() %>% 
  arrange(.config)
```



ดังนั้นเราสามารถสร้าง visualization เพื่อเปรียบเทียบประสิทธิภาพได้เลย



```{r}
all_tuned_results_wfset %>% collect_metrics() %>% 
  filter(.metric == "f_meas") %>% 
  filter(str_detect(wflow_id,"svm")) %>% 
  ggplot(aes(x = reorder(wflow_id, mean), y=mean, col = wflow_id))+
  geom_point()+
  geom_errorbar(aes(ymin = mean - std_err, ymax = mean + std_err))+
  theme_light()+
  coord_flip()
```

```{r}
all_tuned_results_wfset %>% collect_metrics() %>% 
  filter(.metric == "f_meas") %>% 
  filter(str_detect(wflow_id,"svm")) %>% 
  ggplot(aes(x = reorder(wflow_id, mean), y=mean, col = wflow_id))+
  geom_boxplot()+
  theme_light()+
  coord_flip()
```



## Extract workflow results from workflowset



```{r}
all_tuned_results_wfset %>% 
  extract_workflow_set_result(id = "smote_rec_svm_poly") %>% 
  collect_metrics() %>% 
  filter(.metric == "roc_auc") %>%
  arrange(desc(mean))

all_tuned_results_wfset %>% 
  extract_workflow_set_result(id = "adasyn_rec_svm_poly") %>% 
  collect_metrics() %>% 
  filter(.metric == "roc_auc") %>%
  arrange(desc(mean))


all_tuned_results_wfset %>% 
  extract_workflow_set_result(id = "smote_rec_svm_rbf") %>% 
  collect_metrics() %>% 
  filter(.metric == "roc_auc") %>%
  arrange(desc(mean))
```

```{r}
all_tuned_results_wfset %>% 
  extract_workflow_set_result(id = "adasyn_rec_svm_poly") %>% 
  collect_predictions() %>% 
  filter(.config == "Preprocessor1_Model40") %>% 
  conf_mat(truth = research_score, estimate = .pred_class)


all_tuned_results_wfset %>% 
  extract_workflow_set_result(id = "adasyn_rec_svm_poly") %>% 
  collect_predictions() %>% 
  filter(.config == "Preprocessor1_Model40") %>% 
  sens(truth = research_score, estimate = .pred_class)

all_tuned_results_wfset %>% 
  extract_workflow_set_result(id = "adasyn_rec_svm_poly") %>% 
  collect_predictions() %>% 
  filter(.config == "Preprocessor1_Model40") %>% 
  precision(truth = research_score, estimate = .pred_class)

all_tuned_results_wfset %>% 
  extract_workflow_set_result(id = "adasyn_rec_svm_poly") %>% 
  collect_predictions() %>% 
  filter(.config == "Preprocessor1_Model40") %>% 
  spec(truth = research_score, estimate = .pred_class)
```

