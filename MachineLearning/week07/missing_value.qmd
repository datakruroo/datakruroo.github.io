---
title: "Missing Value Analysis"
format: html
toc: true
message: false
warning: false
editor: visual
---

## Introduction

ที่ผ่านมาเรายังทำงานโดยไม่ได้เจอกับปัญหา missing value เท่าไหร่นัก อย่างไรก็ตามในสถานการณ์จริงปัญหา missing value เป็นปัญหาใหญ่เหมือนกัน และสามารถสร้างผลกระทบเชิงลบต่อโมเดลการวิเคราะห์ได้อย่างมาก ซึ่งส่งผลทั้งความตรงภายในและความตรงภายนอกของผลการวิเตราะห์

การสูญหายของข้อมูลเป็นไปได้จากสาเหตุที่หลากหลาย ขึ้นอยู่กับบริบทหรือวิธีการเก็บรวบรวมข้อมูลที่ผู้วิจัยใช้ด้วย

-   ใน survey ผู้ตอบอาจจะลืมตอบบาง item โดยบังเอิญ ไม่ตอบเพราะไม่รู้หรือไม่สนใจ ไม่ตอบเพราะไม่สะดวก หรือไม่ตอบเพราะไม่มีคำตอบที่ตรงกับตัวเลือกที่ต้องการ

-   การเก็บรวบรวมข้อมูลผ่านระบบเช่น LMS บางตัวชี้วัดอาจมีข้อมูลขาดหายเพราะพฤติกรรมบางอย่างของนักเรียน เช่น ต้องการวัดระยะเวลาที่นักเรียนแต่ละคนใช้ในการทำ quiz หรือการบ้านที่มอบหมาย แต่นักเรียนไม่เข้ามาทำการบ้าน คะแนนค่านี้ก็จะเป็นค่าสูญหาย

-   การเก็บรวบรวมข้อมูลระยะยาวที่จะต้องเก็บข้อมูลจากหน่วยข้อมูลเดียวกันหลาย ๆ ครั้ง หากระหว่างทางมีหน่วยข้อมูลออกจากระบบก็เกิดข้อมูลขาดหายได้เช่นกัน

-   การเก็บข้อมูลจากฐานข้อมูลของหน่วยงานต่าง ๆ เช่น สพฐ. สทศ. สมศ. รวมทั้งหน่วยงานภาครัฐอื่น ๆ แล้วนำมารวมกันเพื่อดำเนินการวิเคราะห์ ก็มีโอกาสที่บางหน่วยข้อมูลขาดหายไปเนื่องจากความแตกต่างของการเก็บข้อมูลในแต่ละฐาน

-   นอกจากนี้ยังมีสาเหตุอื่น ๆ อีกมากมาย

อัลกอริทึมและโมเดลการวิเคราะห์ข้อมูลส่วนใหญ่มักมีข้อสมมุตินึงที่ผู้สอนส่วนใหญ่ก็มักไม่ได้กล่าวถึงคือ ข้อมูลที่นำมาวิเคราะห์จะต้องเป็นข้อมูลที่ไม่มีค่าสูญหาย (เรียกว่า complete data) อย่างไรก็ตามหากมองย้อนตอนที่เราวิเคราะห์ข้อมูลจริง ๆ มีโอกาสน้อยมากที่เราจะพบกับ complete data ดังกล่าว

กระบวนการปกติที่เรามักใช้ในการจัดการข้อมูลสูญหายคือ

1.  ลบหน่วยข้อมูลที่มีค่าสูญหายออกไปจากการวิเคราะห์ (listwise deletion)

2.  แทนค่าสูญหายด้วยค่าที่เหมาะสม

ทั้งสองวิธีการผลลัพธ์สุดท้ายที่ได้คือข้อมูลสมบูรณ์เหมือนกัน (แต่ ...)

บทเรียนวันนี้เราจะพูดถึงวิธีการที่ใช้แก้ปัญหาค่าสูญหาย โดยจะพยายามกล่าวถึงหลาย ๆ วิธีทั้งวิธีการที่ผู้วิเคราะห์ทั่วไปมักนิยมใช้กัน และวิธีการสมัยใหม่ที่เหมาะสมกับการวิเคราะห์แต่ละวัตถุประสงค์

## ขั้นตอนการวิเคราะห์ข้อมูลที่มีค่าสูญหาย

การวิเคราะห์ข้อมูลเมื่อมีค่าสูญหายนั้นมีแนวทางหรือวิธีดำเนินงานที่หลากหลายขึ้นอยู่กับว่าเราอ้างอิงสำนักไหน นักสถิติหรือนักวิทยาการข้อมูลคนไหน กลุ่มไหน

-   Little and Rubin (2002) \<-- classic

-   Allison (2001)

-   [Khun, & Johnson (2019)](http://www.feat.engineering/)

อย่างไรก็ตามแนวทางโดยทั่วไปที่เหมือนกันประกอบด้วย

1.  การสำรวจและระบุค่าสูญหาย

2.  การวิเคราะห์รูปแบบหรือกลไกของค่าสูญหาย

3.  การจัดการค่าสูญหาย

## กลไกการเกิดค่าสูญหาย

สำนัก classic คือ Little และ Rubin นำเสนอ framework ของค่าสูญหายที่ปัจจุบันก็มีการใช้อย่างแพร่หลายมาก ๆ โดยทั้งสองจำแนกประเภทของค่าสูญหายออกเป็น 3 ประเภท การอธิบายลักษณะการสูญหายทั้ง 3 นี้ใช้โมเดลความน่าจะเป็น

### Missing Completely at Random (MCAR)

กล่าวคือ ถ้าการมีอยู่ของข้อมูลที่ขาดหายไปในตัวแปรหนึ่ง ๆ ไม่มีความสัมพันธ์กับตัวแปรอื่น ๆ ที่สังเกตเห็นหรือไม่ได้สังเกตเห็น ข้อมูลนั้นจะถือว่าขาดหายไปแบบสุ่มโดยสมบูรณ์ (Missing Completely At Random - MCAR)

กำหนดให้ $m{ij}$ เป็นตัวแปร dummy แสดงการสูญหายของหน่วยข้อมูลที่ i ในตัวแปรที่ j ถ้ามีค่าเท่ากับ 1 คือเป็นค่าสูญหาย และ $X_{obs}$ คือข้อมูลที่ผู้วิเคราะห์สามารถสังเกตได้ในชุดข้อมูล ส่วน $X_{mis}$ คือข้อมูลที่สูญหาย

การสูญหายแบบ MCAR สามารถเขียนอธิบายได้ดังนี้

$$
p(m_{ij} = 1 | X_{obs}, X_{mis}) = p
$$

การ simulation ด้านล่างแสดงกลไกการเกิดค่าสูญหายแบบ MCAR ได้อย่างชัดเจน

```{r}
library(tidyverse)
library(naniar)
data <- read_csv("/Users/choat/Downloads/exam.csv")
glimpse(data)
### การ screen หยาบที่สุดเลยว่าใช้ชุขด้อมูลมีค่าสูญหายอย่างน้อย 1 ค่ามั้ย
any_na(data)
```

สมมุติว่ามีการสูญหายแบบ MCAR ขึ้นบนตัวแปร `ach` ร้อยละ 20 นั่นเทียบเท่ากับการสุ่มตัวอย่างแบบ SRS ออกจาก vector ของ `ach` ในสัดส่วน 0.2 ดังนี้

```{r fig.width = 8, fig.height=3}
library(patchwork)
set.seed(123)
data <- data %>% 
  mutate(ach_mcar = ifelse(runif(387,0,1)<0.2, NA, ach))
p1<-data %>% 
  pivot_longer(cols=starts_with("ach")) %>% 
  ggplot(aes(x=value))+
  geom_histogram(aes(fill = name))

p2<-data %>% 
  pivot_longer(cols=starts_with("ach")) %>% 
  ggplot(aes(x = value, y=name))+
  geom_boxplot(aes(fill = name))

p1+p2
```

```{r}
data %>% 
  dplyr::select(ach, ach_mcar) %>% 
  summary()
```

การสูญหายแบบ MCAR ไม่ได้ทำให้เกิด bias ในการวิเคราะห์ แต่อาจมีผลกับ precision ของการวิเคราะห์ (ทำไม?)

ค่าคลาดเคลื่อนมาตรฐาน (standard error) จะมีส่วนประกอบในคำนวณค่ามีการเอาขนาดตัวอย่างไปหาร ยกตัวอย่างเช่น ค่าคลาดเคลื่อนมาตรฐานของค่าเฉลี่ยตัวอย่าง

$$
SE(\bar{X}) = \frac{SD}{\sqrt{n}}
$$

```{r}
data %>% 
  ggplot(aes(x=learning_performance))+
  geom_point(aes(y=ach),alpha=0.1)+
  geom_point(data = data %>% filter(is.na(ach_mcar)==T), 
             aes(y=ach), col="maroon", shape = 2)+
  theme_light()+
  theme(panel.grid = element_blank())

data %>% 
  select(learning_performance, ach, ach_mcar) %>% 
  pivot_longer(cols = c(ach, ach_mcar)) %>% 
  group_by(name) %>% 
  summarise(mean = mean(value, na.rm = T),
            sd = sd(value,na.rm = T),
            median = median(value,na.rm = T),
            cor = cor(learning_performance, value, use = "complete.obs"),
            r2 = cor^2)
```

### Missing at Random (MAR)

กล่าวคือ ถ้าการมีอยู่ของข้อมูลที่ขาดหายไปในตัวแปรหนึ่ง ๆ มีความสัมพันธ์กับตัวแปรอื่น ๆ ที่ผู้วิเคราะห์มีข้อมูลสามารถสังเกตค่าได้ โดยไม่เกี่ยวข้องกับข้อมูลที่สูญหายไปของตัวแปรนั้น ข้อมูลนั้นจะถือว่าขาดหายไปแบบ MAR

$$
p(m_{ij} = 1 | X_{obs}, X_{mis}) = f(X_{obs})
$$

```{r fig.width = 8, fig.height=3}
set.seed(123)
data <- data %>% 
  mutate(ach_mar = case_when(
    learning_performance > 70 | learning_performance < 30 ~ ifelse(runif(387,0,1)<0.4,NA, ach) ,
    .default = ach
  )
  )
p1<-data %>% 
  pivot_longer(cols=starts_with("ach")) %>% 
  ggplot(aes(x=value))+
  geom_histogram(aes(fill = name))

p2<-data %>% 
  pivot_longer(cols=starts_with("ach")) %>% 
  ggplot(aes(x = value, y=name))+
  geom_boxplot(aes(fill = name))

p1+p2
```

```{r}
data %>% 
  ggplot(aes(x=learning_performance))+
  geom_point(aes(y=ach),alpha=0.1)+
  geom_point(data = data %>% filter(is.na(ach_mar)==T), 
             aes(y=ach), col="maroon", shape = 2)+
  theme_light()+
  theme(panel.grid = element_blank())

data %>% 
  select(learning_performance, ach, ach_mcar, ach_mar) %>% 
  pivot_longer(cols = c(ach, ach_mcar, ach_mar)) %>% 
  group_by(name) %>% 
  summarise(mean = mean(value, na.rm = T),
            sd = sd(value,na.rm = T),
            median = median(value,na.rm = T),
            cor = cor(learning_performance, value, use = "complete.obs"),
            r2 = cor^2)
```

### Missing Not at Random (MNAR)

-   หากการสูญหายไม่ใช่ทั้ง MCAR และ MAR การสูญหายนั้นเป็น MNAR กล่าวในเชิงเทคนิคคือ เป็นการสูญหายที่มีความสัมพันธ์กับค่าที่สูญหายไป และอาจมีความสัมพันธ์กับค่าที่สังเกตได้ด้วย

-   กล่าวง่าย ๆ เป็นการสูญหายที่เกิดขึ้นโดยสัมพันธ์กับค่าที่สูญหาย การสูญหายแบบนี้ไม่สามารถอธิบายได้ด้วยข้อมูลที่มี เช่น

    -   ผู้ตอบไม่ตอบคำถามเกี่ยวกับรายได้เพราะรายได้ของตนเองสูงเกินไป

    -   นักเรียนที่มีคะแนนต่ำมากไม่ตอบคำถาม ไม่เข้าเรียน หรือไม่ส่งงานทำให้ครูไม่สามารถประเมินคะแนนให้นักเรียนได้

$$
p(m_{ij} = 1 | X_{obs}, X_{mis}) = f(X_{obs}, X_{mis})
$$

```{r fig.width = 8, fig.height=3}
set.seed(123)
data <- data %>% 
  mutate(ach_mnar = case_when(
    ach > 50  ~ ifelse(runif(387,0,1)<0.4,NA, ach) ,
    .default = ach
  )
  )
p1<-data %>% 
  pivot_longer(cols=starts_with("ach")) %>% 
  ggplot(aes(x=value))+
  geom_histogram(aes(fill = name))

p2<-data %>% 
  pivot_longer(cols=starts_with("ach")) %>% 
  ggplot(aes(x = value, y=name))+
  geom_boxplot(aes(fill = name))

p1+p2
```

```{r}
data %>% 
  ggplot(aes(x=learning_performance))+
  geom_point(aes(y=ach),alpha=0.1)+
  geom_point(data = data %>% filter(is.na(ach_mnar)==T), 
             aes(y=ach), col="maroon", shape = 2)+
  theme_light()+
  theme(panel.grid = element_blank())

data %>% 
  select(learning_performance, ach, ach_mcar, ach_mar, ach_mnar) %>% 
  pivot_longer(cols = c(ach, ach_mcar, ach_mar, ach_mnar)) %>% 
  group_by(name) %>% 
  summarise(mean = mean(value, na.rm = T),
            sd = sd(value,na.rm = T),
            median = median(value,na.rm = T),
            cor = cor(learning_performance, value, use = "complete.obs"),
            r2 = cor^2)
```

## การสำรวจและระบุค่าสูญหาย

ทัศนภาพข้อมูลเป็นเครื่องมือสำคัญที่จะช่วยให้ผู้วิเคราะห์ทำความเข้าใจสภาพการสูญหายของข้อมูลในชุดข้อมูลที่ทำงานด้วย โดยปกตินักวิเคราะห์จะใช้ทั้งทัศนภาพข้อมูลควบคู่กับการวิเคราะห์ผลทางสถิติเพื่อทำความเข้าใจและระบุค่าสูญหายในชุดข้อมูล

อย่างไรก็ตามจากประสบการณ์ของผู้สอน เทคนิคการวิเคราะห์เพื่อสำรวจค่าสูญหายที่ใช้อาจมีความแตกต่างกันขึ้นอยู่กับขนาดของชุดข้อมูลด้วย

-   การใช้ทัศนภาพข้อมูลและสถิติพื้นฐานเพื่อสำรวจค่าสูญหายเหมาะกับการทำงานบนชุดข้อมูลขนาดเล็ก

-   ข้อมูลขนาดปานหลางหรือขนาดใหญ่อาจจะต้องใช้เทคนิคโดยเฉพาะ ML เข้ามาช่วยเพื่อให้แสดงสภาพการสูญหายของข้อมูลของตัวแปรทั้งหมดได้

### Tabulating Missing data

```{r}
library(naniar)
any_na(data)
miss_var_summary(data)
miss_case_summary(data) %>% 
  arrange(desc(pct_miss)) %>% 
  filter(n_miss > 0)
```

### Visualization for Missing data

เทคนิคทั้งหมดในหัวข้อนี้เหมาะสำหรับใช้กับชุดข้อมูลที่มีขนาดไม่ใหญ่มาก

-   heatmap

-   missing data pattern plot

-   co-occurence plot

-   scatter plot

ตัวอย่างมีดังนี้

การสร้าง heatmap สามารถทำได้หลายวิธีการ ตั้งแต่การสร้างแบบ manual (ซึ่งทำบ่อย ๆ ก็เหนื่อย) ไปจนถึงมีฟังก์ชันสำเร็จรูปจากหลาย library

#### heatmap

```{r}
## install.packages("visdat")
library(visdat)
## create shadow matrix
vis_dat(data)
vis_miss(data, cluster = TRUE)

temp <- data %>% 
  mutate(performance = learning_performance > 50) %>% 
  mutate(performance = factor(performance))

vis_miss(temp, cluster = TRUE, facet = performance)
```

```{r}
p1<-vis_miss(data, cluster = TRUE)
p1
```

```{r}
p2<-vis_miss(data, cluster = TRUE, facet = ontime_class)
p2
```

```{r}
data %>% 
  bind_shadow() %>% 
  summary()
```

#### md plot

```{r fig.width = 8}
## install.packages("mice")
library(mice)
md.pattern(data, rotate.names = TRUE)
```

#### co-occurence plot

co-occurence plot ช่วยแสดงสภาพการสูญหายที่ลึกกว่า heatmap เพราะมีทั้งมิติความถี่ของการสูญหายเป็นรายตัวแปรซึ่งจำแนกเป็นการสูญหายในตัวแปรเดียว และการสูญหายร่วมกัน

การสูญหายร่วมกันที่มากมีผลทำให้การแก้ปัญหาแบบตัดข้อมูลที่ missing ออกจากไปการวิเคราะห์เริ่มไม่ work (ทำไม?)

```{r}
library(naniar)
gg_miss_upset(data)
```

#### Scatter plot

แผนภาพการกระจายมีประโยชน์มากสำหรับวิเคราะห์กลไกการสูญหายของข้อมูล

```{r}
data %>% 
  bind_shadow() %>% 
  ggplot(aes(x = learning_performance, y=ach_mar))+
  geom_point()+
  geom_rug(aes(x=learning_performance ,col = ach_mar_NA), sides = "b")+
  scale_color_manual(values = c("!NA" = NULL, "NA" = "maroon"),
                     labels=c(NULL, "missing in ach"))+
  theme_light()
```

จากรูปจะเห็นได้อย่างชัดเจนว่าการสูญหายที่เกิดขึ้นใน ach มีความสัมพันธ์กับ learning performance ของนักเรียน ซึ่งสะท้อน MAR mechanism

### การสำรวจค่าสูญหายสำหรับข้อมูลขนาดใหญ่

ในกรณีที่ชุดข้อมูลมีขนาดใหญ่ โดยเฉพาะเมื่อมีตัวแปรจำนวนมาก การใช้ heatmap หรือ co-occurence plot อาจมีประสิทธิภาพน้อยลง ลองใช้วิธีการข้างต้นวิเคราะห์สภาพการสูญหายในชุดข้อมูลต่อไปนี้

[ดาวน์โหลด](https://bit.ly/2JoKcqX)

```{r}
large_data <- read_csv("/Users/choat/Downloads/onlinelearning_miss.csv")
large_data <- large_data %>% select(-1) %>% 
  rename(student_id = X)

miss_var_summary(large_data) %>% 
  arrange(desc(pct_miss)) %>% 
  filter(n_miss >0)
```

```{r}
miss_case_summary(large_data)%>% 
  arrange(desc(pct_miss))
```

```{r}
large_data %>% 
select(where(~ any(is.na(.)))) %>% 
  vis_miss(cluster = TRUE)+
  theme(text = element_text(family = "ChulaCharasNew"))

gg_miss_upset(large_data, nsets = 10)
```

idea คือเราอาจใช้เทคนิค dimensionality reduction เพื่อย่อขนาดข้อมูลก่อนที่จะสร้างทัศนภาพข้อมูล ผลลัพธ์ที่ได้จะช่วยให้ผู้วิเคราะห์สามารถทำความเข้าใจสภาพการสูญหายของข้อมูลได้ง่ายขึ้น

การใช้ PCA ในบริบทนี้สามารถดำเนินการได้ดังนี้

1.  แปลงข้อมูลของตัวแปรที่มีค่าสูญหายเป็น dummy variable โดยใช้ 1 แทนค่าสูญหาย และ 0 แทนค่าที่ไม่สูญหาย

2.  ใช้ PCA เพื่อสกัดองค์ประกอบหลักจาก matrix ของ dummy ดังกล่าว

3.  ลักษณะการทำงานของ PCA คือจะสร้างองค์ประกอบหลักที่สามารถอธิบายความแปรปรวนของตัวแปรต้นฉบับเดิมให้ได้มากที่สุด ดังนั้นเมื่อตัวแปรนำเข้าเป็นแบบ binary 0,1 องค์ประกอบหลักที่ได้จึงจะสะท้อนความแปรปรวนหรือรูปแบบการสูญหายของข้อมูล

ทดลองดำเนินการดังนี้

```{r}
dummy_mat <- large_data %>% 
  bind_shadow() %>% 
  dplyr::select(ends_with("NA")) %>% 
  select(-1) %>% 
  mutate_all(as.numeric) %>% 
  mutate_all(~ .-1) %>% 
  select_if(~ sum(.) > 0)
```

ผลการวิเคราะห์สำคัญของ PCA ได้แก่

-   Eigenvalues เพื่อบอกความสำคัญของแต่ละองค์ประกอบ --\> ใช้ตัดสินใจด้วยว่าการบรรยายสภาพข้อมูลด้วยการลดมิตินี้ควรมีกี่องค์ประกอบถึงจะพอ \<-- สามารถอธิบายความแปรปรวนส่วนใหญ่ในข้อมูลต้นฉบับ \<--- สาระสำคัญเดิมของข้อมูลต้นฉบับ

-   Factor loadings เพื่อบอกสหสัมพันธ์ระหว่างต้นแปรต้นฉบับกับองค์ประกอบหลักแต่ละองค์ประกอบ

```{r}
pca_prep <- dummy_mat  %>% 
  recipe(~.) %>% 
# step_normalize(all_predictors()) %>%
  step_pca(all_predictors()) %>% 
  prep() 
  
  
pca_prep %>% 
  tidy(1, type = "variance") %>% 
  filter(terms == "percent variance") %>% 
  ggplot(aes(x=component, y=value))+
  geom_col()

pca_prep %>% 
  tidy(1) %>% 
  filter(component %in% c("PC1","PC2","PC3","PC4","PC5","PC6")) %>% 
  ggplot(aes(x=value, y=terms))+
  geom_col()+
  facet_wrap(~component)+
  theme(text = element_text(family = "ChulaCharasNew"))
```

```{r}
library(tidymodels)
library(ggrepel)
dummy_mat  %>% 
  recipe(~.) %>% 
# step_normalize(all_predictors()) %>%
  step_pca(all_predictors()) %>% 
  prep() %>%
  juice() %>%  ## ผลลัพธ์จาก PCA ส่วนนี้จะเป็นคะแนนองค์ประกอบหลักของการสูญหายในข้อมูล
  bind_cols(id = large_data$student_id) %>% 
  ggplot(aes(PC1, PC2))+
  geom_vline(xintercept = 0, linetype=2)+
  geom_hline(yintercept = 0, linetype=2)+
  geom_jitter(width = 0.05, height = 0.05)+
  geom_text(aes(label = id))+
  ggtitle("หน่วยข้อมูลไหนมีค่าสูญหายในตัวแปรไหน")+
  theme(text = element_text(family = "ChulaCharasNew"))


dummy_mat  %>% 
  recipe(~.) %>% 
# step_normalize(all_predictors()) %>%
  step_pca(all_predictors()) %>% 
  prep() %>%
  juice() %>%  ## ผลลัพธ์จาก PCA ส่วนนี้จะเป็นคะแนนองค์ประกอบหลักของการสูญหายในข้อมูล
  bind_cols(id = large_data$student_id) %>% 
  dplyr::select(id, PC1) %>% 
  filter(PC1 > 0.8)
```

```{r}
dummy_mat  %>% 
  recipe(~.) %>% 
# step_normalize(all_predictors()) %>%
  step_pca(all_predictors()) %>% 
  prep() %>%
  juice() %>% 
  dplyr::select(PC1) %>% 
  bind_cols(large_data) %>% 
  select_if(is.numeric) %>% 
  select(-student_id) %>% 
  drop_na() %>% 
  cor(use = "complete.obs") %>% 
  data.frame() %>% 
  dplyr::select(PC1)

```

### การบ้าน อย่าลืมให้ใน canvas

> ลอง transpose dummy_mat แล้วทำ PCA ผลลัพธ์ที่ได้คืออะไร

```{r}
dummy_mat  %>% 
#  rownames_to_column(var = "student_id") %>%  # เก็บ rownames เป็นคอลัมน์ (ถ้าต้องการ)
#  mutate(student_id = paste0("student", student_id)) %>% 
#  pivot_longer(cols = -student_id, names_to = "variable", values_to = "value") %>%
#  pivot_wider(names_from = student_id, values_from = value) %>% 
#  column_to_rownames("variable") %>%
  recipe(~.) %>% 
  step_pca(all_predictors(), num_comp = 2) %>% 
  prep() -> pca_prep

pca_prep %>% 
  tidy(1) %>% 
  filter(component %in% c("PC1","PC2")) %>% 
  ggplot(aes(x=value, y=terms))+
  geom_col()+
  facet_wrap(~component)+
  theme(text = element_text(family = "ChulaCharasNew"))
```

## การแก้ปัญหาค่าสูญหาย

การแก้ปัญหาค่าสูญหายอาจทำให้หลายวิธีการ ทั้งนี้ขึ้นอยู่กับความเหมาะสมว่าในแต่ละกรณีควรเลือกใช้วิธีการใด โดยปกติอาจจำแนกวิธีการแก้ปัญหาได้เป็นดังนี้

-   เลือกใช้โมเดลการวิเคราะห์ที่แกร่งต่อการสูญหายของข้อมูล เช่น tree-based models

-   การลบข้อมูลที่มีค่าสูญหายทิ้ง ซึ่งสามารถทำได้หลายลักษณะ เช่น การลบตัวแปรที่มีค่าสูญหายอย่างรุนแรงออกไปจากการวิเคราะห์ หรือการลบหน่วยข้อมูลที่มีค่าสูญหายออกไปจากการวิเคราะห์ วิธีการนี้อาจเหมาะสมถ้าในการวิเคราะห์มีตัวแปรหรือหน่วยข้อมูลบางตัวที่มีค่าสูญหายมากอย่างผิดปกติหรือรุนแรงมากเมื่อเปรียบเทียบกับตัวแปรหรือหน่วยข้อมูลอื่น ๆ อย่างไรก็ตามหากพบว่าการสูญหายมีการกระจายตัวไปหลายตัวแปรพและหลายหน่วยข้อมูลพร้อมกันวิธีการนี้จะไม่ work เพราะอาจสร้าง bias ให้กับการวิเคราะห์

```{r}
data <- read_csv("/Users/choat/Downloads/exam.csv")
glimpse(data)
### ลองสร้าง missign value ใน learning performance
set.seed(123)
data_miss <- data %>% 
  mutate(learning_performance = 
           case_when(
             ach < 30 ~ ifelse(runif(387,0,1)<2, NA, learning_performance),
             ach >=30 ~ learning_performance
           )
  )
 #dplyr::select(-learning_performance)
data_miss %>% vis_miss(cluster = T)
data_miss %>% miss_var_summary()

data_miss %>% 
  bind_shadow() %>% 
  ggplot(aes(x=learning_performance, y=ach))+
  geom_point(data = data, col = "maroon")+
  geom_smooth(method="lm", se = F)+
  geom_point(col = "steelblue")+
  geom_smooth(data = data, col = "maroon", method = "lm")
```

อีกปัจจัยหนึ่งที่ควรนำมาพิจารณาร่วมในการลบข้อมูลคือกลไกการสูญหายของข้อมูล กล่าวคือหากการสูญหายที่เกิดขึ้นเป็นแบบ MCAR การลบข้อมูลสามารถทำได้โดยไม่ได้ทำให้เกิดความลำเอียงในผลการวิเคราะห์ อย่างไรก็ตามหากการสูญหายเป็น MAR หรือ MNAR การลบข้อมูลอาจทำให้เกิดความลำเอียงดังที่ได้กล่าวไว้

-   การลงรหัสข้อมูลสูญหาย กล่าวคือในบางกรณีการสูญหายของข้อมูลสอดคล้องกับธรรมชาติของตัวแปรที่สูญหายทำให้ผู้วิเคราะห์สามารถลงรหัสของข้อมูลได้แทนที่จะกำหนดเป็นค่าสูญหาย ยกตัวอย่างจากชุดข้อมูล `exam.csv` หากผู้วิเคราะห์ทราบว่ามีหน่วยข้อมูลหลายหน่วยที่มีค่าสูญหายในตัวแปร `engage` และ `ontime_class` โดยที่หน่วยข้อมูลดังกล่าวเป็นนักเรียนที่ขาดเรียนบ่อยหรือแทบจะไม่มาเรียนในคลาสเลย กรณีเช่นนี้ผู้วิเคราะห์สามารถลงรหัสข้อมูลของนักเรียนดังกล่าวเป็น `no engage` และ `missed class` ตามลำดับ แทนที่จะกำหนดเป็นค่าสูญหาย และหากมีการสูญหายใน learning_performance ผู้วิเคราะห์อาจใช้ค่าเฉลี่ย learning_performance ของกลุ่มนักเรียนที่ไม่มาเรียนหรือมาเรียนน้อยเป็นตัวแทนค่าสูญหายดังกล่าวได้

```{r}
data %>% count(ontime_class)
```

-   การทดแทนค่าสูญหาย (imputation methods) วิธีการนี้มักทดแทนค่าสูญหายโดยใช้ความสัมพันธ์ระหว่างตัวแปรที่มีค่าสูญหายกับตัวแปรอื่น ๆ เพื่อหาค่าทดแทนที่มีความสมเหตุสมผลมากที่สุด

การวิจัยในอดีตมักเน้นการวิเคราะห์เพื่ออนุมานเชิงสถิติ ดังนั้นที่ผ่านมาวิธีการทดแทนค่าสูญหายหลายวิธีการจึงมีการออกแบบให้คำนึงถึงผลกระทบที่จะมีต่อการอนุมานเชิงสถิติในโมเดลต่าง ๆ กล่าวคือวัตถุประสงค์หลักในการหาค่าทดแทนคือการรับประกันว่าค่าทดแทนที่กำหนดให้กับข้อมูลสูญหายจะมีคุณภาพเพียงพอที่จะทำให้การทดสอบสมมุติฐานหรือการประมาณค่าแบบช่วงมีความน่าเชื่อถือ วิธีการที่มักใช้แก้ปัญหาเป็นหลักในกลุ่มนี้คือ การทดแทนค่าสูญหายแบบหลายค่า (multiple imputation)

![](mi.png)

อย่างไรก็ตามวิธีการดังกล่าวอาจไม่ work ในการพัฒนาโมเดลทำนายทั้งนี้เป็นเพราะ

1.  โมเดลทำนายหลายตัวไม่ได้เป็น parametric model กล่าวคือไม่ได้มีข้อตกลงเบื้องต้นเกี่ยวกับการแจกแจงของข้อมูล เช่น decision tree, K-NN ทำให้โมเดลดังกล่าวไม่สามารถสร้างสารสนเทศในการอนุมานเชิงสถิติได้ multiple imputation จะไม่เหมาะกับการทำงานร่วมกับโมเดลแบบนี้

2.  การพัฒนาโมเดลทำนายมีกระบวนการที่ค่อนข้างซับซ้อนหลายขั้น มีการใช้การสุ่มตัวอย่างซ้ำ เช่น cross-validation หรือ bootstraping เพื่อคำนวณความคลาดเคลื่อนแบบ out-sample นอกจากนี้หลายโมเดลยังมีการประมวลผลที่ซับซ้อนใช้เวลาต่อหนึ่งรอบในการประมาณที่ค่อนข้างมาก การทำ multiple imputation จะยิ่งเพิ่มเวลาในการประมวลผลและการใช้ทรัพยากรไปอีก

อย่างไรก็ตามการประเมินความผันแปรในการทดแทนค่าสูญหายเป็นประเด็นที่ควรวิเคราะห์/ศึกษาในงานวิจัย ซึ่งเราสามารถทำได้ผ่านการสุ่มซ้ำในขั้นตอนการ train model แทนการใช้ multiple imputation (กล่าวคือกำหนดการทดแทนค่าสูญหายเป็นขั้นตอนหนึ่งในแต่ละ cross-validation เลย) ผลลัพธ์ที่ได้จะช่วยลดภาระในการคำนวณ และสะท้อน variation ที่เกิดจากการทดแทนข้อมูลสูญหายได้

3.  การพัฒนาโมเดลทำนายมีวัตถุประสงค์เพื่อทำนายข้อมูลที่ยังไม่เคยเห็นหรือไม่ทราบคำตอบมาก่อน แทนที่จะอธิบายความสัมพันธ์หรือสร้างองค์ความรู้จากความสัมพันธ์ระหว่างตัวแปร ดังนั้นค่าที่ทดแทนค่าสูญหายที่สร้างขึ้นจึงควรมีความใกล้เคียงกับค่าจริงให้มากที่สุดเท่าที่จะเป็นไปได้

4.  การทำ multiple imputation เป็นการสร้างผลลัพธ์การอนุมานเชิงสถิติซึ่งจะไม่สามารถโมเดลหรืออัลกอริทึมสำหรับการทดแทนค่าสูญหายเอาไว้ใช้ต่อได้ ทำให้เป็นอุปสรรคในการนำโมเดลนี้ไปใช้กับกลุ่มเป้าหมายในกรณีทั่วไป

5.  การทดแทนค่าสูญหายในการพัฒนาโมเดลทำนายควรมีลักษณะเฉพาะคือ มีความแกร่งต่อการสูญหายในหลายตัวแปรพร้อมกัน สามารถเก็บอัลกอริทึมหรือโมเดลการทดแทนค่าสูญหายเอาไว้ได้เพื่อเอาไปผนวกหรือใช้ร่วมกับโมเดลการทำนายในกรณีทั่วไป ควรรองรับการสูญหายของตัวแปรได้หลายประเภทในโมเดลเดียว และควรมีความทนทานต่อค่าผิดปกติมีความเสถียรในการสร้างค่าทดแทนค่าสูญหาย

> การทดแทนค่าสูญหายควรเป็นกระบวนการแรกในการเตรียมข้อมูล

## Imputing Missing Values in Recipe

```{r eval = F}
# Impute via bagged trees
step_impute_bag() 

# Impute via k-nearest neighbours
step_impute_knn()

# Impute numeric variables via a linear model
step_impute_linear()

# Impute numeric data using the mean
step_impute_mean() 

# Impute numeric data using the median
step_impute_median() 

# Impute nominal data using the most common value
step_impute_mode() 

# Impute numeric data using minimum value
step_impute_lower()

# Assign missing categories to "unknown" 
step_unknown()
```

## กิจกรรม

สร้างโมเดลทำนาย student_outcome_online และ onsite โดยมีทั้งโมเดลที่ไม่ได้ทดแทนค่าสูญหาย และมีการทดแทนค่าสูญหายแบบต่าง ๆ

```{r}
large_data %>% glimpse()
```

```{r}
recipe(y ~ ., data= train_data) %>% 
  step_impute_knn(interaction.online1 ,neighbors = 10) %>% 
  step_normalize(all_predictors()) %>%
  prep()
  
```
