---
title: "Week 2: Modelling Process"
author: "ผศ.ดร.สิวะโชติ ศรีสุทธิยากร"
institute: "ภาควิชาวิจัยและจิตวิทยาการศึกษา <br> คณะครุศาสตร์ จุฬาลงกรณ์มหาวิทยาลัย"
format:
  revealjs:
    slide-number: c/t
    footer: "week 2: 2758623 Machine Learning Principles and Application<br>
            ผศ.ดร.สิวะโชติ ศรีสุทธิยากร"
    logo: https://github.com/ssiwacho/picture/blob/main/datakruroo.png?raw=true
    theme: theme.scss
    css: my_css.css
    scrollable: true
    transition: fade
    background-transition: fade
    highlight-style: github
    title-slide-attributes:
      data-background-image: img/ML.jpg
      data-background-opacity: 8%
      data-background-size: full
code-link: true
execute:
  echo: true
  freeze: auto
---

## Outline

- Data splitting

- Creating models

- Model evaluation

## Modeling Process {.smaller}

<br>

:::: {.columns}

::: {.column width="35%"}

- Data-driven approaches

- Iterative Procedure

- Trial and Error

:::

::: {.column width="65%"}

![](https://datakruroo.github.io/MachineLearning/week01/img/process.png)

:::

::::

## Frame the Problem {.smaller}

- Regression: ใช้ G3 - final grade (numeric: from 0 to 20) เป็นตัวแปรตาม
 
- Binary Classification: ใช้เกณฑ์ $G3 \geq 10$ หมายถึงสอบผ่าน (pass) 

```{r echo = T}
library(tidyverse)
data <- read_delim("/Users/choat/Documents/GitHub/datakruroo.github.io/MachineLearning/week02/student/student-mat.csv", delim = ";")
glimpse(data)
```

## Frame the Problem {.smaller}

- Model A: ใช้ทุกตัวแปรเป็นตัวแปรทำนาย

- Model B: ตัด G2-second period grade (numeric: from 0 to 20) ออกจากตัวแปรทำนาย

- Model C: ตัด G1-first period grade (numeric: from 0 to 20) ออกจากตัวแปรทำนายเพิ่ม

## Data Splitting {.smaller}

เพื่อให้การฝึกสอนและประเมินประสิทธิภาพของโมเดลเป็นไปได้อย่างถูกต้อง ผู้วิเคราะห์จำเป็นต้องแบ่งข้อมูลออกเป็นสองส่วน

- **Training data**: ใช้สำหรับพัฒนาชุดของตัวแปรอิสระ และโมเดลการเรียนรู้ ผลลัพธ์สุดท้ายที่จะได้จากชุดข้อมูลนี้คือ โมเดลการเรียนรู้ที่ดีที่สุด (final models) ที่คาดว่าจะนำไปใช้งานจริง

- **Test data**: ใช้ประเมินประสิทธิภาพของ final models อย่างเป็นกลาง ผลการประเมินที่ได้จากชุดข้อมูลนี้จะสะท้อนคุณสมบัติด้าน generaliability ของโมเดล กล่าวคือ โมเดลการเรียนรู้แต่ละตัวมีความสามารถที่จะนำไปใช้กับข้อมูลใหม่ได้ดีมากน้อยเพียงใด 

สัดส่วนการแบ่งชุดข้อมูลโดยทั่วไปคือ 60:40, 70:30, 80:20 ปัจจัยที่ใช้ประกอบการพิจารณา 

- จำนวนข้อมูลทั้งหมดที่มี

- จำนวนตัวแปรอิสระ


## Data Leakage {.smaller}

ปัญหาที่เกิดขึ้นจากการที่ข้อมูลที่ไม่ควรใช้ในกระบวนการพัฒนาโมเดลถูกนำมาใช้โดยไม่ได้ตั้งใจ ส่งผลให้โมเดลมีประสิทธิภาพสูงเกินจริงในขั้นตอนการประเมิน แต่ไม่สามารถนำไปใช้งานจริงได้อย่างน่าเชื่อถือ เช่น

- มีข้อมูลใน test data เข้ามามีส่วนในกระบวนการสร้างโมเดล

- ข้อมูลที่เกี่ยวข้องกับตัวแปรตามหรือเป็นตัวชี้วัดของตัวแปรตามถูกใช้เป็นตัวแปรอิสระ

- การเอา id ของข้อมูลมาเป็นตัวแปรทำนาย

## กิจกรรม 1: Data Splitting {.smaller}

:::: {.columns}

::: {.column width="15%"}

![](img/rsample.png)
:::

::: {.column width="85%"}

- Simple random sampling


```{r echo = T}
## install.packages("rsample")
library(rsample)
## SRS
set.seed(123)
srs_split <- initial_split(data = data, prop = 0.7)
train_srs <- training(srs_split)
test_srs <- testing(srs_split)
```

- Stratified random sampling


```{r echo = T}
## Stratified
set.seed(123)
strat_split <- initial_split(data = data, prop = 0.7, 
                           strata = G3, breaks = 4)
train_strat <- training(strat_split)
test_strat <- testing(strat_split)
```


:::

::::

## Data Splitting: Distribution Consistency {.smaller}

```{r echo = F, fig.height = 3}
library(patchwork)
p1 <- train_srs %>% 
  ggplot(aes(x = G3, y = after_stat(density)))+
  geom_histogram(col = "white", 
                 fill = "black",
                 bins = 20)+
  theme_light()+
  ggtitle("training data (SRS)")+
  ylim(0,0.2)

p2 <- test_srs %>% 
  ggplot(aes(x = G3, y = after_stat(density)))+
  geom_histogram(col = "white", 
                 fill = "steelblue",
                 bins = 20)+
  theme_light()+
  ggtitle("test data (SRS)")+
  ylim(0,0.2)

p1+p2
```

```{r echo = F , fig.height = 3}
p1 <- train_strat %>% 
  ggplot(aes(x = G3, y = after_stat(density)))+
  geom_histogram(col = "white", 
                 fill = "black",
                 bins = 20)+
  theme_light()+
  ggtitle("training data (STR)")+
  ylim(0,0.25)

p2 <- test_strat %>% 
  ggplot(aes(x = G3, y = after_stat(density)))+
  geom_histogram(col = "white", 
                 fill = "steelblue",
                 bins = 20)+
  theme_light()+
  ggtitle("test data (STR)")+
  ylim(0,0.25)

p1+p2
```

## Data Splitting: Class Imbalances {.smaller}

- เกิดขึ้นในปัญหาแบบ classification เมื่อตัวแปรตามมีการแจกแจงที่ไม่สมดุล

- มีผลกระทบสูงต่อประสิทธิภาพการเรียนรู้และการทำนายของโมเดล

```{r eval = F}
binary_data <- data %>% mutate(result = ifelse(G3>=10,"pass","fail")) %>% select(-G3)
set.seed(123)
strat_split <- initial_split(data = binary_data, prop = 0.7, 
                           strata = result)
train_strat <- training(strat_split)
test_strat <- testing(strat_split)

p1 <- train_strat %>% 
  ggplot(aes(x=result))+geom_bar()+
  ggtitle("training data")

p2 <- test_strat %>% 
  ggplot(aes(x=result))+geom_bar()+
  ggtitle("test data")

p1+p2
```

## Data Splitting: Class Imbalances {.smaller}

```{r echo = F}
binary_data <- data %>% mutate(result = ifelse(G3>=10,"pass","fail")) %>% select(-G3)
set.seed(123)
strat_split <- initial_split(data = binary_data, prop = 0.7, 
                           strata = result)
train_strat_class <- training(strat_split)
test_strat_class <- testing(strat_split)

p1 <- train_strat_class %>% 
  ggplot(aes(x=result))+geom_bar()+
  ggtitle("training data")

p2 <- test_strat_class %>% 
  ggplot(aes(x=result))+geom_bar()+
  ggtitle("test data")

p1+p2
```

## Explore the (Training) Data {.smaller}

- ทำความเข้าใจตัวแปรตาม (target variable)

  - ลักษณะการแจกแจงของตัวแปรตามเป็นอย่างไร
  
  - summary stat ของตัวแปรตาม
  
  - ความผิดปกติหรือความไม่สมบูรณ์ของข้อมูลตัวแปรตาม

. . .  
  
- ทำความเข้าใจตัวแปรอิสระ (features)

  - มีตัวแปรอิสระจำนวนกี่ตัว จำแนกเป็นตัวแปรเชิงปริมาณและจัดประเภทอย่างไร?
  
  - การลงรหัสตัวแปรอิสระมีความเหมาะสมแล้วหรือไม่
  
  - การแจกแจงของตัวแปรอิสระและ summary stat

## Explore the (Training) Data {.smaller}

- วิเคราะห์ความสัมพันธ์เบื้องต้นระหว่างตัวแปรตามกับตัวแปรอิสระ

  - Scatter plot
  
  - Correlation coefficients
  
  - Boxplot/Violin plot
  
  - ANOVA
  
  - Interaction Effects


## กิจกรรม 2: สำรวจข้อมูล training data {.smaller}

ขอให่้นิสิตดำเนินการสำรวจข้อมูล training data ประกอบด้วย

- สำรวจตัวแปรตาม (regression task)

- ตัวแปรอิสระ

- ความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระ

ผลการสำรวจเป็นอย่างไร?

## Syntax สำหรับกิจกรรม 2 {.smaller}

#### 1. แปลงข้อมูลจัดประเภทให้เป็น factor

```{r}
train_str2 <- train_strat %>%
  mutate_at(vars(school, sex, address, famsize, Pstatus, 
                 Medu, Fedu, Mjob, Fjob, reason, guardian,
                 traveltime, studytime, schoolsup,
                 famsup, paid, activities, nursery, higher,internet,
                 romantic, famrel, freetime, goout, Dalc, Walc, health), 
            factor)
```

<br>

#### 2. สำรวจตัวแปรอิสระแบบจัดประเภท

```{r eval = F}
train_str2 %>% 
select_if(is.factor) %>%
  pivot_longer(cols = everything()) %>% 
  ggplot(aes(x = value))+
  geom_bar(fill = "black")+
  theme_light()+
  facet_wrap(~name, scale = "free")
```

## Syntax สำหรับกิจกรรม 2 {.smaller}

#### 3. สำรวจความสัมพันธ์ระหว่าง y กับ x

```{r}
features_name <- names(train_str2 %>% select(-G3))

# สร้าง tibble ว่างเพื่อเก็บผลลัพธ์
results <- tibble(
  predictor = character(),
  rsq = numeric()
)

# ใช้ for loop เพื่อวนลูปคำนวณ
for (x in features_name) {
  # สร้างสูตรโมเดล
  formula <- as.formula(paste("G3 ~", x))
  
  # เทรนโมเดล
  model <- lm(formula, data = train_strat)
  
  # ดึงค่า R-squared
  rsq <- summary(model)$r.squared
  
  # เพิ่มผลลัพธ์ลงใน tibble
  results <- results %>%
    add_row(predictor = x, rsq = rsq)
}
```


## Syntax สำหรับกิจกรรม 2 {.smaller}

#### สำรวจความสัมพันธ์ระหว่าง y กับ x (ต่อ)

:::: {.columns}

::: {.column width="50%"}

```{r}
results %>% 
  arrange(desc(rsq))
```


:::

::: {.column width="50%"}

```{r fig.height = 8}
results %>% arrange(desc(rsq)) %>% 
  ggplot(aes(x = rsq, 
             y= reorder(predictor, rsq)))+
  geom_col(fill = "black", alpha = 0.8)+
  theme_light()+
  theme(text = element_text(size = 20))+
  ylab("")+ xlab("\n R-Square")
```


:::

::::

## Creating Models {.smaller}

- Base library

- tidymodels

- caret

- mlr3

- H2O

- autoML

- scikit-learn

## Tidymodels {.smaller}


```{r eval = F}
## install.packages("tidymodels")
library(tidymodels)
```

```{r echo = F}
library(tidymodels)
```

![](img/tidymodels.jpeg)

<div class="caption">https://rpubs.com/chenx/tidymodels_tutorial</div>


## Tidymodels {.smaller}

<left>
![](img/tidymodel_functions.png){width="60%"}
</left>


<div class="caption">https://rpubs.com/chenx/tidymodels_tutorial</div>



## Tidymodels: parsnip {.smaller}


:::: {.columns}

::: {.column width="15%"}

![](img/parsnip.png)

:::

::: {.column width="85%"}

ส่วนประกอบจำเป็นสำหรับการระบุโมเดล 

- **model type** อัลกอริทึมที่จะใช้สร้างโมเดลทำนาย

- **engine** เลือก library ที่ใช้สำหรับประมวลผล

- **mode** กำหนดประเภทของโมเดล

นอกจากนี้หลายอัลกอริทึมจะมี hyperparameters ที่ใช้ปรับแต่งลักษณะการเรียนรู้ของโมเดล ซึ่งอาจปรับแต่งอย่างเหมาะสมอาจช่วยเพิ่มประสิทธิภาพของโมเดลได้ (จะกล่าวภายหลัง)

```{r}
## linear regression model
lm_spec <- linear_reg() |> 
  set_engine("lm") |> 
  set_mode("regression")
## k-nearest neighbor
knn_spec <- nearest_neighbor() |> 
  set_engine("kknn") |> 
  set_mode("regression")
```

:::

::::


<div class="caption">[https://www.tidymodels.org/find/parsnip/](https://www.tidymodels.org/find/parsnip/)</div>

## Tidymodels: Model Fitting {.smaller}

- `fit()` เป็นฟังก์ชันหลักตัวหนึ่งของ `parsnip` สำหรับ train โมเดลทำนายที่ต้องการด้วยอัลกอริทึมและชุดข้อมูลที่กำหนด

```{r}
lm_fit <- lm_spec %>% 
  fit(G3 ~ ., data = train_strat)

knn_fit <- knn_spec %>% 
  fit(G3 ~ ., data = train_strat)
```

บางโมเดลมีความสามารถในการอธิบายความสัมพันธ์ในตัวเอง เช่น linear regression หรือ decision tree ผู้วิเคราะห์สามารถดึงผลการประมาณค่าพารามิเตอร์ หรือผลการวิเคราะห์ที่เกี่ยวข้องเพื่อนำไปใช้ได้ เช่น

- `extract_fit_engine()` เป็นฟังก์ชันใน `parsnip` ใช้สำหรับดึง model object จากผลการสร้างโมเดลด้วย `parsnip` หรือ `workflow` ใน tidymodels

ลองพิมพ์คำสั่งต่อไปนี้แล้วพิจารณาผลลัพธ์ที่ได้

```{r eval = F}
raw_lm_model <- extract_fit_engine(lm_fit)
summary(raw_lm_model)
```

## Tidymodels: Model Evaluation {.smaller}

โดยปกติวัตถุประสงค์ของการสร้างโมเดลทำนายคือการทำนาย ดังนั้นการประเมินประสิทธิภาพของโมเดลทำนายจึงเน้นไปที่การตรวจสอบความถูกต้องของการทำนายเป็นหลัก

:::: {.columns}

::: {.column width="50%"}

- คำนวณค่าทำนายใน test data 

- คำนวณค่าของ evaluation metrices


#### Regression models

- MSE

- RMSE

- MAE

- Rsq

:::

::: {.column width="50%"}

#### Classification models

- Confusion Matrix

  - Accuracy (hit rate)
  
  - Misclassification rate
  
  - Precision
  
  - Sensitivity (or recall)
  
  - Specificity
  
  - AUC

- Brier score

- Cross-entropy

:::

::::

## Tidymodels: Model Evaluation {.smaller}



การคำนวณค่าประสิทธิภาพของโมเดลทำนายแบบ regression ภายใต้ tidymodels framework สามารถทำได้ง่าย ๆ โดยใช้ฟังก์ชันจาก package yardstick ได้แก่ `rmse()` และ `rsq()`


::::: {.columns}

::: {.column width="50%"}

```{r echo = F, fig.width = 4, fig.height = 4} 
lm_fit %>% 
  predict(new_data = test_strat) %>% 
  rename(lm_pred = 1) %>% 
  bind_cols(test_strat) %>% 
  select(lm_pred, G3) %>% 
  ggplot(aes(x = G3, y = lm_pred))+
  geom_point()+
  geom_abline(intercept = 0, slope = 1)+
  theme_light()+
  coord_obs_pred()
```

:::

::: {.column width="50%"}

```{r}
test_dataset_lm <- lm_fit %>% 
  predict(new_data = test_strat) %>% 
  rename(lm_pred = 1) %>% 
  bind_cols(test_strat)

metric <- metric_set(yardstick::rmse,
                     yardstick::rsq,
                     yardstick::mae)

test_dataset_lm %>% 
  metric(truth = G3, estimate = lm_pred)

```

:::

:::::

## Classification {.smaller}

Binary Classification: ใช้เกณฑ์ $G3 \geq 10$ หมายถึงสอบผ่าน (pass) 

ขอให้นิสิตดำเนินการต่อไปนี้

1. สร้างตัวแปรตามชื่อ `result` ในชุดข้อมูล `data`

2. แบ่งชุดข้อมูล `train_data` และ `test_data` โดยใช้ `result`

3. สำรวจการแจกแจงของตัวแปร `result` 

4. กำหนด classification model สำหรับจำแนกผลการเรียนของนักเรียน ในที่นี้ให้เลิือกใช้ binary logistic regression 

5. ทดลอง fit model กับข้อมูล มีข้อสังเกตอะไรหรือไม่

6. และคำนวณเกณฑ์สำหรับพิจารณาประสิทธิภาพโมเดล ได้แก่ brier score, confusion matrix, accuracy, misclassification rate, sensitivity (recall), specificity, precision, F1

## Divergent & Perfect Separation Problem {.smaller}


:::: {.columns}

::: {.column width="50%"}


```{r echo = F}
binary_data <- data %>% mutate(result = ifelse(G3>=10,"pass","fail"),
                               result = fct_relevel(result, "pass")) %>% select(-G3)
set.seed(123)
strat_split <- initial_split(data = binary_data, prop = 0.7, 
                           strata = result)
train_strat <- training(strat_split)
test_strat <- testing(strat_split)
```


```{r warning = T}
## model specification
logit_mod <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

## fitting
fit_logit <- logit_mod %>% 
  fit(result ~ ., data = train_strat)
```



:::

::: {.column width="50%"}

**แนวทางแก้ปัญหา**


- เพิ่ม iteration

- ทำ regularization L1/L2

- ตรวจสอบและลบตัวแปรอิสระที่ทำให้เกิด perfect seperation ออก

- แก้ปัญหา Imbalanced class

- แก้ปัญหา outlier

- แก้ปัญหา multicollinearity (สำหรับบางโมเดล)

- ปรับค่า Tolerance

- เปลี่ยนอัลกอริทึม



:::

::::

## Roc & AUC {.smaller}

ROC (Receiver Operating Characteristic) และ AUC (Area Under the Curve) เป็นเครื่องมือที่ใช้วัดและประเมินประสิทธิภาพของ classification model โดยเฉพาะการจำแนกแบบ binary classification จุดเด่นคือเป็นการพิจารณาความสามารถของโมเดลจากทุก threshold
 
:::: {.columns}


::: {.column width="50%"}

```{r echo = F} 
library(ggrepel)
## model specification
logit_mod <- logistic_reg() %>% 
  set_engine("glm",
             control = list(maxit = 100)) %>% 
  set_mode("classification")

## fitting
fit_logit <- logit_mod %>% 
  fit(result ~ ., data = train_strat)
```


```{r echo = T}
predicted_value <- fit_logit %>% 
  predict(new_data = test_strat,
          type = "prob") %>% 
  bind_cols(test_strat) %>% 
  select(.pred_pass, result)
predicted_value  %>%roc_curve(truth = "result", .pred_pass)
predicted_value  %>% roc_auc(truth = "result", .pred_pass)
```

:::


::: {.column width="50%"}

```{r echo = F, fig.width = 4.5}

fit_logit %>% 
  predict(new_data = test_strat,
          type = "prob") %>% 
  bind_cols(test_strat) %>% 
  select(.pred_pass, result) %>% 
  roc_curve(truth = "result", .pred_pass) %>% 
  ggplot(aes(x = 1-specificity, y=sensitivity))+
  geom_path(col = "steelblue", linewidth = 1.5)+
  geom_abline(slope = 1, intercept = 0, linetype = 2)+
  geom_point()+
  geom_text(aes(x = 0.35, y= 0.6, label = "AUC = 0.902"), size = 5)+
  theme_light()+
  theme(panel.grid.minor = element_blank(),
        text = element_text(size = 15))+
  xlab("\n False Positive Rate")+
  ylab("True Positive Rate \n")+
  coord_obs_pred()+
  ggtitle("ROC")
```

:::

:::: 


## F1 Score {.smaller}

F1 Score เป็นตัวชี้วัดประสิทธิภาพการจำแนกของโมเดล classification โดยพิจารณาด้านความไวและความน่าเชื่อถือไปพร้อมกัน ในเชิงคณิตศาสตร์ F1 เป็นค่าเฉลี่ย Harmonic ระหว่าง sensitivity กับ precision 

$$
F_1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
$$

```{r}
fit_logit %>% 
  predict(new_data = test_strat,
          type = "class") %>% 
  bind_cols(test_strat) %>% 
  select(.pred_class, result) %>% 
  f_meas(truth = result, estimate = .pred_class)
```

## LASSO Regression {.smaller}

Lasso Regression (Least Absolute Shrinkage and Selection Operator) เป็นรูปแบบหนึ่งของ regularized regression ที่ใช้ในการลดความซับซ้อนของโมเดลและป้องกันปัญหา overfitting โดยเพิ่ม penalty term ที่จะเพิ่ม bias อย่างเหมาะสมให้กับโมเดลเพื่อให้ variance ของโมเดลต่ำลงลดการเกิดปัญหา overfitting 

#### regression

$$
\text{Minimize: } \frac{1}{n} \sum_{i=1}^{n} \left( y_i - \beta_0 - \sum_{j=1}^{p} \beta_j x_{ij} \right)^2 + \lambda \sum_{j=1}^{p} |\beta_j|
$$

#### binary logistic regression

$$
\text{Minimize: } - \frac{1}{n} \sum_{i=1}^{n} \left[ y_i \log(\hat{p}_i) + (1 - y_i) \log(1 - \hat{p}_i) \right] + \lambda \sum_{j=1}^{p} |\beta_j|
$$


## LASSO Regression {.smaller}


:::: {.columns}


::: {.column width="50%"}

![](img/lasso.png)

:::

::: {.column width="50%"}

```{r echo = F}
library(tidymodels)
library(glmnet)
library(ggplot2)

# สร้างข้อมูลตัวอย่าง
set.seed(42)
data <- as_tibble(matrix(rnorm(1000), nrow = 100, ncol = 10))
colnames(data) <- paste0("X", 1:10)
data$y <- 2 * data$X1 - 3 * data$X2 + rnorm(100)


# แยกข้อมูล Train และ Test
set.seed(42)
data_split <- initial_split(data, prop = 0.8)
train_data <- training(data_split) %>%
  mutate(y = y + rnorm(n(), mean = 0, sd = 3))  # เพิ่ม noise ให้ชุด train
test_data <- testing(data_split)

# สร้าง Matrix สำหรับ glmnet
x_train <- as.matrix(train_data %>% select(-y))
y_train <- train_data$y
x_test <- as.matrix(test_data %>% select(-y))
y_test <- test_data$y

# สร้างโมเดล Lasso ด้วย glmnet
x_matrix <- as.matrix(data %>% select(-y))
y_vector <- data$y

lasso_fit <- glmnet(x_train, y_train, alpha = 1, lambda = 10^seq(-3, 1, length = 50))

# ดึงค่า coefficient ออกมา
coefs <- t(as.matrix(coef(lasso_fit))[-1, ])  # ลบ intercept ออก
lambda_values <- lasso_fit$lambda

# เปลี่ยนค่า coefficient เป็น dataframe
coefs_df <- as_tibble(coefs, .name_repair = "unique") %>%
  mutate(lambda = lambda_values) %>%
  pivot_longer(-lambda, names_to = "feature", values_to = "coefficient")

# สร้างแผนภาพ
ggplot(coefs_df, aes(x = lambda, y = coefficient, color = feature)) +
  geom_line(linewidth = 1.5) +
  scale_x_log10() +  # ใช้ log scale สำหรับ lambda
  labs(
    title = "Path of Coefficients with Increasing Penalty",
    x = "Lambda (Regularization Strength)",
    y = "Coefficient Value",
    color = "Feature"
  ) +
  theme_minimal()+
  theme(text = element_text(size=16))


# คำนวณ RMSE สำหรับ Train และ Test
rmse_results <- tibble(lambda = lambda_values)

rmse_results <- rmse_results %>%
  mutate(
    train_rmse = map_dbl(lambda, ~ {
      preds <- predict(lasso_fit, s = .x, newx = x_train)
      sqrt(mean((y_train - preds)^2))  # RMSE สำหรับ train
    }),
    test_rmse = map_dbl(lambda, ~ {
      preds <- predict(lasso_fit, s = .x, newx = x_test)
      sqrt(mean((y_test - preds)^2))  # RMSE สำหรับ test
    })
  )

ggplot(rmse_results, aes(x = lambda)) +
  geom_line(aes(y = train_rmse, color = "Train RMSE"), linewidth = 1.2) +
  geom_line(aes(y = test_rmse, color = "Test RMSE"), linewidth = 1.2) +
  scale_x_log10() +  # ใช้ log scale สำหรับ lambda
  labs(
    title = "RMSE vs Lambda for Train and Test Sets",
    x = "Lambda (Regularization Strength)",
    y = "RMSE",
    color = "Dataset"
  ) +
  theme_minimal() +
  theme(text = element_text(size = 16))
```


:::

::::

## Validation Approach: K-fold CV {.smaller}

- ชุด training set (ชุดฝึกฝนใหม่)

- ชุด validation set (หรือเรียกว่า holdout set) อย่างไรก็ตามการใช้ validation set เพียงชุดเดียวมีโอกาสสูงที่ผลการประเมินจะขาดความเสถียร มีอคติ ไม่น่าเชื่อถือ

![](img/kfold.png)

## Resampling: Cross-validation {.smaller}

![](img/cv.png)


## Validation Approach: K-fold CV {.smaller}

ค่า  k  ใหญ่ขึ้น:

- ความแตกต่างระหว่างประสิทธิภาพที่ประเมินได้และประสิทธิภาพจริงจะลดลง

- เพิ่มทรัพยากรที่ต้องใช้ในการประมวลผล

ค่า  k = 10 :

- มีผลลัพธ์คล้ายกับ Leave-One-Out Cross Validation (LOOCV) ซึ่งเป็นกรณีที่  k = n  (Molinaro et al. ,2005)

- การทำ k-Fold CV ซ้ำ (repeated k-Fold CV) สามารถเพิ่มความแม่นยำของการประเมินผล เช่น ใช้ 10-Fold CV ทำซ้ำ 5-10 ครั้งเพื่อเพิ่มความน่าเชื่อถือ

## Validation Approach: K-fold CV {.smaller}

![](https://www.tmwr.org/premade/proper-workflow.svg)

## Validation Approach: K-fold CV {.smaller}


```{r}
# สร้าง model specification
logit_mod <- logistic_reg(
  penalty = tune(),   
  mixture = 1       
) %>%
  set_engine("glmnet") %>% 
  set_mode("classification")

# สร้าง workflow
logit_wf <- workflow() %>%
  add_formula(result ~.) %>%
  add_model(logit_mod)

# สร้าง resamples สำหรับ Cross-Validation
set.seed(123)
cv_folds <- vfold_cv(train_strat, v = 10, repeats = 3)

# สร้าง grid สำหรับ lambda
lambda_grid <- grid_regular(
  penalty(range = c(-3, 1)),  # lambda ตั้งแต่ 10^-3 ถึง 10^1
  levels = 30
)

# ใช้ tune_grid() เพื่อปรับ lambda
tune_results <- tune_grid(
  logit_wf,
  resamples = cv_folds,
  grid = lambda_grid,
  metrics = metric_set(roc_auc, accuracy, sens, spec, precision)
)
```

## Validation Approach: K-fold CV {.smaller}


```{r fig.height = 6}
autoplot(tune_results)
```

## Validation Approach: K-fold CV {.smaller}

- `collect_metrics()` เป็นฟังก์ชันที่ช่วยให้ผู้วิเคราะห์เข้าถึงผลที่ได้จากการทดลอง fit model ในเงื่อนไขต่าง ๆ พร้อมค่าบ่งชี้ประสิทธิภาพ

```{r}
tune_results %>% collect_metrics()
```




## Finalized Workflows {.smaller}

```{r}
## select best
best_params <- tune_results %>%
  select_best(metric = "roc_auc")

## finalizing
final_wf <- logit_wf %>%
  finalize_workflow(best_params)

## last fit
final_wf %>%
  fit(data = train_strat) %>% extract_fit_engine() %>% plot(xvar = "lambda")
```

## Finalized Workflows {.smaller}

```{r}
final_wf %>% last_fit(strat_split,
                       metrics = metric_set(accuracy, roc_auc, 
                                            sens, spec, precision)) %>% 
  collect_metrics()
```


