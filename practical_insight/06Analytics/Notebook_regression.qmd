---
title: "Basic Regression Example"
format: html
---

## สถานการณ์

นักวิเคราะห์ต้องการทำนายเงินเดือนของอาจารย์มหาวิทยาลัย ด้วยตัวแปรทำนายได้แก่ เพศ ตำแหน่งทางวิชาการ สาขาวิชา ประสบการณ์ในการเป็นอาจารย์ และประสบการณ์ทำงานตั้งแต่จบปริญญาเอก

```{r}
library(readr)
dat <- read_csv("TeacherSalaryData.csv")
head(dat)
```

```{r message = F}
#install.packages("tidymodels")
library(tidymodels)
```

ขั้นตอนการพัฒนาโมเดลด้วย tidymodels framework มีดังนี้

### 1. แบ่งชุดข้อมูลออกเป็น training และ test set

```{r}
set.seed(123)
split <- initial_split(dat, prop = 0.8)
train <- training(split)
test <- testing(split)
```

### 2. สำรวจข้อมูลเบื้องต้น

```{r eval = F}
library(DataExplorer)
plot_intro(train)
plot_missing(train)
plot_bar(train)
plot_histogram(train)
plot_correlation(train)
```

```{r}
train |> 
  ggplot(aes(x=yrs.service, y=salary))+
  geom_point()+
  geom_smooth(aes(col = discipline), method = "lm")

train |> 
  ggplot(aes(x=yrs.since.phd, y=salary))+
  geom_point()+
  geom_smooth(aes(col = discipline), method = "lm")

train |>
  ggplot(aes(x=rank, y=salary))+
  geom_boxplot(aes(fill = discipline))
```

### 3. สร้าง recipe สำหรับทำ data preprocessing ใน training set

```{r}
### recipe1: no interaction
rec_noint <- recipe(salary ~ ., data = train) |> 
  step_select(-1) |> 
  step_mutate(rank = factor(rank, levels=c("AsstProf", "AssocProf", "Prof")),
              discipline = factor(discipline, labels=c("science","social"))) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  prep(train) 


### recipe2: with interaction
rec_int <- recipe(salary ~ ., data = train) |> 
  step_select(-1) |> 
  step_mutate(rank = factor(rank, levels=c("AsstProf", "AssocProf", "Prof")),
              discipline = factor(discipline, labels=c("science","social"))) |>
  step_normalize(all_numeric_predictors()) |>
  step_interact(terms = ~ yrs.service:discipline) |>
  step_dummy(all_nominal_predictors()) |>
  prep(train)
```

### 4. สร้าง model specification และ fit model ใน training set

ในกรณีนี้จะลองใช้ 4 โมเดล คือ linear regression, regularized regression, KNN และ random forest

```{r}
ols_reg <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

ridge_reg <- linear_reg(penalty = tune(), mixture = 0) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

knn_reg <- nearest_neighbor(weight_func = "gaussian", neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression")

rand_forest <- rand_forest(trees = 500, mtry = tune(), min_n = tune()) %>%
  set_engine("ranger") %>%
  set_mode("regression")
```

### 5. สร้าง workflowset และ tune พารามิเตอร์

```{r}
my_workflowset <- workflow_set(
  preproc = list(rec_noint = rec_noint, rec_int = rec_int, rec_noint = rec_noint, rec_noint = rec_noint),
  models = list(
    ols = ols_reg,
    ridge = ridge_reg,
    knn = knn_reg,
    rand_forest = rand_forest
  ),
  cross = FALSE
)
my_workflowset
```

กำหนด evaluation metric และ tune hyperparameter เมื่อทำการ train เสร็จ tidymodel จะให้ผลลัพธ์เป็น tibble ที่บรรจุผลการ train ของแต่ละโมเดลเอาไว้

```{r}
## กำหนด evaluation metric
eval_metric <- metric_set(rmse, rsq)
train_result <- my_workflowset |> 
  workflow_map(
    grid = 10,
    resamples = vfold_cv(train, v = 5, repeats = 3),
    metrics = eval_metric
  )
train_result
```

### 6. ประเมินผลลัพธ์ของโมเดล

```{r}
train_result |>
  autoplot()

train_result |> 
  rank_results() 


train_result |> 
  collect_metrics() |> 
  filter(.metric == "rsq") |> 
  arrange(desc(mean))
```

### 7. คัด best model ไปตรวจสอบผลลัพธ์ในข้อมูล test

```{r}
### วิเคราะห์ OLS
train_result |> 
  extract_workflow_set_result(id = "rec_noint_ols") |>
  collect_metrics(summarise = T) |> 
  filter(.metric == "rsq") |> 
  arrange(-mean)

### วิเคราะห์ Ridge Regression

train_result |> 
  extract_workflow_set_result(id = "rec_int_ridge") |> 
  collect_metrics(summarise = T) |> 
  filter(.metric == "rsq") |> 
  arrange(-mean)

best_ridge <- train_result |> 
  extract_workflow_set_result(id = "rec_int_ridge") |> 
  show_best("rsq", n = 1)

### วิเคราะห์ KNN algorithm
knn_result <- train_result |> 
  extract_workflow_set_result(id = "rec_noint_knn") |> 
  collect_metrics(summarise = T) |> 
  filter(.metric == "rsq") |> 
  arrange(-mean)

best_knn <- train_result |> 
  extract_workflow_set_result(id = "rec_noint_knn") |> 
  show_best("rsq", n = 1)

### วิเคราะห์ Random Forest


train_result |> 
  extract_workflow_set_result(id = "rec_noint_rand_forest") |> 
  collect_metrics(summarise = T) |> 
  filter(.metric == "rsq") |> 
  arrange(-mean)

best_rf <- train_result |> 
  extract_workflow_set_result(id = "rec_noint_rand_forest") |> 
  show_best("rsq", n = 1)
```

### 8. ประเมินผลใน test data

เมื่อคัดเลือก best model ของแต่ละอัลกอริทึมได้แล้ว จะ train ใหม่กับข้อมูลทั้งหมด เพื่อนำไปตรวจสอบใน test data

```{r}
ols_trained <- train_result |> 
  extract_workflow(id = "rec_noint_ols") |>
  fit(train)

ridge_trained <- train_result |> 
  extract_workflow(id = "rec_int_ridge") |>
  finalize_workflow(best_ridge) |>
  fit(train)

knn_trained <- train_result |> 
  extract_workflow(id = "rec_noint_knn") |>
  finalize_workflow(best_knn) |>
  fit(train)

rf_trained <- train_result |> 
  extract_workflow(id = "rec_noint_rand_forest") |>
  finalize_workflow(best_rf) |>
  fit(train)
```

นำโมเดลทั้งหมดไปทำนาย salary ใน test

```{r}
## data preprocessing
test_noint <- rec_noint |> 
              bake(test)

test_int <- rec_int |>
            bake(test)


## ทำนาย
ols_pred <- ols_trained |> 
  extract_fit_parsnip() |>
  predict(test_noint) |> 
  bind_cols(test_noint) |> 
  select(salary, .pred)

ridge_pred <- ridge_trained |> 
  extract_fit_parsnip() |>
  predict(test_int) |> 
  bind_cols(test_int) |> 
  select(salary, .pred)

knn_pred <- knn_trained |> 
  extract_fit_parsnip() |>
  predict(test_noint) |> 
  bind_cols(test_noint) |> 
  select(salary, .pred)

rf_pred <- rf_trained |> 
  extract_fit_parsnip() |>
  predict(test_noint) |> 
  bind_cols(test_noint) |> 
  select(salary, .pred)

pred_dat <- bind_rows(
  ols_pred |> mutate(model = "ols"),
  ridge_pred |> mutate(model = "ridge"),
  knn_pred |> mutate(model = "knn"),
  rf_pred |> mutate(model = "rf")
)

pred_dat |> 
  ggplot(aes(x = salary, y = .pred)) +
  geom_point() +
  geom_smooth(method = "lm", se = F)+
  facet_wrap(~model, scales = "fixed")

```
