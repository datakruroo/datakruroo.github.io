# Multiclass classification

## Introduction

ขอให้ผู้เรียนใช้ชุดข้อมูล [`train.csv`](datasets/train.csv.zip) และ [`test.csv`](datasets/test.csv.zip) เพื่อพัฒนาโมเดลจำแนกตัวเลขจากลายมือ (digit recognition) เมื่อดาวน์โหลดข้อมูลมาแล้วจะต้องแตก zip ไฟล์ข้อมูลทั้งสองก่อนที่จะวิเคราะห์จริง

```{r message= F}
library(tidymodels)
unzip(zipfile = "datasets/train.csv.zip", files = "train.csv")
unzip(zipfile = "datasets/test.csv.zip", file = "test.csv")

train <- read.csv("train.csv")
test <- read.csv("test.csv")
head(train[,1:10])
```

## สำรวจข้อมูล

ลองเรียกชื่อตัวแปรทั้งหมดในชุดข้อมูล `train` ขึ้นมาดู

```{r}
names(train) %>% head()
names(train) %>% tail()
```

ชุดข้อมูลทั้งสองชุดประกอบด้วยข้อมูลภาพของตัวเลข 0 - 9 ที่เขียนด้วยลายมือที่มีขนาด 28 x 28 pixels โดยรูปภาพแต่ละรูปถูกแปลงให้อยู่ในรูปของ feature จำนวน 784 ตัว (คอลัมน์) ซึ่งแทน pixels แต่ละจุดบนรูปภาพต้นฉบับ และข้อมูลภายในแต่ละ pixel ถูกแปลงให้เป็นค่าความเข้มของสีดำ ที่มีค่าอยู่ในช่วง 0 - 255 นอกจากนี้ภายในชุดข้อมูลทั้งสองชุดยังมีตัวแปร `label` ที่ใช้ระบุว่าข้อมูลภายในแต่ละแถวของชุดข้อมูลนั้นเป็นภาพของตัวเลขใด

![](images/image-1842286070.png){width="262"}

ลองดึงข้อมูลของรูปภาพรูปที่หนึ่ง ซึ่งอยู่ในแถวแรกของชุดข้อมูล `train` ขึ้นมาดู พบว่ามีลักษณะดังนี้

```{r}
#plot function
plot_digit <- function(data, index)
{
title_lab <- data[index,"label"]
data %>%
  slice(index) %>%
  dplyr::select(starts_with("pixel")) %>%
  pivot_longer(starts_with("pixel")) %>%
  mutate(x = rep(1:28,28),
         y = rep(1:28, each = 28)) %>%
  ggplot(aes(x = x, y = y))+
  geom_tile(aes(fill = value))+
  scale_y_reverse()+
  scale_fill_gradient(low = "white", high = "black")+
  theme_light()+
  theme(text = element_text(family = "ChulaCharasNew"),
        panel.grid = element_blank()
  )+
  ggtitle(title_lab)+
  labs(fill = "Darkness")
}
# -------
library(gridExtra)
p1 <- plot_digit(train, 1)
p2 <- plot_digit(train,10)
p3 <- plot_digit(train,20)
p4 <- plot_digit(train,30)
grid.arrange(p1,p2,p3,p4, ncol=2)
```

สุดท้ายลองแจกแจงความถี่ของ `label` ว่ามีตัวเลขอะไรบ้างในชุดข้อมูล

```{r fig.height = 3.5}
ggplot(data = train, aes(x = label)) +
  geom_bar()+
  scale_x_continuous(breaks=seq(0,9,1))
```

## Model Training

ปัญหาจำแนกตัวเลขจากลายมือนี้จัดอยู่ในกลุ่มปัญหาที่เรียกว่า multi-class classfication ซึ่งเกี่ยวกับการจำแนกข้อมูลที่มีจำนวนหลาย categories อัลกอริทึมที่จะใช้ในตัวอย่างนี้ประกอบด้วย

-   Multinomial logistic regression with regularization

-   Decision Tree

-   Random Forest

รายละเอียดการพัฒนาโมเดลมีดังนี้

### 1. สร้าง recipe object

```{r}
# แปลงให้ outcom เป็น factor ก่อน
train$label <- factor(train$label)
train <- train %>% drop_na()
# sampling ข้อมูลบางส่วนมา train model
set.seed(123)
split <- initial_split(train, prop = 0.2, strata = "label")
sample_train <- training(split)
sample_test <- testing(split)

table(sample_train$label)
sample_train %>%
  ggplot(aes(x=label))+
  geom_bar()
```

### 2. ทดลอง fit model (no tuning)

กำหนดโมเดลด้วย parsnip package รายละเอียดสามารถศึกษาได้จาก <https://www.tidymodels.org/find/parsnip/> สำหรับ multinomial logistic regression สามารถกำหนดโมเดลได้ดังนี้

#### Multinomial logistic regression

```{r}
start <- Sys.time()
multinom_reg <- multinom_reg(penalty = 0.01,
                             mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("classification") %>%
  fit(label ~ . , data= sample_train)
time_usage <- Sys.time() - start
time_usage

#par(mfrow = c(5,2), mar=c(5,5,1,1))
#multinom_reg %>% extract_fit_engine() %>%plot()

pred_multinom_test <- predict(multinom_reg, new_data = sample_test)

pred_result <- sample_test %>%
  bind_cols(pred_multinom_test) %>%
  select(label, .pred_class)

confusion_glmnet<-pred_result %>% conf_mat(truth = label,
                         estimate = .pred_class)
confusion_glmnet %>% autoplot(type = "heatmap")
confusion_glmnet %>% summary()
```

#### Decision Trees

```{r}
library(rpart.plot)
start <- Sys.time()
dt_fit <- decision_tree(min_n = 900,
                    tree_depth = 30,
                    cost_complexity = 0.0001) %>%
  set_engine("rpart") %>%
  set_mode("classification") %>%
  fit(label ~ ., data = sample_train)
time_usage <- Sys.time() - start
time_usage
dt_fit %>% extract_fit_engine() %>% rpart.plot(type = 4)

pred_dt_test <- predict(dt_fit, new_data = sample_test)

pred_result_dt <- sample_test %>%
  bind_cols(pred_dt_test) %>%
  select(label, .pred_class)

confusion_dt<-pred_result_dt %>% conf_mat(truth = label,
                         estimate = .pred_class)
confusion_dt %>% autoplot(type = "heatmap")
confusion_dt %>% summary()
```

#### Random Forest

```{r}
start <- Sys.time()
rf_fit <- rand_forest(mtry = 46,
                      trees = 1000,
                      min_n = 61) %>%
  set_engine("ranger") %>%
  set_mode("classification") %>%
  fit(label ~ ., data = sample_train)
time_usage <- Sys.time() - start
time_usage
rf_fit

pred_rf_test <- predict(rf_fit, new_data = sample_test)

pred_result_rf <- sample_test %>%
  bind_cols(pred_rf_test) %>%
  select(label, .pred_class)

confusion_rf<-pred_result_rf %>% conf_mat(truth = label,
                         estimate = .pred_class)
confusion_rf %>% autoplot(type = "heatmap")
confusion_rf %>% summary()
```

จากการทดลองรันโมเดลทำนายเบื้องต้นพบว่า glmnet และ random forest เป็นโมเดลที่มีประสิทธิภาพค่อนข้างดีใกล้เคียงกัน อย่างไรก็ตาม glmnet ใช้เวลาประมวลผลค่อนข้างนานมาก ดังนั้นการ fine tune hyperparameter จะทำกับโมเดล random forest อย่างเดียว รายละเอียดอยู่ในหัวข้อถัดไป

### 3. สร้าง Workflow set

```{r}
## create recipe object for workflow
preproc <- recipe(label ~. , data= sample_train)
```

กำหนด workflow เพื่อ fine tune hyperparameter ของ random forest จากการวิเคราะห์เบื้องต้นพบว่า hyperparameter ที่ค่อนข้างมีผลต่อประสิทธิภาพการทำนายคือ `mtry` ดังนั้นจึงจะ fine tune เฉพาะ hyperparameter ตัวนี้เพียงตัวเดียว

```{r}
## model specification
rf_model <- rand_forest(mtry = tune(),
                      trees = 200,
                      min_n = tune()) %>%
  set_engine("ranger") %>%
  set_mode("classification")

rf_workflow <- workflow() %>%
  add_recipe(preproc) %>%
  add_model(rf_model)

rf_workflow
```

### 4. Hyperparameters Tuning

นำโมเดลทั้งหมดมา train และปรับแต่งค่า hyperparameter ของโมเดล ดังนี้

```{r message = F}
## create 10-folds CV 
boot <- bootstraps(sample_train, times = 25, strata = "label")
#vfold_cv(sample_train, v = 5, repeats = 3, strata= "label")
# create eval metric
eval_metrics <- metric_set(accuracy,roc_auc, sens, spec)
# create grid
params <- parameters(mtry(range = c(5,50)),
                     min_n(range = c(50,400)))
mygrid <- grid_max_entropy(params, size = 15)

## tuning with default grid
library(doMC)
registerDoMC(cores = parallel::detectCores())
start <- Sys.time()
all_tuning_results <- rf_workflow %>%
  tune_grid(resamples = boot,
               grid = mygrid,
               metrics = eval_metrics,
               control = control_grid(save_pred = TRUE,
                                      verbose = TRUE)
               )
# stop parallel
time_usage <- Sys.time() - start
time_usage
```

### 5. วิเคราะห์ hyperparameters

```{r}
all_tuning_results %>% collect_metrics(summarise = T) %>%
  filter(.metric == "sens") %>%
  arrange(desc(mean))
all_tuning_results %>% autoplot()
show_best(all_tuning_results,3, metric = "roc_auc")
show_best(all_tuning_results,3, metric = "sens")
show_best(all_tuning_results,3, metric = "spec")
```

### 6. Finalized workflow

นำโมเดลที่ดีที่สุดจากข้้างต้นมา fit ใหม่

```{r}
mybest_mod <- show_best(all_tuning_results,1, metric = "sens")
set.seed(123)
split <- initial_split(train, prop = 0.7, strata = "label")
sample_train <- training(split)
sample_test <- testing(split)

rf_model2 <- rand_forest(mtry = tune(),
                      trees = 1000,
                      min_n = tune()) %>%
  set_engine("ranger") %>%
  set_mode("classification")

rf_workflow2 <- workflow() %>%
  add_recipe(preproc) %>%
  add_model(rf_model2)

start <- Sys.time()
registerDoMC(cores = parallel::detectCores())
rf_fit_final <- rf_workflow2 %>%
  finalize_workflow(mybest_mod) %>%
  last_fit(split,
           metrics = eval_metrics)
time_usage <- Sys.time() - start
time_usage

rf_fit_final %>% 
  collect_metrics()

rf_fit_final %>%
  collect_predictions() %>%
  conf_mat(truth = label,
           estimate = .pred_class) %>%
  summary()

## mosaic plot
rf_fit_final %>%
  collect_predictions() %>%
  conf_mat(truth = label,
           estimate = .pred_class) %>%
  autoplot()

## heatmap of confusion matrix
rf_fit_final %>%
  collect_predictions() %>%
  conf_mat(truth = label,
           estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

### 7. Predict a new dataset

```{r}
predict_val <- rf_fit_final %>%
  extract_workflow() %>%
  predict(test[1:6,])
predict_val <- as.character(predict_val$.pred_class)
p1<-plot_digit(test,1)+
  ggtitle(predict_val[1])
p2<-plot_digit(test,2)+
  ggtitle(predict_val[2])
p3<-plot_digit(test,3)+
  ggtitle(predict_val[3])
p4<-plot_digit(test,4)+
  ggtitle(predict_val[4])
p5<-plot_digit(test,5)+
  ggtitle(predict_val[5])
p6<-plot_digit(test,6)+
  ggtitle(predict_val[6])
grid.arrange(p1,p2,p3,p4,p5,p6,ncol=3)
```

### 8. Predict new dataset (from raw)

สมมุติว่ามีข้อมูลใหม่ได้แก่ [อันนี้](images/Screenshot%202566-03-04%20at%2010.58.21.png)กับ [อันนี้](images/Screenshot%202566-03-04%20at%2018.45.19.png) เราจะลองใช้โมเดลที่พัฒนาขึ้นเพื่อจำแนกตัวเลขในรูปทั้งสอง

```{r}
library(EBImage)
# define import function
import_img<-function(path)
{
myimg <- readImage(path)
#myimg
colorMode(myimg) <- Grayscale
img_resize <- resize(myimg, w=28, h=28)
#display(img_resize)
img_neg <- max(img_resize) - img_resize
#display(img_neg)
#img_neg
myimg <- imageData(img_neg)[,,1]
#myimg %>% dim()
vector <- myimg %>% as.numeric()
temp <- data.frame(t(vector))
names(temp) <- paste0("pixel",0:783)
temp <-temp*255
temp<-round(temp,0)
return(temp)
}
# import image
temp<-import_img("images/Screenshot 2566-03-04 at 10.58.21.png")
temp<-rbind(temp,import_img("images/Screenshot 2566-03-04 at 18.45.19.png") )
# predict
predict_val <- rf_fit_final %>%
  extract_workflow() %>%
  predict(temp)
# results!!
predict_val
plot_digit(temp,1)
plot_digit(temp,2)
```
