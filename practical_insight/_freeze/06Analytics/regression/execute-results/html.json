{
  "hash": "bdd40f56b56d2a976377e14129d4df34",
  "result": {
    "markdown": "---\ntitle: \"Basic Regression Example\"\nsubtitle: \"<b>Practical Insight: Doing Data Science in Education with R</b>\"\nauthor: ผศ.ดร.สิวะโชติ ศรีสุทธิยากร\nlogo: \"images/logo.png\"\nfooter: \"[Practical Insight: Doing Data Science in Education with R](https://datakruroo.netlify.app/practical_insight/_site/)\"\nformat: \n  html:\n    number_sections: true\neditor: visual\nexecute:\n  freeze: auto\n---\n\n\n## Types of Data Analytics\n\n<center>![](images/analytictypes.png){width=\"80%\"}</center>\n\n## สถานการณ์\n\nนักวิเคราะห์ต้องการทำนายเงินเดือนของอาจารย์มหาวิทยาลัย ด้วยตัวแปรทำนายได้แก่ เพศ ตำแหน่งทางวิชาการ สาขาวิชา ประสบการณ์ในการเป็นอาจารย์ และประสบการณ์ทำงานตั้งแต่จบปริญญาเอก\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\ndat <- read_csv(\"TeacherSalaryData.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nRows: 397 Columns: 7\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): rank, discipline, sex dbl (4): ...1, yrs.since.phd, yrs.service, salary\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n```\n:::\n\n```{.r .cell-code}\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n   ...1 rank      discipline yrs.since.phd yrs.service sex   salary\n  <dbl> <chr>     <chr>              <dbl>       <dbl> <chr>  <dbl>\n1     1 Prof      B                     19          18 Male  139750\n2     2 Prof      B                     20          16 Male  173200\n3     3 AsstProf  B                      4           3 Male   79750\n4     4 Prof      B                     45          39 Male  115000\n5     5 Prof      B                     40          41 Male  141500\n6     6 AssocProf B                      6           6 Male   97000\n```\n:::\n:::\n\n\n## มโนทัศน์ของการพัฒนาโมเดลทำนาย\n\nเราต้องการโมเดลทำนายที่มีคุณสมบัตื\n\n- Unbiased\n\n- Minimum variance\n\n![](https://datakruroo.netlify.app/mlcourse/_site/documents/images/image-1638148101.png)\n\n\n\n## กระบวนการพัฒนาโมเดลทำนาย\n\n![](https://datakruroo.netlify.app/mlcourse/_site/documents/images/image-1728379488.png)\n\n\n## Resampling \n\n![](https://datakruroo.netlify.app/mlcourse/_site/documents/images/image-468626522.png)\n\n\n- K-fold cross-validation\n\n- Bootstraping\n\n## K-fold cross-validation\n\n![](https://datakruroo.netlify.app/mlcourse/_site/documents/images/image-1150746472.png)\n\n\n## [Tidymodels Framework](https://www.tidymodels.org/start/)\n\n![](https://datakruroo.netlify.app/mlcourse/_site/documents/images/image-258190158.png)\n\n\n- package-rsample ใช้ในงาน resampling ข้อมูล เช่นการสร้าง training/validation/test dataset การสร้าง cross-validation dataset หรือการสร้าง bootstrape dataset ซึ่งได้กล่าวการใช้งานเบื้องต้นไปแล้ว\n\n- package-recipes ใช้แปลง/แก้ปัญหาที่เกิดขึ้นในข้อมูลของตัวแปรที่ใช้ในการพัฒนาโมเดล ขั้นตอนนี้เรียกว่า feature engineering\n\n- package-parsnip ใช้ fit machine learning กับข้อมูล โมเดลที่สามารถ fit ได้จาก parsnip มีหลายโมเดล เช่น linear regression, logistic regression, random forest, support vector machine, neural network, gradient boosting machine, etc. ผู้เรียนสามารถอ้างอิงการระบุโมเดลต่าง ๆ จาก [https://www.tidymodels.org/find/parsnip/](https://www.tidymodels.org/find/parsnip/)\n\n\n- package-Tune และ package-dials มีฟังก์ชันที่อำนวยความสะดวกในการ fine tune hyperparameter ของโมเดลเพื่อเพิ่มประสิทธิภาพการทำนายของโมเดลให้สูงที่สุด\n\n- package-yardstick มีฟังก์ชันของ metric ที่ใช้ประเมินประสิทธิภาพของโมเดลทำนาย ตัวชี้วัดสำหรับโมเดล regression ได้แก่ RMSE, MAE, MAPE, R-squared, etc.\n\n\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ **RMSE**\n\n$$\nRMSE = \\sqrt\\frac{\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}{n}\n$$\n\n\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ **R-squared**\n\n$$\nR^2=Corr(y,\\hat{y})^2\n$$\n\n\ntidymodels ถูกพัฒนาขึ้นโดยได้รับการออกแบบให้สามารถทำซ้ำกระบวนการพัฒนาโมเดลได้ง่าย โดยใช้ไวยกรณ์ของภาษาในลักษณะเดียวกัน และถูกออกแบบโดยเน้นใช้กับ supervised learning เป็นหลัก ผู้ใช้งานไม่จำเป็นต้องติดตั้งทุก package ในข้างต้นด้วยตนเอง แต่ติดตั้งเพียง package-tidymodels ก็สามารถใช้งานทุก package ภายใต้ framework ดังกล่าวได้แล้ว โดยการพิมพ์คำสั่งต่อไปนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"tidymodels\")\nlibrary(tidymodels)\n```\n:::\n\n\n\nขั้นตอนการพัฒนาโมเดลด้วย tidymodels framework มีดังนี้\n\n### 1. แบ่งชุดข้อมูลออกเป็น training และ test set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nsplit <- initial_split(dat, prop = 0.8)\ntrain <- training(split)\ntest <- testing(split)\n```\n:::\n\n\n\n### 2. สำรวจข้อมูลเบื้องต้น\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DataExplorer)\nplot_intro(train)\nplot_missing(train)\nplot_bar(train)\nplot_histogram(train)\nplot_correlation(train)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain |> \n  ggplot(aes(x=yrs.service, y=salary))+\n  geom_point()+\n  geom_smooth(aes(col = discipline), method = \"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](regression_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntrain |> \n  ggplot(aes(x=yrs.since.phd, y=salary))+\n  geom_point()+\n  geom_smooth(aes(col = discipline), method = \"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](regression_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n```{.r .cell-code}\ntrain |>\n  ggplot(aes(x=rank, y=salary))+\n  geom_boxplot(aes(fill = discipline))\n```\n\n::: {.cell-output-display}\n![](regression_files/figure-html/unnamed-chunk-5-3.png){width=672}\n:::\n:::\n\n\n### 3. สร้าง recipe สำหรับทำ data preprocessing ใน training set\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### recipe1: no interaction\nrec_noint <- recipe(salary ~ ., data = train) |> \n  step_select(-1) |> \n  step_mutate(rank = factor(rank, levels=c(\"AsstProf\", \"AssocProf\", \"Prof\")),\n              discipline = factor(discipline, labels=c(\"science\",\"social\"))) |>\n  step_normalize(all_numeric_predictors()) |>\n  step_dummy(all_nominal_predictors()) |>\n  prep(train) \n\n\n### recipe2: with interaction\nrec_int <- recipe(salary ~ ., data = train) |> \n  step_select(-1) |> \n  step_mutate(rank = factor(rank, levels=c(\"AsstProf\", \"AssocProf\", \"Prof\")),\n              discipline = factor(discipline, labels=c(\"science\",\"social\"))) |>\n  step_normalize(all_numeric_predictors()) |>\n  step_interact(terms = ~ yrs.service:discipline) |>\n  step_dummy(all_nominal_predictors()) |>\n  prep(train)\n```\n:::\n\n\n### 4. สร้าง model specification และ fit model ใน training set\n\nในกรณีนี้จะลองใช้ 3 โมเดล คือ linear regression, regularized regression และ KNN\n\n\n\n\n![](https://datakruroo.netlify.app/mlcourse/_site/documents/images/image-676691868.png){width=50%}\n\n\n![](https://datakruroo.netlify.app/mlcourse/_site/documents/images/image-849757700.png)\n\n![](https://datakruroo.netlify.app/mlcourse/_site/documents/images/image-343319787.png)\n\n\n\n\nประเภทของ regularization จำแนกได้ 3 ประเภท ได้แก่\n\n- ridge regression\n\n- lasso regression\n\n- elastic net regression\n\n#### หลักการคร่าว ๆ ของ ridge regression\n\nฟังก์ชันวัตถุประสงค์ของ regularized regression ประเภท ridge regression สามารถเขียนได้ดังนี้\n\n$$\n\\underset{\\beta}{min}\\left\\{SSE+\\lambda\\sum_{j=1}^p\\beta_j^2\\right\\}\n$$\n![](https://datakruroo.netlify.app/mlcourse/_site/documents/images/image-75951276.png)\nจากผลในข้างต้นจะเห็นว่า ridge regression เป็นเทคนิคที่ช่วยปรับขนาดของสัมประสิทธิ์ความชันของตัวแปรอิสระในโมเดลให้มีค่าลดลง แต่จะไม่ได้ทำให้เป็น 0 ดังนั้นตัวแปรอิสระทั้งหมดที่ผู้วิเคราะห์นำเข้าในอัลกอริทึมตอนแรกนั้นจะอยู่ในโมเดลทำนายครบทุกตัว แต่จะถูกปรับลดขนาดของค่าสัมประสิทธิ์ความชันลง ดังนั้น ridge regression จึงไม่ใช่เทคนิคสำหรับคัดเลือกตัวแปรอิสระ แต่เป็นเทคนิคที่เหมาะสำหรับแก้ปัญหา multicollinearity มากกว่า ดังนั้น ridge regression จึงเหมาะที่จะใช้ในสถานการณ์ที่ผู้วิเคราะห์มีตัวแปรอิสระจำนวนมากและตัวแปรดังกล่าวมีความสัมพันธ์กันเองสูงหรือมีความซ้ำซ้อนกัน แต่ผู้วิเคราะห์ไม่ต้องการที่จะตัดตัวแปรอิสระตัวใดออกจากโมเดลทำนาย อัลกอริทึม ridge regression จะช่วยให้ผู้วิเคราะห์สามารถสร้างโมเดลทำนายที่มีตัวแปรอิสระทั้งหมดอยู่ภายในโมเดลโดยหลีกเลี่ยงหรือลดทอนผลกระทบที่เกิดจากปัญหา multicollinearity ได้\n\n\n#### lasso regression\n\n::::{.columns}\n\n:::{.column width=\"50%\"}\nLasso regression เป็นอัลกอริทึมที่ถูกพัฒนาขึ้นโดยมีวัตถุประสงค์หลักคือการคัดเลือกตัวแปรอิสระ (feature selection) เข้าสู่โมเดลทำนาย อัลกอริทึมนี้เป็น feature selection ที่จัดอยู่ในกลุ่ม embedded method กล่าวคือเป็นอัลกอริทึมการเรียนรู้ที่มีอัลกอริทึมของการคัดเลือกตัวแปรอิสระรวมอยู่ในขั้นตอนการประมาณค่าพารามิเตอร์ของโมเดล หลักการของ lasso regression เหมือนกับ ridge regression แต่มีการใช้ penalty term ในฟังก์ชันวัตถุประสงค์ที่แตกต่างออกไปดังนี้\n\n\n$$\n\\underset{\\beta}{min}\\left\\{SSE+\\lambda\\sum_{j=1}^p|\\beta_j|\\right\\}\n$$\n\n:::\n\n:::{.column width=\"50%\"}\n![](https://datakruroo.netlify.app/mlcourse/_site/documents/images/image-1836348765.png){width=100%}\n\n:::\n::::\n\n#### KNN\n\n![](images/knn.png){width=70%}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols_reg <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  set_mode(\"regression\")\n\nridge_reg <- linear_reg(penalty = tune(), mixture = 0) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"regression\")\n\nknn_reg <- nearest_neighbor(weight_func = \"gaussian\", neighbors = tune()) %>%\n  set_engine(\"kknn\") %>%\n  set_mode(\"regression\")\n\nrand_forest <- rand_forest(trees = 500, mtry = tune(), min_n = tune()) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"regression\")\n```\n:::\n\n\n\n### 5. สร้าง workflowset และ tune พารามิเตอร์\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_workflowset <- workflow_set(\n  preproc = list(rec_noint = rec_noint, rec_int = rec_int, rec_noint = rec_noint, rec_noint = rec_noint),\n  models = list(\n    ols = ols_reg,\n    ridge = ridge_reg,\n    knn = knn_reg,\n    rand_forest = rand_forest\n  ),\n  cross = FALSE\n)\nmy_workflowset\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 4 × 4\n  wflow_id              info             option    result    \n  <chr>                 <list>           <list>    <list>    \n1 rec_noint_ols         <tibble [1 × 4]> <opts[0]> <list [0]>\n2 rec_int_ridge         <tibble [1 × 4]> <opts[0]> <list [0]>\n3 rec_noint_knn         <tibble [1 × 4]> <opts[0]> <list [0]>\n4 rec_noint_rand_forest <tibble [1 × 4]> <opts[0]> <list [0]>\n```\n:::\n:::\n\n\nกำหนด evaluation metric และ tune hyperparameter เมื่อทำการ train เสร็จ tidymodel จะให้ผลลัพธ์เป็น tibble ที่บรรจุผลการ train ของแต่ละโมเดลเอาไว้\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## กำหนด evaluation metric\neval_metric <- metric_set(rmse, rsq)\ntrain_result <- my_workflowset |> \n  workflow_map(\n    grid = 10,\n    resamples = vfold_cv(train, v = 5, repeats = 3),\n    metrics = eval_metric\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n:::\n\n```{.r .cell-code}\ntrain_result\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 4 × 4\n  wflow_id              info             option    result   \n  <chr>                 <list>           <list>    <list>   \n1 rec_noint_ols         <tibble [1 × 4]> <opts[3]> <rsmp[+]>\n2 rec_int_ridge         <tibble [1 × 4]> <opts[3]> <tune[+]>\n3 rec_noint_knn         <tibble [1 × 4]> <opts[3]> <tune[+]>\n4 rec_noint_rand_forest <tibble [1 × 4]> <opts[3]> <tune[+]>\n```\n:::\n:::\n\n\n### 6. ประเมินผลลัพธ์ของโมเดล\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_result |>\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](regression_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntrain_result |> \n  rank_results() \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 62 × 9\n   wflow_id      .config  .metric    mean std_err     n preprocessor model  rank\n   <chr>         <chr>    <chr>     <dbl>   <dbl> <int> <chr>        <chr> <int>\n 1 rec_noint_knn Preproc… rmse    2.28e+4 6.44e+2    15 recipe       near…     1\n 2 rec_noint_knn Preproc… rsq     4.55e-1 2.14e-2    15 recipe       near…     1\n 3 rec_noint_knn Preproc… rmse    2.28e+4 6.59e+2    15 recipe       near…     2\n 4 rec_noint_knn Preproc… rsq     4.55e-1 2.22e-2    15 recipe       near…     2\n 5 rec_noint_knn Preproc… rmse    2.28e+4 6.61e+2    15 recipe       near…     3\n 6 rec_noint_knn Preproc… rsq     4.54e-1 2.14e-2    15 recipe       near…     3\n 7 rec_noint_knn Preproc… rmse    2.28e+4 6.46e+2    15 recipe       near…     4\n 8 rec_noint_knn Preproc… rsq     4.52e-1 2.10e-2    15 recipe       near…     4\n 9 rec_noint_knn Preproc… rmse    2.29e+4 6.45e+2    15 recipe       near…     5\n10 rec_noint_knn Preproc… rsq     4.50e-1 2.06e-2    15 recipe       near…     5\n# ℹ 52 more rows\n```\n:::\n\n```{.r .cell-code}\ntrain_result |> \n  collect_metrics() |> \n  filter(.metric == \"rsq\") |> \n  arrange(desc(mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 × 9\n   wflow_id      .config    preproc model .metric .estimator  mean     n std_err\n   <chr>         <chr>      <chr>   <chr> <chr>   <chr>      <dbl> <int>   <dbl>\n 1 rec_noint_knn Preproces… recipe  near… rsq     standard   0.455    15  0.0214\n 2 rec_noint_knn Preproces… recipe  near… rsq     standard   0.455    15  0.0222\n 3 rec_noint_knn Preproces… recipe  near… rsq     standard   0.454    15  0.0214\n 4 rec_noint_knn Preproces… recipe  near… rsq     standard   0.452    15  0.0210\n 5 rec_noint_knn Preproces… recipe  near… rsq     standard   0.450    15  0.0206\n 6 rec_noint_knn Preproces… recipe  near… rsq     standard   0.446    15  0.0217\n 7 rec_noint_knn Preproces… recipe  near… rsq     standard   0.440    15  0.0218\n 8 rec_int_ridge Preproces… recipe  line… rsq     standard   0.440    15  0.0222\n 9 rec_int_ridge Preproces… recipe  line… rsq     standard   0.440    15  0.0222\n10 rec_int_ridge Preproces… recipe  line… rsq     standard   0.440    15  0.0222\n# ℹ 21 more rows\n```\n:::\n:::\n\n\n\n### 7. คัด best model ไปตรวจสอบผลลัพธ์ในข้อมูล test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### วิเคราะห์ OLS\ntrain_result |> \n  extract_workflow_set_result(id = \"rec_noint_ols\") |>\n  collect_metrics(summarise = T) |> \n  filter(.metric == \"rsq\") |> \n  arrange(-mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rsq     standard   0.437    15  0.0174 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\n### วิเคราะห์ Ridge Regression\n\ntrain_result |> \n  extract_workflow_set_result(id = \"rec_int_ridge\") |> \n  collect_metrics(summarise = T) |> \n  filter(.metric == \"rsq\") |> \n  arrange(-mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 7\n    penalty .metric .estimator  mean     n std_err .config              \n      <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1 2.48e-10 rsq     standard   0.440    15  0.0222 Preprocessor1_Model01\n 2 1.24e- 9 rsq     standard   0.440    15  0.0222 Preprocessor1_Model02\n 3 4.59e- 8 rsq     standard   0.440    15  0.0222 Preprocessor1_Model03\n 4 1.75e- 7 rsq     standard   0.440    15  0.0222 Preprocessor1_Model04\n 5 3.49e- 6 rsq     standard   0.440    15  0.0222 Preprocessor1_Model05\n 6 4.85e- 5 rsq     standard   0.440    15  0.0222 Preprocessor1_Model06\n 7 3.47e- 4 rsq     standard   0.440    15  0.0222 Preprocessor1_Model07\n 8 2.79e- 3 rsq     standard   0.440    15  0.0222 Preprocessor1_Model08\n 9 6.49e- 2 rsq     standard   0.440    15  0.0222 Preprocessor1_Model09\n10 3.69e- 1 rsq     standard   0.440    15  0.0222 Preprocessor1_Model10\n```\n:::\n\n```{.r .cell-code}\nbest_ridge <- train_result |> \n  extract_workflow_set_result(id = \"rec_int_ridge\") |> \n  show_best(\"rsq\", n = 1)\n\n### วิเคราะห์ KNN algorithm\nknn_result <- train_result |> \n  extract_workflow_set_result(id = \"rec_noint_knn\") |> \n  collect_metrics(summarise = T) |> \n  filter(.metric == \"rsq\") |> \n  arrange(-mean)\n\nbest_knn <- train_result |> \n  extract_workflow_set_result(id = \"rec_noint_knn\") |> \n  show_best(\"rsq\", n = 1)\n\n### วิเคราะห์ Random Forest\n\n\ntrain_result |> \n  extract_workflow_set_result(id = \"rec_noint_rand_forest\") |> \n  collect_metrics(summarise = T) |> \n  filter(.metric == \"rsq\") |> \n  arrange(-mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1     1    12 rsq     standard   0.438    15  0.0169 Preprocessor1_Model06\n 2     2    27 rsq     standard   0.434    15  0.0165 Preprocessor1_Model03\n 3     3     9 rsq     standard   0.434    15  0.0172 Preprocessor1_Model07\n 4     3     4 rsq     standard   0.432    15  0.0186 Preprocessor1_Model04\n 5     2    33 rsq     standard   0.429    15  0.0166 Preprocessor1_Model02\n 6     4    16 rsq     standard   0.428    15  0.0177 Preprocessor1_Model01\n 7     5    24 rsq     standard   0.427    15  0.0192 Preprocessor1_Model09\n 8     5    32 rsq     standard   0.426    15  0.0192 Preprocessor1_Model10\n 9     4    17 rsq     standard   0.425    15  0.0182 Preprocessor1_Model08\n10     6    39 rsq     standard   0.423    15  0.0191 Preprocessor1_Model05\n```\n:::\n\n```{.r .cell-code}\nbest_rf <- train_result |> \n  extract_workflow_set_result(id = \"rec_noint_rand_forest\") |> \n  show_best(\"rsq\", n = 1)\n```\n:::\n\n\n### 8. ประเมินผลใน test data\n\nเมื่อคัดเลือก best model ของแต่ละอัลกอริทึมได้แล้ว จะ train ใหม่กับข้อมูลทั้งหมด เพื่อนำไปตรวจสอบใน test data \n\n\n::: {.cell}\n\n```{.r .cell-code}\nols_trained <- train_result |> \n  extract_workflow(id = \"rec_noint_ols\") |>\n  fit(train)\n\nridge_trained <- train_result |> \n  extract_workflow(id = \"rec_int_ridge\") |>\n  finalize_workflow(best_ridge) |>\n  fit(train)\n\nknn_trained <- train_result |> \n  extract_workflow(id = \"rec_noint_knn\") |>\n  finalize_workflow(best_knn) |>\n  fit(train)\n\nrf_trained <- train_result |> \n  extract_workflow(id = \"rec_noint_rand_forest\") |>\n  finalize_workflow(best_rf) |>\n  fit(train)\n```\n:::\n\n\n\nนำโมเดลทั้งหมดไปทำนาย salary ใน test \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## data preprocessing\ntest_noint <- rec_noint |> \n              bake(test)\n\ntest_int <- rec_int |>\n            bake(test)\n\n\n## ทำนาย\nols_pred <- ols_trained |> \n  extract_fit_parsnip() |>\n  predict(test_noint) |> \n  bind_cols(test_noint) |> \n  select(salary, .pred)\n\nridge_pred <- ridge_trained |> \n  extract_fit_parsnip() |>\n  predict(test_int) |> \n  bind_cols(test_int) |> \n  select(salary, .pred)\n\nknn_pred <- knn_trained |> \n  extract_fit_parsnip() |>\n  predict(test_noint) |> \n  bind_cols(test_noint) |> \n  select(salary, .pred)\n\nrf_pred <- rf_trained |> \n  extract_fit_parsnip() |>\n  predict(test_noint) |> \n  bind_cols(test_noint) |> \n  select(salary, .pred)\n\npred_dat <- bind_rows(\n  ols_pred |> mutate(model = \"ols\"),\n  ridge_pred |> mutate(model = \"ridge\"),\n  knn_pred |> mutate(model = \"knn\"),\n  rf_pred |> mutate(model = \"rf\")\n)\n\npred_dat |> \n  ggplot(aes(x = salary, y = .pred)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F)+\n  facet_wrap(~model, scales = \"fixed\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](regression_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}