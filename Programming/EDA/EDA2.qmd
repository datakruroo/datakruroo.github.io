---
title: "Exploratory Data Analysis Part 2: Clustering"
author: ผศ.ดร.สิวะโชติ ศรีสุทธิยากร </br> 
institute: ภาควิชาวิจัยและจิตวิทยาการศึกษา </br> คณะครุศาสตร์ จุฬาลงกรณ์มหาวิทยาลัย
format: 
  revealjs:
    theme: theme.scss
    width: 1000
    height: 1000
    margin: 0.05
    scrollable: true
    slideNumber: true
    highlight-style: github
    css: my_css.css
    logo: https://github.com/ssiwacho/picture/blob/main/datakruroo.png?raw=true
    footer: 2758615 สมรรถนะสําคัญของการเขียนโปรแกรมวิเคราะห์ข้อมูลทางการศึกษา
editor: visual
---

## 

<br>
<br>

#### `learning_data.csv`

- นักเรียนในชั้นเรียนมีพฤติกรรมการเรียนรู้เป็นอย่างไร สามารถจำแนกได้เป็นกี่กลุ่ม


```{r}
library(tidyverse)
## importing data
data <- read_csv("learning_data2.csv")
## print some of data
glimpse(data , 50)
```





## Clustering {.smaller}

- Unsupervised Learning ที่ใช้ ค้นหากลุ่มที่มีลักษณะร่วมกันตามคุณลักษณะหรือตัวแปรของหน่วยข้อมูล โดยการจัดกลุ่มนี้ช่วยในการแบ่งข้อมูลออกเป็นกลุ่มย่อย ๆ ที่ภายในกลุ่มเดียวกันหน่วยข้อมูลจะมีลักษณะที่คล้ายคลึงกันมากที่สุด และระหว่างกลุ่มหน่วยข้อมูลจะมีความแตกต่างกันมากที่สุด

- เรามักใช้ technique ประเภทนี้ในกรณีที่เราไม่มี label data หรืออยากทำความเข้าใจสภาพของหน่วยข้อมูลตามคุณลักษณะหรือตัวแปรที่กำหนด


  - K-Means

  - Hierarchical Clustering

  - DBSCAN

  - Gaussian Mixture Models


## K-Means Clustering {.smaller}

::: {style="font-size: 80%;"}

1. เลือกจำนวนกลุ่ม (k) ที่ต้องการแบ่งข้อมูลออก

2. สุ่มเลือกหน่วยข้อมูลจากแต่ละกลุ่มใน 1. มาเป็นจุดศูนย์กลางเริ่มต้น (centroids) สำหรับแต่ละกลุ่ม

3. จัดหน่วยข้อมูลลงกลุ่มใหม่ระยะห่างที่ใกล้ที่สุดจาก centroid ใน 2.

  - Euclidean distance 

  - Manhattan distance

  - Cosine Similarity

  - Hamming distance

  - Mahalonoblis distance

**Note :** หน่วยของตัวแปรที่แตกต่างกันอาจเป็นปัจจัยแทรกซ้อนที่ทำให้การคำนวณระยะทางมีความคลาดเคลื่อนดังนั้นก่อนการจัดกลุ่มควรจะต้องมีการ standardized ค่าสังเกตของตัวแปรที่จะนำมาจัดกลุ่มก่อน

4. คำนวณจุดศูนย์กลางใหม่จากการจัดกลุ่มใน 3.โดยหาค่าเฉลี่ยของจุดข้อมูลทั้งหมดในกลุ่มนั้น ๆ และใช้เป็นจุดศูนย์กลางใหม่

5. จัดกลุ่มข้อมูลใหม่อีกครั้งตามจุดศูนย์กลางที่คำนวณในขั้นตอนที่ 4

6. ทำซ้ำขั้นตอนที่ 4 และ 5 จนกว่าจุดศูนย์กลางจะไม่เปลี่ยนแปลงอีก หรือจนกว่าจะถึงจำนวนรอบที่กำหนดไว้ล่วงหน้า

7. เมื่อการทำซ้ำเสร็จสิ้น ผลลัพธ์ที่ได้คือข้อมูลทั้งหมดที่ถูกจัดกลุ่มตามลักษณะที่คล้ายคลึงกันมากที่สุด โดยมีจุดศูนย์กลางที่แสดงถึงตำแหน่งเฉลี่ยของข้อมูลในแต่ละกลุ่ม

<br>

<div class="caption">Reference: https://www.analyticsvidhya.com/blog/2020/02/4-types-of-distance-metrics-in-machine-learning/</div>

:::


## K-Means Clustering

:::: {.columns}

::: {.column width="50%"}

![](img/1-600x575.png){width="80%"}

![](img/3-600x575.png){width="80%"}

:::

::: {.column width="50%"}

![](img/2-600x575.png){width="80%"}

![](img/4_600x575.png){width="80%"}

:::

::::


## Standardized and Normalized Score {.smaller}

:::: {.columns}

::: {.column width="50%"}

- Standardized score
$$
Z = \frac{X - \overline{x}}{SD_x}
$$

:::

::: {.column width="50%"}

- Normalized Score
$$
X_{\text{normalized}} = \frac{X - X_{\text{min}}}{X_{\text{max}} - X_{\text{min}}}
$$

:::
::::




:::: {.columns}

::: {.column width="50%"}


```{r echo=T}
## create standardized function
z_function <- function(x)
  {
    z <- (x-mean(x,na.rm=T))/sd(x,na.rm=T)
    return(z)
  }
data |> 
  select_if(is.numeric) |> 
  mutate_all(z_function) |> 
  pivot_longer(cols = everything()) |> 
  ggplot(aes(x=value))+
  geom_histogram()+
  facet_wrap(~name)
```

:::

::: {.column width="50%"}

```{r echo=T}
## create standardized function
n_function <- function(x)
  {
    n<- (x-min(x,na.rm=T))/diff(range(x,na.rm=T))
    return(n)
  }
data |> 
  select_if(is.numeric) |> 
  mutate_all(n_function) |> 
  pivot_longer(cols = everything()) |> 
  ggplot(aes(x=value))+
  geom_histogram()+
  facet_wrap(~name)
```

:::

::::


## K-Means clustering using R {.smaller}

ในทางปฏิบัติการทำ K-Means clustering ประกอบด้วยขั้นตอนหลัก ได้แก่

1. เตรียมข้อมูลให้เป็น tidydata ตัดค่าสูญหายออกจากชุดข้อมูล เลือกตัวแปรสำหรับจัดกลุ่ม และปรับสเกลของข้อมูลให้เป็นหน่วยมาตรฐาน

2. กำหนดจำนวนกลุ่ม

3. จัดกลุ่มตามอัลกอริทึม K-Means

<br>

#### ตัวอย่างการวิเคราะห์ในชุดข้อมูล `learning_data.csv`

ลองจัดกลุ่มนักเรียนโดยใช้คะแนนความรู้พื้นฐานทางสถิติ และพฤติกรรมในการเรียน ฟังก์ชันสำหรับทำ K-Means clustering ใน R มีหลายตัว ฟังก์ชันพื้นฐานที่ใช้กันอย่างแพร่หลายคือ 

<center>
`kmeans(x, centers)`

</center>


โดยที่ `x` คือ matrix หรือ data.frame ของข้อมูลที่จะใช้ในการจัดกลุ่ม ข้อมูลที่ใช้จะต้องเป็นเชิงปริมาณเท่านั้น และ `centers` คือจำนวนกลุ่มที่ต้องการให้อัลกอริทึมจัดข้อมูล (ค่า k)

## Code Example {.smaller}

**1. เตรียมข้อมูล**
```{r result = T, eval = T, echo = T}
## preparing data
clustering_data <- data |> drop_na() |> 
              select_if(is.numeric) |> 
              select(-research_score) |> 
              mutate_all(z_function)
```

**2. ลองทำ kmeans clustering (k=3)**
```{r result = T, eval = T, echo = T}
### 2. กำหนด k และทำการจัดกลุ่ม
kmeans_result3 <- kmeans(x=clustering_data, centers = 3)
```

**3. Output ที่สำคัญ**
```{r result = T, eval = T, echo = T}
### within Sum Squares
kmeans_result3$withinss

### clustering results
## ผลการจัดกลุ่มของแต่ละหน่วยข้อมูล
cluster3_result <- fitted(kmeans_result3, method = "classes")
cluster3_result
cluster3_result |> table()
```

## Code Example {.smaller}

```{r echo = T}
clustering_data |> 
  bind_cols(cluster3_result) |> 
  rename(cluster = 8) |> 
  pivot_longer(cols = -cluster) |> 
  group_by(cluster, name) |> 
  summarise(mean = mean(value)) |> 
  ggplot(aes(x=mean, y=name))+
  geom_col(aes(fill = mean>0))+
  geom_vline(xintercept = 0, linetype = 2)+
  facet_wrap(~cluster)
```



## Code Example {.smaller}

```{r echo = T}
clustering_data |> 
  bind_cols(cluster3_result) |> 
  rename(cluster = 8) |> 
  pivot_longer(cols = -cluster) |> 
  ggplot(aes(x=value, y=name))+
  geom_boxplot(width = 0.6)+
  geom_jitter(height = 0.15, aes(col = value), alpha = 0.3)+
  geom_vline(xintercept = 0, linetype = 2)+
  facet_wrap(~cluster)
```



## How to choose `k` value? {.smaller}

มีหลายวิธีในการกำหนดจำนวน k ที่เหมาะสม

- theory/prior knowledge

- rule of thumb เช่น $k=\sqrt{n/2}$ 

- Statistical method เช่น Elbow method 

- Cross-validation

<br>

#### Elbow Method 

วิธีการนี้พยายามเลือก k ที่ทำให้ค่าผลรวมกำลังสองภายในกลุ่มต่ำที่สุด

$$
Total_{withinSS} = \sum_{j=1}^k WWS_j
$$

โดยที่ $WSS = \sum_{j=1}^{k} \sum_{i \in C_j} (y_i - \bar{y}_j)^2$

## `for` Loop {.smaller}

for loop เป็นโครงสร้างการวนซ้ำ (iteration) ที่ใช้ในอัลกอริธึมเพื่อทำซ้ำชุดคำสั่งในโปรแกรมเป็นจำนวนครั้งที่กำหนดไว้ล่วงหน้า หรือสำหรับการทำงานกับทุกองค์ประกอบในชุดข้อมูล


```{r eval = F, echo = T}
for (variable in sequence) {
  # คำสั่งที่จะทำในแต่ละรอบการวนซ้ำ
}

```

ตัวอย่างการวนซ้ำ


```{r echo = T}
for (i in 1:5) {
  print(i)
}
```

เราสามารถใช้การวนซ้ำแบบ for นี้มาช่วยให้การทำงานด้าน data science ทำได้ง่ายมากขึ้น


## Elbow Method

```{r echo=T}
set.seed(123)
max_k <- 10
wss <- numeric(max_k)

for(i in 1:max_k)
  {
    results <- kmeans(clustering_data, centers = i)
    wss[i] <- results$tot.withinss 
  }

head(wss)
```


```{r echo=F}
library(patchwork)
p1 <- data.frame(k = 1:max_k, wss = wss) |> 
  ggplot(aes(x=k, y=wss))+
  geom_line()+
  geom_point()+
  xlab("\n number of cluster")+
  ylab("WSS \n")


p2 <- data.frame(k = 1:max_k, wss = wss) |> 
  mutate(diff = -c(0,diff(wss, 1)),
  percent_diff = diff*100/2292) |> 
  filter(k>1) |> 
  ggplot(aes(x=k, y=percent_diff))+
  geom_line()+
  geom_point()+
  ylab("Percentage Different")+
  xlab("number of cluster")

p1/p2
```

## Kmeans Results for 3 clusters


```{r echo=T}

clustering_data |> 
  bind_cols(cluster = kmeans_result3$cluster) |> 
  group_by(cluster) |> 
  summarise_all(mean) |> 
  pivot_longer(cols = -cluster) |> 
  ggplot(aes(x=value, y=name))+
  geom_col(aes(fill = value>0))+
  facet_wrap(~cluster)+
  ggtitle("3 clusters result")

```

## Kmeans Results for 4 clusters

```{r echo=T, fig.width=12}
kmeans_result4 <- kmeans(x=clustering_data, centers = 4)

clustering_data |> 
  bind_cols(cluster = kmeans_result4$cluster) |> 
  group_by(cluster) |> 
  summarise_all(mean) |> 
  pivot_longer(cols = -cluster) |> 
  ggplot(aes(x=value, y=name))+
  geom_col(aes(fill = value>0))+
  facet_wrap(~cluster, ncol=4)+
  ggtitle("4 clusters result")

```


## Kmeans Results for 5 clusters

```{r echo=T, fig.width=12}
kmeans_result5 <- kmeans(x=clustering_data, centers = 5)

clustering_data |> 
  bind_cols(cluster = kmeans_result5$cluster) |> 
  group_by(cluster) |> 
  summarise_all(mean) |> 
  pivot_longer(cols = -cluster) |> 
  ggplot(aes(x=value, y=name))+
  geom_col(aes(fill = value>0))+
  facet_wrap(~cluster)+
  ggtitle("4 clusters result")

```

## new generation `for loop`

:::: {.columns}

::: {.column width="20%"}

![](img/logo.png){width="100%"}

:::

::: {.column width="80%"}

<br>

```
map(.x, .f)
```
:::

::::

```{r echo=T}
wss_cal <- function(data,k) {
  kmeans(data , centers = k, nstart = 10)$tot.withinss
}

k<-1:10
wss_results <- map(.x = k, .f = ~wss_cal(clustering_data, .x))
wss_results |> unlist() |> head()
```


```{r}
plot(wss_results |> unlist(), type = "b")
```