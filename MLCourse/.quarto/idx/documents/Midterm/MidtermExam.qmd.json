{"title":"Midterm Examination","markdown":{"yaml":{"title":"Midterm Examination","date":"6 Apr 2023","toc":true,"toc-depth":3,"toc-title":"สารบัญ","theme":"default"},"headingText":"สถานการณ์","containsRefs":false,"markdown":"\n\n\nจงใช้สถานการณ์ที่กำหนดให้เพื่อตอบคำถาม\n\nสมมุติว่าหน่วยงานทางการศึกษาแห่งหนึ่งได้มาขอคำปรึกษากับนิสิตเกี่ยวกับการใช้ประโยชน์จากฐานข้อมูลนักเรียนของหน่วยงาน ฐานข้อมูลดังกล่าวประกอบด้วยข้อมูลด้านภูมิหลัง พฤติกรรมการเรียนรู้และผลการเรียนของนักเรียนในรายวิชา คณิตศาสตร์ และภาษาอังกฤษ ทั้งนี้หน่วยงานได้ export ชุดข้อมูลออกมาเป็นไฟล์ CSV\n\n### 1.1 นำชุดข้อมูลเข้าและสำรวจข้อมูลเบื้องต้น\n\n```{r message=F}\nlibrary(tidyverse)\ndat1<-read.csv(\"Math_miss.csv\")\ndat2<-read.csv(\"Eng_miss.csv\")\n```\n\nสำรวจชุดข้อมูลเบื้องต้น พบว่าข้อมูลทั้งสองชุดเก็บข้อมูลของตัวแปรเดียวกัน (ลองเขียนคำสั่ง `table(names(dat1)==names(dat2))`ส่วนที่แตกต่างกันคือคะแนน `PreTest` และ `Ach` ที่เป็นความรู้พื้นฐานและผลสัมฤทธิ์ทางการเรียนคนละรายวิชากัน\n\nคราวนี้มาพิจารณาตัวแปรภายในชุดข้อมูล จะเห็นว่าสามารถจัดกลุ่มตัวแปร โดยใช้บริบทของข้อมูลเป็นเกณฑ์ดังนี้\n\n+--------------------------------------------+--------------------------------------------------+\n| **กลุ่ม**                                    | **ตัวแปร**                                        |\n+--------------------------------------------+--------------------------------------------------+\n| 1.  **ภูมิหลังทางบ้านของนักเรียน**               | -   ภูมิลำเนา (`location`)                         |\n|                                            |                                                  |\n|                                            | -   จำนวนพี่น้อง (`famsize`)                        |\n|                                            |                                                  |\n|                                            | -   สถานะครอบครัว (`ParentStat`)                  |\n|                                            |                                                  |\n|                                            | -   ผู้ปกครองของนักเรียน (`StuParent`)               |\n|                                            |                                                  |\n|                                            | -   การศึกษาของมารดา (`MomEdu`)                   |\n|                                            |                                                  |\n|                                            | -   การศึกษาของบิดา (`DadEdu`)                     |\n|                                            |                                                  |\n|                                            | -   อาชีพมารดา (`MomJob`)                         |\n|                                            |                                                  |\n|                                            | -   อาชีพบิดา (`DadJob`)                           |\n|                                            |                                                  |\n|                                            | -   ความสัมพันธ์ภายในครอบครัว (`fam_relation`)       |\n|                                            |                                                  |\n|                                            | -   บ้านมี internet มั้ย (`internet`)                |\n|                                            |                                                  |\n|                                            | -   ระยะเวลาเดินทางจากบ้านมาโรงเรียน (`traveltime`) |\n+--------------------------------------------+--------------------------------------------------+\n| 2.  **ภูมิหลังและการสนับสนุนของโรงเรียน**        | -   โรงเรียนที่นักเรียนสังกัด (`school`)                |\n|                                            |                                                  |\n|                                            | -   การได้รับทุนสนับสนุนทางการศึกษา (`scholarship`)    |\n+--------------------------------------------+--------------------------------------------------+\n| 3.  **ภูมิหลังและพฤติกรรมด้านการเรียนของนักเรียน** | -   เพศ (`gender`)                               |\n|                                            |                                                  |\n|                                            | -   อายุ (`age`)                                  |\n|                                            |                                                  |\n|                                            | -   เวลาที่ใช้ทบทวนบทเรียน (`readingtime`)           |\n|                                            |                                                  |\n|                                            | -   จำนวนเวลาว่างหลังเลิกเรียน (`freetime`)          |\n|                                            |                                                  |\n|                                            | -   จำนวนครั้งที่เคยสอบตก (`fail`)                   |\n|                                            |                                                  |\n|                                            | -   การมีทำกิจกรรมชมรม/งานอดิเรก (`club_act`)       |\n|                                            |                                                  |\n|                                            | -   เคยเรียนอนุบาลหรือไม่ (`nursery`)                |\n|                                            |                                                  |\n|                                            | -   อยากเรียนต่อระดับอุดมศึกษามั้ย (`higher`)           |\n|                                            |                                                  |\n|                                            | -   กำลังมีแฟนมั้ย (`InLove`)                        |\n|                                            |                                                  |\n|                                            | -   ความบ่อยในการไปเที่ยวกับเพื่อน (`goout`)           |\n|                                            |                                                  |\n|                                            | -   การดื่มสุรา (`Drink_alc`)                       |\n|                                            |                                                  |\n|                                            | -   สุขภาพโดยรวม (`health`)                       |\n|                                            |                                                  |\n|                                            | -   การขาดเรียน (`absences`)                      |\n|                                            |                                                  |\n|                                            | -   ความรู้พื้นฐาน (`PreTest`)                       |\n+--------------------------------------------+--------------------------------------------------+\n| 4.  **ผลการเรียน**                          | -   ผลสัมฤทธิ์ทางการเรียน (`Ach`)                    |\n+--------------------------------------------+--------------------------------------------------+\n\n### 1.2 รวมชุดข้อมูลเข้าด้วยกัน\n\nความรู้พื้นฐานและผลสัมฤทธิ์ในรายวิชา Math และ Eng ไม่เหมือนกันดังนั้นต้องสร้างตัวแปรใหม่อีกตัวเพื่อแยกคะแนนของรายวิชาทั้งสอง ดังนี้\n\n```{r}\ndat1$subject <- \"Math\"\ndat2$subject <- \"Eng\"\n### merge dat1 and dat2 together using `bind_rows()`\ndat <- bind_rows(dat1, dat2)\nglimpse(dat, width=50)\n```\n\nจากการสำรวจชุดข้อมูลข้างต้นจะเห็นว่าสถานะของตัวแปรจัดประเภทภายในชุดข้อมูลยังไม่เหมาะสม จึงมีการปรับสถานะให้เหมาะสม ดังนี้\n\n```{r message=F}\nlibrary(tidymodels)\ndat_preproc <- recipe(Ach~., data=dat) %>%\n  step_string2factor(all_string_predictors()) %>%\n  prep(NULL) %>%\n  juice()\ndat_preproc %>% head()\n```\n\n### 1.3 ตรวจสอบค่าสูญหายภายในชุดข้อมูล\n\nการตรวจสอบค่าสูญหายสามารถทำได้หลายวิธีการ ตั้งแต่การใช้ฟังก์ชันทางสถิติพื้นฐานของ R ใช้ทัศนภาพข้อมูล รวมไปถึงมี package เฉพาะหลายตัวที่ถูกพัฒนาขึ้นเพื่อแก้ปัญหาดังกล่าว เนื้อหาส่วนนี้จะใช้ package naniar\n\n```{r}\n#install.packages(\"naniar\")\nlibrary(naniar)\n```\n\n#### ภายในชุดข้อมูลมี missing values เกิดขึ้นมั้ย?\n\nฟังก์ชันง่าย ๆ สำหรับสำรวจค่าสูญหาย เช่น `miss_var_summary()` หรือ `miss_var_table()` เพื่อสำรวจค่าสูญหายในตัวแปร หรือ `miss_case_summary()` หรือ `miss_case_table()` เพื่อสำรวจค่าสูญหายในหน่วยข้อมูล ดังผลการวิเคราะห์ด้านล่าง\n\nจากผลการวิเคราะห์จะเห็นว่ามีตัวแปรจำนวน 3 ตัวในชุดข้อมูลที่พบค่าสูญหาย ได้แก่ `traveltime`, `fam_relation` และ `PreTest` โดยพบค่าสูญหายในแต่ละตัวแปรคิดเป็นร้อยละ 14.2, 12.5 และ 11.3 ตามลำดับ นอกจากนี้เมื่อพิจารณาในมิติของหน่วยข้อมูลพบว่า รูปแบบการสูญหายของข้อมูลในหน่วยข้อมูลมีแบบเดียวคือ มีการสูญหายหนึ่งตัวแปรต่อหน่วยข้อมูล โดยมีหน่วยข้อมูลที่พบค่าสูญหายทั้งหมด 396 หน่วย คิดเป็นร้อยละ 37.93\n\n```{r}\nmiss_var_summary(dat)\nmiss_case_table(dat)\n```\n\nฟังก์ชัน `vis_miss()` สามารถใช้เพื่อสร้างทัศนภาพของเมทริกซ์ค่าสูญหาย ซึ่งช่วยให้เห็นภาพรวมของค่าสูญหายภายในชุดข้อมูลทั้งในมิติของตัวแปรและหน่วยข้อมูลไปพร้อม ๆ กัน ดังนี้ จากรูปจะเห็นว่า มีค่าสูญหายเกิดขึ้นคิดเป็นร้อยละ 1.3 ของค่าสังเกตทั้งหมดในชุดข้อมูล\n\n```{r}\nvis_miss(dat, cluster = TRUE, sort_miss = TRUE)\n```\n\nจากสภาพข้างต้นจะเห็นว่าหากผู้วิเคราะห์มีการใช้ตัวแปร ได้แก่ `traveltime`, `fam_relation` และ `PreTest` ในการวิเคราะห์และเลือกใช้วิธีการแก้ปัญหาค่าสูญหายด้วยการตัดข้อมูล ได้แก่ listwise หรือ pairwise deletion จะทำให้ผู้วิเคราะห์สูญเสียหน่วยข้อมูลในการวิเคราะห์ไปได้มากที่สุดถึง 396 หน่วย (ร้อยละ 37.93) ซึ่งเป็นปริมาณที่มีนัยสำคัญต่อความถูกต้องของผลการวิเคราะห์ที่จะได้\n\n### 1.4 ตรวจสอบกลไกการสูญหายของข้อมูล\n\nจากสภาพการสูญหายของข้อมูลข้างต้น จึงจำเป็นที่จะต้องมีการวิเคราะห์และแก้ไขด้วยการทดแทนค่าสูญหาย เนื้อหาส่วนนี้จะใช้การตรวจสอบ 2 วิธีการ วิธีการแรกจะตรวจสอบกลไกการสูญหายด้วย PCA และวิธีการที่สองจะใช้ logistic regression เพื่อตรวจสอบ รายละเอียดมีดังนี้ั\n\n#### การตรวจสอบกลไกค่าสูญหายด้วย PCA\n\nผู้วิเคราะห์แปลงข้อมูลตัวแปรทั้งหมดในชุดข้อมูลให้เป็นตัวแปรแบบให้คะแนนสองค่า โดยมีค่าเท่ากับ 1 เมื่อมีข้อมูล และมีค่าเท่ากับ 0 เมื่อเป็นข้อมูลสูญหาย ผลลัพธ์ที่ได้จะได้เมทริกซ์ค่าสูญหาย (D) ดังนี้\n\n```{r}\nhead(dat_preproc)\nglimpse(dat_preproc, width=50)\nmiss_var_summary(dat_preproc)\n\ndat_preproc %>%\n  bind_shadow() %>%\n  glimpse()\n\n\nna<-function(x){\n  y<-ifelse(x==\"NA\",1,0)\n  return(y)\n}\nmissing <- dat_preproc %>% \n  bind_shadow() %>%\n  dplyr::select(contains(\"NA\")) %>%\n  mutate_all(na)\nmissing %>% dplyr::select(traveltime_NA, fam_relation_NA, PreTest_NA) \n```\n\nจากนั้นดำเนินการวิเคราะห์องค์ประกอบหลัก (PCA) โดยใช้ binary matrix ดังกล่าวเป็นข้อมูลนำเข้า ผลการวิเคราะห์ที่ใช้พิจารณามีด้านล่างได้แก่ biplot และ factor score plot ผลการวิเคราะห์สรุปได้ดังนี้\n\nจากค่า eigen value และ biplot พบว่า องค์ประกอบหลักทั้งสองสามารถอธิบายความแปรปรวนของค่าสูญหายในตัวแปรทั้ง 3 ได้คิดเป็นร้อยละ 76.29 โดยที่องค์ประกอบหลักที่ 1 สร้างจากการสูญหายใน `travel_time` เป็นหลัก คิดเป็นร้อยละ `r round(0.8473^2*100,2)` รองลงมาคือการสูญหายใน `fam_relation` (ร้อยละ `r 0.6048^2*100`) ส่วนองค์ประกอบหลักที่ 2 สร้างจากการสูญหายใน `PreTest` เป็นหลัก คิดเป็นร้อยละ `r 0.8375^2*100`\n\nจาก factor score plot พบว่า หน่วยข้อมูลมีค่า factor score ที่รวมกลุ่มกันโดยจำแนกเป็น 4 กลุ่ม กลุ่มแรกอยู่บริเวณจุดกำเนิดแสดงถึงหน่วยข้อมูลที่มีข้อมูลสมบูรณ์ อีก 3 กลุ่มที่เหลือมีค่า factor score ที่แตกต่างจาก 0 แสดงถึงการมีค่าสูญหาย ซึ่งจำแนกเป็น 3 รูปแบบตามตัวแปรที่มีค่าสูญหาย ผลการวิเคราะห์นี้ยังบ่งชี้ว่ากลไกการสูญหายของข้อมูลมีแนวโน้มเป็นแบบ MAR\n\n```{r}\noptions(scipen = 999)\n```\n\n```{r message=F, fig.width=9, warning=F}\nlibrary(FactoMineR)\nlibrary(gridExtra)\n# do PCA\npca_result<-PCA(missing, graph = F)\npca_result$eig\n\n# eigen values and Cumulative percentage of variance\nround(pca_result$eig %>% head(),4)\n# factor loading matrix\nround(pca_result$var$coord %>% data.frame() %>% drop_na(),4) %>%\n  filter(Dim.1!=0)\n# access factor scores (coordinate of individuals)\np1 <- plot(pca_result, choix = \"var\")\nmissing_factorscore <- pca_result$ind$coord\np2 <- missing_factorscore %>% data.frame() %>%\n  ggplot(aes(x = Dim.1, y=Dim.2))+\n  geom_jitter(width=0.3, height=0.3, alpha=0.5)+\n  ggtitle(\"factor score plot\")\ngrid.arrange(p1,p2,ncol=2)\n```\n\nตัวแรกเรียกว่า biplot ใช้นำเสนอความสัมพันธ์ระหว่างองค์ประกอบหลัก (2 องค์ประกอบแรก) กับตัวแปรเดิม ว่ามีความหมายอย่างไร การพิจารณาแผนภาพดังกล่าวให้พิจารณาจาก\n\n1.  **ความยาวของ factor loading vecto**r ของตัวแปรบ่งบอกความสำคัญของตัวแปรสังเกตได้แต่ละตัวในการสร้างองค์ประกอบหลัก\n2.  **ภาพฉาย (projection) ของ factor loading vector บนแกนขององค์ประกอบหลัก** ใช้แสดงความสำคัญของตัวแปรสังเกตได้แต่ละตัวภายในแต่ละองค์ประกอบ\n3.  **มุมระหว่างเวกเตอร์ของ factor loading** แสดงความสัมพันธ์ระหว่างตัวแปรสังเกตได้ จากรูปจะเห็นว่าการสูญหายในตัวแปรทั้งสามมีแนวโน้มที่จะไม่สัมพันธ์กัน\n4.  **การรวมกลุ่มของตำแหน่งของ factor loading บนแผนภาพ** ตัวแปรสังเกตได้ที่อยู่ใกล้กันบนแผนภาพมีแนวโน้มที่จะสัมพันธ์กัน\n\nผู้วิเคราะห์ดำเนินการวิเคราะห์เพื่อยืนยันกลไกลการสูญหายแบบ MAR โดยใช้ logistic regression อีกครั้งหนึ่ง การวิเคราะห์นี้จำแนกเป็น 3 โมเดล ตามตัวแปรที่มีค่าสูญหายแต่ละตัว ดังนี้\n\n```{r echo=F}\ndat_na <- dat_preproc%>%bind_shadow() %>%\n  dplyr::select(school:Ach, \n         PreTest_NA, traveltime_NA, fam_relation_NA) %>%\n  mutate(MomEdu = factor(MomEdu, levels=c(0,1,2,3,4),\n         labels=c(\"none\",\"primary\",\"highsch1\",\"highsch2\",\"grad\")),\n         DadEdi = factor(DadEdi, levels=c(0,1,2,3,4),\n         labels=c(\"none\",\"primary\",\"highsch1\",\"highsch2\",\"grad\")),\n         traveltime = factor(traveltime, levels=c(1,2,3,4),\n                             labels=c(\"<15mins\",\n                                      \"15-30mins\",\n                                      \"30-60mins\",\n                                      \">60mins\")),\n         readingtime = factor(readingtime, levels=c(1,2,3,4),\n                              labels=c(\"<2hours\",\n                                       \"2-5hours\",\n                                       \"5-10hours\",\n                                       \">10hours\")),\n         fam_relation = factor(fam_relation, levels=c(1,2,3,4,5),\n                               labels=c(\"worst\",\n                                        \"bad\",\n                                        \"fair\",\n                                        \"good\",\n                                        \"very good\")),\n         freetime = factor(freetime, levels=c(1,2,3,4,5),\n                           labels=c(\"very little\",\n                                    \"litter\",\n                                    \"moderate\",\n                                    \"high\",\n                                    \"highest\")),\n         goout = factor(goout, levels=c(1,2,3,4,5),\n                           labels=c(\"very little\",\n                                    \"litter\",\n                                    \"moderate\",\n                                    \"high\",\n                                    \"highest\")),\n         Drink_alc = factor(Drink_alc, levels=c(1,2,3,4,5),\n                            labels=c(\"very little\",\n                                    \"litter\",\n                                    \"moderate\",\n                                    \"high\",\n                                    \"highest\")),\n         health = factor(health, levels=c(1,2,3,4,5),\n                         labels=c(\"worst\",\n                                        \"bad\",\n                                        \"fair\",\n                                        \"good\",\n                                        \"very good\"))\n  )\n```\n\n```{r message=F}\n# defined preprocess\nrec1 <- recipe(PreTest_NA ~., data=dat_na) %>%\n  step_rm(traveltime_NA,fam_relation_NA, PreTest) %>%\n  step_normalize(all_numeric_predictors()) %>%\n  step_impute_knn(traveltime, fam_relation) %>%\n  step_dummy(all_nominal_predictors())\nrec2 <- recipe(traveltime_NA ~., data=dat_na) %>%\n  step_rm(PreTest_NA, fam_relation_NA, traveltime) %>%\n  step_normalize(all_numeric_predictors())%>%\n  step_impute_knn(PreTest, fam_relation) %>%\n  step_dummy(all_nominal_predictors())\nrec3<- recipe(fam_relation_NA ~., data=dat_na) %>%\n  step_rm(PreTest_NA, traveltime_NA, fam_relation) %>%\n  step_normalize(all_numeric_predictors())%>%\n  step_impute_knn(traveltime, PreTest) %>%\n  step_dummy(all_nominal_predictors())\n# defined model\nlogistic_mod <- logistic_reg(penalty = tune(),\n                             mixture = tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n# defined workflow\nfolds<-vfold_cv(data = dat_na, v=10)\nlibrary(doMC)\nregisterDoMC(cores=15)\nna_result1 <- workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(logistic_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\nna_result2 <- workflow() %>%\n  add_recipe(rec2) %>%\n  add_model(logistic_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\nna_result3 <- workflow() %>%\n  add_recipe(rec3) %>%\n  add_model(logistic_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\n\nbest1<-show_best(na_result1, n=1, metric = \"roc_auc\")\nbest2<-show_best(na_result2, n=1, metric = \"roc_auc\")\nbest3<-show_best(na_result3, n=1, metric = \"roc_auc\")\nbest1 %>% bind_rows(best2,best3)\n```\n\nผลการวิเคราะห์ข้างต้นแสดงให้เห็นว่าโมเดลทำนายค่าสูญหายในตัวแปรทั้งสามมีประสิทธิภาพการทำนายพิจารณาจากค่า roc_auc อยู่ในช่วงร้อยละ 57 - 69 ซึ่งแสดงว่ามีตัวแปรในชุดข้อมูลที่สามารถทำได้การสูญหายในตัวแปรทั้งสามได้พอสมควร นอกจากนี้เมื่อพิจารณาผลการวิเคราะห์ด้วย Variable Importance Plots พบว่ามีตัวแปรหลายตัวที่มีความสัมพันธ์กับการสูญหายในตัวแปรทั้ง 3 อย่างมีนัยสำคัญ ([vip package](https://cran.r-project.org/web/packages/vip/vignettes/vip-introduction.pdf)) จากผลการวิเคราะห์ส่วนนี้สรุปได้ว่า การสูญหายในตัวแปรทั้ง 3 มีแนวโน้มเป็นแบบ MAR\n\n```{r}\n## finalized best model\nna1 <-  workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(logistic_mod) %>%\n  finalize_workflow(best1) %>%\n  fit(dat_na)\n\nna2 <-  workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(logistic_mod) %>%\n  finalize_workflow(best1) %>%\n  fit(dat_na)\n\nna3 <-  workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(logistic_mod) %>%\n  finalize_workflow(best1) %>%\n  fit(dat_na)\n\n# create Variable Importance Plots\nlibrary(vip)\np1<-vip(na1%>%extract_fit_engine(),geom=\"point\")+\n  theme(text = element_text(size=5))\np2<-vip(na2%>%extract_fit_engine(),geom=\"point\")+\n  theme(text = element_text(size=5))\np3<-vip(na3%>%extract_fit_engine(),geom=\"point\")+\n  theme(text = element_text(size=5))\ngrid.arrange(p1,p2,p3, ncol=3)\n```\n\n### 1.5 การทดแทนค่าสูญหาย (แถม)\n\nในกรณีที่ค่าสูญหายมีจำนวนมาก วิธีการตัดข้อมูลออกจากการวิเคราะห์ หรือการทดแทนค่าสูญหายด้วยค่าเฉลี่ยจะไม่ใช่วิธีการที่ควรนำมาใช้แก้ปัญหา ภายใต้สถานการณ์นี้ผู้วิเคราะห์ควรพิจารณาปัจจัยตัวที่สองประกอบการเลือกวิธีการแก้ปัญหาที่เหมาะสมด้วย ได้แก่ กลไกการสูญหายของข้อมูล โดยหากกลไกการสูญหายเป็นแบบ MAR ผู้วิเคราะห์สามารถเลือกใช้เทคนิคได้หลายตัว เช่น การทดแทนค่าสูญหายด้วยการวิเคราะห์การถดถอย การทดแทนค่าสูญหายด้วยอัลกอริทึม K-nearest neighbors การทดแทนค่าสูญหายแบบหลายค่า การทดแทนค่าสูญหายด้วยวิธีการแบบเบย์ และการทดแทนค่าสูญหายด้วยอัลกอริทึมการเรียนรู้ของเครื่องอื่น ๆ\n\n```{r message=F}\nlibrary(simputation)\nimputed_knn <- recipe(Ach ~., data=dat_na) %>%\n  step_rm(traveltime_NA,fam_relation_NA, PreTest_NA) %>%\n  step_impute_knn(traveltime, fam_relation, PreTest) %>%\n  prep(NULL) %>%\n  juice()\n\nimputed_bag <- recipe(Ach ~., data=dat_na) %>%\n  step_rm(traveltime_NA,fam_relation_NA, PreTest_NA) %>%\n  step_impute_bag(traveltime, fam_relation, PreTest) %>%\n  prep(NULL) %>%\n  juice()\n```\n\n```{r echo=F}\nfull_math<-read.csv(\"Math.csv\")\nfull_eng<-read.csv(\"Eng.csv\")\nfull<-full_math%>%bind_rows(full_eng)\nfull_preproc <- full %>%\n   mutate(MomEdu = factor(MomEdu, levels=c(0,1,2,3,4),\n         labels=c(\"none\",\"primary\",\"highsch1\",\"highsch2\",\"grad\")),\n         DadEdi = factor(DadEdi, levels=c(0,1,2,3,4),\n         labels=c(\"none\",\"primary\",\"highsch1\",\"highsch2\",\"grad\")),\n         traveltime = factor(traveltime, levels=c(1,2,3,4),\n                             labels=c(\"<15mins\",\n                                      \"15-30mins\",\n                                      \"30-60mins\",\n                                      \">60mins\")),\n         readingtime = factor(readingtime, levels=c(1,2,3,4),\n                              labels=c(\"<2hours\",\n                                       \"2-5hours\",\n                                       \"5-10hours\",\n                                       \">10hours\")),\n         fam_relation = factor(fam_relation, levels=c(1,2,3,4,5),\n                               labels=c(\"worst\",\n                                        \"bad\",\n                                        \"fair\",\n                                        \"good\",\n                                        \"very good\")),\n         freetime = factor(freetime, levels=c(1,2,3,4,5),\n                           labels=c(\"very little\",\n                                    \"litter\",\n                                    \"moderate\",\n                                    \"high\",\n                                    \"highest\")),\n         goout = factor(goout, levels=c(1,2,3,4,5),\n                           labels=c(\"very little\",\n                                    \"litter\",\n                                    \"moderate\",\n                                    \"high\",\n                                    \"highest\")),\n         Drink_alc = factor(Drink_alc, levels=c(1,2,3,4,5),\n                            labels=c(\"very little\",\n                                    \"litter\",\n                                    \"moderate\",\n                                    \"high\",\n                                    \"highest\")),\n         health = factor(health, levels=c(1,2,3,4,5),\n                         labels=c(\"worst\",\n                                        \"bad\",\n                                        \"fair\",\n                                        \"good\",\n                                        \"very good\"))\n  )\n```\n\nผู้วิเคราะห์ทดลองเปรียบเทียบผลการทดแทนค่าสูญหายจากวิธี Bagged Tree\n\n```{r}\ncor(full_preproc$PreTest, imputed_bag$PreTest)\ntable(full_preproc$traveltime, imputed_bag$traveltime)\ntable(full_preproc$fam_relation, imputed_bag$fam_relation)\n```\n\n### 2.1 จัดกลุ่มนักเรียนด้วยตัวแปรที่มี\n\nผลการวิเคราะห์ส่วนนี้แสดงการจัดกลุ่มนักเรียนด้วยอัลกอริทึม kprototype อัลกอริทึมดังกล่าวใช้สำหรับจัดกลุ่มข้อมูลเหมือนกับ kmeans แต่มีจุดเด่นคือสามารถใช้จัดกลุ่มข้อมูลโดยอิงกับข้อมูลหลากหลายประเภทพร้อมกัน แตกต่างจาก kmeans ที่สามารถใช้กับข้อมูลเชิงปริมาณเท่านั้น อัลกอริทึมนี้นำเสนอโดย Zhexue Huang (1997) สามารถมองเป็นอัลกอริทึมที่รวมกันระหว่าง kmeans และ kmodes clustering รายละเอียดของอัลกอริทึมเป็นดังนี้\n\n1.  กำหนดจำนวนกลุ่ม ให้มีค่าเท่ากับ k\n2.  แบ่งชุดข้อมูลออกเป็น k ส่วนอย่างสุ่ม (เรียกว่า initial prototype)\n3.  คำนวณคะแนนความแตกต่าง (dissimilarity) ระหว่างหน่วยข้อมูลแต่ละหน่วยกับ initial prototype ที่สร้างขึ้นในข้อ 2. ทั้งนี้คะแนนความแตกต่างดังกล่าวจะต้องคำนวณจากข้อมูลเชิงปริมาณและจัดประเภท คะแนนจึงคำนวณจากค่าเฉลี่ยถ่วงน้ำหนักระหว่างระยะห่างของข้อมูลเชิงปริมาณ เช่น euclidean distance กับระยะห่างของข้อมูลจัดประเภท เช่น Hamming distance คะแนนความแตกต่างดังกล่าวเป็นดังนี้ $Dis(x1,x2) = w \\times Euclid(x1_{cont},x2_{cont}) + (1-w) \\times Hamming(x1_{cat}, x2_{cat})$\n4.  ย้ายกลุ่มให้กับหน่วยข้อมูลไปยัง prototype ที่มีคะแนนความแตกต่างต่ำที่สุด\n5.  ทวนซ้ำขั้น 3 และ 4 จนกระทั้งไม่มีการเปลี่ยนกลุ่มของหน่วยข้อมูล หรือครบจำนวนรอบการทวนซ้ำที่กำหนด\n\n**หมายเหตุ** การคำนวณคะแนนความแตกต่างในขั้นที่ 3 สามารถเลือกใช้ระยะห่างแบบ Gower ก็ได้ ระยะห่างนี้ถูกนำเสนอโดย John C. Gower (1971) เพื่อใช้เปรียบเทียบความแตกต่างระหว่างหน่วยข้อมูลจากตัวแปรที่มีหลายประเภท\n\n**Gower distance (x, y)** = $\\frac{\\sum w_i * d_i(x, y)}{\\sum w_i}$\n\nเมื่อ $x$ และ $y$ คือหน่วยข้อมูล, $w_i$ คือน้ำหนักของตัวแปรที่ i (ค่าเริ่มต้นเท่ากับ 1.00) และ $d_i(x,y)$ คือความแตกต่าง/ระยะห่าง ระหว่าง $x$ กับ $y$ ภายใต้ตัวแปรที่ i\n\n> The dissimilarity \\$d_i(x, y)\\$ is calculated differently for different data types:\n>\n> 1.  **Continuous variables**: The dissimilarity is the normalized absolute difference between the two data points:\n>\n>     $d_i(x, y)$ = $\\frac{|x_i - y_i|}{\\max(x_i) - \\min(x_i)}$\n>\n> 2.  **Ordinal variables**: The dissimilarity is the normalized absolute difference between the two data points, considering the variable's rank:\n>\n>     $d_i(x, y)$ = $\\frac{|\\text{rank}(x_i) - \\text{rank}(y_i)|}{\\max(\\text{rank}(x_i)) - \\min(\\text{rank}(x_i))}$\n>\n> 3.  **Categorical variables**: The dissimilarity is 0 if $x_i = y_i$, and 1 otherwise:\n>\n>     $d_i(x, y)$ = $\\begin{cases} 1 & \\text{if } x_i \\neq y_i \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n```{r message=F, results=F}\nlibrary(FactoMineR)\nlibrary(factoextra)\nlibrary(ggrepel)\nlibrary(cluster)\n#do cluster analysis with mixed variable\nlibrary(clustMixType)\n\nk_range <- 2:10\ntot_withinSS <- numeric(length(k_range))\nsil_scores <- numeric(length(k_range))\n\nimputed_bag_scaled<-recipe(Ach~.,data=imputed_bag) %>%\n  step_normalize(all_numeric()) %>%\n  prep(NULL) %>%\n  juice()\n\ngower_dist <- daisy(imputed_bag_scaled, metric = \"gower\")\n\nfor(k in k_range){\n  kproto_res <- kproto(imputed_bag_scaled, k)\n  tot_withinSS[k-1]<-kproto_res$tot.withinss\n  sil_scores[k-1]<-mean(silhouette(kproto_res$cluster,\n                                   gower_dist)[,3])\n}\n# Plot the total within-cluster sum of squares for each k\nplot(k_range, tot_withinSS, type = \"b\", xlab = \"Number of clusters (k)\", ylab = \"Total within-cluster sum of squares\", main = \"Elbow Method\")\n\n# Plot the average silhouette width for each k\nplot(k_range, sil_scores, type = \"b\", xlab = \"Number of clusters (k)\", ylab = \"Average silhouette width\", main = \"Silhouette Method\")\n```\n\nผลการวิเคราะห์ข้างต้นแสดงให้เห็นว่า จำนวนกลุ่มที่เหมาะสมน่าจะอยู่ในช่วง 2-4 กลุ่ม ขั้นตอนต่อไปคือการวิเคราะห์ profile ของแต่ละกลุ่ม เพื่อพิจารณาเลือกจำนวนกลุ่มที่เหมาะสมอีกครั้งหนึ่ง ผลการวิเคราะห์ที่ได้พบว่า...\n\n```{r}\ncluster_result2 <- kproto(imputed_bag, k=2)\ncluster_result3 <- kproto(imputed_bag, k=3)\ncluster_result4 <- kproto(imputed_bag, k=4)\n\nimputed_bag$clus2 <- cluster_result2$cluster\nimputed_bag$clus3 <- cluster_result3$cluster\nimputed_bag$clus4 <- cluster_result4$cluster\n\n# preprocessing\nrec_cluster2 <- recipe(clus2 ~., data=imputed_bag) %>%\n  step_rm(clus3, clus4) %>%\n  step_mutate(clus2 = factor(clus2)) %>%\n  step_normalize(all_numeric_predictors())\n\nrec_cluster3 <- recipe(clus3 ~., data=imputed_bag) %>%\n  step_rm(clus2, clus4) %>%\n  step_mutate(clus3 = factor(clus3)) %>%\n  step_normalize(all_numeric_predictors())\n\nrec_cluster4 <- recipe(clus4 ~., data=imputed_bag) %>%\n  step_rm(clus2, clus3) %>%\n  step_mutate(clus4 = factor(clus4)) %>%\n  step_normalize(all_numeric_predictors())\n\n# defined model\nrf_mod <- rand_forest(mtry=tune(),\n                      trees = 500,\n                      min_n = tune()) %>%\n  set_engine(\"ranger\", importance = \"permutation\") %>%\n  set_mode(\"classification\")\n\n# defined workflow\nfolds<-vfold_cv(data = imputed_bag, v=10)\nlibrary(doMC)\nregisterDoMC(cores=15)\ncluster2_result <- workflow() %>%\n  add_recipe(rec_cluster2) %>%\n  add_model(rf_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\ncluster3_result <- workflow() %>%\n  add_recipe(rec_cluster3) %>%\n  add_model(rf_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\ncluster4_result <- workflow() %>%\n  add_recipe(rec_cluster4) %>%\n  add_model(rf_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\n\n\n\nbest1<-show_best(cluster2_result, n=1, metric = \"roc_auc\")\nbest2<-show_best(cluster3_result , n=1, metric = \"roc_auc\")\nbest3<-show_best(cluster4_result , n=1, metric = \"roc_auc\")\n\nbest1 %>% bind_rows(best2, best3)\n```\n\n```{r}\n## finalized best model\nclus2 <-  workflow() %>%\n  add_recipe(rec_cluster2) %>%\n  add_model(rf_mod) %>%\n  finalize_workflow(best1) %>%\n  fit(imputed_bag)\n\nclus3 <-  workflow() %>%\n  add_recipe(rec_cluster3) %>%\n  add_model(rf_mod) %>%\n  finalize_workflow(best2) %>%\n  fit(imputed_bag)\n\nclus4 <-  workflow() %>%\n  add_recipe(rec_cluster4) %>%\n  add_model(rf_mod) %>%\n  finalize_workflow(best3) %>%\n  fit(imputed_bag)\n\n# create Variable Importance Plots\np1<-vip(clus2%>%extract_fit_engine(),geom=\"point\", num_features = 15)+\n  theme(text = element_text(size=7))+\n  ggtitle(\"2 clusters\")\np2<-vip(clus3%>%extract_fit_engine(),geom=\"point\", num_features = 15)+\n  theme(text = element_text(size=7))+\n  ggtitle(\"3 clusters\")\np3<-vip(clus4%>%extract_fit_engine(),geom=\"point\", num_features = 15)+\n  theme(text = element_text(size=7))+\n  ggtitle(\"4 clusters\")\ngrid.arrange(p1,p2,p3, ncol=3)\n```\n\n```{r fig.height=6}\n# 3 clusters\np1<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=absences))+\n  geom_boxplot()\np2<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=Ach))+\n  geom_boxplot()\np3<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=PreTest))+\n  geom_boxplot()\np4<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=as.numeric(gender)))+\n  geom_jitter(aes(col = gender))\np5<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=as.numeric(subject)))+\n  geom_jitter(aes(col = subject))\np6<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=as.numeric(goout)))+\n  geom_jitter(aes(col = goout))\ngrid.arrange(p1,p2,p3,p4,p5,p6,ncol=2)\n```\n\n```{r fig.height=6}\n# 4 clusters\np1<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=absences))+\n  geom_boxplot()\np2<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=Ach))+\n  geom_boxplot()\np3<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=PreTest))+\n  geom_boxplot()\np4<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=as.numeric(MomEdu)))+\n  geom_jitter(aes(col = MomEdu))\np5<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=as.numeric(DadEdi)))+\n  geom_jitter(aes(col = DadEdi))\np6<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=as.numeric(school)))+\n  geom_jitter(aes(col = school))\ngrid.arrange(p1,p2,p3,p4,p5,p6,ncol=2)\n```\n\nผลการวิเคราะห์ข้างต้นควรเลือกกี่กลุ่ม และแต่ละกลุ่มมี profile เป็นอย่างไร?\n\n### 2.2 พัฒนาโมเดลทำนายผลสัมฤทธิ์ทางการเรียน\n\nการวิเคราะห์ส่วนนี้ผู้วิเคราะห์เลือกอัลกอริทึมมาเปรียบเทียบกัน 3 ตัวได้แก่\n\n-   regularized logistic regression\n\n-   random forest\n\n-   gradient boosting\n\n#### Data Preprocessing\n\nผลวิเคราะห์ส่วนนี้ผู้วิเคราะห์ออกแบบให้ใช้ classification model ทั้งนี้เพื่อให้ผลการทำนายมีความหมายที่เป็นรูปธรรมมากกว่าการทำนายด้วยคะแนนสอบปกติ\n\n```{r}\ntemp <- imputed_bag %>%\n  mutate(Ach_class = factor(ifelse(Ach>=15,3,ifelse(Ach<=5,1,2))))\ntable(temp$Ach_class)\n```\n\nการแบ่งระดับผลสัมฤทธิ์ข้างต้นจะเห็นว่าก่อให้เกิดปัญหา **Imbalance class** ขึ้น สภาพดังกล่าวอาจทำให้การวิเคราะห์มีประสิทธิภาพการทำนายที่ต่ำกว่าที่ควรจะเป็น ดังนั้น job แรกของการวิเคราะห์จะพิจารณาผลกระทบของ imbalance class ดังกล่าวก่อน วิธีการแก้ไขที่ใช้ในตัวอย่างจะใช้ SMOTE (synthetic minority over-sampling) ซึ่งเป็นวิธีการพื้นฐานตัวหนึ่งที่ใช้แก้ปัญหา imbalance class ดังกล่าว\n\nSMOTE จะสร้างข้อมูลสังเคราะห์ (synthetic data) ให้กับ minority class โดยใช้การ interpolate ระหว่างหน่วยข้อมูลของกลุ่ม minority ภายใต้ปริภูมิของ feature หลักสำคัญของการสร้างข้อมูลสังเคราะห์คือ จะสร้างข้อมูลใหม่ที่เหมือนกับหน่วยข้อมูลเดิมในกลุ่ม minority แต่จะไม่เท่ากับหน่วยข้อมูลเดิมดังกล่าว ทั้งนี้เพื่อลดความลำเอียงที่จะเกิดขึ้นจากการบิดเบือนการแจกแจงของข้อมูล อัลกอริทึมดังกล่าวจะดำเนินไปเพื่อสร้างข้อมูลสังเคราะห์ให้กับหน่วยข้อมูลแต่ละหน่วยของ minority class มีขั้นตอนดำเนินการในแต่ละหน่วยข้อมูล (x) ดังนี้\n\n1.  กำหนด hyperparameter k (nearest neightbors)\n2.  เลือกหน่วยข้อมูลใน minority class ภายใต้ k nearest neightbors ของ x อย่างสุ่มขึ้นมา 1 ตัว\n3.  สร้างข้อมูลสังเคราะห์โดยใช้การ interpolate ระหว่างหน่วยข้อมูล x กับหน่วยข้อมูลที่เลือกมาในขั้นที่ 2\n4.  ทวนซ้ำ 2 - 3 จนได้จำนวนข้อมูลสังเคราะห์ตามที่ต้องการ\n\nผลลัพธ์ด้านล่างแสดงให้เห็นว่าการทำ smote ช่วยให้ประสิทธิภาพการทำนายดีกว่า\n\n```{r}\nlibrary(themis)\nrec_nosmote <- recipe(Ach_class ~. , data= temp) %>%\n  step_rm(clus2:clus4, Ach) %>%\n  step_normalize(all_numeric_predictors()) %>%\n  step_dummy(all_nominal_predictors())\n\n\nrec_smote <- recipe(Ach_class ~. , data= temp) %>%\n  step_rm(clus2:clus4, Ach) %>%\n  step_normalize(all_numeric_predictors()) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_smote(Ach_class, neighbors = 5) \n\nlogit_mod1 <- multinom_reg(penalty=tune(),\n                          mixture=tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\nlogit_mod2 <- multinom_reg(penalty=tune(),\n                          mixture=tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\nwfset <- workflow_set(\n  preproc = list(rec_nosmote, rec_smote),\n  models = list(logit_mod1, logit_mod2),\n  cross=F\n)\n\nfold<-vfold_cv(temp, v=5, repeats=3, strata = Ach_class)\nlibrary(doMC)\nregisterDoMC(cores=15)\neval_metrics <- metric_set(roc_auc, sens, spec)\nresult_smote<-wfset %>%\n  workflow_map(resamples=fold,\n               grid=50,\n               metrics = eval_metrics)\nresult_smote %>% collect_metrics(summarise=T) %>%\n  filter(.metric %in% c(\"roc_auc\")) %>%\n  arrange(desc(mean)) %>%\n  dplyr::select(wflow_id, .metric, mean, n, std_err)\n\nresult_smote %>% collect_metrics(summarise=T) %>%\n  filter(.metric %in% c(\"sens\")) %>%\n  arrange(desc(mean)) %>%\n  dplyr::select(wflow_id, .metric, mean, n, std_err)\n```\n\nผลการสร้างข้อมูลสังเคราะห์ด้วย SMOTE\n\n```{r echo=F}\nrec_smote  %>%\n  prep(NULL) %>%\n  juice() %>%\n  select(Ach_class) %>% table()\n```\n\n#### Training\n\nขั้นตอนต่อไปคือการ train โมเดลทั้งสามในข้างต้น ดังนี้\n\n```{r message=F}\nsplit <- initial_split(temp, prop=0.75, strata=Ach_class)\ntrain <- training(split)\ntest <- testing(split)\n\n# preprocessing\nrec_smote <- recipe(Ach_class ~. , data= train) %>%\n  step_rm(clus2:clus4, Ach) %>%\n  step_normalize(all_numeric_predictors()) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_smote(Ach_class, neighbors = 5) \n\n# model specification\n### regularized logistic regression\nlogit_mod <- multinom_reg(penalty=tune(),\n                          mixture=tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\n### random forest (ุ6.3 secs)\nrf_mod <- rand_forest(trees=300,\n                      mtry=tune(),\n                      min_n=tune()\n                      ) %>%\n  set_engine(\"ranger\", importance = \"permutation\") %>%\n  set_mode(\"classification\")\n\n### KNN (4.44 sec per round)\nknn_mod <- nearest_neighbor(neighbors = tune(),\n                            weight_func = tune(),\n                            dist_power = 2) %>%\n  set_engine(\"kknn\") %>%\n  set_mode(\"classification\")\n\n### gradient boosting (10.42 secs per round)\nlibrary(xgboost)\nboost_mod <- boost_tree(trees=300,\n                        min_n = tune(),\n                        tree_depth = tune(),\n                        learn_rate = tune()\n                      ) %>%\n  set_engine(\"xgboost\") %>%\n  set_mode(\"classification\")\n\n# create workflowset\nwfset <- workflow_set(\n  preproc = list(rec_smote),\n  models = list(logit_mod, knn_mod, rf_mod)\n)\nfold<-vfold_cv(train, v=5, repeats=2, strata = Ach_class)\n\n# tuning hyperparameters\neval_metrics <- metric_set(roc_auc, sens, spec)\nlibrary(doMC)\nregisterDoMC(cores=15)\nstart <- Sys.time()\nresult <- wfset %>%\n  workflow_map(resamples = fold,\n               grid = 50,\n               control = control_grid(save_pred = TRUE),\n               metrics = eval_metrics)\npaste(\"time usage\", round(Sys.time() - start,2), \"mins\")\n```\n\nผลการปรับแต่ง hyperparameter ของโมเดลข้างต้นเป็นดังนี้\n\n```{r}\nresult\nresult %>% autoplot()\nresult %>% extract_workflow_set_result(id = \"recipe_multinom_reg\") %>%\n  autoplot()\n```\n\n### 2.3 ปัจจัยที่มีความสำคัญหรือปัจจัยเสี่ยงต่อความสำเร็จในการเรียน\n\n```{r}\nbest <- show_best(result %>% extract_workflow_set_result(id = \"recipe_multinom_reg\"),\n                  n=1, metric = \"sens\")\nbest\n## last fit\nlogit_result <- workflow() %>%\n  add_recipe(rec_smote) %>%\n  add_model(logit_mod) %>%\n  finalize_workflow(best) %>%\n  last_fit(split)\n\nlogit_result %>% collect_metrics(summarise=T)\nlogit_result %>% collect_predictions() %>%\n  conf_mat(truth = Ach_class , estimate = .pred_class)\n```\n\n```{r}\nlogit_result %>% extract_fit_engine() %>% vip(num_feature=20)+\n  scale_y_continuous(breaks=seq(0,18,1))+\n  theme(panel.grid.minor = element_blank())\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"output-file":"MidtermExam.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","editor":"visual","urlcolor":"steelblue","linkcolor":"steelblue","theme":{"light":["pandoc","../../theme.scss"]},"mainfont":"Krub","code-copy":true,"title":"Midterm Examination","date":"6 Apr 2023","toc-title":"สารบัญ"},"extensions":{"book":{"multiFile":true}}}}}