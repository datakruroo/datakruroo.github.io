{"title":"Deep Learning 101","markdown":{"yaml":{"title":"Deep Learning 101","author":"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร","toc":true,"toc-depth":3,"toc-title":"สารบัญ","theme":"default"},"headingText":"What's Deep Learning","containsRefs":false,"markdown":"\n\n\nพิจารณา neural network ต่อไปนี้\n\n![](images/Screen%20Shot%202564-05-15%20at%2002.29.19.png)\n\nจากรูปจะเห็นว่า neural network ประกอบด้วยส่วนประกอบหลัก เรียกว่า layer จำนวน 3 ส่วนได้แก่\n\n1.  input layer\n\n2.  hidden layer\n\n3.  output layer\n\n![](images/Screenshot%202566-04-28%20at%2021.22.05.png)\n\n![Perceptron model](images/simple%20ANN.png){alt=\"Perceptron model\" width=\"60%\"}\n\n# ทบทวน AI vs ML vs DL\n\nปัจจุบันมีการใช้คำว่า AI, ML และ DL แทนกันไปมาจนบางครั้งเหมือนว่าจะเป็นคำเดียวกัน ในความเป็นจริงทั้งสามคำดังกล่าวม่ได้เป็นสิ่งเดียวกันเลยทีเดียว แต่มีทั้งส่วนที่เหมือนและแตกต่างกัน รายละเอียดมีดังนี้\n\n-   **AI ย่อมาจาก Artificial Intelligent** เป็นเทคนิคหรือวิธีการที่นักวิทยาการข้อมูลใช้เพื่อพัฒนาโปรแกรมคอมพิวเตอร์ รวมถึงหุ่นยนต์หรือจักรกลที่สามารถเลียนแบบการทำงานต่าง ๆ ของมนุษย์ได้ AI จะมีความสามารถในการทำงานใกล้เคียงหรือดีกว่ามนุษย์ ทั้งความสามารถในการจดจำ จำแนก และตัดสินใจดำเนินงานเองโดยอาศัยข้อมูลที่เป็นไปได้ทั้งข้อมูลตัวเลข ข้อความ รูปภาพ และเสียง ตัวอย่างของ AI เช่น รถยนต์หรือยานพาหนะไร้คนขับ, AlphaGo - DeepMind, Chatgpt เป็นต้น\n\n-   **Machine Learning (ML)** เป็นกลุ่มของเทคนิคหรือศาสตร์ย่อยแขนงนึงภายใต้ AI ที่เกี่ยวข้องกับการใช้ประยุกต์ใช้ทฤษฎีทางสถิติและคณิตศาสตร์เพื่อเรียนรู้หรือสกัดสารสนเทศจากข้อมูล สารสนเทศดังกล่าวสามารถนำมาใช้ได้หลายลักษณะ ทั้งการบรรยาย อธิบาย ทำนาย และตัดสินใจ ML ถือเป็นส่วนประกอบที่สำคัญที่สนับสนุนการทำงานของ AI\n\n-   **Deep Learning (DL)** เป็นแขนงย่อย (subdivision) ของ ML ที่เกี่ยวข้องกับการใช้เทคนิคที่เรียกว่าเครือข่ายประสาทเทียม (artificial neural network: ANN) ที่มีความลึกของเครือข่ายหลายชั้นเพื่อเรียนรู้หรือสกัดสารสนเทศจากข้อมูลและใช้ในวัตถุประสงค์หลักคือเพื่อทำนาย/จำแนกค่าสังเกตของตัวแปรตาม นอกจากนี้ลักษณะเฉพาะตัวที่โดดเด่นของ DL คือเครือข่ายประสาทเทียมที่ใช้ในการเรียนรู้นั้นถูกพัฒนาขึ้นเลียนแบบการทำงานของเซลล์เครือข่ายสมองของมนุษย์ การเรียนรู้ของเครื่องที่ใช้ DL จึงสามารถเรียนรู้ข้อมูลที่มีความซับซ้อนเช่น ข้อความ ภาพ และเสียงได้มีประสิทธิภาพมากกว่าการใช้เทคนิค ML แบบปกติ\n\n[![AI, ML และ DL](images/image-744630750.png){alt=\"https://k21academy.com/datascience/deep-learning/dl-vs-ml/\" width=\"70%\"}](https://k21academy.com/datascience/deep-learning/dl-vs-ml/)\n\nจากความหมายในข้างต้นจะเห็นว่า DL ถือเป็น machine learning ตัวหนึ่งที่ใช้ในวัตถุประสงค์เพื่อทำนายหรือจำแนกค่าสังเกตของตัวแปรตาม เมื่อเปรียบเทียบความแตกต่างระหว่าง machine learning algorithm ในกลุ่มที่ใช้สำหรับทำนาย กับ DL มีความแตกต่างหนึ่งที่เห็นได้อย่างชัดเจนคือในส่วนของกระบวนการเรียนรู้ของโมเดล ดังรูปด้านล่าง\n\n![Machine Learning Process](images/image-1871870544.png){alt=\"ML (https://www.advancinganalytics.co.uk/blog/2021/12/15/understanding-the-difference-between-ai-ml-and-dl-using-an-incredibly-simple-example)\" fig-alt=\"ML (https://www.advancinganalytics.co.uk/blog/2021/12/15/understanding-the-difference-between-ai-ml-and-dl-using-an-incredibly-simple-example)\" width=\"50%\"}\n\n![Deep Learning Process](images/image-1842751579.png){alt=\"https://www.advancinganalytics.co.uk/blog/2021/12/15/understanding-the-difference-between-ai-ml-and-dl-using-an-incredibly-simple-example\" fig-alt=\"DL (https://www.advancinganalytics.co.uk/blog/2021/12/15/understanding-the-difference-between-ai-ml-and-dl-using-an-incredibly-simple-example)\" width=\"50%\"}\n\nจากรูปข้างต้นจะเห็นว่า ทั้ง ML และ DL เป็นเครื่องมือที่มีวัตถุประสงค์เดียวกันคือเพื่อทำนาย หรือจำแนกประเภทของหน่วยข้อมูล โดยใช้ข้อมูลจากตัวแปรอิสระที่มี การพัฒนาโมเดลทำนายมีกระบวนการที่จะต้อง train และตรวจสอบประสิทธิภาพของโมเดลเหมือนกัน แต่ส่วนที่มีความแตกต่างกันอย่างชัดเจนระหว่าง ML กับ DL คือ การพัฒนาโมเดลประเภท ML ผู้วิเคราะห์จะต้องเป็นผู้ดำเนินการสำรวจ คัดเลือก รวมทั้งเตรียมข้อมูลของตัวแปรอิสระที่จะใช้ในโมเดลทำนายด้วยตนเอง เรียกขั้นตอนนี้ว่า feature extraction ในขณะที่ DL เป็นโมเดลแบบเครือข่ายประสาทเทียมที่มีชั้นของการเรียนรู้หรือประมวลผลข้อมูลหลายชั้น ทำให้สามารถผนวกส่วนของการทำ feature extraction และส่วนของการทำนายเอาไว้ภายในโมเดล DL เดียวกันได้ และมีแนวโน้มที่จะช่วยให้ผู้วิเคราะห์สามารถใช้ประโยชน์ได้จากข้อมูลที่มีปริมาณมาก ๆ ได้อย่างสูงสุด\n\n# Artificial Neural Network\n\nดังที่กล่าวในข้างต้นว่าโมเดลการเรียนรู้เชิงลึกเป็นกลุ่มของโมเดลทำนายที่จัดอยู่ในโมเดลประเภทโครงข่ายประสาทเทียม (artificial neural network: ANNs) ดังนั้นในหัวข้อนี้จะกล่าวถึงความรู้พื้นฐานที่จำเป็นต้องทราบเกี่ยวกับ ANN ก่อนรายละเอียดมีดังนี้\n\n## Simple artificial neural\n\nหรืออาจเรียกว่า perceptron เป็นโมเดลตัวพื้นฐานมากที่สุดในกลุ่มของ ANN รูปด้านล่างแสดงโครงสร้างของ perceptron model ดังกล่าว จากรูปจะเห็นว่าโมเดลประกอบด้วยส่วนประกอบหลัก 3 ส่วนได้แก่\n\n# \n\n# พัฒนาการของ DL\n\nThe history of deep learning can be traced back to the early days of artificial intelligence and has gone through several key milestones and developments. Here is an overview of the history of deep learning and some of its recent advancements:\n\n1.  Early neural networks (1940s-1960s):\n\n    -   The foundation of deep learning was laid by the development of artificial neural networks, inspired by the structure and function of biological neurons in the brain.\n\n    -   The first simple artificial neuron, called the perceptron, was introduced by Frank Rosenblatt in 1958. It could learn to perform simple binary classification tasks.\n\n2.  Backpropagation algorithm (1970s-1980s):\n\n    -   In 1974, Paul Werbos introduced the backpropagation algorithm, a key technique for training multi-layer neural networks.\n\n    -   In 1986, David Rumelhart, Geoffrey Hinton, and Ronald J. Williams popularized the backpropagation algorithm in their seminal paper, which became the cornerstone of modern deep learning.\n\n3.  The AI winter (1980s-1990s):\n\n    -   During this period, AI research faced skepticism and a lack of funding due to unfulfilled promises and the limitations of early neural networks.\n\n    -   However, some researchers continued to work on neural networks, leading to advancements such as the development of Convolutional Neural Networks (CNNs) by Yann LeCun in 1989, which laid the groundwork for image recognition tasks.\n\n4.  Revival and the rise of deep learning (2000s):\n\n    -   The term \"deep learning\" was coined by Geoffrey Hinton and his colleagues in the early 2000s, referring to neural networks with many layers.\n\n    -   Key factors in the revival of deep learning include the availability of large-scale datasets, advances in computational hardware (such as GPUs), and new algorithms that improved training efficiency.\n\n5.  Recent developments (2010s-present):\n\n    -   In 2012, Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton achieved a breakthrough in image recognition with their deep CNN called AlexNet, which significantly outperformed other methods in the ImageNet challenge.\n\n    -   Since then, deep learning has made significant progress in various domains, such as natural language processing (e.g., transformers like BERT and GPT), speech recognition, and reinforcement learning (e.g., DeepMind's AlphaGo).\n\n    -   New architectures, techniques, and applications continue to emerge, such as Generative Adversarial Networks (GANs), unsupervised learning, and transfer learning.\n\nThe history of deep learning has seen both periods of rapid advancement and stagnation. However, in recent years, deep learning has become a dominant force in AI research, leading to groundbreaking achievements and applications across a wide range of fields.\n\n# ความรู้พื้นฐาน\n\nเนื้อหาส่วนนี้จะอธิบายโครงสร้างของโมเดลโครงข่ายประสาทเทียม (artificial neural network: ANN) หรือที่เรียกว่า perceptron model ซึ่งเป็นพื้นฐานความรู้ที่สำคัญสำหรับการศึกษาการเรียนรู้เชิงลึก\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"output-file":"DL101.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","editor":"visual","urlcolor":"steelblue","linkcolor":"steelblue","theme":{"light":["pandoc","../../theme.scss"]},"mainfont":"Krub","code-copy":true,"title":"Deep Learning 101","author":"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร","toc-title":"สารบัญ"},"extensions":{"book":{"multiFile":true}}}}}