{"title":"Regularization","markdown":{"yaml":{"title":"Regularization","author":"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร","toc":true,"toc-depth":3,"toc-title":"สารบัญ","theme":"default"},"headingText":"บทที่ 6 : Regularized Regression","containsRefs":false,"markdown":"\n\n```{r echo=F, message=F}\nlibrary(tidymodels)\nlibrary(gridExtra)\n```\n\n\nLinear regression เป็นโมเดลทำนายที่มีจุดเด่นคือเป็นโมเดลอย่างง่ายที่นอกจากจะใช้ทำนายแนวโน้มของตัวแปรอิสระได้แล้ว ยังสามารถใช้ในการอธิบายความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระได้ง่ายและชัดเจนกว่าการใช้โมเดลการเรียนรู้อื่น ๆ อย่างไรก็ตามการใช้งาน linear regression นั้นอยู่ภายใต้ข้อจำกัดหรือข้อตกลงเบื้องต้นที่เคร่งครัดหลายตัว ซึ่งหากข้อตกลงเบื้องต้นดังกล่าวไม่เป็นจริงแล้วการทำนายหรือการอธิบายความสัมพันธ์ด้วย linear regression ก็อาจจะมีปัญหาและขาดความน่าเชื่อถือ\n\nบทเรียนนี้จะ focus ไปที่ปัญหาหนึ่งที่สำคัญและเกิดขึ้นบ่อยในการพัฒนาโมเดลทำนายทั้งใน linear regression และอัลกอริทึมอื่น ๆ คือการที่โมเดลทำนายมีจำนวนตัวแปรอิสระหรือเทอมของตัวแปรอิสระมากเกินไป สถานการณ์ดังกล่าวอาจก่อให้เกิดปัญหาในเชิงเทคนิคหลายประการ ดังนี้\n\n1.  overfitting model กล่าวคือการมีตัวแปรอิสระหรือเทอมของตัวแปรอิสระ เช่น เทอมพหุนาม (polynomial) หรือเทอมปฏิสัมพันธ์ (interaction) จำนวนมากเกินไปภายในโมเดล ย่อมทำให้โมเดลเรียนรู้ความสัมพันธ์ในชุดข้อมูลฝึกหัดดีเกินไป และก่อให้เกิดปัญหา overfitting ได้\n2.  infinite solution ปัญหานี้เป็นปัญหาเชิงเทคนิค กล่าวคือผู้วิเคราะห์มีจำนวนตัวแปรอิสระหรือเทอมของตัวแปรอิสระ (จำนวนคอลัมน์) ที่ต้องการนำเข้าสู่โมเดลมากกว่าจำนวนหน่วยข้อมูล (จำนวนแถว) สถานการณ์ดังกล่าวทำให้ไม่สามารถหาคำตอบเดียวของค่าประมาณพารามิเตอร์ภายในโมเดลทำนายได้\n3.  multicollinearity ปัญหานี้เป็นปัญหาในเชิงเทคนิคที่เกิดขึ้นเมื่อผู้วิเคราะห์มีตัวแปรอิสระจำนวนมากในโมเดล โดยที่ตัวแปรอิสระดังกล่าวมีความซ้ำซ้อนกัน (redundant) กล่าวคือมีความสัมพันธ์ซึ่งกันและกันเองสูงเกินไป สถานการณ์เช่นนี้จะทำให้การประมาณค่าพารามิเตอร์ในโมเดลมีแนวโน้มที่จะไม่เสถียร (unstable solution) ส่งผลให้โมเดลทำนายที่ได้มีความไม่เสถียรตามไปด้วย โมเดลทำนายที่ได้จากสถานการณ์ดังกล่าวจึงจะขาดความน่าเชื่อถือ\n\nในบทที่ 6 เราได้กล่าวถึงการคัดเลือกตัวแปรอิสระเข้าสู่โมเดลด้วยวิธีในกลุ่ม wrapper method ซึ่งผู้อ่านจะเห็นว่าวิธีการดังกล่าวนั้นมีข้อจำกัดสำคัญคือ เป็นวิธีที่ใช้ข้อมูลจากชุดข้อมูลฝึกหัดในการคัดเลือกตัวแปรอิสระแต่เพียงอย่างเดียว ซึ่งอาจทำให้มีความเสี่ยงสูงที่การพัฒนาโมเดลทำนายภายใต้ผลการคัดเลือกตัวแปรอิสระดังกล่าวจะมีปัญหา overfitting ตามมา บทเรียนนี้จะกล่าวถึงเทคนิค regularization ที่สามารถทำมาใช้เพื่อแก้ปัญหาดังกล่าว ปัจจุบันมีการนำเทคนิคนี้ไปใช้ในหลายโมเดลทั้ง linear regression, decision tree ไปจนถึง neural network โดยในบทเรียนนี้จะกล่าวถึงมโนทัศน์สำคัญของการทำ regularization และการนำเทคนิค regularization ไปใช้ในอัลกอริทึม linear regression รายละเอียดมีดังนี้\n\n## 6.1 มโนทัศน์สำคัญของ regularized regression\n\nconcept ของ regularization เป็นเรื่องเกี่ยวกับการปรับสมดุลของโมเดลทำนายเพื่อลดทอนหรือแก้ปัญหา overfitting และ/หรือ ปัญหาตัวอย่างอิสระ สำหรับโมเดล linear regression การปรับสมดุลดังกล่าวจะเป็นการปรับค่าสัมประสิทธิความชันของสมการถดถอยให้น้อยลงเพื่อ**ลดหรือลบ**ผลกระทบของตัวแปรอิสระบางตัวออกจากโมเดลอย่างเหมาะสม\n\nเพื่อให้ผู้อ่านเห็นภาพและเข้าใจมโนทัศน์ของ regularization ได้อย่างชัดเจน อยากให้ผู้อ่านลองพิจารณาตัวอย่างง่าย ๆ ต่อไปนี้\n\nสมมุติว่าผู้วิเคราะห์ต้องการสร้างโมเดลทำนายคะแนนผลสัมฤทธิ์ทางการเรียนของนักเรียน (ACH) โดยใช้จำนวนชั่วโมงการทบทวนบทเรียนต่อสัปดาห์ของนักเรียน (HOUR) เป็นตัวแปรทำนาย แผนภาพการกระจายด้านล่าง (พิจารณาเฉพาะจุด) จะเห็นว่าความสัมพันธ์ระหว่างตัวแปรทั้งสองมีลักษณะเป็นความสัมพันธ์เชิงเส้น (linear relationship) ที่ค่อนข้างชัดเจน ในกรณีนี้ผู้วิเคราะห์จึงเลือกใช้อัลกอริทึม linear regression เป็นอัลกอริทึมการเรียนรู้ เพื่อสร้างโมเดลทำนายที่ต้องการ\n\nการสร้างโมเดลทำนายด้วย linear regression อัลกอริทึมจะพยายามหาสมการเส้นตรงที่ดีที่สุด โดยการคัดเลือกชุดของสัมประสิทธิ์การถดถอย (จุดตัดแกน y และความชัน) ที่ทำให้ฟังก์ชันวัตถุประสงค์ (objective function) มีค่าสูงหรือต่ำที่สุด โดยทั่วไปฟังก์ชันวัตถุประสงค์มักใช้เป็น sum squared error (SSE) การหาค่าประมาณของสัมประสิทธิ์ถดถอยดังกล่าวจึงเป็นการหาค่าที่ทำให้ SSE มีค่าต่ำที่สุด\n\nการหาค่าประมาณพารามิเตอร์ดังกล่าวสามารถทำได้หลายวิธีการ วิธีการแรกที่มักใช้กันในฝั่ง data analysis คือการใช้การ optimization ด้วย first และ second order derivative (ใช้ขั้นตอนวิธีของ calculas) ในโมเดล linear regression ทั่วไปวิธีการนี้สามารถให้สูตรปิดของการหาค่าประมาณสัมประสิทธิ์การถดถอยดังกล่าวได้ อีกวิธีการหนึ่งคือการใช้อัลกอริทึมเชิงตัวเลข (numerical algorithm) เรียกว่า gradient descent หรือ stochastic gradient descent ซึ่งเป็นกระบวนการทวนซ้ำเพื่อหาชุดของสัมประสิทธิ์การถดถอยที่เหมาะสมที่สุดโดยอิงจากค่าของฟังก์ชันวัตถุประสงค์ที่กำหนด\n\nเมื่อกำหนดให้ข้อตกลงเบื้องต้นอื่น ๆ ของ linear regression เป็นจริง และตัวแปรอิสระที่เลือกเข้าสู่โมเดลเป็นตัวแปรอิสระที่มีคุณภาพ กล่าวคือ (1) ให้สารสนเทศในการทำนายตัวแปรตาม และ (2) ไม่ซ้ำซ้อนกันเองกับตัวแปรอิสระอื่น ๆ โมเดลทำนายที่ได้จากอัลกอริทีมจะมีคุณสมบัติที่ดีในทางสถิติกล่าวคือมีความไม่ลำเอียงและมีความแปรปรวนต่ำที่สุด หนังสือสถิติจะเขียนว่าตัวประมาณที่ได้จาก OLS regression เป็นตัวประมาณ BLUE ซึ่งย่อมาจาก Best Linear Unbised Estimator (สามารถพิสูจน์ได้โดยใช้ Gauss-Markov Theorem)\n\n![Least Squared Regression](images/image-676691868.png){alt=\"Least Squared Regression\" fig-align=\"center\" width=\"70%\"}\n\nโดยปกติ linear regression เป็นโมเดลที่ง่ายที่สุดสำหรับทำนาย กล่าวคือเป็นโมเดลที่มีแนวโน้มจะมีประสิทธิภาพในการทำนายที่ไม่สูงมากนัก แต่จุดเด่นคือมีความยืดหยุ่นในการนำไปใช้ทำนายชุดข้อมูลอื่นนอกเหนือจากชุดข้อมูลฝึกหัดสูง linear regression อย่างไรก็ตามหากหากชุดข้อมูลฝึกหัดไม่ได้เป็นตัวแทนที่ดีของประชากร หรือในขั้นตอนของการพัฒนาโมเดลผู้วิเคราะห์มีการใส่ตัวแปรอิสระหรือเทอมของตัวแปรทำนาย เช่น polynomial หรือ interaction terms ที่ไม่ให้สารสนเทศจำนวนมากเข้าไปในโมเดล สถานการณ์เช่นนี้มักเพิ่มโอกาสที่โมเดลจะเกิดปัญหา overfitting ซึ่งทำให้โมเดลทำนายที่พัฒนาได้นั้นไม่สามารถทำนายชุดข้อมูลทดสอบหรือข้อมูลอื่น ๆ ที่อยู่นอกเหนือชุดข้อมูลฝึกหัดได้อย่างมีประสิทธิภาพ\n\nรูปด้านล่างแสดงสภาพของปัญหา overfitting ที่เกิดขึ้นในโมเดลทำนาย ACH ด้วย HOUR ดังกล่าว จากรูปเมื่อพิจารณาจุดและเส้นโมเดลทำนาย (สีเขียว) จะพบว่าโมเดลเรียนรู้ความสัมพันธ์ระหว่างตัวแปรทั้งสองในชุดข้อมูลฝึกหัดได้ดี แต่เมื่อนำโมเดลดังกล่าวไปใช้ทำนาย ACH ในชุดข้อมูลทดสอบจะพบว่า สมการทำนายเส้นสีเขียวกลายเป็นสมการที่ไม่เหมาะสมในกรณีทั่วไป โดยจะให้ค่าความคลาดเคลื่อนในการทำนาย (SSE) ของชุดข้อมูลทดสอบที่สูงมากกว่า SSE ในชุดข้อมูลฝึกหัดค่อนข้างมาก เส้นสมการทำนายที่เหมาะสมควรเป็นสมการเส้นสีเทาในรูปมากกว่า\n\n![ปัญหา overfitting](images/image-849757700.png){alt=\"ปัญหา overfitting\"}\n\nการแก้ปัญหาดังกล่าวผู้วิเคราะห์จะต้องปรับแต่งโมเดลการทำนายใหม่ให้มีความสมดุลในการทำนายชุดข้อมูลที่ไม่รู้จักได้มากขึ้น เทคนิค regularization ถูกพัฒนาขึ้นเพื่อใช้สำหรับการปรับแต่งโมเดลทำนายดังกล่าว คำถามคือการปรับแต่งโมเดลทำนายนั้นควรดำเนินการอย่างไร?\n\nรูปด้านล่างแสดงแนวคิดหลักของ regularization จากรูปจะเห็นว่าโมเดลทำนายเส้นสีเขียวนั้นเกิดปัญหา overfitting ขึ้นกล่าวคือ โมเดลทำนายดังกล่าวเรียนรู้ความสัมพันธ์ในชุดข้อมูลฝึกหัด (จุดสีเขียว) ได้ดีมากเกินไป กล่าวคือโมเดลทำนายนี้มีความแปรปรวนสูงมากเกินไปนั่นเอง จากมโนทัศน์เกี่ยวกับ bias & variance trace-off เราทราบว่าความลำเอียงกับความแปรปรวนของโมเดลทำนายนั้นมีความสัมพันธ์ที่ผกผันกัน โดยโมเดลที่มีความลำเอียงต่ำมีแนวโน้มที่จะมีความแปรปรวนสูง ในทางกลับกันโมเดลที่มีความลำเอียงสูงก็มีแนวโน้มที่จะมีความแปรปรวนต่ำ ดังนั้นจากความสัมพันธ์นี้หากผู้วิเคราะห์มีโมเดลทำนายที่มีความแปรปรวนสูง ผู้วิเคราะห์อาจปรับแต่งโมเดลทำนายดังกล่าวให้มีความแปรปรวนต่ำลงได้ด้วยการเพิ่มความลำเอียงให้กับโมเดลทำนายดังกล่าวอย่างเหมาะสม ดังตัวอย่างในรูป (b) ด้านล่าง\n\n![main idea ของ regularization](images/image-343319787.png){alt=\"main idea ของ regularization\"}\n\nสำหรับ linear regression สามารถใส่ความลำเอียงให้กับโมเดลทำนายได้ในขั้นตอนของการหาค่าประมาณพารามิเตอร์ของโมเดล โดยปรับสูตรของฟังก์ชันวัตถุประสงค์ใหม่จากเดิม $SSE = \\sum_{i=1}^n(y_i-\\hat{y}_i)^2$ เป็น\n\n$$\nSSE_{reg}=\\sum_{i=1}^n(y_i-\\hat{y}_i)^2 + P = SSE + P\n$$\n\nเรียกเทอม $P$ ในสมการข้างต้นว่า penality term หนังสือบางเล่มเลยอาจใช้ชื่อ penalized regression แทน regularized regression ผู้อ่านลองสังเกตการบวกเทอม $P$ ดังกล่าวในฟังก์ชันวัตถุประสงค์ โดยจะเห็นว่าเมื่อ $P>0$ จะทำให้ค่า $SSE_{reg} > SSE$ ซึ่งเป็นการทำให้ค่าประมาณพารามิเตอร์ได้แก่ สัมประสิทธิจุดตัดแกน และความชันในโมเดลทำนายนั้น มีแนวโน้มที่มีความลำเอียงมากกว่าโมเดลทำนายที่ไม่ได้ใส่ penalty term ดังกล่าว ซึ่งหากใส่อย่างเหมาะสมจะช่วยลดความแปรปรวนของโมเดลทำนายได้อย่างที่ได้กล่าวไปแล้ว\n\nค่า$P$ ดังกล่าวไม่ใช่พารามิเตอร์ที่สามารถประมาณได้โดยตรงจากข้อมูล กล่าวคือเป็น hyperparameter ที่ต้องกำหนดโดยผู้วิเคราะห์ก่อนที่จะดำเนินการประมาณค่าพารามิเตอร์ของโมเดล **คำถามใหญ่ของการทำ regularization จึงเกิดขึ้นว่า** **การกำหนดค่า** $P$ **ดังกล่าวให้เหมาะสมควรดำเนินการอย่างไร?**\n\nแนวคิด regularization ดังกล่าวสามารถนำไปประยุกต์ใช้กับอัลกอริทึมการเรียนรู้ได้อีกหลายตัว เช่น ใน regularized logistic regression ฟังก์ชันวัตถุประสงค์จะสามารถเขียนได้เป็น $lnL + P$ เมื่อ $lnL$ คือ log-likelihood function ของโมเดล หรือใน decision tree (มักเรียกว่า pruning tree) ฟังก์ชันวัตถุประสงค์จะเขียนได้เป็น $R_{reg}(T) = R(T) + \\alpha|T|$ โดยที่ $R(T)$ คือ training error ของ decision tree ที่มีจำนวน terminal nodes เท่ากับ $T$ และจะเรียก $\\alpha$ ว่า cost complexity hyperparameter\n\n## 6.2 ประเภทของ Regularization\n\nการกำหนดค่า $P$ ให้กับฟังก์ชันวัตถุประสงค์ในข้างต้นอาจดำเนินการโดยจำแนกได้เป็น 3 วิธี ดังนี้\n\n1.  Ridge regression\n2.  Lasso regression\n3.  Elastic-Net regression\n\n### Ridge Regression\n\nฟังก์ชันวัตถุประสงค์ของ regularized regression ประเภท ridge regression สามารถเขียนได้ดังนี้\n\n$$\nSSE_{ridge} = SSE+\\lambda\\sum_{j=1}^kb_j^2\n$$\n\nจากสมการข้างต้นจะเห็นว่า $P = \\lambda\\sum_{j=1}^kb_j^2$ คือ penalty term ในกรณีนี้จะเรียกว่า ridge regression penalty หรือหนังสือบางเล่มอาจจะเรียกว่า L2 norm การกำหนด penalty term ดังกล่าวทำให้เกิดผลอย่างไรต่อการพัฒนาโมเดลทำนาย สามารถทำความเข้าใจง่าย ๆ ได้จากการพิสูจน์ด้านล่าง ผู้อ่านจะเห็นว่าตัวประมาณของสัมประสิทธิ์การถดถอยใน ridge regression จะมีเทอม $\\lambda$ เพิ่มเข้ามาในเทอมตัวหาร เมื่อเปรียบเทียบกับ linear regression แบบ OLS ธรรมดา ผู้อ่านจะเห็นได้อย่างชัดเจนว่าเมื่อ $\\lambda = 0$ ค่าประมาณของสัมประสิทธิ์ความชันจากทั้งสองวิธีการจะเท่ากัน แต่เมื่อกำหนดให้ $\\lambda>0$ ค่าประมาณของสัมประสิทธิ์ความชันที่ได้จาก ridge regression จะมีแนวโน้มที่ลดลงต่ำกว่า ols regression อย่างไรก็ตามหากลองพิจารณา $lim_{\\lambda \\rightarrow \\infty}\\frac{\\sum x_iy_i}{\\sum x_i^2+\\lambda}$ จะพบว่าค่าสัมประสิทธิ์ความชันของ ridge regression จะมีค่าลู่เข้าใกล้ 0 แต่จะไม่เท่ากับ 0\n\n![](images/image-75951276.png)\n\nจากผลในข้างต้นจะเห็นว่า ridge regression เป็นเทคนิคที่ช่วยปรับขนาดของสัมประสิทธิ์ความชันของตัวแปรอิสระในโมเดลให้มีค่าลดลง แต่จะไม่ได้ทำให้เป็น 0 ดังนั้นตัวแปรอิสระทั้งหมดที่ผู้วิเคราะห์นำเข้าในอัลกอริทึมตอนแรกนั้นจะอยู่ในโมเดลทำนายครบทุกตัว แต่จะถูกปรับลดขนาดของค่าสัมประสิทธิ์ความชันลง ดังนั้น ridge regression จึงไม่ใช่เทคนิคสำหรับคัดเลือกตัวแปรอิสระ แต่เป็นเทคนิคที่เหมาะสำหรับแก้ปัญหา multicollinearity มากกว่า ดังนั้น ridge regression จึงเหมาะที่จะใช้ในสถานการณ์ที่ผู้วิเคราะห์มีตัวแปรอิสระจำนวนมากและตัวแปรดังกล่าวมีความสัมพันธ์กันเองสูงหรือมีความซ้ำซ้อนกัน แต่ผู้วิเคราะห์ไม่ต้องการที่จะตัดตัวแปรอิสระตัวใดออกจากโมเดลทำนาย อัลกอริทึม ridge regression จะช่วยให้ผู้วิเคราะห์สามารถสร้างโมเดลทำนายที่มีตัวแปรอิสระทั้งหมดอยู่ภายในโมเดลโดยหลีกเลี่ยงหรือลดทอนผลกระทบที่เกิดจากปัญหา multicollinearity ได้\n\nข้อสังเกตหนึ่งคือถึงแม้ว่าในชุดข้อมูลของผู้วิเคราะห์จะมีตัวแปรอิสระที่ไม่ให้สารสนเทศในการทำนายอยู่ด้วย แต่ ridge regression ก็จะไม่ได้ตัดตัวแปรอิสระดังกล่าวออกจากโมเดล ภายใต้สถานการณ์ดังกล่าวการใช้อัลกอริทึม ridge regression ก็จะไม่เหมาะสมควรเปลี่ยนไปใช้ lasso หรือ elastic-net regression มากกว่า\n\n### Lasso Regression\n\nLasso regression เป็นอัลกอริทึมที่ถูกพัฒนาขึ้นโดยมีวัตถุประสงค์หลักคือการคัดเลือกตัวแปรอิสระ (feature selection) เข้าสู่โมเดลทำนาย อัลกอริทึมนี้เป็น feature selection ที่จัดอยู่ในกลุ่ม embedded method กล่าวคือเป็นอัลกอริทึมการเรียนรู้ที่มีอัลกอริทึมของการคัดเลือกตัวแปรอิสระรวมอยู่ในขั้นตอนการประมาณค่าพารามิเตอร์ของโมเดล หลักการของ lasso regression เหมือนกับ ridge regression แต่มีการใช้ penalty term ในฟังก์ชันวัตถุประสงค์ที่แตกต่างออกไปดังนี้\n\n$$\nSSE_{lasso} = SSE+\\lambda\\sum_{j=1}^k |b_j|\n$$\n\nจะเห็นว่ามีการเปลี่ยนแปลงจากการใช้ฟังก์ชันกำลังสองเป็นค่าสมบูรณ์ใน penalty term ผลกระทบที่เกิดขึ้นกับโมเดลทำนายเมื่อใช้ penalty term ดังกล่าวสามารถอธิบายได้โดยใช้การพิสูจน์ง่าย ๆ ด้านล่าง ผู้อ่านจะเห็นว่าตัวประมาณของสัมประสิทธิ์ความชันในโมเดลทำนายมีรูปแบบที่เปลี่ยนแปลงไปจาก ridge regression โดยเทอม $\\lambda$ ไม่ได้อยู่ในส่วนของตัวเศษแล้ว แต่ขึ้นมาอยู่ที่ตัวเศษแทน ดังนั้นการกำหนด $\\lambda$ ที่เหมาะสมจึงสามารถทำให้ค่าสัมประสิทธิ์ความชันดังกล่าวมีค่าเท่ากับ 0 ได้ ซึ่งหมายถึงการตัดตัวแปรอิสระดังกล่าวออกจากโมเดลทำนาย ด้วยหลักการดังกล่าวอัลกอริทึม lasso regression จึงสามารถคัดเลือกตัวแปรอิสระเข้าสู่โมเดลได้ด้วยการกำหนดค่า $\\lambda$ ดังกล่าว\n\n![](images/image-1836348765.png){width=\"50%\"}\n\n### Elastic-Net Regression\n\nอัลกอริทึมนี้เป็นการผสมกันระหว่าง ridge และ lasso regression จึงเป็นอัลกอริทึมที่สามารถใช้ทั้งแก้ปัญหา multicollineatiry และคัดเลือกตัวแปรอิสระไปพร้อม ๆ กัน ฟังก์ชันวัตถุประสงค์ของ elastic-net regression เป็นดังนี้\n\n$$\nSSE_{elasticnet}=SSE+(1-\\alpha)\\lambda_1\\sum_{j=1}^kb_j^2+\\alpha\\lambda_2\\sum_{j=1}^k|b_j|\n$$\n\nโดยที่ $\\alpha$ เรียกว่า mixing parameter ซึ่งมีค่าที่เป็นไปได้อยู่บนช่วง 0 ถึง 1 ทำหน้าที่สำหรับกำหนดน้ำหนักให้กับ penalty term ทั้งสอง\n\n$\\lambda$ และ $\\alpha$ ที่อยู่ในฟังก์ชันวัตถุประสงค์ของอัลกอริทึมทั้ง 3 ตัวเป็น hyperparameters ของอัลกอริทึม กล่าวคือผู้วิเคราะห์จะต้องกำหนดค่าของพารามิเตอร์ทั้งสองเอง ในทางปฏิบัติผู้วิเคราะห์สามารถปรับแต่งค่า hyperparameters ดังกล่าวได้โดยใช้ตัวอย่างที่ได้จากการสุ่มซ้ำ เช่น cross-validation หรือ bootstraping ในทำนองเดียวกับการปรับแต่ง hyperparameter ของ decision tree ที่กล่าวถึงในบทที่ 5\n\n## 6.3 Implement regularized regression using tidymodels\n\nการพัฒนาโมเดลทำนายโดยใช้การทำ regularization ใน R สามารถทำได้หลายวิธี เช่น การใช้ฟังก์ชัน `cv.glmnet()` ของ package glmnet หรือการใช้ `tuneGrid()` ใน package caret ในหัวข้อนี้จะกล่าวถึงการพัฒนาอัลกอริทึมดังกล่าวภายใต้ tidymodels framework ชุดข้อมูลที่ใช้เป็นตัวอย่างจะมี 2 ชุด ชุดแรกคือ [`TeacherSalaryData.csv`](https://github.com/ssiwacho/2758688_ML/blob/main/week%201/TeacherSalaryData.csv) และชุดที่สองคือ [`gpax.csv`](https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week4/gpax.csv)\n\n### โมเดลทำนายเงินเดือนครู\n\nตัวอย่างนี้จะพัฒนาโมเดลทำนายเงินเดือนครูโดยจะใช้อัลกอริทึม regularization ก่อนที่จะเริ่มพัฒนาโมเดล ผู้วิเคราะห์ควรเริ่มจากการสำรวจข้อมูลเบื้องต้นก่อน จากวัตถุประสงค์ของงานนี้อาจจำแนกการสำรวจข้อมูลออกเป็นสองส่วน ส่วนแรกคือการสำรวจรูปแบบตารางข้อมูล ขอบเขตข้อมูล และลักษณะการจัดเก็บ/บันทึกข้อมูล และส่วนที่สองคือการสำรวจลักษณะความสัมพันธ์ระหว่างตัวแปรตามคือเงินเดือนครู (salary) และตัวแปรอิสระต่างในโมเดล\n\n```{r}\nlibrary(tidymodels)\ntidymodels_prefer()\n#importing data\ndat <- read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/TeacherSalaryData.csv\")\nglimpse(dat)\n```\n\nจากผลการสำรวจข้อมูลข้างต้นจะเห็นว่าชุดข้อมูลดังกล่าวเป็นชุดข้อมูลขนาดเล็ก มีรูปแบบตารางเป็นแบบ tidydata แล้ว โดยมีหน่วยข้อมูลทั้งหมดจำนวน 397 หน่วย มีตัวแปรที่สามารถนำมาใช้เป็นตัวแปรอิสระในโมเดลได้ 5 ตัวแปร ได้แก่ `rank`, `discipline`, `yrs.since.phd`, `yrs.service` และ `sex` ผู้อ่านจะเห็นว่าตัวแปรอิสระดังกล่าวมีทั้งตัวแปรที่เป็นเชิงปริมาณ และตัวแปรจัดประเภท โดยในกลุ่มของตัวแปรจัดประเภทพบว่าทุกตัวแปรถูกจัดเก็บอยู่ในรูปแบบของตัวอักษร ซึ่งไม่เหมาะสมที่จะนำเข้าสู่โมเดลทำนาย\n\n```{r fig.height=3}\n# exploring data using statistics\nsummary(dat)\ndat %>% \n  select(salary, yrs.since.phd, yrs.since.phd) %>% \n  cor()\n# exploring data using visualization\ndat %>% \n  select(-X) %>% \n  pivot_longer(cols=c(\"yrs.since.phd\",\"yrs.service\"),\n               names_to=\"predictor\",values_to=\"value\")%>%\n  ggplot()+\n  geom_point(aes(x=value, y=salary))+\n  facet_wrap(.~ factor(predictor),\n             scales = \"free_x\")\ndat %>% \n  select(-X) %>% \n  pivot_longer(cols=c(\"discipline\",\"rank\",\"sex\"),\n               names_to=\"predictor\",values_to=\"value\")%>%\n  ggplot()+\n  geom_boxplot(aes(x=value, y=salary, fill=value))+\n  facet_wrap(.~ factor(predictor),\n             scales = \"free_x\")+\n  theme(legend.position=\"none\")\n```\n\nนอกจากนี้ผู้วิเคราะห์ยังลองตรวจสอบว่ามีอิทธิพลปฏิสัมพันธ์ระหว่างตัวแปรอิสระที่มีต่อตัวแปรตามหรือไม่ โดยใช้ visualization เป็นเครื่องมือตรวจสอบเช่นเดียวกัน\n\n```{r fig.height=5, echo=F}\np1<-dat %>% \n  select(-X) %>% \n  pivot_longer(cols=c(\"yrs.since.phd\",\"yrs.service\"),\n               names_to=\"predictor\",values_to=\"value\")%>%\n  ggplot()+\n  geom_point(aes(x=value, y=salary, col=sex))+\n  facet_wrap(.~ factor(predictor),\n             scales = \"free_x\")\np2<-dat %>% \n  select(-X) %>% \n  pivot_longer(cols=c(\"yrs.since.phd\",\"yrs.service\"),\n               names_to=\"predictor\",values_to=\"value\")%>%\n  ggplot()+\n  geom_point(aes(x=value, y=salary, col=rank))+\n  facet_wrap(.~ factor(predictor),\n             scales = \"free_x\")\np3<-dat %>% \n  select(-X) %>% \n  pivot_longer(cols=c(\"yrs.since.phd\",\"yrs.service\"),\n               names_to=\"predictor\",values_to=\"value\")%>%\n  ggplot()+\n  geom_point(aes(x=value, y=salary, col=discipline))+\n  facet_wrap(.~ factor(predictor),\n             scales = \"free_x\")\np4<-dat %>% \n  select(-X) %>% \n  pivot_longer(cols=c(\"discipline\",\"rank\"),\n               names_to=\"predictor\",values_to=\"value\")%>%\n  ggplot()+\n  geom_boxplot(aes(x=value, y=salary, fill=sex))+\n  facet_wrap(.~ factor(predictor),\n             scales = \"free_x\")\np5<-dat %>% \n  select(-X) %>% \n  pivot_longer(cols=c(\"discipline\",\"sex\"),\n               names_to=\"predictor\",values_to=\"value\")%>%\n  ggplot()+\n  geom_boxplot(aes(x=value, y=salary, fill=rank))+\n  facet_wrap(.~ factor(predictor),\n             scales = \"free_x\")\ngrid.arrange(p1,p2,p3, nrow=3)\n```\n\n```{r echo=F, fig.height=4}\ngrid.arrange(p4,p5,nrow=2)\n```\n\nผลการสำรวจความสัมพันธ์ระหว่างตัวแปรข้างต้นเป็นอย่างไร ?\n\nใน tidymodels framework การเรียกใช้อัลกอริทึม ridge regression, lasso regression หรือ elastic-net regression สามารถทำได้โดยเลือก model type เป็น `linear_reg()` และกำหนด engine เป็น `glmnet` เมื่อพิจารณาการกำหนดอาร์กิวเมนท์ของ glmnet ในคู่มือ <https://www.tidymodels.org/find/parsnip/> พบว่า engine ดังกล่าวสามารถใช้ได้กับ model type ทั้ง linear regression, logistic regression และ multinomial regression ซึ่งสอดคล้องกับที่ได้กล่าวในส่วนภาคทฤษฎีว่าหลักของการ regularization สามารถนำไปใช้ได้กับอัลกอริทึมการเรียนรู้ได้มากมาย\n\nจากตารางจะเห็นว่า glmnet มีอาร์กิวเมนท์ 2 ตัวได้แก่ `penalty` และ `mixture` ที่เป็น hyperparameters ของอัลกอริทึม โดยที่\n\n-   `penalty` คือ regularization hyperparameter\n\n-   `mixture` คือสัดส่วนของ lasso penalty (เท่ากับค่า $\\alpha$ ใน part ทฤษฎี) หาก $\\alpha =1$ หมายถึงกำหนดให้ใช้อัลกอริทึมแบบ lasso แต่หาก $\\alpha = 0$ หมายถึงกำหนดให้ใช้อัลกอริทึม ridge regression และหากกำหนดให้ $\\alpha \\in (0,1)$ หมายถึงกำหนดให้ใช้ elastic-net regression\n\n#### Data Preprocessing Note:\n\nผู้วิเคราะห์จะต้องแปลงค่าของตัวแปรจัดประเภทให้เป็นตัวแปร dummy หรือตัวแปรแบบ indicator (หรือที่เรียกว่า one-hot encoding) ในกรณีที่ผู้วิเคราะห์เก็บข้อมูลของตัวแปรจัดประเภทเป็นแบบ factor ฟังก์ชัน `fit()` จะแปลงข้อมูลของตัวแปรแบบ factor ให้เป็น indicator โดยอัตโนมัติ สำหรับตัวแปรเชิงปริมาณจำเป็นที่ต้องทำการแปลงให้เป็นสเกลมาตรฐานก่อน\n\nตัวอย่างต่อไปนี้จะแสดงการ fit regularized regression ด้วย parsnip โดยยังไม่มีการปรับแต่ง hyperparameter ก่อน ส่วนตัวอย่างที่แสดงการพัฒนาอัลกอริทึมเต็มรูปแบบจะแสดงในส่วนถัดไป คำสั่งในส่วนแรกแสดงการแบ่งชุดข้อมูลเป็น training และ test dataset นอกจากนี้ยังแสดงการทำ feature engineering เพื่อทำให้ข้อมูลของตัวแปรอิสระเป็นไปตามข้อตกลงเบื้องต้นของการวิเคราะห์ regularized regression ผลลัพธ์ที่ได้จากขั้นตอนนี้คือชุดข้อมูล training และ test ที่ผ่านการทำ preprocessing แล้ว\n\n```{r}\n#data splitting\nsplit <- initial_split(data = dat, prop=0.8)\ntrain <- training(split)\ntest <- testing(split)\n#data preprocessing \nrec_dat <- recipe(salary ~., data = train) %>%\n  #remove X\n  step_select(-X) %>%\n  #create dummy variable\n  step_dummy(rank, discipline, sex) %>% \n  #standarized numeric\n  step_normalize(all_numeric_predictors()) %>% \n  #create interaction term\n  step_interact(terms = ~ yrs.since.phd:starts_with(\"discipline\")) %>%\n  prep(training_data = train)\nrec_dat\n# create preprocessed train and test dataset\ntrain_preproc <- rec_dat %>% bake(NULL)\ntest_preproc <- rec_dat %>% bake(new_data = test)\nglimpse(train_preproc)\n```\n\nตัวอย่างต่อไปนี้แสดงการระบุโมเดลด้วย engine glmnet โดยตัวอย่างแรกนี้จะกำหนดให้อาร์กิวเมนท์ `penalty = 0` ผลการวิเคราะห์ที่ได้จากการระบุโมเดลนี้จะเท่ากับ ols regression แบบปกติ\n\n```{r}\n#model specification: ols regression\nregularized_reg <- linear_reg(mixture = 0, penalty = 0) %>% \n  set_engine(engine = \"glmnet\") %>%\n  set_mode(\"regression\")\nreg_fit <- regularized_reg %>% \n  fit(salary ~., data = train_preproc)\n#ols regression estimate\ntidy(reg_fit)\n```\n\nการใช้ tidymodels framework ช่วยให้ผู้วิเคราะห์สามารถเรียกดูค่าประมาณของสัมประสิทธิ์ความชันของโมเดลในกรณีที่มีการกำหนด penalty hyperparameter ต่าง ๆ ได้ เช่น\n\n```{r fig.height=3}\ntidy(reg_fit, penalty=10000)\n# magnitude of b\nreg_fit%>%\n  autoplot()\n```\n\nจากตัวอย่างการวิเคราะห์ข้างต้นจะเห็นว่าเมื่อกำหนดให้ penalty term มีค่ามากขึ้นเรื่อย ๆ ค่าของสัมประสิทธิ์ความชันของโมเดลจะมีแนวโน้มลู่เข้าหา 0 ดังที่ได้กล่าวไว้ในในส่วนทฤษฎี\n\nผลการวิเคราะห์ต่อไปนี้แสดงการเปรียบเทียบประสิทธิภาพของการทำนายที่ได้จากโมเดล ridge regression ที่มีการกำหนด penalty term เท่ากับ 0, 5000 และ 10000 ตามลำดับ\n\n```{r}\npred1 <- predict(reg_fit, new_data = test_preproc)\npred2 <- predict(reg_fit, new_data = test_preproc, penalty = 5000)\npred3 <- predict(reg_fit, new_data = test_preproc, penalty = 10000)\ntest_preproc %>%\n  dplyr::select(salary) %>%\n  bind_cols(pred1, pred2, pred3) %>%\n  rename( pred_ols = .pred...2 ,\n          pred_ridge5k = .pred...3,\n          pred_ridge_10k = .pred...4) %>%\n  pivot_longer(cols = starts_with(\"pred\"),\n               names_to = \"model\",\n               values_to = \"pred_value\") %>%\n  group_by(model) %>%\n  summarise(rmse = sqrt(mean((salary-pred_value)^2)),\n            rsq = cor(salary, pred_value)^2\n  )\n```\n\nผลลัพธ์ที่ได้ข้างต้นแสดงให้เห็นว่าการกำหนด penalty term ที่แตกต่างกันมีผลต่อประสิทธิภาพในการทำนายของโมเดล อย่างไรก็ตามวิธีการข้างต้นไม่ใช่วิธีที่มีประสิทธิภาพที่จะให้หาค่าที่ดีที่สุดของ hyperparameters ทั้งสองค่าดังกล่าว ตัวอย่างต่อไปจะแสดงการใช้ k-folds cross-validation เข้ามาช่วยเฟ้นหาค่า hyperparameters ที่เหมาะสม คำสั่งด้านล่างแสดงการใช้ workflow ของ tidymodels เข้ามาช่วยปรับแต่งค่า hyperparameters ดังกล่าว รูปด้านล่างแสดงลักษณะของ workflow ซึ่งจะเห็นว่าเป็นการรวม object สองชนิดเข้าด้วยกันคือ recipe และ parsnip\n\n![tidymodels workflow (ดัดแปลงจาก Mark Khun)](images/image-1608202707.png){alt=\"tidymodels workflow (ดัดแปลงจาก Mark Khun)\"}\n\nคำสั่งต่อไปนี้แสดงการปรับแต่ง hyperparameter ด้วย workflow ของ tidymodels ดังกล่าว\n\n```{r}\n# create repeated 10-folds CV datasets\nfolds_data <- vfold_cv(data = train, \n                       v = 10, \n                       repeats = 3)\nfolds_data\n```\n\nจะเห็นว่า repeated 10-folds CV เป็นการทำ 10-folds CV ซ้ำจำนวน 3 ครั้ง ผลลัพธ์ข้างต้นจึงจะเห็นว่าเป็น tibble ขนาด 30 x 3\n\n### ตัวอย่างการสร้าง workflow เพื่อทำ hyperparameter tuning : Ridge Regression\n\nขั้นตอนต่อไปเป็นการสร้าง workflow สำหรับพัฒนา regularized regression จากรูปจากข้างจะเห็นว่า workflow หนึ่ง ๆ ประกอบด้วยส่วนของการเตรียมข้อมูล และ modelling ที่จัดเก็บอยู่ใน recipe และ parsnip objects รายละเอียดของชุดคำสั่งมีดังนี้\n\n```{r}\n#data preprocessing specification\ndat_rec <- recipe(salary ~., data = train) %>%\n  step_select(-X) %>%\n  step_dummy(rank, discipline, sex) %>% \n  step_normalize(all_numeric_predictors()) %>% \n  step_interact(terms = ~ yrs.since.phd:starts_with(\"discipline\"))\n#model specification\nregularized_reg <- linear_reg(penalty = tune(),\n                              mixture = 0) %>% #ridge regression\n  set_mode(\"regression\") %>%\n  set_engine(\"glmnet\")\n#create a workflow object\nregularized_workflow <- workflow() %>%\n  add_recipe(dat_rec) %>%\n  add_model(regularized_reg)\nregularized_workflow\n```\n\nผลลัพธ์ข้างต้นจะเห็นว่า workflow ช่วยรวบรวมส่วนของการ preprocessing และ modeling ให้อยู่ภายใต้ object เดียวกัน เมื่อสร้าง workflow เรียบร้อยแล้ว ขั้นตอนถัดไปคือการสร้าง grid ของ hyperparameters เพื่อใช้สำหรับการเฟ้นหาชุดของ hyperparameter ที่มีความเหมาะสมกล่าวคือทำให้ประสิทธิภาพการทำนายของโมเดลมีสูงที่สุด ดังที่ได้กล่าวในบทที่ 5 ว่าการกำหนด grid อาจทำได้สองวิธี วิธีการแรกคือการใช้ regular grid search ที่จะสร้าง grid จาก combination ของค่าที่เป็นไปได้ทั้งหมดของ hyperparameters ที่สนใจ การสร้าง grid ดังกล่าวสามารถทำได้หลายวิธีการ โดยใน tidymodels สามารถทำได้ด้วยฟังก์ชัน `grid_regular()` ของ package dial ดังตัวอย่างต่อไปนี้\n\n```{r}\np<-parameters(penalty(range=c(-100,100)))\nregular_grid <- grid_regular(p, levels=50)\nregular_grid\n```\n\nการปรับแต่งค่าพารามิเตอร์ด้วยการดำเนินการข้างต้นมีข้อจำกัดคือเป็นวิธีการที่ใช้ทรัพยากรค่อนข้างมาก อีกวิธีการหนึ่งที่ช่วยลดการใช้ทรัพยากรของเครื่องลงได้คือการใช้ random grid search ซึ่งเป็นการสุ่มชุดของ hyperparameter มาวิเคราะห์ การดำเนินการตามวิธีการนี้สามารถทำได้ด้วยฟังก์ชัน `grid_random()` ดังนี้\n\n```{r}\nrandom_grid <- grid_random(p, size = 10)\nrandom_grid\n```\n\nตัวอย่างต่อไปนี้จะเปรียบเทียบผลที่ได้จากการปรับแต่งค่า hyperparameters ด้วยการทำ repeated 10-fold CV บน grid ของ hyperparameter ที่สร้างขึ้นจากสองวิธีการข้างต้น จากตัวอย่างด้านล่างจะเห็นว่าการ fit model ในแต่ละ fold จะใช้ฟังก์ชัน `tune_grid()` เป็นตัวดำเนินการแทนฟังก์ชัน `fit()` ทั้งนี้ `tune_grid()` มีอาร์กิวเมนท์ที่สำคัญได้แก่\n\n-   `resamples` ใช้ระบุชุดข้อมูลที่สร้างขึ้นจากกระบวนการสุ่มซ้ำ เช่น k-folds CV หรือ boostraping dataset\n\n-   `grid` ใช้สำหรับระบุ grid ของ hyperparameter ของอัลกอริทึมการเรียนรู้ที่เลือกใช้\n\n-   `control` ใช้กำหนด option สำหรับควบคุมกระบวนการสุ่มซ้ำ (resample) และปรับแต่งค่า hyperparameter การกำหนดอาร์กิวเมนท์นี้จะต้องกำหนดผ่านฟังก์ชัน `control_resamples()` หรือ `control_grid()` อีกทีหนึ่ง รายละเอียดของฟังก์ชันทั้งสองสามารถศึกษาได้จากคู่มือการใช้งาน (พิมพ์ `?control_resamples` หรือ `?control_grid`)\n\n-   `metrics` ใช้กำหนด evalution metrics ที่ผู้วิเคราะห์จะใช้เพื่อประเมินประสิทธิภาพของโมเดลระหว่างการปรับแต่งค่าพารามิเตอร์ การกำหนดอาร์กิวเมนท์นี้ให้ทำผ่านฟังก์ชัน `metric_set()` ในกรณีที่ไม่ได้กำหนดโปรแกรมจะกำหนดให้ใช้ค่าเริ่มต้น ซึ่งจะเลือกให้เหมาะสมกับ mode ของโมเดล\n\n```{r warning=F, message=F}\ncontrol_options <- control_grid(verbose = TRUE, save_pred = TRUE)\neval_metric <- metric_set(rsq, rmse, mae)\n#regular grid search \nstart <- Sys.time()\ntune_regular <- regularized_workflow %>%\n  tune_grid(resamples = folds_data,\n            grid = regular_grid,\n            control = control_options,\n            metrics = eval_metric)\nend <- Sys.time()\npaste(\"time usage (regular grid search) = \", round(end - start,1))\n#random grid search \nstart <- Sys.time()\ntune_random <- regularized_workflow %>%\n  tune_grid(resamples = folds_data,\n            grid = random_grid,\n            control = control_options,\n            metrics = eval_metric)\nend <- Sys.time()\npaste(\"time usage (random grid search) = \", round(end - start,1))\n```\n\n**การประมวลผลข้างต้นการปรับแต่งค่า hyperparameters แต่ละวิธีการใช้เวลาเท่าไหร่ และผลที่ได้จากการปรับแต่งค่า hyperparameters มีความเหมือนหรือแตกต่างกันอย่างไร?**\n\n```{r fig.height=4}\ntune_regular %>% autoplot()\ntune_random %>% autoplot()\n```\n\nจากการทำ workflow ข้างต้นผู้วิเคราะห์สามารถเรียกดูผลการประเมินประสิทธิภาพของโมเดลทำนายที่คำนวณจากการทำ cross-validation โดยใช้ฟังก์ชัน `collect_metric()` ฟังก์ชันนี้มีอาร์กิวเมนท์ที่ควรรู้จักคือ `summarize` ค่าเริ่มต้นจะกำหนดให้เป็น `TRUE` ผลลัพธ์ที่ได้จะเป็นค่าสรุปประสิทธิภาพการทำนายของโมเดลในแต่ละ grid แต่ถ้ากำหนดให้เป็น `FALSE` ผลลัพธ์ที่ได้จะลงรายละเอียดของประสิทธิภาพเป็นราย validation dataset\n\n```{r}\ntune_regular %>% \n  collect_metrics(summarize = TRUE)\ntune_regular %>% \n  collect_metrics(summarize = TRUE)%>%\n  ggplot(aes(x=penalty, y=mean, col=.metric))+\n  geom_line()+\n  geom_point(aes(shape = .metric))\ntune_random %>% \n  collect_metrics(summarize = FALSE)\n```\n\nนอกจากนี้ยังมีฟังก์ชัน `collect_predictions()` ที่สามารถใช้เรียกค่าทำนายของตัวแปรตามที่ได้จากแต่ละ resample และชุดของ hyperparameter ภายใน grid การใช้ฟังก์ชันนี้ทำในทำนองเดียวกับ `collect_metrics()` ดังตัวอย่างต่อไปนี้\n\n```{r}\ntune_regular %>%\n  collect_predictions()\n```\n\nนอกจากการวิเคราะห์ข้างต้นแล้วยังสามารถใช้ฟังก์ชัน `show_best()` เพื่อคัดเลือกโมเดลทำนายที่ดีที่สุดจาก grid ที่ผู้วิเคราะห์วิเคราะห์ไว้ในข้างต้น ฟังก์ชันนี้ยังมีอาร์กิวเมนท์ `n` สำหรับกำหนดว่าต้องการให้เลือกโมเดลที่ดีที่สุดกี่อันดับแรกขึ้นมาให้ผู้วิเคราะห์ และอาร์กิวเมนท์ `metric` ใชัสำหรับระบุ evaluation metric ที่จะใช้คัดเลือกโมเดลทำนายดังกล่าว ตัวอย่างต่อไปนี้แสดงผลคัดเลือกโมเดลทำนายจากวิธีการสร้าง grid ทั้งสองวิธี จะเห็นว่าผลลัพธ์ที่ได้สอดคล้องกัน\n\n```{r}\nshow_best(tune_regular, n=5, metric=\"rmse\")\nshow_best(tune_random, n=5, metric=\"rmse\")\n```\n\n#### กิจกรรม 1 :\n\nขอให้นิสิตทดลอง plot R square plot ของโมเดลที่ดีที่สุดข้างต้น ผลลัพธ์ที่ได้เป็นอย่างไร นิสิตที่ข้อเสนอแนะในการพัฒนาโมเดลทำนายดังกล่าวอย่างไร?\n\n```{r echo=F, eval=F}\npenalty_best <- show_best(tune_random, n=1, metric=\"rmse\")$penalty\ntune_random %>%\n  collect_predictions() %>%\n  filter(penalty == penalty_best) %>%\n  ggplot()+\n  geom_point(aes(x=salary, y=.pred))\n```\n\n#### กิจกรรม 2 :\n\nขอให้นิสิตลองใช้อัลกอริทึม regularized regression ตัวอื่นเพื่อพัฒนาโมเดลทำนายเงินเดือนอาจารย์มหาวิทยาลัย โดยใช้ชุดข้อมูล `TeacherSalaryData.csv` ผลลัพธ์ที่ได้เป็นอย่างไร\n\n## 6.4 Tuning and Comparing Models\n\nโดยทั่วไปในการพัฒนาโมเดลทำนาย ผู้วิเคราะห์จำเป็นต้องทดลองพัฒนาโมเดลทำนายจากอัลกริทึมการเรียนรู้หลายตัว การดำเนินงานดังกล่าวจึงต้องมีทั้งส่วนของการปรับแต่งค่า hyperparameters ของแต่ละอัลกอริทึม และต้องมีส่วนของการเปรียบเทียบประสิทธิภาพการทำนายของโมเดลในชุดข้อมูลทดสอบ จะเห็นว่าการดำเนินการดังกล่าวค่อนข้างมีความซับซ้อน และต้องมีการเขียนชุดคำสั่งเป็นจำนวนมาก\n\nใน tidymodels มีตัวแปรอีกประเภทที่เรียกว่า workflow set ที่ใช้เก็บ workflow หลาย ๆ ตัวเข้ามารวมไว้ในตัวแปรเดียว ซึ่งทำให้การทำ data preprocessing การปรับแต่งค่า hyperparameters และการเปรียบเทียบประสิทธิภาพระหว่างโมเดลทำนายที่พัฒนาจากอัลกอริทึมที่แตกต่างกันหลาย ๆ ตัวสามารถทำได้ง่ายมากขึ้น\n\nตัวอย่างต่อไปนี้จะแสดงการพัฒนาโมเดลทำนายโดยใช้อัลกอริทึมได้แก่ regularized logistic regression และ decision tree โดยจะใช้ชุดข้อมูลตัวอย่างจาก package modeldata\n\n```{r}\n#importing data\ndata(parabolic)\nglimpse(parabolic)\n# splitting data\nsplit <- initial_split(data = parabolic)\ntrain <- training(split)\ntest <- testing(split)\n```\n\nชุดข้อมูล parabolic ประกอบด้วยตัวแปร 3 ตัว โดยตัวแปรตามเป็นตัวแปรจัดประเภทที่มี 2 categories และตัวแปรอิสระประกอบด้วย X1 และ X2\n\n```{r fig.height=4, fig.width=4}\ntrain %>%\n  ggplot(aes(x = X1, y = X2, col=class))+\n  geom_point(alpha=0.7)+\n  theme_light()+\n  theme(legend.position=\"top\")\n```\n\n### Model Specification\n\nสร้าง model specification ทั้งหมดที่ต้องการ\n\n```{r}\nlogistic_mod <- logistic_reg(penalty= tune(),\n                             mixture = tune()) %>%\n  set_engine(\"glmnet\")%>%\n  set_mode(\"classification\")\n\ntree_mod <- decision_tree(cost_complexity = tune(),\n                            min_n = tune())%>%\n  set_engine(\"rpart\")%>%\n  set_mode(\"classification\")\n```\n\n### สร้าง workflowset และวิเคราะห์ hyperparemeters\n\n```{r warning=F, eval=F}\n# create workflowset\nmod_specs <- workflow_set(\n  preproc = list(\"formula\" = class ~ .),\n  models = list(glmnet = logistic_mod,\n                cart = tree_mod)\n)\n#create resamples\nresamples <- bootstraps(data = train)\n\n# tunegrid using workflowmap\ntune_results<- mod_specs %>% \n  workflow_map(\"tune_grid\",\n                           resamples = resamples,\n                           grid = 10,\n                           metrics = metric_set(roc_auc, sens, spec),\n               verbose = TRUE)%>%\n    option_add(control = control_grid(save_pred=T, parallel_over =\"resamples\"))\n# rankmodels\nrank_results(tune_results, rank_metric =\"roc_auc\")\nautoplot(tune_results)\n\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"output-file":"04Regularization.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","editor":"visual","urlcolor":"steelblue","linkcolor":"steelblue","theme":{"light":["pandoc","../theme.scss"]},"mainfont":"Krub","code-copy":true,"title":"Regularization","author":"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร","toc-title":"สารบัญ"},"extensions":{"book":{"multiFile":true}}}}}