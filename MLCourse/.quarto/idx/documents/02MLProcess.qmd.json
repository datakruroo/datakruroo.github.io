{"title":"Modelling Process","markdown":{"yaml":{"title":"Modelling Process","author":"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร","toc":true,"toc-depth":3,"toc-title":"สารบัญ","theme":"default"},"headingText":"บทที่ 3 กระบวนการพัฒนา Machine Learning Models","containsRefs":false,"markdown":"\n\n```{r echo=F, message=F, warning = F}\nlibrary(tidyverse)\n```\n\n\nกระบวนการพัฒนา machine learning models อาจจำแนกได้เป็นสองส่วน ส่วนแรกคือส่วนของการพัฒนาโมเดล และส่วนที่สองคือส่วนของการนำโมเดลไปใช้งาน\n\nส่วนการพัฒนาโมเดลมีกระบวนการพัฒนาแสดงไว้ในรูป 15 จากรูปจะเห็นว่าเริ่มตั้งแต่การเก็บรวบรวมข้อมูล การจัดการข้อมูล จากนั้นจะมีการแบ่งชุดข้อมูลออกเป็นส่วน traning dataset และ test dataset ข้อมูลส่วนที่เป็น traning dataset จะถูกนำมาพัฒนาการเรียนรู้/ความสามารถในการทำนายของโมเดล ผ่านอัลกอริทึมต่าง ๆ จากนั้นจะเลือกอัลกอริทึมที่มีประสิทธิภาพสูงที่สุด (ประเมินจาก test dataset) ไปใช้งาน ทั้งนี้การจะนำโมเดลทำนายไปใช้งานได้นั้นจะต้องมีบันทึกโมเดลที่พัฒนาขึ้นเพื่อนำไปเรียกใช้ต่อไป\n\n![Modeling Process](images/image-1728379488.png){alt=\"Modeling Process\"}\n\nลักษณะเฉพาะในกระบวนการพัฒนาโมเดลทำนายคือ การดำเนินงานในหลายขั้นตอน เช่น การจัดการข้อมูล การ fit และปรับแต่งโมเดล หรือการคัดเลือกโมเดลทำนายที่ดีที่สุด ไม่ได้มีแนวทางหรือกฎเกณฑ์ที่ชัดเจนตายตัวว่าต้องดำเนินการอย่างไร นอกจากนี้กระบวนการดังกล่าวยังมีลักษณะเป็นแบบทวนซ้ำไปมา รูป 16 แสดงตัวอย่างการดำเนินงานของผู้วิเคราะห์เพื่อพัฒนาโมเดลทำนายโมเดลหนึ่ง\n\n![ตัวอย่างขั้นตอนการพัฒนาโมเดลทำนาย (ที่มา : Max Kuhn and Kjell Johnson (2019))](images/image-1908104112.png){alt=\"ตัวอย่างขั้นตอนการพัฒนาโมเดลทำนาย (ที่มา : Max Kuhn and Kjell Johnson (2019))\" fig-align=\"center\" width=\"70%\"}\n\nจากรูปข้างต้นจะเห็นว่ากระบวนการเริ่มต้นด้วยกากการวิเคราะห์เพื่อสำรวจข้อมูล (exploratory data analysis: EDA) ก่อน (จุด a) โดยที่ EDA เป็นเทคนิคที่ผู้วิเคราะห์ใช้เพื่อทำความเข้าใจคุณลักษณะสำคัญของตัวแปรต่าง ๆ ภายในชุดข้อมูล ซึ่งประกอบด้วย (1) การวิเคราะห์สถานะและการแจกแจงของตัวแปร (2) การวิเคราะห์ความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระ รวมทั้งความสัมพันธ์ระหว่างตัวแปรอิสระ (3) การวิเคราะห์รูปแบบการสูญหายของข้อมูล และ (4) ความผิดปกติที่อาจเกิดขึ้นในข้อมูล กระบวนการในส่วนของการสำรวจนี้เป็นกระบวนการทวนซ้ำและอาจมีการสลับไปมาระหว่างการใช้ทัศนภาพข้อมูลเชิงสำรวจ และการใช้เทคนิคการวิเคราะห์เชิงปริมาณ (จุด b) เข้ามาช่วย สารสนเทศที่ได้จากกระบวนส่วนนี้จะสามารถใช้เป็นแนวทางเพื่อจัดข้อมูลของตัวแปรอิสระให้เหมาะสมและมีประสิทธิภาพสูงที่สำหรับการพัฒนาโมเดลทำนายต่อไป เรียกขั้นตอนนี้ว่า feature engineering (จุด c) เมื่อสิ้นสุดขั้นตอนนี้ผลผลิตที่ควรได้คือชุดข้อมูลต้นแบบที่ประกอบด้วยตัวแปรตาม และตัวแปรอิสระที่ผ่านการคัดเลือกหรือทำ feature engineering มาแล้ว และอยู่ในรูปแบบที่พร้อมจะนำไปวิเคราะห์\n\nเมื่อได้ชุดข้อมูลต้นแบบมาเรียบร้อยแล้ว ผู้วิเคราะห์จะนำชุดข้อมูลดังกล่าวไปเป็นต้นแบบให้อัลกอริทึมการเรียนรู้ของเครื่องหลาย ๆ ตัวได้เรียนรู้ เพื่อพัฒนาเป็นโมเดลทำนาย (จุด d) จากรูปจะเห็นว่าอัลกอริทึมที่ถูกเลือกมาใช้จำนวน 4 อัลกอริทึม ทั้งนี้อัลกอริทึมส่วนใหญ่มักมีส่วนประกอบที่เรียกว่า hyperparameters ที่ต้องกำหนดค่าด้วยการปรับแต่ง (tuning) จากรูปจะเห็นว่าการเรียนรู้ในแต่ละอัลกอริทึมจะมีขั้นตอนของการเรียนรู้ และการปรับแต่ง hyperparameters ที่ต้องดำเนินการแบบทวนซ้ำสลับไปมาจนกระทั่งได้โมเดลที่มีประสิทธิภาพสูงสุด ทั้งนี้เมื่อได้โมเดลดังกล่าวแล้ว ผู้วิเคราะห์จะนำโมเดลที่พัฒนาได้ไปประเมินประสิทธิภาพการทำนายของโมเดล การดำเนินงานในส่วนนี้จะมีการใช้ทั้งการวิเคราะห์เชิงปริมาณผ่านค่าสถิติต่าง ๆ เช่น evaluation metrics ต่าง ๆ ที่ใช้ประเมินประสิทธิภาพการทำนาย รวมทั้งยังอาจมีการใช้ EDA อีก เพื่อวิเคราะห์ประสิทธิภาพ หรือข้อจำกัดของแต่ละโมเดลในการทำนายผลลัพธ์ที่ต้องการ (จุด e และ f)\n\nสารสนเทศที่ได้จากการวิเคราะห์ประสิทธิภาพของโมเดลจะเป็นตัวกำหนดการดำเนินงานต่อไปของผู้วิเคราะห์ โดยอาจจำแนกเป็นสองกรณี กรณีแรกคือหากโมเดลมีประสิทธิภาพในการทำนายสูงอยู่ระดับที่สามารถนำไปใช้งานได้แล้วผู้วิเคราะห์จะหยุดการดำเนินงานไว้ที่ขั้นตอนนี้แล้วนำโมเดลดังกล่าวไปใช้งานต่อไป กรณีที่สองหากโมเดลทำนายที่พัฒนาขึ้นยังมีประสิทธิภาพไม่ถึงเกณฑ์ที่กำหนด ผู้วิเคราะห์สามารถใช้สารสนเทศจาก EDA ในจุด f ประกอบการคัดเลือกโมเดลเบื้องต้น และปรับแต่งโมเดลรวมทั้งอาจดำเนินการทำ feature engineering อีกครั้งหนึ่งเพื่อเพิ่มประสิทธิภาพการทำนายให้กับโมเดล (จุด h) เมื่อได้โมเดลสุดท้ายแล้วผู้วิเคราะห์สามารถเปรียบเทียบประสิทธิภาพระหว่างโมเดลคู่แข่งขันโดยใข้ชุดข้อมูลทดสอบ (test dataset) แล้วเลือกโมเดลที่ดีที่สุดไปใช้งาน\n\nส่วนของการนำโมเดลไปใช้งาน ต้องทำความเข้าใจว่า ML model ที่พัฒนาขึ้นนั้นเป็นเหมือนสมองซึ่งต้องเข้าไปอยู่ในโปรแกรมหรือ application สักตัวหนึ่ง โดยโปรแกรมดังกล่าวจะมีหน้าที่หลัก ๆ เช่นมี interface สำหรับรับข้อมูลจากผู้ใช้ เพื่อนำไปประมวลผลด้วยโมเดลทำนายที่เราสร้างขึ้น และรายงานผลการทำนาย/จำแนก ที่ได้จากโมเดลให้แก่ผู้ใช้ ทั้งนี้โปรแกรมดังกล่าวยังอาจมีส่วนอื่น ๆ ที่ยอมให้ผู้ใช้เลือกหรือปรับแต่งการทำงานของโปรแกรมได้ ทั้งนี้ขึ้นอยู่กับวัตถุประสงค์การใช้งาน ตัวอย่างด้านล่างแสดงโปรแกรมทำนายผลการเรียนของนิสิต [KruRooTeller](https://siwachoat.shinyapps.io/reportandpredict/?_ga=2.42051557.1707159165.1666195773-1113918738.1613372414&utm_source=KruRooTeller)\n\n![ระบบ KruRooTeller](images/image-1909139629.png){alt=\"ระบบ KruRooTeller\" width=\"90%\"}\n\nเนื้อหาส่วนที่เหลือของบทเรียนนี้จะกล่าวถึงกระบวนการในส่วนของการพัฒนา supervised learning models โดยจะกล่าวถึงมโนทัศน์ที่จำเป็นก่อน จากนั้นจึงกล่าวถึงกระบวนการพัฒนาโมเดลดังกล่าว รายละเอียดมีดังนี้\n\n\\newpage\n\n## 3.1 Bias and Variance in ML models\n\nพิจารณารูป 18 แสดงการ fit โมเดลทำนาย 3 แบบกับชุดข้อมูลฝึกหัดชุดหนึ่ง จะเห็นว่าแต่ละโมเดลมีความสามารถในการเรียนรู้ความสัมพันธ์ที่เกิดขึ้นในชุดข้อมูลแตกต่างกัน ความแตกต่างระหว่างค่าจริงของตัวแปรตามในชุดข้อมูลฝึกหัดกับค่าทำนายที่ได้จากโมเดล เรียกว่า **ความลำเอียง (bias)** **จากรูป 16 ผู้อ่านคิดว่าโมเดลใดที่มีประสิทธิภาพในการทำนายสูงที่สุดเพราะเหตุใด ?**\n\n```{r echo=F, warning=F, fig.cap=\"regression model on training dataset\", fig.width=3.5, fig.height=2.5,  message=F}\nx<-runif(25,0,1)\ny<-sin(1.2*x*pi)+rnorm(25,0,0.15)\ndat<-data.frame(x,y)\ndat%>%ggplot(aes(x=x,y=y))+\n   geom_point(size=2,alpha=0.6)+\n    theme_minimal()+\n   geom_line(data=dat, \n             aes(x=x, y=y), col=\"maroon\", size=1, alpha=0.7)+\n    geom_smooth(se=F, alpha=0.7)+\n    geom_smooth(method=\"lm\", se=F, alpha=0.7, col=\"black\")+\n  annotate(geom = \"text\", x=0.3, y = -0.25, \n           label = \"Model = Signal + Error\")+\n  scale_x_continuous(limits=c(0,1))\n\n```\n\nพิจารณารูป 19 ผู้วิเคราะห์ได้นำโมเดลทำนายทั้ง 3 แบบ ที่พัฒนาจากชุดข้อมูลฝึกหัดมาใช้ทำนายข้อมูลใหม่ที่โมเดลทั้ง 3 ไม่เคยได้เรียนรู้มาก่อน ความแตกต่างระหว่างค่าจริงของตัวแปรตามในชุดข้อมูลใหม่ (หรือชุดข้อมูลที่ไม่ได้ใช้ในขั้นการพัฒนาโมเดล) กับค่าทำนายของโมเดล เรียกว่า **ความแปรปรวน (variance)** ความแปรปรวนของโมเดลทั้ง 3 เป็นอย่างไร?\n\n```{r echo=F, warning=F, fig.cap=\"regression model on new dataset\", fig.width=3.5, fig.height=2.5, message=F}\nx<-seq(0,1,length=10)\ny<-sin(1*x*pi)+rnorm(10,0,0.15)\ndat2<-data.frame(x,y)\ndat$type<-1\ndat2$type<-2\ntemp<-bind_rows(dat,dat2)\ntemp$type<-factor(temp$type, labels=c(\"training data\",\"new data\"))\n\n\nggplot()+\n   geom_point(data=temp%>%filter(type==\"new data\"),\n              aes(x=x,y=y, col=type), \n              size=2, \n              alpha=0.6, show.legend = F)+\n    theme_minimal()+\n   geom_line(data=temp%>%filter(type==\"training data\"), \n             aes(x=x, y=y), col=\"maroon\")+\n    geom_smooth(data=temp%>%filter(type==\"training data\"),\n                aes(x=x, y=y),\n                se=F, col=\"steelblue\", alpha=0.7)+\n  geom_smooth(data=temp%>%filter(type==\"training data\"),\n                aes(x=x, y=y),\n              method=\"lm\",\n                se=F, col=\"black\", alpha=0.7)+\n    scale_color_discrete(direction=-1)+\n    scale_x_continuous(limits=c(0,1))+\n  annotate(geom=\"text\", x=0.8, y= 0.95, label=\"new data\")\n\n```\n\nจากตัวอย่างข้างต้นจะเห็นว่า ถึงแม้จะสามารถพัฒนาโมเดลทำนายให้สามารถเรียนรู้ความสัมพันธ์ภายในชุดข้อมูลฝึกหัดได้เป็นอย่างดี (มีความลำเอียงต่ำที่สุดแล้ว) แต่ก็ไม่ใช่เงื่อนไขเพียงพอที่จะสรุปได้ว่าโมเดลทำนายดังกล่าวจะมีประสิทธิภาพในการทำนายได้ดีในกรณีทั่วไป การตรวจสอบอีกชั้นหนึ่งคือตรวจสอบความแปรปรวนของโมเดลทำนาย โดยนำโมเดลดังกล่าวไปทำนายชุดข้อมูลที่ไม่เคยได้เรียนรู้มาก่อน โมเดลที่มีทั้งความลำเอียงและความแปรปรวนต่ำจึงเป็นโมเดลที่มีประสิทธิภาพที่จะนำไปใช้ในกรณีทั่วไป\n\nในเชิงอุดมคติ ผู้วิเคราะห์ต้องการให้ทั้งความลำเอียง และความแปรปรวนมีค่าต่ำที่สุดเท่าที่จะสามารถต่ำได้ แต่ในความเป็นจริงความคลาดเคลื่อนทั้งสองไม่ควบคุมให้ต่ำที่สุดพร้อมกันได้ **(เพราะอะไร?)** รูป 20 ด้านล่างแสดงความสัมพันธ์ระหว่างความลำเอียง และความแปรปรวน ซึ่งจะเห็นว่ามีการแปรผกผันซึ่งกันและกัน โมเดลที่มีความลำเอียงสูงมีแนวโน้มที่จะมีความแปรปรวนต่ำ และในทางกลับกันโมเดลที่มีความลำเอียงต่ำจะมีแนวโน้มที่มีความแปรปรวนสูง **ดังนั้นวัตถุประสงค์ของการพัฒนาโมเดลจึงเป็นการหาจุดที่ดีที่สุดที่ทำให้ความคลาดเคลื่อนทั้งสองอยู่ในจุดที่ต่ำที่สุดเท่าที่จะเป็นไปได้**\n\n![bias and variance trace-off](images/image-712567945.png){alt=\"bias and variance trace-off\" fig-align=\"center\" width=\"60%\"}\n\n## 3.2 Underfitting, Overfitting และ Good fit models\n\nหากจำแนกโมเดลทำนายที่ถูกพัฒนาขึ้นตามประสิทธิภาพการทำนายของโมเดล อาจจำแนกได้เป็น 3 ประเภท ได้แก่\n\n1.  underfitting models คือโมเดลที่มีความลำเอียงสูง ความลำเอียงเป็นความคลาดเคลื่อนที่เป็นระบบ อันเนื่องมาจากโมเดลทำนายที่พัฒนาขึ้นยังไม่สามารถเรียนรู้แนวโน้มหรือรูปแบบความสัมพันธ์หลักระหว่างตัวแปรภายในชุดข้อมูลฝึกหัดได้ดีเพียงพอ จากรูป 21 ซ้ายมือ จะเห็นว่าแนวโน้มความสัมพันธ์ตามธรรมชาติระหว่างตัวแปรตามกับตัวแปรอิสระคือความสัมพันธ์เชิงเส้นโค้ง แต่โมเดลทำนายที่พัฒนาขึ้นอยู่ในรูปแบบเส้นตรง ความแตกต่างระหว่างรูปแบบความสัมพันธ์ดังกล่าวก่อให้เกิดความลำเอียงขึ้น และเรียกโมเดลที่มีความลำเอียงในระดับที่มากเกินไปนี้ว่า underfitting model\n2.  overfitting models คือโมเดลที่มีความแปรปรวนสูง ความแปรปรวนเกิดขึ้นจากการที่โมเดลทำนายที่พัฒนาขึ้นสามารถเรียนรู้ความสัมพันธ์ในชุดข้อมูลฝึกหัดได้ดีมากเกินไป จนขาดความยืดหยุ่นในการนำโมเดลดังกล่าวไปใช้ในกรณีทั่วไป ดังตัวอย่างในรูป 21 ขวามือ จากรูปจะเห็นว่าโมเดลสามารถเรียนรู้ความสัมพันธ์ได้เกือบสมบูรณ์ แต่หากนำโมเดลนี้ไปใช้ทำนายข้อมูลใหม่ที่อยู่นอกเหนือจากชุดข้อมูลที่โมเดลนี้ได้เรียนรู้มีแนวโน้มสูงที่จะเกิดความคลาดเคลื่อนในการทำนาย\n3.  good fit models คือโมเดลที่สามารถสมดุลความลำเอียงและความแปรปรวนให้มีค่าต่ำที่สุดเท่าที่จะเป็นไปได้\n\n![underfitting, good fit, and overfitting model](images/image-1638148101.png){alt=\"underfitting, good fit, and overfitting model\"}\n\n## 3.3 Training, validation, and Test Dataset\n\nจาก concept ข้างต้นจะเห็นว่าในกระบวนการพัฒนาโมเดลผู้วิเคราะห์จะให้ความสำคัญกับประสิทธิภาพในการทำนายของโมเดลเฉพาะด้านความลำเอียงไม่ได้ ยังต้องคำนึงถึงด้านความแปรปรวนด้วย การพัฒนาโมเดลการเรียนรู้ของเครื่องจึงจะมีแค่ชุดข้อมูลฝึกหัดไม่ได้ ยังต้องมีชุดข้อมูลอีกชุดหนึ่งเพื่อเอาไว้ตรวจสอบความแปรปรวนของโมเดลด้วย ในเชิงเทคนิคเรียกชุดข้อมูลนี้ว่า **ชุดข้อมูลทดสอบ (test dataset)**\n\nภายในอัลกอริทึม supervised learning จะมีส่วนประกอบหลัก ๆ ได้แก่ อัลกอริทึม พารามิเตอร์ และ ไฮเปอร์พารามิเตอร์\n\n-   **อัลกอริทึม** เป็นส่วนของวิธีการเรียนรู้ของสำหรับแต่ละการเรียนรู้ของเครื่องที่ใช้ในการเรียนรู้หรือสกัดสารสนเทศจากข้อมูลในชุดข้อมูลฝึกหัด\n\n-   **พารามิเตอร์** **(parameters)** ส่วนที่ทำให้การเรียนรู้ของเครื่อง fit กับข้อมูล กล่าวง่าย ๆ คือค่าของพารามิเตอร์ที่เปลี่ยนแปลงไป จะทำให้รูปแบบการเรียนรู้มีการเปลี่ยนไป ค่าพารามิเตอร์นี้สามารถประมาณได้จากข้อมูลด้วยวิธีการทางสถิติ/คณิตศาสตร์ ตัวอย่างของพารามิเตอร์เช่น ใน linear regression model มีพารามิเตอร์คือ สัมประสิทธิ์จุดตัดแกน และสัมประสิทธิ์ความชัน เป็นต้น อย่างไรก็ตามบางอัลกอริทึมไม่ได้มีพารามิเตอร์ของโมเดล เช่น K-NN เป็นต้น\n\n-   **ไฮเปอร์พารามิเตอร์ (Hyperparameters)** เป็นพารามิเตอร์ประเภทหนึ่งในอัลกอริทึมการเรียนรู้ของเครื่อง พารามิเตอร์ประเภทนี้ไม่สามารถประมาณค่าจากข้อมูลโดยตรงด้วยวิธีการทางสถิติ แต่จะใช้การกำหนด/ปรับแต่งค่าโดยตัวผู้วิเคราะห์เอง **ในเชิงเทคนิคเรียกการปรับแต่งค่าดังกล่าวว่า hyperparameter tuning** การปรับแต่งค่าของ hyperparameter ดังกล่าวจะใช้วิธีการทดลองกำหนดค่า hyperparameter จำนวนหนึ่งให้กับอัลกอริทึม จากนั้นเลือกใช้ค่า hyperparameter ที่ทำให้ค่าประสิทธิภาพของโมเดลทำนายสูงที่สุด ทั้งนี้การพิจารณาประสิทธิภาพดังกล่าวจะพิจารณาบนชุดข้อมูลอีกชุดหนึ่งที่เรียกว่า **validation dataset**\n\nจากที่กล่าวข้างต้นจะเห็นว่าในกระบวนการพัฒนาโมเดลการเรียนรู้ของเครื่อง ต้องการชุดข้อมูลทั้งหมดจำนวน 3 ชุด ได้แก่ training, validation และ test dataset โดยที่ training และ validation dataset เป็นชุดข้อมูลที่ใช้ในระยะพัฒนาการเรียนรู้ของโมเดลให้มีประสิทธิภาพสูงสุด ส่วน test dataset เป็นชุดข้อมูลที่ใช้ตรวจสอบประสิทธิภาพด้านความเป็นนัยทั่วไปแต่จะไม่ได้มีส่วนเกี่ยวข้องกับระยะการพัฒนาการเรียนรู้ของโมเดล\n\n\\newpage\n\n## 3.4 Data Partitioning\n\nในทางปฏิบัติผู้วิเคราะห์มักมีข้อมูลต้นฉบับเพียงชุดเดียวเท่านั้นแต่ละใช้การแบ่งส่วนข้อมูลโดยใช้วิธีการสุ่มตัวอย่าง (random sampling) เพื่อสร้าง training, validation และ test dataset รูปด้านล่างแสดงลักษณะการแบ่งส่วนข้อมูล\n\n![training, validation และ testing dataset](images/image-2117384298.png){alt=\"training, validation และ testing dataset\" fig-align=\"center\" width=\"40%\"}\n\nโดยปกติการแบ่งส่วนข้อมูลดังกล่าวไม่ได้มีกฎเกณฑ์ตายตัวว่าควรแบ่งส่วนใดอย่างละเท่าไหร่ โดยปกติผู้วิเคราะห์มักกำหนดสัดส่วนระหว่าง training + validation dataset กับ test dataset เป็น 80 : 20, 75 : 25, 70 : 30, 60: 40 หรือ 50: 50 ขึ้นอยู่กับว่าชุดข้อมูลต้นฉบับที่มีนั้นมีขนาดใหญ่มากเพียงใด นอกจากนี้การแบ่งส่วนข้อมูลด้วยวิธีการสุ่มตัวอย่างอาจจำแนกเป็น 2 วิธีการ วิธีการแรกคือการสุ่มตัวอย่างแบบง่าย (simple random sampling: SRS) และวิธีการที่สองคือการสุ่มตัวอย่างแบบชั้นภูมิ (stratified random sampling)\n\n### ชุดข้อมูล `mpg`\n\nชุดข้อมูลที่ใช้เป็นตัวอย่างในหัวข้อนี้จะใช้ dataset `mpg` ที่เป็นชุดข้อมูลตัวอย่างซึ่งถูกติดตั้งมาพร้อมกับการติดตั้งโปรแกรม R อยู่แล้ว ผู้วิเคราะห์สามารถเรียกดูข้อมูลภายในชุดข้อมูลดังกล่าวได้โดยใช้คำสั่งพื้นฐานต่าง ๆ เช่น `head()`, `str()`, `glimpse()` หรือ `summary()` เป็นต้น\n\n```{r}\nlibrary(dplyr)\nhead(mpg)\n```\n\n\\newpage\n\n```{r}\nglimpse(mpg)\n```\n\n### การแบ่งข้อมูลด้วยการสุ่มอย่างง่าย\n\nการแบ่งด้วย simple random sampling เป็นการแบ่งโดยสุ่มข้อมูลตามจำนวนที่กำหนดออกมาเป็นชุดข้อมูล training dataset หรือ test dataset โดยการสุ่มดังกล่าวมีข้อสมมุติว่าหน่วยข้อมูลทุกหน่อยในชุดข้อมูลต้นฉบับมีโอกาสที่จะถูกสุ่มขึ้นมาเท่ากันทั้งหมด การแบ่งข้อมูลด้วยวิธีการนี้ใน R สามารถทำได้หลายวิธี แต่ในบทความนี้จะใช้วิธีที่อยู่ภายใต้ framework ของ tidymodels การแบ่งข้อมูลด้วยวิธีการดังกล่าวมีสองขั้นตอน **ขั้นแรก** คือการสร้างกรอบของการแบ่งข้อมูลออกเป็น training และ test data สามารถทำได้ด้วยฟังก์ชัน `initial_split()` ของ package rsample อาร์กิวเมนท์สำคัญที่จะต้องระบุในฟังก์ชันได้แก่ `data` และ `prop`**ขั้นที่สอง** คือการแบ่งข้อมูลตามกรอบในขั้นตอนแรก โดยจะใช้ฟังก์ชัน `training()` เพื่อแบ่งชุด training dataset ออกมา และใช้ฟังก์ชัน `testing()` เพื่อแบ่งชุดข้อมูล test dataset ออกมา\n\n```{r}\n# import rsample\nlibrary(rsample)\n# generate sampling frame\nmpg_split1 <- initial_split(data = mpg, prop = 0.75)\nmpg_split1\n# create training and test dataset\ntrain_srs <- mpg_split1 %>% training()\ntest_srs <- mpg_split1 %>% testing()\n```\n\n### การแบ่งข้อมูลด้วยการสุ่มแบบชั้นภูมิ\n\nการแบ่งชุดข้อมูลด้วยการสุ่มแบบชั้นภูมิสามารถทำได้ด้วยฟังก์ชัน `initial_split()` เช่นเดียวกัน แต่จะต้องมีการระบุอาร์กิวเมนท์ของฟังก์ชันเพิ่มเติมได้แก่ `strata` เพื่อระบุตัวแปรตามหรือตัวแปรเกณฑ์ที่จะใช้แบ่งชั้นภูมิก่อนการสุ่มตัวอย่าง และ `breaks` ใช้กำหนดจำนวนอันตรภาคชั้นของตัวแปรตามหรือตัวแปรเกณฑ์ที่จะใช้แบ่งชั้นภูมิหากตัวแปรดังกล่าวเป็นตัวแปรเชิงปริมาณ ค่าเริ่มต้นของอาร์กิวเมนท์นี้กำหนดให้ `breaks = 4`ตัวอย่างต่อไปนี้แสดงการแบ่งชุดข้อมูล training และ test ด้วยการสุ่มแบบชั้นภูมิ\n\n```{r}\nmpg_split2 <- initial_split(data = mpg, \n                            prop = 0.75,\n                            strata = \"hwy\",\n                            breaks = 10)\ntrain_str <- mpg_split2 %>% training()\ntest_str <- mpg_split2 %>% testing()\n```\n\nรูปด้านล่างแสดงการเปรียบเทียบการแจกแจงของตัวแปรตามระหว่างชุดข้อมูลต้นฉบับ (full dataset), training และ test dataset ที่แบ่งด้วยวิธีการสุ่มตัวอย่างแบบง่าย และแบบชั้นภูมิ\n\n```{r echo=F, message=F, warning=F, fig.cap=\"เปรียบเทียบระหว่าง SRS กับ STR\", fig.height= 4.5}\nlibrary(ggplot2)\nlibrary(gridExtra)\n\ntotal<-mpg%>%ggplot()+geom_histogram(aes(x=hwy))+\n  scale_x_continuous(limits=c(0,50))+\n  theme_minimal()+\n  ggtitle(\"original dataset\")\n\np1<-train_srs%>%ggplot()+\n  geom_histogram(aes(x=hwy))+\n  scale_x_continuous(limits=c(0,50))+\n  theme_minimal()+\n  ggtitle(\"training dataset (SRS)\")+\n  theme(panel.grid.minor = element_blank())\n\n\np2<-train_str%>%ggplot()+\n  geom_histogram(aes(x=hwy))+\n  scale_x_continuous(limits=c(0,50))+\n  ggtitle(\"training dataset (STR)\")+\n  theme(panel.grid.minor = element_blank())\n\np3<-test_srs%>%ggplot()+\n  geom_histogram(aes(x=hwy))+\n  scale_x_continuous(limits=c(0,50))+\n  scale_y_continuous(limits=c(0,13))+\n  theme_minimal()+\n  ggtitle(\"test dataset (SRS)\")\n\np4<-test_str%>%ggplot()+\n  geom_histogram(aes(x=hwy))+\n  scale_x_continuous(limits=c(0,50))+\n  scale_y_continuous(limits=c(0,13))+\n  ggtitle(\"test dataset (STR)\")+\n  theme(panel.grid.minor = element_blank())\n\ngrid.arrange(total, p1 , p2, p3, p4 , layout_matrix=rbind(c(1,1),c(2,3),c(4,5)))\n```\n\nการสุ่มแบบชั้นภูมิเหมาะสำหรับการพัฒนา classification models เมื่อสัดส่วนของค่าที่เป็นไปได้ของตัวแปรตามมีความแตกต่างกันมาก ๆ หรือมีบางค่าสังเกตของตัวแปรตามที่มีสัดส่วนการเกิดที่น้อยเมื่อเปรียบเทียบกับค่าสังเกตอื่น ๆ (imbalanced outcome) นอกจากนี้ยังเหมาะกับการพัฒนา regression models เมื่อตัวแปรตามมีลักษณะการแจกแจงแบบเบ้ขวา\n\n## 3.5 การสุ่มซ้ำ (resampling)\n\nอัลกอริทึมการเรียนรู้ของเครื่องหลายตัวมี hyperparameters ที่หากมีการกำหนดค่าที่เหมาะสมจะช่วยพัฒนาการเรียนรู้ได้ดีขึ้นและช่วยให้โมเดลทำนายมีประสิทธิภาพการทำนายที่สูงขึ้นได้ อย่างไรก็ตาม hyperparameters ดังกล่าวไม่สามารถประมาณได้โดยตรงจากข้อมูล แต่ต้องอาศัยการกำหนดค่าเองโดยผู้วิเคราะห์ ดังนั้นในระหว่างการพัฒนาโมเดลจึงมีความจำเป็นที่ผู้วิเคราะห์จะต้องทราบประสิทธิภาพการทำนายของโมเดลเมื่อมีการกำหนดค่า hyperparameters ต่าง ๆ เพื่อใช้เป็นสารสนเทศประกอบการกำหนดค่า hyperparameters ดังกล่าว\n\nด้วยเหตุผลเดียวกับการประเมินประสิทธิภาพของโมเดลด้วยชุดข้อมูลทดสอบ การประเมินประสิทธิภาพในระยะของการพัฒนาโมเดลดังกล่าวไม่ช่วยใช้ข้อมูลจากชุดข้อมูลฝึกหัด เพราะจะทำให้ค่าประสิทธิภาพดังกล่าวมีค่าสูงเกินความเป็นจริงและอาจทำให้การกำหนดค่า hyperparameters มีความคลาดเคลื่อน เพื่อแก้ปัญหาดังกล่าวจึงมีการใช้เทคนิคการสุ่มซ้ำ (resampling) ในการสุ่มชุดข้อมูลย่อยจากชุดข้อมูลฝึกหัด โดยแบ่งชุดข้อมูลฝึกหัดออกเป็นสองชุดข้อมูลย่อย อาจเรียกว่าชุดข้อมูลสำหรับวิเคราะห์ (analysis) ต่อไปจะเรียกว่า traning dataset และชุดข้อมูลสำหรับสำหรับประเมินประสิทธิภาพ (assessment) ซึ่งต่อไปจะเรียกว่า validation dataset ดังรูป 24\n\n![resampling strategy](images/image-468626522.png){alt=\"resampling strategy\"}\n\nเนื่องจากเทคนิคการสุ่มซ้ำเป็นการสุ่มแบบที่มีการใส่คืน (sampling with replacement) จึงทำให้ในระยะของการพัฒนาโมเดลผู้วิเคราะห์สามารถทวนซ้ำการสุ่มซ้ำดังกล่าวเพื่อสร้าง training และ validation dataset ได้จำนวนหลายชุด การดำเนินการดังกล่าวช่วยให้การประเมินประสิทธิภาพของโมเดลทำนายภายใต้เงื่อนไขของการกำหนด hyperparameters ต่าง ๆ สามารถทำได้อย่างแม่นยำ\n\nปัจจุบันมีเทคนิคการสุ่มซ้ำสำหรับการพัฒนาโมเดลทำนายดังกล่าวหลายตัว ได้แก่ K-fold Cross-Validation, Monte Carlo Cross-Validation, Bootstrapping และ Rolling Origin Forecasting รายละเอียดมีดังนี้\n\n### K-fold Cross-Validation และวิธีการอื่น ๆ ที่เกี่ยวข้อง\n\nเป็นเทคนิคการสุ่มซ้ำที่นิยมใช้กันอย่างแพร่หลาย เทคนิคนี้จะแบ่งชุดข้อมูล traning dataset โดยใช้การสุ่มแบบใส่คืนออกเป็นข้อมูลชุดย่อยจำนวน K ชุด จากนั้นจะดำเนินการวิเคราะห์และประเมินประสิทธิภาพของโมเดลจำนวน K ครั้ง โดยที่แต่ละครั้งที่จะมีการหมุนเวียนใช้ชุดข้อมูลจำนวน K-1 ชุดเพื่อวิเคราะห์ และใช้ชุดข้อมูลที่เหลืออีก 1 ชุดเพื่อประเมินประสิทธิภาพ\n\nรูป 25 แสดงตัวอย่างของ 5-fold cross-validation จากรูปจะเห็นว่ามีการสุ่มเพื่อแบ่งชุดข้อมูลฝึกหัดออกเป็น 5 ชุดย่อย จากนั้นทวนซ้ำการดำเนินการวิเคราะห์และประเมินประสิทธิภาพของโมเดลจำนวน 5 ครั้ง โดยที่ในแต่ละครั้งจะใช้ชุดข้อมูลย่อยจำนวน 4 ชุด เป็น training dataset เพื่อสร้างโมเดลทำนาย และใช้อีก 1 ชุดที่เหลือเป็น validation dataset เพื่อตรวจสอบประสิทธิภาพของโมเดลทำนาย จากรูปจะเห็นว่าในแต่ละครั้งจะมีการหมุนเวียนชุดข้อมูลที่จะใช้เป็น training และ validation ไปเรื่อย ๆ จนครบ การดำเนินการดังกล่าวจะทำให้ผู้วิเคราะห์มีค่าสถิติที่ใช้ประเมินประสิทธิภาพของโมเดลจำนวน 5 ค่า ผู้วิเคราะห์จะใช้ผลการวิเคราะห์จากค่าสถิติดังกล่าว เช่น ค่าเฉลี่ยของ RMSE หรือ R square ในการประเมินประสิทธิภาพของโมเดลภายใต้เงื่อนไขต่าง ๆ เช่น ภายใต้การกำหนดค่า hyperparameters ต่าง ๆ เป็นต้น\n\n![5-fold CV (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)](images/image-1150746472.png){alt=\"5-fold CV (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)\" fig-align=\"center\"}\n\nเนื่องจาก K-fold CV สุ่มเพื่อแบ่งชุดข้อมูลในครั้งแรกเพียงครั้งเดียว และใช้การหมุนเวียนชุดข้อมูลย่อยที่ได้จากการสุ่มดังกล่าวเพื่อวิเคราะห์และประเมินประสิทธิภาพของโมเดล จึงทำให้หน่วยข้อมูลแต่ละหน่วยมีโอกาสที่จะปรากฎอยู่ใน validation dataset ได้เพียงครั้งเดียวดังตัวอย่างในรูป 26 ข้อจำกัดนี้ทำให้ค่าประมาณประสิทธิภาพของโมเดลทำนายที่มีแนวโน้มจะมีความแปรปรวนมากที่สุดเมื่อเปรียบเทียบกับ resampling วิธีการอื่น ๆ การที่จะลดทอนความแปรปรวนดังกล่าวให้น้อยลงสามารถทำได้ด้วยการเพิ่มจำนวน K ให้มากขึ้น โดยจากการศึกษาพบว่าการกำหนดให้ K มีค่าตั้งแต่ 10 ขึ้นไป จะช่วยลดทอนความแปรปรวนของการประเมินประสิทธิภาพได้ อย่างไรก็ตาม K-fold CV ก็ยังมีแนวโน้มที่จะมีความแปรปรวนดังกล่าวมากกว่าการใช้การสุ่มซ้ำแบบอื่นอยู่ดี\n\nอีกข้อจำกัดหนึ่งของการทำ K-fold CV คือการกำหนดค่า K จำนวนมากจะทำให้การประมวลผลต้องดำเนินการหลายรอบและต้องใช้เวลาและทรัพยากรในการประมวลผลที่มากขึ้น ในกรณีที่ข้อมูลและโมเดลมีความซับซ้อนการประมวลผลในขั้นตอนนี้อาจใช้เวลานานหลายชั่วโมงหรือเป็นวันซึ่งอาจไม่คุ้มค่าที่จะดำเนินการในลักษณะดังกล่าว โดยในกรณีที่กำหนดให้ K = n เมื่อ n คือจำนวนหน่วยข้อมูลทั้งหมดจะเรียกการสุ่มนี้ว่า leave-one-out CV (LOOCV) ที่เป็นกรณีสุดโต่งที่สุดของการทำ K fold CV ปัจจุบัน LOOCV ไม่ค่อยถูกใช้งานแล้วเนื่องจากใช้เวลาและทรัพยากรอย่างมาก\n\n![10-fold CV จากชุดข้อมูลที่มีหน่วยข้อมูลจำนวน 32 หน่วย (ที่มา : Boehmke, and Greenwell (2020))](images/image-998799574.png){alt=\"10-fold CV จากชุดข้อมูลที่มีหน่วยข้อมูลจำนวน 32 หน่วย (ที่มา : Boehmke, and Greenwell (2020))\"}\n\nเพื่อแก้ปัญหาของ K-fold CV ข้างต้นถึงมีการพัฒนาเทคนิคอีกตัวหนึ่งเรียกว่า repeated K-fold cross-validation เทคนิคดังกล่าวเป็นการทำ K-fold CV ซ้ำ ๆ หลาย ๆ รอบ วิธีการนี้ทำให้หน่วยข้อมูลแต่ละหน่วยสามารถปรากฎอยู่ใน validation dataset ได้มากกว่าหนึ่งครั้ง ซึ่งช่วยให้ความแปรปรวนในการประมาณค่าประสิทธิภาพของโมเดลทำนายลดลงได้\n\n### Monte Carlo Cross-Validation\n\nในขณะที่ K-fold CV เป็นวิธีการที่ยอมให้หน่วยข้อมูลแต่ละหน่วยปรากฎใน validation dataset ได้เพียงครั้งเดียว แต่ในทางกลับกัน Monte Carlo CV (MCCV) จะสร้างชุดข้อมูลย่อย K ชุดที่ยอมให้มีหน่วยข้อมูลที่ร่วมกันได้ซึ่งทำให้หน่วยข้อมูลแต่ละหน่วยสามารถปรากฎอยู่ใน validation dataset มากกว่าหนึ่งครั้งและช่วยลดทอนความแปรปรวนในการประมาณค่าประสิทธิภาพของโมเดลลงได้ โดย MCCV มีขั้นตอนการดำเนินการดังนี้\n\n\\newpage\n\n1.  แบ่งชุดข้อมูลที่จะนำมาพัฒนาโมเดลออกเป็นสองส่วน ได้แก่ ส่วน training dataset และ validation dataset (อาจใช้สัดส่วน 70:30, 80:20, ... ตามที่ผู้วิเคราะห์เห็นว่าเหมาะสม)\n2.  นำข้อมูลใน training dataset ไปดำเนินการวิเคราะห์ และใช้ validation dataset เพื่อประเมินประสิทธิภาพของโมเดล จากนั้นเก็บค่าประสิทธิภาพดังกล่าวไว้\n3.  ทวนซ้ำขั้นตอนที่ 1. ใหม่ การทวนซ้ำอาจทำเป็นจำนวน 100, 500 หรือ 1,000 รอบ ซึ่งเมื่อครบตามจำนวนรอบที่กำหนดแล้วผู้วิเคราะห์จะนำค่าประมาณประสิทธิภาพจากแต่ละรอบมาหาค่าเฉลี่ย\n\nรูป 27 แสดงตัวอย่างของการทำ MCCV จำนวน 100 รอบ\n\n![Monte Carlo CV จำนวน 100 รอบ (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)](images/image-103001330.png){alt=\"Monte Carlo CV จำนวน 100 รอบ (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)\"}\n\nรูป 28 แสดงการเปรียบเทียบผลที่ได้จากการแบ่งชุดข้อมูลระหว่าง 10-fold CV กับ 10 resample MCCV (โดยกำหนดให้สัดส่วนการสุ่มเป็น 90:10) ของชุดข้อมูลต้นฉบับที่มีจำนวน 20 หน่วย จากรูปจะเห็นว่าหน่วยข้อมูลมีโอกาสปรากฎใน validation dataset ได้เพียงครั้งเดียวเมื่อใช้ 10-fold CV แต่สามารถปรากฎได้มากกว่าหนึ่งครั้งเมื่อใช้ 10 resample MCCV\n\n![ผลที่ได้จากการแบ่งชุดข้อมูลระหว่าง 10-fold CV กับ 10 resample MCCV (โดยกำหนดให้สัดส่วนการสุ่มเป็น 90:10) ของชุดข้อมูลต้นฉบับที่มีจำนวน 20 หน่วย (ที่มา : Max Kuhn and Kjell Johnson (2019))](images/image-1721863239.png){alt=\"ผลที่ได้จากการแบ่งชุดข้อมูลระหว่าง 10-fold CV กับ 10 resample MCCV (โดยกำหนดให้สัดส่วนการสุ่มเป็น 90:10) ของชุดข้อมูลต้นฉบับที่มีจำนวน 20 หน่วย (ที่มา : Max Kuhn and Kjell Johnson (2019))\"}\n\n\\newpage\n\n### Bootstraping\n\nกำหนดให้ชุดข้อมูลต้นฉบับมีขนาด n หน่วย **bootstrap sample** คือตัวอย่างสุ่มขนาด n หน่วย (เท่ากับชุดข้อมูลต้นฉบับ) ที่ได้จากการสุ่มตัวอย่างอย่างง่ายแบบใส่คืน (simple random sampling with replacement) จากชุดข้อมูลต้นฉบับ จากลักษณะของการสุ่มตัวอย่างแบบ bootstrap ข้างต้นจะได้ว่า ความน่าจะเป็นที่หน่วยข้อมูลแต่ละหน่วยจะถูกเลือกในการสุ่มข้อมูลตัวที่ $i$ โดยที่ $i = 1,2,3,...,n$ จะมีค่าเท่ากับ $P(select_i) = \\frac{1}{n}$ ซึ่งทำให้ความน่าจะเป็นที่หน่วยข้อมูลจะไม่ถูกเลือกในการสุ่มครั้งที่ $i$ เท่ากับ $P(not \\ select)=1-\\frac{1}{n}$ ดังนั้นความน่าจะเป็นที่หน่วยข้อมูลแต่ละหน่วยจะอยู่ในตัวอย่างแบบ bootstrap จะมีค่าเท่ากับ $(1-\\frac{1}{n})^n$ เมื่อ $n \\rightarrow \\infty$ จะได้ว่าความน่าจะเป็นที่หน่วยข้อมูลแต่ละหน่วยจะปรากฎอยู่ในตัวอย่างแบบ bootstrap มีค่าเท่ากับ 63.2% (การพิสูจน์ใช้คุณสมบัติของ Taylor series) รูป 29 ด้านล่างแสดงลักษณะของตัวอย่างแบบ bootstrap\n\n![](images/image-1881794685.png)\n\nในกระบวนการพัฒนาโมเดลทำนาย จะใช้ตัวอย่าง bootstrap เป็นชุดข้อมูลสำหรับวิเคราะห์ และใช้ชุดข้อมูลที่เหลือที่ไม่ได้ถูกสุ่มไว้ในตัวอย่าง bootstrap เป็นชุดข้อมูลสำหรับประเมินประสิทธิภาพของโมเดลทำนายระหว่างการพัฒนาโมเดล (เทียบเท่ากับ validation dataset) โดยจะเรียกตัวอย่างที่ไม่ได้ถูกสุ่มไว้ในตัวอย่าง bootstrap ในแต่ละรอบว่า **out-of-bag sample (OOB)**\n\nจากคุณลักษณะของตัวอย่าง bootstrap ที่หน่วยข้อมูลแต่ละหน่วยมีโอกาสปรากฏอยู่ในชุดข้อมูล bootstrap ได้มากกว่า 1 ชุด จึงทำให้การประมาณค่าประสิทธิภาพของโมเดลที่ได้จากการสุ่มซ้ำแบบ bootstrap มีแนวโน้มที่จะมีความแปรปรวนต่ำกว่าการสุ่มซ้ำแบบ k-fold CV อย่างไรก็ตามในกรณีที่ข้อมูลต้นฉบับมีขนาดเล็กการสุ่มซ้ำแบบ boostrap มีแนวโน้มที่จะให้ค่าประมาณประสิทธิภาพของโมเดลที่ลำเอียง จึงควรใช้เทคนิคการสุ่มซ้ำแบบ bootstrap เมื่อข้อมูลมีขนาดใหญ่เพียงพอ (n \\> 1000) (Boehmke, B., & Greenwell, B., 2020)\n\n## 3.6 Tidymodels Framework\n\nปัจจุบันมีเครื่องมือที่ช่วยให้ผู้วิเคราะห์สามารถพัฒนา machine model ได้หลายตัว บทเรียนนี้จะกล่าวถึงการใช้โปรแกรม R เพื่อพัฒนา ML model ดังกล่าว ทั้งนี้ต้องทำความเข้าใจก่อนว่า การทำงานบน R แม้จะเป็นปัญหาเดียวกัน ชุดข้อมูลเดียวกัน แต่ผู้วิเคราะห์ต่างคนกันก็มีทางที่จะดำเนินการด้วยวิธีการที่แตกต่างกันได้ (ใน Python หรือโปรแกรมอื่น ๆ ก็เช่นเดียวกัน) วิธีการหนึ่งใน R ที่สามารถ modeling ได้ง่ายและมีประสิทธิภาพคือการใช้ **tidymodels framework** ดังรูป 23\n\n![tidymodel framework](images/image-258190158.png){alt=\"tidymodel framework\" fig-align=\"center\" width=\"80%\"}\n\n-   **package-rsample** ใช้ในงาน resampling ข้อมูล เช่นการสร้าง training/validation/test dataset การสร้าง cross-validation dataset หรือการสร้าง bootstrape dataset ซึ่งได้กล่าวการใช้งานเบื้องต้นไปแล้ว\n\n-   **package-recipes** ใช้แปลง/แก้ปัญหาที่เกิดขึ้นในข้อมูลของตัวแปรที่ใช้ในการพัฒนาโมเดล ขั้นตอนนี้เรียกว่า feature engineering\n\n-   **package-parsnip** ใช้ fit machine learning กับข้อมูล\n\n-   **package-Tune** และ **package-dials** มีฟังก์ชันที่อำนวยความสะดวกในการ fine tune hyperparameter ของโมเดลเพื่อเพิ่มประสิทธิภาพการทำนายของโมเดลให้สูงที่สุด\n\n-   **package-yardstick** มีฟังก์ชันของ metric ที่ใช้ประเมินประสิทธิภาพของโมเดลทำนาย\n\ntidymodels ถูกพัฒนาขึ้นโดยได้รับการออกแบบให้สามารถทำซ้ำกระบวนการพัฒนาโมเดลได้ง่าย โดยใช้ไวยกรณ์ของภาษาในลักษณะเดียวกัน และถูกออกแบบโดยเน้นใช้กับ supervised learning เป็นหลัก ผู้ใช้งานไม่จำเป็นต้องติดตั้งทุก package ในข้างต้นด้วยตนเอง แต่ติดตั้งเพียง package-tidymodels ก็สามารถใช้งานทุก package ภายใต้ framework ดังกล่าวได้แล้ว โดยการพิมพ์คำสั่งต่อไปนี้\n\n```{r eval=F}\ninstall.packages(\"tidymodels\") # ดาวน์โหลดและติดตั้ง tidymodels\nlibrary(tidymodels) # เรียกใช้ tidymodels\n```\n\n```{r echo=F}\nlibrary(tidymodels)\n```\n\n### Fitting Linear Regression using parsnip\n\n![](images/image-538379331.png){width=\"30%\"}\n\nการ fit machine learning model กับข้อมูลด้วย R ในยุคเริ่มแรกค่อนข้างมีความยากลำบากพอสมควร เพราะ R ไม่ได้มี package ที่เป็น framework รวมสำหรับการ fit ML model ดังกล่าว การที่จะ fit ML model ในงานหนึ่ง ๆ ผู้วิเคราะห์อาจจะต้องยุ่งเกี่ยวกับ package จำนวนมาก เช่น\n\n-   package rpart สำหรับ fit decision tree\n\n-   package glmnet สำหรับ fit regularized regression model\n\n-   package knn สำหรับ fit K-NN model\n\nโดย package ที่แตกต่างกันมักมีแนวคิดและไวยกรณ์การเขียนคำสั่งที่แตกต่างกัน ทำให้เป็นอุปสรรคต่อการทำงานโดยเฉพาะการทำซ้ำในอนาคต จากปัญหานี้ tidymodels จึงมีการพัฒนา package parsnip ขึ้นเพื่อเป็น interface สำหรับใช้ package ใน R ที่เกี่ยวข้องกับการ fit supervised learning ทั้งนี้ parsnip ได้ถูกออกแบบมาให้การสั่งงานทั้งหมดอยู่ภายใต้ไวยกรณ์แบบเดียวกัน ปัจจุบันการ fit ML models ใน R จึงดำเนินการได้ง่ายขึ้นอย่างมาก\n\nขั้นตอนการ fit ML models ด้วย parsnip มี 2 ขั้นตอน ได้แก่ การระบุโมเดล และการประมวลผล รายละเอียดมีดังนี้\n\n#### (1) การระบุโมเดล (model specification)\n\nการระบุโมเดลใน parsnip มีส่วนประกอบ 3 ส่วนที่จำเป็นได้แก่\n\n-   **model type** หรืออัลกอริทึมการเรียนรู้ของเครื่องที่ผู้วิเคราะห์จะใช้ในการทำงาน\n\n-   **engine** หรือ package ของ R ที่จะใช้สำหรับประมวลผล model type ที่เลือก\n\n-   **mode** สำหรับกำหนดว่าปัญหาที่ทำงานด้วยอยู่นี้เป็น regression หรือ classification\n\nรายละเอียดว่าผู้วิเคราะห์สามารถกำหนด model type, engine และ mode แบบใดได้บ้างและต้องกำหนดอย่างไร สามารถศึกษาได้จาก <https://www.tidymodels.org/find/parsnip/> รูป 24 ด้านล่างแสดงค้นหาสำหรับอัลกอริทึม linear regression จากผลการค้นหาในรูปด้านล่างจะเห็นว่าการ fit linear regression ด้วย parsnip สามารถทำได้ด้วย model type คือ `linear_reg()` เมื่อพิจารณาในคอลัมน์ engine จะเห็นว่าการ fit linear regression มี engine จำนวนมากที่สามารถใช้เพื่อประมาณค่าพารามิเตอร์ของโมเดลได้ engine ดังกล่าวจริง ๆ แล้วคือ package ต่าง ๆ ของ R ที่ใช้ประมวลผล mode type ที่เลือกไว้ได้ ผู้อ่านจะเห็นว่า model type แบบ `linear_reg` มี engine ที่สามารถใช้ประมวลผลได้จำนวนมาก ซึ่งมีความเหมือนและความแตกต่างกัน เนื้อหาส่วนนี้มีความละเอียดพอสมควรจึงจะกล่าวถึงในบท regression model ต่อไป\n\n![parsnip manual](images/image-33185451.png){alt=\"parsnip manual\" fig-align=\"center\" width=\"70%\"}\n\nในคู่มือข้างต้นยังมีเครื่องมือให้ค้นหาการกำหนดอาร์กิวเมนท์ของฟังก์ชัน model type ในข้างต้น จากรูป 25 จะเห็นรายละเอียดในการกำหนดอาร์กิวเมนท์ของฟังก์ชัน `linear_reg()` เมื่อกำหนด engine ในลักษณะต่าง ๆ\n\n![argument ในฟังก์ชัน model type](images/image-1313501193.png){alt=\"argument ในฟังก์ชัน model type\" fig-align=\"center\" width=\"70%\"}\n\n\\newpage\n\nความหมายของการกำหนดอาร์กิวเมนท์แต่ละค่าสามารถศึกษาได้จากคู่มือของฟังก์ชัน `linear_reg()` ซึ่งสามารถกด hyperlink จากคู่มือได้เลย (คู่มือ [`linear_reg()`](https://parsnip.tidymodels.org/reference/linear_reg.html))\n\nเอกสารเพิ่มเติมเกี่ยวกับ package parsnip\n\n-   <https://cran.r-project.org/web/packages/parsnip/parsnip.pdf>\n\n-   <https://cran.r-project.org/web/packages/parsnip/vignettes/parsnip.html>\n\nสมมุติว่าผู้วิเคราะห์ต้องการพัฒนาโมเดลการเรียนรู้ของเครื่องด้วยอัลกอริทึม linear regression โดยมีตัวแปรตามคือ `hwy` และตัวแปรอิสระเพียง 1 ตัวได้แก่ `cty` ตัวอย่างคำสั่งต่อไปนี้แสดงการกำหนดโมเดลการเรียนรู้ด้วย parsnip ดังกล่าว\n\n```{r}\nlm_model <- linear_reg() %>%        # model type\n              set_engine(\"lm\") %>%  # model engine\n              set_mode(\"regression\") # model mode\n```\n\n#### (2) การประมวลผล\n\nเมื่อกำหนดโมเดลการเรียนรู้แล้วขั้นตอนถัดไปคือการนำ model specification ดังกล่าว ไปดำเนินการประมวลผล โดยส่งผ่านไปยังฟังก์ชัน `fit()` ซึ่งมีอาร์กิวเมนท์สำคัญ 2 ตัวได้แก่ model formula และ training dataset ที่จะใช้สำหรับฝึกหัดโมเดล\n\nการเขียน model formula จะเขียนอยู่ในรูปของ `y ~ x1+x2+x3+…` โดยที่ `y` คือตัวแปรตาม ส่วน `x1, x2, x3 ,…` คือตัวแปรอิสระภายในชุดข้อมูลฝึกหัด และสัญลักษณ์ `~` หมายความว่า \"regress on\" ในกรณีที่ต้องการใช้ตัวแปรที่เหลือในชุดข้อมูลทั้งหมดเป็นตัวแปรทำนาย สามารถเขียน model formula สั้น ๆ ได้ดังนี้ \\`y \\~ .\\` ตัวอย่างต่อไปนี้แสดงการส่งผ่าน model specification `lm_model` ในข้างต้นไปประมวลผล\n\n```{r}\nfit_lm <- lm_model %>%\n            fit(hwy ~ cty,  # model formula\n                data = train_str) # training dataset\n\nfit_lm\n```\n\n#### (3) การเรียกดูค่าประมาณพารามิเตอร์ของ ML model\n\nอย่างไรก็ตาม tidymodels มีฟังก์ชัน `tidy()` ซึ่งช่วยสร้างตารางสรุปผลลัพธ์จากการประมาณค่าพารามิเตอร์หรือการเรียนรู้ของโมเดลทำนายที่ใช้ให้อยู่ในรูปแบบเดียวกัน ดังนี้\n\n```{r}\ntidy(fit_lm)\n```\n\nภายใต้ framework ของ tidymodels จะใช้ฟังก์ชันใน package parsnip เพื่อ fitting model ทำนายดังกล่าว package ดังกล่าว จุดเด่นของ parsnip คือถูกออกแบบมาเพื่อเป็น interface สำหรับ fit supervised learning model ที่มีรูปแบบการใช้คำสั่งเป็นไวยกรณ์แบบเดียว\n\n#### (4) Prediction\n\nผู้วิเคราะห์สามารถนำโมเดลที่ผ่านการ train เรียบร้อยแล้วไปใช้หาค่าทำนาย โดยส่งผ่านโมเดลที่ train แล้ว (ในที่นี้คือ `fit_lm`) ไปยังฟังก์ชัน `predict()` ที่มีอาร์กิวเมนท์สำคัญคือ `new_data` ตัวอย่างด้านล่างแสดงนำ `fit_lm` ไปทำนายตัวแปร `hwy` ในชุดข้อมูลทดสอบ ผลลัพธ์ที่ได้จากการทำนายจะเป็นตารางแบบ tibble ที่แต่ละ row คือค่าทำนายของหน่วยข้อมูลใน row เดียวกันกับใน `test_str` ดังนี้\n\n```{r}\nhwy_pred <- fit_lm %>%\n              predict(new_data = test_str)\nhwy_pred\n```\n\n\\newpage\n\nเมื่อได้ค่าทำนายในชุดข้อมูลทดสอบมาแล้ว ขั้นตอนถัดไปคือการประเมินประสิทธิภาพของโมเดลทำนาย โดยทั่วไปผู้วิเคราะห์มักจะรวมค่าทำนายที่ได้ (ในที่นี้คือ `hwy_pred`) ไปไว้อยู่ภายในชุดข้อมูลทดสอบ การดำเนินการนี้สามารถทำได้หลายวิธีการขึ้นอยู่กับว่าถนัดจะดำเนินการแบบนี้ ในตัวอย่างนี้จะใช้ฟังก์ชัน `bind_cols()`\n\n```{r}\ntest_results <- test_str %>%\n                  dplyr::select(hwy, cty) %>%\n                  bind_cols(hwy_pred)\ntest_results\n```\n\n#### (5) Evaluating models using yardstick\n\nการคำนวณค่าประสิทธิภาพของโมเดลทำนายแบบ regression ภายใต้ tidymodels framework สามารถทำได้ง่าย ๆ โดยใช้ฟังก์ชันจาก package yardstick ได้แก่ `rmse()` และ `rsq()` ตัวอย่างต่อไปนี้แสดงการเขียนคำสั่งเพื่อคำนวณ metric ทั้งสอง\n\n```{r}\ntest_results %>%\n  rmse(truth = hwy, estimate = .pred)\n```\n\n\\newpage\n\n```{r}\ntest_results %>%\n  rsq(truth = hwy, estimate = .pred)\n```\n\nผลลัพธ์ข้างต้นเมื่อพิจารณาค่า RMSE พบว่าโมเดลทำนายที่พัฒนาขึ้นมีความคลาดเคลื่อนในการทำนายค่าของตัวแปร `hwy` โดยเฉลี่ย 1.64 หน่วย และเมื่อพิจารณาจากค่า R square พบว่ามีค่าเท่ากับ .913 แสดงว่าค่าจริงของ `hwy` กับค่าทำนายมีความผันแปรร่วมกันคิดเป็นร้อยละ 91.3 ซึ่งอยู่ในระดับที่สูงมาก ผลการวิเคราะห์นี้จึงบ่งชี้ว่าโมเดลทำนายที่พัฒนาขึ้นสามารถใช้ทำนายคะแนน `hwy` ได้ดี\n\nนอกจาก metric ที่เป็นค่าสถิติแล้วยังมี metric ที่เป็น visualization ด้วย เช่นในกรณีของ regression model สามารถใช้ R squared plots เพื่อประเมินความสอดคล้องกันระหว่างค่าจริงของตัวแปรตามกับค่าทำนายได้ การสร้าง R squared plot ใน R สามารถทำได้หลายวิธี ทั้งการใช้ฟังก์ชัน `plot()` ของ package graphic เหมือนกับตัวอย่างในบทที่ 2 นอกจากนี้ยังสามารถใช้ package ggplot2 เพื่อสร้างแผนภาพดังกล่าวได้เหมือนกัน\n\n```{r fig.height=3.5, fig.width=3.5, eval=T}\n# create R squared plot using graphic package\nplot(x = test_results$hwy, \n     y = test_results$.pred,\n     pch = 16,\n     xlab = \"predicted value\",\n     ylab = \"actual value\")\nabline(a=1,b=1, lty=3, col=\"steelblue\")\n```\n\nในกรณีที่ต้องการใช้ ggplot2 สามารถเขียนคำสั่งได้ดังนี้\n\n```{r fig.height=3.5, fig.width=3.5, fig.align=\"center\", fig.cap=\"R squared plot via ggplot2\"}\n# create R squared plot using ggplot2 package\nlibrary(ggplot2)\ntest_results %>% ggplot()+  # create 2D plane\n  geom_point(aes(x = hwy, # create scatter plot\n                 y = .pred))+\n  geom_abline(intercept=1, slope=1, linetype=3, col=\"steelblue\")+\n  coord_obs_pred()+\n  theme(text=element_text(size = 10))\n```\n\nผลการวิเคราะห์จาก R square plot ข้างต้นแสดงให้เห็นว่าโมเดลสามารถทำนายค่าของตัวแปร `hwy` ได้ค่อนข้างดี อย่างไรก็ตามหากพิจารณาเปรียบเทียบความสัมพันธ์ระหว่างค่าจริงกับค่าทำนายจะพบว่าโมเดลนี้มีแนวโน้มให้ค่าทำนายที่ต่ำกว่าความเป็นจริง (underestimate)\n\n**คำถาม เราได้เรียน** linear regression มาพอสมควรแล้ว โดยหากจำได้จะทราบว่า linear regression เป็นโมเดลทางสถิติที่มีข้อตกลงเบื้องต้นที่ค่อนข้างเข้มงวด ได้แก่ independence, homoscedasticity, normality, no multicollinearity, no outlier, ... คำถามคือในการพัฒนา ML model ดังกล่าวจำเป็นมั้ยที่จะต้องตรวจสอบข้อตกลงเบื้องต้นดังกล่าว เพราะอะไร?\n\n\\newpage\n\n### Fitting Classification models (logistic regression) using parsnip\n\nหัวข้อนี้จะใช้ tidymodels framework เพื่อ fit logistic regression model สำหรับทำนายชุดข้อมูล ชุดข้อมูลที่ใช้ชื่อ `classification.csv` [สามารถดาวน์โหลดได้ที่นี่](https://github.com/ssiwacho/2758688_ML/blob/79a225047656cb9a22a4e1b78835b8bdd91a1d26/week%201/classification.csv) ชุดข้อมูลนี้มีตัวแปรตามที่สนใจคือ `Class` ซึ่งเป็นสถานะการ dropout ออกจากระบบ LMS ของนักเรียน ส่วนที่เหลือเป็นตัวแปรที่คาดว่าจะนำมาเป็นตัวแปรอิสระ\n\n#### (1) การนำเข้าและสำรวจข้อมูล\n\nในกรณีนี้นำเข้าข้อมูล `classfication.csv` ด้วยฟังก์ชัน `read.csv()` จากนั้นสำรวจข้อมูลเบื้องต้นด้วยฟังก์ชัน `glimpse()` ได้ผลเป็นดังนี้\n\n```{r}\n# import\ndat<-read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/classification.csv\")\n# explore dataset\nglimpse(dat)\n```\n\nจากผลการสำรวจข้างต้น จงตอบคำถามต่อไปนี้ ชุดข้อมูล `classification.csv` ...\n\n-   มีหน่วยข้อมูลจำนวนกี่หน่วย?\n\n-   มีตัวแปรจำนวนกี่ตัวแปร\n\n-   การแจกแจงของตัวแปรตามเป็นอย่างไร?\n\n-   type ของตัวแปรที่จัดเก็บใน `dat` ข้างต้นมีแบบไหนบ้าง เหมาะสมแล้วหรือไม่ที่จะนำไปวิเคราะห์ logistic regression ต่อไป\n\n#### (2) การแบ่งชุดข้อมูล\n\nในทำนองเดียวกับการพัฒนา regression models ผู้วิเคราะห์ต้องแบ่งชุดข้อมูล `dat` ออกเป็นสองส่วนได้แก่ ส่วน training dataset เพื่อพัฒนาโมเดล และ test dataset เพื่อตรวจสอบประสิทธิภาพของโมเดล\n\n```{r}\nset.seed(123)\ndat$Class <- factor(dat$Class, levels=c(\"drop\", \"stay\"))\nclass_split <- initial_split(data= dat,\n                             prop=0.8,\n                             strata = Class)\ntrain <- class_split %>% training()\ntest <-  class_split %>% testing()\n```\n\n#### (3) การประมวลผลและสำรวจโมเดล\n\nเมื่อแบ่งชุดข้อมูลแล้วขั้นตอนต่อมาคือการพัฒนาโมเดลทำนาย ในที่นี้จะใช้ logistic regression ก่อน\n\n```{r}\nlogistic_reg <- logistic_reg(engine =\"glm\",\n                             mode = \"classification\")\n\nfit_logistic <- logistic_reg %>% \n                  fit(Class ~ . , data=train[,-1])\n```\n\n\\newpage\n\nเราสามารถวิเคราะห์สัมประสิทธิถดถอยของตัวแปรอิสระในโมเดลได้ โดยใช้ data visualization มาช่วย เช่น\n\n```{r fig.width=3, fit.height=4, fig.cap=\"boxplot ของสัมประสิทธิ์การถดถอยใน logistic regression\"}\nfit_logistic$fit %>% \n          coef() %>% \n            data.frame(coef= .)%>%\n              ggplot(aes(x=\"\" ,y=coef))+\n                geom_boxplot(alpha = 0.7, fill = \"grey\")+\n                geom_jitter(width=0.1)+\n              theme_minimal()\n```\n\nเราจะเห็นว่าโมเดลทำนายที่พัฒนาขึ้นข้างต้น มีตัวแปรอิสระที่น่าจะใช้ทำนายตัวแปรตาม `Class` ได้ เยอะมาก ปัจจัยนี้อาจเป็นสาเหตุหนึ่งที่ทำให้การประมาณค่าพารามิเตอร์ของโมเดลเกิดปัญหาไม่ลู่เข้า การแก้ปัญหาดังกล่าวอาจทำการคัดเลือกตัวแปรอิสระที่ไม่จำเป็นออกไปจากโมเดล ซึ่งจะเห็นว่าเป็นงานที่ค่อนข้างเหนื่อยเพราะมีตัวแปรอิสระเยอะพอสมควรในชุดข้อมูลนี้ อีกวิธีการหนึ่งคือใช้เทคนิค regularization ซึ่งสามารถทำได้โดยเปลี่ยน `engine = \"glmnet\"` เนื้อหาส่วนนี้จะกล่าวถึงอีกครั้งในบทต่อไป\n\n\\newpage\n\n#### (4) การคำนวณค่าทำนายจากโมเดล\n\nในกรณีนี้สมมุติว่าโมเดลทำนาย logistic regression ไม่ได้มีปัญหาอะไรและจะนำไปสู่ขั้นตอนการตรวจสอบคุณภาพในชุดข้อมูลทดสอบ ในทำนองเดียวกับ regression models การตรวจสอบประสิทธิภาพในการทำนายของโมเดล ผู้วิเคราะห์ต้องมี (1) ค่าสังเกตจริงของตัวแปรตามในชุดข้อมูลทดสอบ และ (2) ค่าทำนายที่ได้จากโมเดลทำนายในชุดข้อมูลทดสอบ\n\nการคำนวณค่าทำนายจากโมเดลสามารถทำได้ด้วยฟังก์ชัน `predict()` เช่นเดียวกับ regression models อย่างไรก็ตามใน classfication models สามารถคำนวณค่าทำนายได้ 2 ประเภทหลัก ได้แก่ ค่าความน่าจะเป็น (probability) ของการเกิดเหตุการณ์/ผลลัพธ์ที่สนใจในตัวแปรตามของหน่วยข้อมูล และค่าทำนายประเภท/ผลลัพธ์ในตัวแปรตามของหน่วยข้อมูล โดยในกรณีที่ต้องการค่าทำนายเป็นค่าความน่าจะเป็นให้กำหนดอาร์กิวเมนท์ `type = \"prob\"` ส่วนในกรณีที่ต้องการค่าทำนายเป็นประเภทในตัวแปรตามให้กำหนดอาร์กิวเมนท์ `type = \"class\"`\n\n##### กรณีกำหนด `type = \"prob\"`\n\nการกำหนดลักษณะนี้จะได้ค่าความน่าจะเป็นซึ่งสามารถนำไปคำนวณเป็นค่าทำนายประเภทของหน่วยข้อมูลได้โดยการกำหนดคะแนนจุดตัดหรือค่า threshold ซึ่งโดยปกติมักกำหนดให้ค่า threshold = 0.5 ตัวอย่างคำสั่งต่อไปนี้แสดงการคำนวณค่าความน่าจะเป็นดังกล่าว รวมทั้งการแปลงค่าความน่าจะเป็นที่ได้โดยการกำหนด threshold เป็น 0.2, 0.5 และ 0.8 ตามลำดับ ทั้งนี้หากโมเดลที่มีประสิทธิภาพไม่คงที่เมื่อเปลี่ยนค่า threshold จะบ่งชี้ว่าโมเดลดังกล่าวมีประสิทธิภาพการทำนายที่ไม่ดีนัก กล่าวคือ เป็นโมเดลที่ไม่ชัดเจนในการทำนาย ในทางกลับกันโมเดลที่มีค่าทำนายประเภทของหน่วยข้อมูลที่คงเส้นคงวา เมื่อกำหนดค่า threshold แตกต่างกัน บ่งชี้ว่าโมเดลดังกล่าวเป็นโมเดลที่มีประสิทธิภาพในการทำนายสูง\n\n```{r}\n# predicted value\npred_prob <- predict(fit_logistic, \n                     new_data = test[,-1],\n                     type=\"prob\")\npred_class_thres0.2 <- factor(ifelse(pred_prob[,1] >=0.2,\"drop\", \"stay\"))\npred_class_thres0.5 <- factor(ifelse(pred_prob[,1] >=0.5,\"drop\", \"stay\"))\npred_class_thres0.8 <- factor(ifelse(pred_prob[,1] >=0.8,\"drop\", \"stay\"))\n\ntable(pred_class_thres0.2)\ntable(pred_class_thres0.5)\ntable(pred_class_thres0.8)\n```\n\nผลการวิเคราะห์ข้างต้นแสดงให้เห็นว่าค่าทำนายประเภทของหน่วยข้อมูลไม่มีการเปลี่ยนแปลงเมื่อกำหนด threshold เท่ากับ 0.2, 0.5 และ 0.8 ซึ่งบ่งชี้ว่าโมเดลทำนายมีแนวโน้มที่จะให้ค่าทำนายที่คงเส้นคงวา อย่างไรก็ตามการวิเคราะห์เพียง 3 จุดของ threshold เป็นการวิเคราะห์ที่ค่อนข้างหยาบ ส่วนท้ายของหัวข้อนี้จะกล่าวถึงการใช้ ROC curve เพื่อวิเคราะห์ประสิทธิภาพของโมเดลบนแต่ละค่าของ threshold ดังกล่าว\n\n##### กรณีกำหนด `type = \"class\"`\n\nเมื่อกำหนดให้ `type = \"class\"` ฟังก์ชัน `predict()` จะทำนายประเภทของหน่วยข้อมูลโดยใช้ค่า threshold = 0.5 ดังนั้นหากผู้วิเคราะห์ต้องการใช้ threshold ค่านี้อยู่แล้ว การกำหนดอาร์กิวเมนท์ลักษณะนี้จะช่วยลดขั้นตอนการทำงานลงได้\n\n```{r}\npred_class2 <- predict(fit_logistic, \n                     new_data = test[,-1],\n                     type=\"class\")\nhead(pred_class2)\n```\n\nจะเห็นว่าผลการทำนายประเภทที่ได้จากฟังก์ชัน `predict()` อยู่ในรูปชุดข้อมูลแบบ tibble โดยคอลัมน์ที่เก็บค่าทำนายจะใช้ชื่อ `.pred_class` และมีสถานะเป็นตัวแปรแบบ factor\n\n```{r}\ntable(pred_class2)\n```\n\n#### (5) การประเมินประสิทธิภาพการทำนายของโมเดล\n\npackage yardstick มีฟังก์ชัน `conf_mat()` ที่ทำหน้าที่เหมือนกับฟังก์ชัน `confusionMatrix()` โดยอาร์กิวเมนท์สำคัญของฟังก์ชันนี้ได้แก่ `data` ที่เป็น data.frame หรือ tibble ที่ต้องมีคอลัมน์ของค่าจริงของตัวแปรตาม และค่าทำนายของตัวแปรตามให้เรียบร้อย `truth` คืออาร์กิวเมนท์สำหรับระบุว่าคอลัมน์ไหนคือค่าจริงของตัวแปรตาม และ `estimate` คือคอลัมน์ที่ใช้ระบุว่าคอลัมน์ไหนคือค่าทำนายของตัวแปรตาม ทั้งนี้ตัวแปรตามและค่าทำนายจะต้องเก็บอยู่ในรูปแบบ factor\n\n```{r}\n# combine .pred_class column to test dataset\ntest_results <- test %>% dplyr::select(Class) %>%\n          bind_cols(pred_class2, pred_prob)\nconf_mat(data = test_results, truth = Class, estimate = .pred_class)\n# accuracy\naccuracy(data = test_results, truth = Class, estimate = .pred_class)\n# sensitivity\nsens(data = test_results, truth = Class, estimate = .pred_class)\n# specificity\nspec(data = test_results, truth = Class, estimate = .pred_class)\n# define metric set function\ncustom_metric<-metric_set(accuracy, sens, spec)\ncustom_metric(data = test_results, truth = Class, estimate = .pred_class)\n```\n\nนอกจากนี้ยังสามารถใช้ฟังก์ชัน `summary()` กับผลลัพธ์ที่ได้จาก `conf_mat()` เพื่อเรียกดูค่าสถิติของ confusion matrix คล้ายกับฟังก์ชัน `confusionMatrix()` ของ package caret ที่ได้กล่าวถึงในหัวข้อ 2.4\n\n```{r}\nconf_mat(data = test_results, \n         truth = Class, \n         estimate = .pred_class) %>%\n  summary()\n```\n\n\\newpage\n\nรายละเอียดของ metric ต่าง ๆ สามารถศึกษาเพิ่มเติมได้จากเอกสารที่เกี่ยวกับ package yardstick\n\n-   https://cran.r-project.org/web/packages/yardstick/yardstick.pdf\n\n-   https://yardstick.tidymodels.org/\n\n-   https://cran.r-project.org/web/packages/yardstick/vignettes/metric-types.html\n\n#### (6) การนำเสนอประสิทธิภาพการทำนายของโมเดลด้วยทัศนภาพข้อมูล\n\nการวิเคราะห์ประสิทธิภาพการทำนายของ classification models สามารถทำได้ด้วยทัศนภาพข้อมูลหลายตัว ซึ่งบางตัวช่วยให้สารสนเทศเชิงลึกประกอบการปรับแต่งโมเดลทำนายแก่ผู้วิเคราะห์ได้เป็นอย่างดี เนื้อหาประกอบด้วย การใช้ heatmap แผนภาพ mosaic และ ROC Curve รายละเอียดมีดังนี้\n\n##### แผนที่ความร้อน (heatmap) ของ confusion matrix\n\nทัศนภาพนี้เหมาะสำหรับ classification model ที่มีการจำแนกประเภทจำนวนหลาย ๆ ประเภท การสร้างแผนที่ความร้อนดังกล่าวสามารถสร้างได้โดยการส่งค่า confusion matrix ที่สร้างจากฟังก์ชัน `conf_mat()` ไปยังฟังก์ชัน `autoplot()` และในฟังก์ชัน `autoplot()` ให้กำหนดอาร์กิวเมนท์ `type = \"heatmap\"` ดังตัวอย่างต่อไปนี้\n\n```{r fig.width=3, fig.height=3, fig.cap = \"plotting the confusion matrix using Heatmap\"}\nconf_mat(data = test_results, \n         truth = Class, \n         estimate = .pred_class) %>%\n  autoplot(type = \"heatmap\")\n```\n\nจากรูป 27 จะเห็นว่าแผนที่ความร้อนที่สร้างขึ้นจะใช้ความเข้มของสีแสดงความถี่ในแต่ละประเภทของการทำนาย โดยในรูปตัวอย่างพบว่าโมเดลทำนายมีแนวโน้มที่จะทำนายได้อย่างถูกต้องเป็นส่วนใหญ่\n\n\\newpage\n\n##### แผนภาพโมเสก (mosaic plot)\n\nทัศนภาพนี้จะแสดงผลลัพธ์ในมิติของ sensitivity หรือ specificity การสร้างแผนภาพโมเสกจาก confusion matrix สามารถใช้ฟังก์ชัน `autoplot()` เช่นเดียวกับการสร้างแผนที่ความร้อน แต่ให้กำหนดอาร์กิวเมนท์ `type = mosaic` ดังตัวอย่างต่อไปนี้\n\n```{r fig.width=3, fig.height=3, fig.cap = \"plotting the confusion matrix using Masaic plot\"}\nconf_mat(data = test_results, \n         truth = Class, \n         estimate = .pred_class) %>%\n  autoplot(type = \"mosaic\")\n```\n\nจากรูป 28 เมื่อพิจารณาในคอลัมน์แรกจะพบว่าเป็นคอลัมน์ที่แสดง sensitivity ของโมเดล (เนื่องจากโมเดลทำนายมุ่งที่จะทำนายกลุ่ม dropout ดังนั้นกลุ่มนี้จึงเป็นพวก positive ของโมเดล) ส่วนคอลัมน์ที่สองแสดง specificity ของโมเดล ซึ่งมีค่าอยู่ในระดับสูงทั้งสอง metrics\n\n##### ROC curve\n\nดังที่ได้กล่าวไว้ก่อนแล้วข้างต้นว่าคุณสมบัติที่ดีของโมเดลทำนายอย่างหนึ่งคือการที่สามารถให้ค่าทำนายประเภทของหน่วยข้อมูลที่คงเส้นคงวาบนแต่ละระดับของค่า threshold การตรวจสอบประสิทธิภาพด้านนี้อย่างละเอียดควรดำเนินการวิเคราะห์ประสิทธิภาพในการทำนายของโมเดลเมื่อกำหนดค่า threshold ตั้งแต่ 0.00 ถึง 1.00 การดำเนินการดังกล่าวด้วย R ในสมัยก่อนผู้วิเคราะห์จำเป็นจะต้องเขียนฟังก์ชันเพื่อทวนซ้ำการทำนายในแต่ละค่า threshold แต่ในปัจจุบันหากใช้ package yardstick ผู้วิเคราะห์สามารถใช้ฟังก์ชัน `roc_curve()` เพื่อช่วยทำการวิเคราะห์นี้ได้ อาร์กิวเมนท์ของฟังก์ชันนี้ประกอบด้วย ค่าจริงของตัวแปรตามในชุดข้อมูลทดสอบ และค่าประมาณความน่าจะเป็นของการเกิดผลลัพธ์ที่สนใจ (positive type) ในตัวแปรตาม\n\n\\newpage\n\n```{r}\ntest_results %>% \n  roc_curve(truth = Class, .pred_drop)\n```\n\nข้อดีของฟังก์ชัน `roc_curve()` คือฟังก์ชันจะกำหนด grid หรือช่วงของค่า threshold ที่เหมาะสมกับข้อมูลซึ่งช่วย output ที่ไม่จำเป็นลงได้ จากตารางข้างต้นจะเห็นว่าถ้าไม่นับกรณีที่กำหนด threshold อย่างสุดโต่งคือ 0 หรือ 1 ประสิทธิภาพของโมเดลทำนายที่พัฒนาขึ้นนี้มีค่า sensitivity และ specificity มากกว่า 0.75 เกือบทุกกรณี\n\nอย่างไรก็ตามในกรณีทั่วไปผลลัพธ์จากตารางข้างต้นอาจมีจำนวนมากจนเป็นการยากที่จะดำเนินการวิเคราะห์ ผู้วิเคราะห์จึงมักนิยมแปลงผลการวิเคราะห์ในตารางดังกล่าวให้เป็นแผนภาพ ROC curve ที่เป็นการพล็อตคู่อันดับของ FPR = 1 - specificity กับ sensitivity ที่คำนวณได้จากแต่ละค่าของ threshold โดยให้ค่า sensitivity อยู่บนแกน Y และค่า FPR อยู่บนแกน X รูปต่อไปนี้แสดงตัวอย่างของ ROC curve\n\n![ตัวอย่าง ROC Curve](images/image-1255912826.png){alt=\"ตัวอย่าง ROC Curve\"}\n\n\\newpage\n\nโมเดลทำนายที่ดีควรมี ROC curve ที่ลู่เข้าไปใกล้คู่อันดับ (0.00,1.00) เนื่องจากคู่อันดับดังกล่าวเป็นจุดที่โมเดลมี FPR = 0.00 และมี sensitivity = 1.00 หรือเป็นจุดที่ดีที่สุดที่เป็นไปได้ (optimal point) ส่วนโมเดลที่มีประสิทธิภาพต่ำจะเป็นโมเดลที่มี Roc curve ลู่เข้าหาหรือมีลักษณะใกล้เคียงกับเส้นอ้างอิง $y=x$ ซึ่งแสดงว่าโมเดลทำนายมีประสิทธิภาพในการทำนายที่ใกล้เคียงกับการเดาสุ่มแบบโยนเหรียญหัวก้อย\n\nจากรูป 30 จะเห็นว่าโมเดลตัวอย่างทางด้านซ้ายมีแนวโน้มที่จะมีประสิทธิภาพในการทำนายสูงกว่าโมเดลตัวอย่างทางด้านขวา ทั้งนี้เป็นเพราะ ROC curve ของโมเดลทางซ้ายมีแนวโน้มลู่เข้าไปหาคู่อันดับ (0.00,1.00) มากกว่าโมเดลทางขวามือ สำหรับการสร้าง ROC curve ด้วย R สามารถทำได้โดยส่งผ่านผลลัพธ์ที่ได้จากฟังก์ชัน `roc_curve()` ในข้างต้นไปในฟังก์ชัน `autoplot()` ดังตัวอย่างต่อไปนี้\n\n```{r fig.width=4, fig.height=3, fig.cap=\"ROC Curve\"}\ntest_results %>%\n  roc_curve(truth = Class, .pred_drop) %>%\n  autoplot()\n```\n\nผลการวิเคราะห์ ROC curve จากรูป 31 สามารถสรุปได้อย่างไร?\n\n##### Area Under Curve (AUC)\n\nพื้นที่ใต้โค้ง ROC (area under curve: AUC) ถูกใช้เป็น metric อีกตัวหนึ่งสำหรับประเมินประสิทธิภาพในการทำนายของโมเดล ที่คำนวณจากพื้นที่ใต้โค้งของกราฟ ROC โดยโมเดลทำนายที่มีค่า AUC สูงเข้าใกล้ 1.00 จะเป็นโมเดลที่มีแนวโน้มจะมีประสิทธิภาพในการทำนายสูง ส่วนโมเดลที่มีค่า AUC เข้าใกล้ 0.5 มีแนวโน้มที่จะมีประสิทธิภาพในการทำนายต่ำใกล้เคียงกับการเดาสุ่ม จากความหมายดังกล่าวจะเห็นว่าค่า AUC สามารถใช้เป็น metric แทนการอ่านผลจากกราฟ ROC โดยตรงได้\n\n![Area Under Curve (AUC)](images/image-1194220562.png){alt=\"Area Under Curve (AUC)\"}\n\n\\newpage\n\nการคำนวณค่า AUC ด้วย R สามารถทำได้โดยใช้ฟังก์ชัน `roc_auc()` ที่มีอาร์กิวเมนท์เหมือนกับฟังก์ชัน `roc_curve()` จากตัวอย่าง logistic regression จะได้ว่าผลการวิเคราะห์ AUC เป็นดังนี้\n\n```{r}\ntest_results %>% roc_auc(truth = Class, .pred_drop)\n```\n\nตารางต่อไปนี้แสดงเกณฑ์การพิจารณาค่า AUC ข้างต้น โดยจำแนกเกรดของโมเดลออกเป็น 5 ระดับตามค่าของ AUC ได้แก่ ดีมาก (A) ดี (B) ไปจนถึงยอมรับไม่ได้ (F)\n\n| AUC           | แปลผล         |\n|---------------|---------------|\n| \\[0.9 , 1.0\\] | ดีมาก (A)      |\n| \\[0.8 , 0.9)  | ดี (B)         |\n| \\[0.7 , 0.8)  | พอใช้ (C)      |\n| \\[0.6 , 0.7)  | แย่ (D)        |\n| \\[0.5 , 0.6)  | ยอมรับไม่ได้ (F) |\n\n: AUC criterion\n\n## 3.6 Scikit-Learn library\n\nscikit-learn เป็น library สำหรับวิเคราะห์ machine learning model ในโปรแกรมภาษา Python ซึ่งมีจุดเด่นคือเป็น library สำหรับพัฒนา machine learning model ที่มีประสิทธิภาพและสามารถใช้งานได้ง่าย นอกจากนี้ยังสามารถทำงานร่วมกับ library Numpy, SciPy, Pandas และ matplotlib\n\ncoming soon ...\n\n## สรุป\n\nบทเรียนนี้ผู้อ่านได้เห็นภาพของกระบวนการพัฒนา regression models ซึ่งเป็น supervised learning ประเภทหนึ่งโดยเป็นการดำเนินงานภายใต้ tidymodels framework เกือบทั้งหมด โดยยังขาดในส่วนของการจัดการข้อมูลหรือที่เรียกว่า feature engineering และส่วนการปรับแต่งค่า hyperparameters ของโมเดลทำนาย ซึ่งจะกล่าวรายละเอียดทั้งหมดในบทเรียนถัดไป\n\n# บทที่ 4 การเตรียมข้อมูล (data preprocessing)\n\n> Garbage in, garbage out ...\n\nจากบทที่ 3 ผู้อ่านจะเห็นว่าข้อมูลเป็นปัจจัยนำเข้าที่สำคัญมากในการพัฒนาโมเดลการเรียนรู้ของเครื่อง การนำข้อมูลที่เป็นขยะเข้าสู่โมเดลผลลัพธ์ที่ได้ย่อมเป็นขยะ ข้อมูลที่เป็นขยะถึงแม้จะได้รับการจัดการที่ดีมากแค่ไหนก็ตาม เมื่อนำเข้าสู่โมเดล ผลลัพธ์ที่ได้ก็ยังเป็นขยะเหมือนเดิม นอกจากนี้ถึงแม้ผู้วิเคราะห์จะมีข้อมูลที่ดีแต่หากมีการจัดการที่ไม่ดี เมื่อนำเข้าสู่โมเดลก็อาจจะได้ผลลัพธ์ที่ไม่ดีเท่าที่ควรหรืออาจจะเป็นขยะเหมือนเดิมก็ได้ ดังนั้นการมีข้อมูลที่ดีและมีการจัดการอย่างเหมาะสมจึงเป็นสิ่งที่สำคัญที่ผู้พัฒนาโมเดลการเรียนรู้ของเครื่องควรให้ความสำคัญ\n\n## 4.1 ภาพรวมและความสำคัญของ Data Preprocessing\n\n**การเตรียมข้อมูล (Data preprocessing)** เป็นคำศัพท์เชิงเทคนิคที่ใช้เรียกกระบวนการต่าง ๆ ที่ผู้วิเคราะห์ดำเนินการกับข้อมูลก่อนที่จะนำข้อมูลไปวิเคราะห์ในอัลกอริทึมการเรียนรู้ โดยมีวัตถุประสงค์เพื่อให้การเรียนรู้ของอัลกอริทึมต่าง ๆ สามารถทำได้สำเร็จและมีประสิทธิภาพ การเตรียมข้อมูลมีหลายวิธีการ โดยแต่ละวิธีการเหมาะกับสถานการณ์และเงื่อนไขที่แตกต่างกัน อย่างไรก็ตามเราอาจจำแนกการเตรียมข้อมูลออกได้เป็น 2 ประเภท ได้แก่ การเตรียมข้อมูลงตามข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้ และการเตรียมเพื่อใช้ประโยชน์จากข้อมูลให้มีประสิทธิภาพสูงที่สุด\n\n**(1) การเตรียมข้อมูลตามข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้** เป็นการจัดระเบียบหรือจัดกระทำข้อมูล (tidying and manipulating data) เพื่อให้ข้อมูลดิบมีความพร้อมหรืออยู่ในรูปแบบที่สอดคล้องกับความต้องการของอัลกอริทึมการเรียนรู้ที่เลือกใช้ การละเลยการจัดการข้อมูลดังกล่าวอาจส่งผลให้การเรียนรู้ของอัลกอริทึมมีความผิดพลาด หรือไม่สามารถเรียนรู้ชุดข้อมูลดังกล่าวได้ ตัวอย่างต่อไปนี้แสดงการเตรียมข้อมูลเพื่อให้สอดคล้องกับข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้\n\n-   การจัดรูปแบบตารางข้อมูล (reshaping data) เพื่อให้ได้ตารางข้อมูลที่อยู่ในรูปแบ tidydata\n\n-   การเปลี่ยนสถานะของตัวแปรตัวอักษร (character variable) ใน R ให้เป็นตัวแปรแบบ factor\n\n-   การทดแทนค่าสูญหาย (missing value imputation) เพื่อทดแทนค่าสูญหายก่อนจะนำไปวิเคราะห์\n\n-   ในโมเดล multiple linear regression มีข้อตกลงเบื้องต้นที่สำคัญหลายข้อ เช่น ต้องไม่มีปัญหา heteroscedasticity และ multicollinearity ซึ่งหากเกิดปัญหาดังกล่าวขึ้นอย่างน้อยหนึ่งอย่าง ผู้วิเคราะห์จำเป็นต้องดำเนินการแก้ไขปัญหาดังกล่าวให้เรียบร้อยก่อนที่จะทำการวิเคราะห์ข้อมูล เช่น (1) อาจใช้การแปลงค่าตัวแปรด้วย logarithm หรือใช้การแปลงแบบ Box-Cox transformation เพื่อแก้ปัญหา heteroscedasticity และ (2) อาจใช้การตัดตัวแปรอิสระที่มีความสัมพันธ์กันเองสูง ๆ ออกจากโมเดล หรือใช้การสกัดองค์ประกอบหลัก (PCA) เพื่อแก้ปัญหา multicollinearity เป็นต้น\n\n-   สำหรับอัลกอริทึม K-NN และ regularized regression ผู้วิเคราะห์จำเป็นต้องแปลงคะแนนของตัวแปรอิสระทั้งหมดให้เป็นหน่วยคะแนนมาตรฐานก่อน เพื่อให้อัลกอริทึมดังกล่าวสามารถเรียนรู้รูปแบบความสัมพันธ์ระหว่างตัวแปรในชุดข้อมูลได้โดยไม่มีปัจจัยเกี่ยวกับหน่วยข้อมูลมาเป็นตัวแทรกซ้อนและก่อให้เกิดความผิดพลาดในการเรียนรู้\n\n\\newpage\n\nผู้อ่านจะเห็นว่าการทำ data preprocessing ประเภทนี้จำเป็นต้องทำตามข้อตกลงเบื้องต้นของโมเดล ทั้งนี้เพื่อให้โมเดลหรืออัลกอริทึมการเรียนรู้สามารถทำงานได้อย่างถูกต้อง หากผู้วิเคราะห์ละเลยการดำเนินการในส่วนนี้อาจส่งผลให้ผลการเรียนรู้ของอัลกอริทึมมีความผิดพลาด และประสบความล้มเหลวในการพัฒนาโมเดลทำนายที่ต้องการ โดยทั่วไปการจัดกระทำข้อมูลอาจจำแนกเป็น การแปลงค่าของตัวแปรจัดประเภทให้เป็นตัวแปรดัมมี (dummy) การตัดตัวแปรที่มีความแปรปรวนน้อยหรือความแปรปรวนเท่ากับ 0 ออกจากชุดข้อมูล (zv) การทดแทนค่าสูญหาย (impute) การแก้ปัญหา multicollinearity (decorrelate) การแปลงคะแนนตัวแปรให้อยู่ในสเกลมาตรฐาน (normalized) และการแปลงค่าของตัวแปรให้มีการแจกแจงที่สมมาตรหรือใกล้เคียง (transform)\n\nตารางต่อไปนี้แสดงตัวอย่าง checklist ของการจัดกระทำข้อมูลที่ควรดำเนินการในแต่ละอัลกอริทึมการเรียนรู้\n\n| อัลกอริทึม              | dummy | zv    | impute | decorrelate | normalized | transform |\n|----------------------|-------|-------|--------|-------------|------------|-----------|\n| linear regression    | yes   | yes   | yes    | yes         | no         | maybe     |\n| binary logistic      | yes   | yes   | yes    | yes         | no         | maybe     |\n| multinomial logistic | yes   | yes   | yes    | yes         | no         | maybe     |\n| K-NN                 | yes   | yes   | yes    | maybe       | yes        | yes       |\n| naive bayes          | no    | yes   | yes    | maybe       | no         | no        |\n| decision tree (CART) | no    | no    | no     | maybe       | no         | no        |\n| decision tree (C5)   | no    | no    | no     | no          | no         | no        |\n| pls regression       | yes   | yes   | yes    | no          | yes        | yes       |\n| MARS                 | yes   | no    | yes    | maybe       | no         | maybe     |\n| SVM                  | yes   | yes   | yes    | yes         | yes        | yes       |\n| random forest        | no    | maybe | yes    | maybe       | no         | no        |\n| bagging tree         | no    | no    | no     | maybe       | no         | no        |\n| bagging MARS         | yes   | no    | yes    | maybe       | no         | maybe     |\n| boosting tree        | no    | maybe | yes    | maybe       | no         | no        |\n\n: Checklist การจัดกระทำข้อมูลของอัลกอริทึมการเรียนรู้ต่าง ๆ\n\n**(2) การเตรียมเพื่อใช้ประโยชน์จากข้อมูลให้มีประสิทธิภาพสูงที่สุด** อาจกล่าวว่าเป็นขั้นตอนที่ทำภายหลังจากการเตรียมข้อมูลให้เป็นไปตามข้อตกลงเบื้องต้นของอัลกอริทึมแล้ว การเตรียมข้อมูลส่วนนี้ไม่ได้เป็นเงื่อนไขจำเป็นของการพัฒนาโมเดลทำนาย แต่อาจเป็นเงื่อนไขที่เพียงพอจะทำให้การพัฒนาโมเดลทำนายประสบความสำเร็จ กล่าวคือได้โมเดลทำนายที่มีประสิทธิภาพในการทำนายสูง การดำเนินการส่วนโดยปกติเป็นการจัดกระทำข้อมูลของตัวแปรอิสระ (independent variables) หรือที่นักวิทยาการข้อมูลมักใช้คำว่า features ให้มีความเหมาะสมกับบบริบทของปัญหาซึ่งจะช่วยให้การเรียนรู้ของโมเดลทำได้อย่างมีประสิทธิภาพมากขึ้น อาจเรียกการเตรียมข้อมูลประเภทนี้ว่า feature engineering\n\nการทำ feature engineering มีลักษณะเด่นที่สำคัญคือเป็นการดำเนินการที่ไม่ได้ขึ้นกับอัลกอริทึมการเรียนรู้แต่ขึ้นกับบริบทของปัญหาหรือข้อมูลที่ผู้วิเคราะห์มี ดังนั้นการที่ผู้วิเคราะห์จะตัดสินใจเลือกว่าจะใช้การจัดการข้อมูลแบบใดกับตัวแปรอิสระภายในชุดข้อมูลอาจต้องพิจารณาในหลายมิติร่วมกัน เช่น สภาพของข้อมูล ตัวเลือกทั้งหมดที่เป็นไปได้ในการจัดกระทำข้อมูลของตัวแปร ลักษณะ/รูปแบบของความสัมพันธ์ในธรรมชาติระหว่างตัวแปรตามกับตัวแปรอิสระ ในหลาย ๆ ครั้งอาจจะต้องใช้หลักเหตุผลรวมทั้งศึกษาค้นคว้าเอกสารงานวิจัยหรือทฤษฎีที่เกี่ยวข้องกับตัวแปรที่กำลังดำเนินงานอยู่ นอกจากนี้การสัมภาษณ์หรือเก็บรวบรวมข้อมูลจากผู้เกี่ยวข้อง เจ้าของข้อมูล หรือผู้มีส่วนได้ส่วนเสีย (stakeholder) อาจให้สารสนเทศที่เป็นประโยชน์ต่อการดำเนินงานในส่วนนี้ จะเห็นว่าการเตรียมข้อมูลลักษณะนี้ต้องใช้ทักษะมากกว่าการเตรียมข้อมูลประเภทแรกค่อนข้างมาก และมีลักษณะที่เป็น data-driven ซึ่งการดำเนินงานจะมีลักษณะทวนซ้ำเพื่อสังเกตผลลัพธ์และปรับแต่งการจัดกระทำตัวแปรเพื่อให้ประสิทธิภาพในการทำนายมีค่าสูงที่สุดเท่าที่จะเป็นไปได้ ทั้งนี้เพื่อให้เข้าใจลักษณะและประสิทธิภาพของการทำ feature engineering มากขึ้น ขอให้ผู้อ่านลองพิจารณาตัวอย่างต่อไปนี้\n\n```{r echo=F, eval=F}\n# สร้างไฟล์ข้อมูล\nn<-2000\nage<-round(seq(18,60,length=n),2)\nage<-age[sample(1:2000)]\nperformance <- seq(-10,10, length=n)\nperformance <- performance[sample(1:2000)]\ng = 100*age + 200*performance + 500*age/performance -10000 + 500*rnorm(n,0,1)\ny<-ifelse(g>0, 1,0)\nplot(performance, g)\ndat<-data.frame(age, performance, y)\ndat$y<-factor(dat$y, levels=c(0,1), labels=c(\"not promoted\",\"promoted\"))\nwrite.csv(dat, file=\"logistic.csv\")\n```\n\nชุดข้อมูล `logistic.csv` ดาวน์โหลดได้จาก <https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week2/logistic.csv> ประกอบด้วยข้อมูลของตัวแปรตาม `y` คือสถานะการเลื่อนตำแหน่งของพนักงาน (promated และ not promoted) ส่วนตัวแปรอิสระมี 2 ตัวได้แก่ อายุของพนักงาน (`age`) และประสิทธิภาพในการทำงาน (`performance`) วัตถุประสงค์ของผู้วิเคราะห์คือพัฒนาโมเดลทำนายการได้เลื่อนตำแหน่งของพนักงานด้วยตัวแปรอิสระทั้งสองตัวดังกล่าว\n\n```{r}\ndat<-read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week2/logistic.csv\")\nglimpse(dat)\n```\n\nผลการสำรวจข้อมูลเบื้องต้นพบว่าชุดข้อมูล `dat` ที่นำเข้ามามีตัวแปรที่ไม่เกี่ยวข้องคือ `X` ซึ่งควรเอาออกจากชุดข้อมูล และตัวแปรตาม `y` อยู่ในรูปแบบของตัวแปรตัวอักษรซึ่งควรเปลี่ยนให้เป็นตัวแปรแบบ factor ก่อน การดำเนินการแก้ไขปัญหาดังกล่าวเป็นการจัดกระทำข้อมูลให้สอดคล้องกับการวิเคราะห์ด้วยอัลกอริทึม logistic regression ในโปรแกรม R จัดอยู่ในกลุ่มการเตรียมข้อมูลประเภทแรกดังที่ได้กล่าวไปแล้ว คำสั่งต่อไปนี้เป็นการเตรียมข้อมูลดังกล่าว\n\n```{r}\ndat <- dat %>% dplyr::select(-X) %>%\n        mutate(y = factor(y, levels=c(\"promoted\",\"not promoted\")))\n```\n\nเมื่อจัดการกับข้อมูลดังกล่าวแล้ว ผู้วิเคราะห์ทำการแบ่งชุดข้อมูลออกเป็นสองชุด ได้แก่ ชุดข้อมูลฝึกหัด และชุดข้อมูลทดสอบ จากนั้นดำเนินการสำรวจความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระด้วยทัศนภาพข้อมูล\n\n```{r fig.width=6, fig.height=4, fig.cap=\"ผลการสำรวจข้อมูลเบื้องต้น\"}\ndat_split <- initial_split(dat, prop = 0.7, strata = y)\ndat_split\ntrain <- dat_split %>% training()\ntest <- dat_split %>% testing()\n# data exploring\ntrain %>% ggplot(aes(x=age, y=performance))+\n            geom_point(aes(col=y))+\n            theme_minimal()\n```\n\nผลการสำรวจความสัมพันธ์ระหว่างตัวแปรด้วยทัศนภาพข้อมูลข้างต้น จะเห็นว่าสามารถจำแนกพนักงานด้วยสายตาออกได้เป็น 3 กลุ่มอย่างค่อนข้างชัดเจน กลุ่มแรกคือกลุ่มที่มีประสิทธิภาพในการทำงานต่ำกว่า 0 คะแนน ซึ่งเกือบทั้งหมดไม่ได้รับการเลื่อนตำแหน่ง กลุ่มที่สองคือกลุ่มพนักงานที่ประสิทธิภาพการทำงานสูงกว่า 0 คะแนน แต่ไม่ได้รับการเลื่อนตำแหน่ง ในจำนวนนี้พบว่าส่วนใหญ่เป็นพนักงานที่มีอายุยังน้อย และกลุ่มที่สามคือกลุ่มพนักงานที่ประสิทธิภาพการทำงานสูงกว่า 0 และได้รับการเลื่อนตำแหน่ง ซึ่งในจำนวนนี้พบว่าส่วนใหญ่เป็นพนักงานที่มีอายุมาก\n\nขั้นตอนถัดมาผู้วิเคราะห์นำชุดข้อมูลฝึกหัดที่สร้างขึ้นไปให้อัลกอริทึมเรียนรู้จากนั้นทำการตรวจสอบประสิทธิภาพการทำนายของโมเดลในชุดข้อมูลทดสอบด้วย package parsnip ดังนี้\n\n```{r fig.width=3.5, fig.height=3.5, fig.cap=\"ROC Curve ของ logistic regression\"}\nfit_logistic1 <- logistic_reg() %>%\n                    set_engine(\"glm\") %>%\n                    set_mode(\"classification\")%>%\n                    fit(y ~ ., data=train)\n# calculate predicted values\npred <- predict(fit_logistic1, \n                new_data = test,\n                type = \"class\")\npred_prob <- predict(fit_logistic1, \n                new_data = test,\n                type = \"prob\")\n\ntest_results <- test %>% dplyr::select(y)%>%\n                bind_cols(pred, pred_prob)\n# evaluate model\nconf_mat(data = test_results,\n         truth = y,\n         estimate = .pred_class)%>%\n        summary()\n# roc curve\ntest_results %>% \n  roc_curve(truth = y,\n            estimate = .pred_promoted)%>%\n  autoplot()\n\ntest_results %>% \n    roc_auc(truth = y,\n            estimate = .pred_promoted)\n```\n\n```{r fig.height=3.5, fig.width=5.5, fig.cap=\"Decision Boundary ของ logistic regression\"}\n# decision boundary\nx1 <- seq(18,60,length=100)\nx2 <- seq(-10,10,length=100)\ngrid <- expand.grid(age = x1,performance = x2)\nbg.dat<-data.frame(grid) %>%\n          bind_cols(predict(fit_logistic1, grid, type=\"class\"),\n                    pred_prob = predict(fit_logistic1, grid, type=\"prob\"))\nggplot()+\n  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), \n             shape=3, size=1, alpha=0.5)+\n  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+\n  labs(col=\"test dataset\", fill=\"Decision Boundary\")+\n  theme(text=element_text(family=\"ChulaCharasNew\"))+\n  theme_minimal()\n```\n\nผลการพัฒนาโมเดลทำนายด้วยอัลกอริทึม logistic regression ในข้างต้นจะเห็นว่ายังไม่ประสบความสำเร็จ โดยจากรูปจะเห็นว่าพื้นที่การตัดสินใจของโมเดลทำนายอยู่บริเวณมุมขวาบนของ feature space ซึ่งยังมีความคลาดเคลื่อนอยู่มาก เมื่อพิจารณาผลการวิเคราะห์จาก confusion matrix ประกอบพบว่าโมเดลมีความไว (sensitivity) ในการทำนายการเลื่อนตำแหน่งเท่ากับ .324 ซึ่งอยู่ในระดับต่ำ แต่มีความจำเพาะ (specificity) เท่ากับ .955 ซึ่งอยู่ในระดับสูงมาก อย่างไรก็ตามค่าความจำเพาะที่สูงดังกล่าวเป็นผลมาจากการที่โมเดลมี sensitivity ต่ำมากนั่นเอง นอกจากนี้เมื่อพิจารณา AUC ของ ROC curve พบว่ามีค่าเท่ากับ .752 แสดงว่าในภาพรวมโมเดลมีประสิทธิภาพการทำนายอยู่ในระดับพอใช้\n\nจากปัญหาที่พบเราสามารถแก้ปัญหาได้หลายวิธีการ วิธีการแรก ๆ ที่ควรดำเนินการคือการทำ feature engineering จากผลการสำรวจความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระในรูป 33 จะเห็นว่าการเลื่อนตำแหน่งของพนักงานไม่ได้ขึ้นกับอายุและประสิทธิภาพในการทำนายแบบเป็นเส้นตรง กล่าวคือพนักงานอายุเยอะไม่จำเป็นต้องได้เลื่อนตำแหน่งเสมอไป และพนักงานที่มีประสิทธิภาพการทำงานที่ดีก็ไม่จำเป็นที่จะต้องได้เลื่อนตำแหน่งเสมอไปเช่นกัน แต่พนักงานที่มีแนวโน้มจะได้เลื่อนตำแหน่งคือพนักงานที่มีประสิทธิภาพการทำงานดีและมีอายุ จากข้อสังเกตนี้แสดงให้เห็นว่ามีอิทธิพลปฏิสัมพันธ์ระหว่างอายุกับประสิทธิภาพการทำนายต่อการเลื่อนตำแหน่ง\n\n```{r}\nfit_logistic2 <- logistic_reg() %>%\n                    set_engine(\"glm\") %>%\n                    set_mode(\"classification\")%>%\n                    fit(y ~ . + age*performance, data=train)\n\n\n```\n\n```{r echo=F, fig.width=3.5, fig.height=3.5, fig.cap=\"ROC Curve ของ logistic regression ที่มีอิทธิพลปฏิสัมพันธ์\"}\n# calculate predicted values\npred <- predict(fit_logistic2, \n                new_data = test,\n                type = \"class\")\npred_prob <- predict(fit_logistic2, \n                new_data = test,\n                type = \"prob\")\n\ntest_results <- test %>% dplyr::select(y)%>%\n                bind_cols(pred, pred_prob)\n# evaluate model\neval_metric <- metric_set(accuracy, sens, spec)\neval_metric(data = test_results,\n         truth = y,\n         estimate = .pred_class)\n# roc curve\ntest_results %>% \n  roc_curve(truth = y,\n            estimate = .pred_promoted)%>%\n  autoplot()\n\ntest_results %>% \n    roc_auc(truth = y,\n            estimate = .pred_promoted)\n```\n\n```{r fig.width=5.5, fig.height=3.5, fig.cap=\"Decision Boundary ของ logistic regression ที่มีอิทธิพลปฏิสัมพันธ์\"}\n# decision boundary\nx1 <- seq(18,60,length=100)\nx2 <- seq(-10,10,length=100)\ngrid <- expand.grid(age = x1,performance = x2)\nbg.dat<-data.frame(grid) %>%\n          bind_cols(predict(fit_logistic2, grid, type=\"class\"),\n                    pred_prob = predict(fit_logistic2, grid, type=\"prob\"))\nggplot()+\n  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), \n             shape=3, size=1, alpha=0.5)+\n  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+\n  labs(col=\"test dataset\", fill=\"Decision Boundary\")+\n  theme(text=element_text(family=\"ChulaCharasNew\"))+\n  theme_minimal()\n```\n\nผลการทำนายของโมเดลที่มีเทอมปฏิสัมพันธ์ระหว่างอายุกับประสิทธิภาพการทำงานพบว่าดีขึ้นเล็กน้อย แต่ยังไม่ประสบความสำเร็จ คราวนี้เราลองพิจารณาทางเลือกในการแปลงค่าของตัวแปรในลักษณะอื่นบ้าง จากผลการสำรวจที่พบว่าการเลื่อนตำแหน่งขึ้นกับปัจจัยอายุและประสิทธิภาพการทำงานผู้วิเคราะห์สร้างตัวแปรใหม่ในชุดข้อมูลเป็นอัตราส่วนอายุต่อประสิทธิภาพการทำงาน (`ratio_age_performance`) จากนั้นดำเนินการ fit โมเดลเหมือนกับสองโมเดลแรกที่ผ่านมา\n\n```{r}\ndat <- dat%>%\n        mutate(ratio_age_performance = age/performance)\n```\n\n```{r echo=F, fig.width=3.5, fig.height=3.5, fig.cap=\"ROC Curve ของ logistic regression ที่มีการทำ feature engineering\"}\ndat_split <- initial_split(dat, prop = 0.7, strata = y)\ndat_split\ntrain <- dat_split %>% training()\ntest <- dat_split %>% testing()\n\nfit_logistic3 <- logistic_reg() %>%\n                    set_engine(\"glm\") %>%\n                    set_mode(\"classification\")%>%\n                    fit(y ~ . , data=train)\n\n# calculate predicted values\npred <- predict(fit_logistic3, \n                new_data = test,\n                type = \"class\")\npred_prob <- predict(fit_logistic3, \n                new_data = test,\n                type = \"prob\")\n\ntest_results <- test %>% dplyr::select(y)%>%\n                bind_cols(pred, pred_prob)\n# evaluate model\nconf_mat(data = test_results,\n         truth = y,\n         estimate = .pred_class)\neval_metric <- metric_set(accuracy, sens, spec)\neval_metric(data = test_results,\n         truth = y,\n         estimate = .pred_class)\n# roc curve\ntest_results %>% \n  roc_curve(truth = y,\n            estimate = .pred_promoted)%>%\n  autoplot()\n```\n\n```{r fig.width=5.5, fig.height=3.5, fig.cap=\"Decision Boundary ของ logistic regression ที่มีการทำ Feature Engineering\"}\n# decision boundary\nx1 <- seq(18,60,length=100)\nx2 <- seq(-10,10,length=100)\ngrid <- expand.grid(age = x1,performance = x2)%>%\n          mutate(ratio_age_performance = age/performance)\n\nbg.dat<-data.frame(grid) %>%\n          bind_cols(predict(fit_logistic3, grid, type=\"class\"),\n                    pred_prob = predict(fit_logistic3, grid, type=\"prob\"))\nggplot()+\n  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), \n             shape=3, size=1, alpha=0.5)+\n  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+\n  labs(col=\"test dataset\", fill=\"Decision Boundary\")+\n  theme(text=element_text(family=\"ChulaCharasNew\"))+\n  theme_minimal()\n```\n\nคราวนี้ลองเปลี่ยนโมเดลทำนายข้างต้นเป็น decision tree แบบ CART ที่มีจุดเด่นคือเป็นโมเดลจำแนกแบบ nonlinear classification กล่าวคือโมเดล decision tree ควรมีประสิทธิภาพในการจำแนกพนักงานที่จะได้เลื่อนและไม่ได้เลื่อนตำแหน่งได้สูงกว่า logistic regression ที่ยังไม่ได้ทำ feature engineering\n\n```{r}\nfit_tree <- decision_tree() %>%\n                    set_engine(\"rpart\") %>%\n                    set_mode(\"classification\")%>%\n                    fit(y ~ . , data=train)\n\n# calculate predicted values\npred <- predict(fit_tree, \n                new_data = test,\n                type = \"class\")\npred_prob <- predict(fit_tree, \n                new_data = test,\n                type = \"prob\")\n\ntest_results <- test %>% dplyr::select(y)%>%\n                bind_cols(pred, pred_prob)\n# evaluate model\nconf_mat(data = test_results,\n         truth = y,\n         estimate = .pred_class)\neval_metric <- metric_set(accuracy, sens, spec)\neval_metric(data = test_results,\n         truth = y,\n         estimate = .pred_class)\n\n```\n\n```{r fig.width=5.5, fig.height=3.5, fig.cap=\"Decision Boundary ของ Decision Tree (CART algorithm)\"}\n# decision boundary\nx1 <- seq(18,60,length=100)\nx2 <- seq(-10,10,length=100)\ngrid <- expand.grid(age = x1,performance = x2)%>%\n          mutate(ratio_age_performance = age/performance)\n\nbg.dat<-data.frame(grid) %>%\n          bind_cols(predict(fit_tree, grid, type=\"class\"),\n                    pred_prob = predict(fit_tree, grid, type=\"prob\"))\nggplot()+\n  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), \n             shape=3, size=1, alpha=0.5)+\n  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+\n  labs(col=\"test dataset\", fill=\"Decision Boundary\")+\n  theme_minimal()\n```\n\nผู้อ่านจะเห็นว่าการทำ feature engineering โดยสร้างเทอมอัตราส่วนระหว่างอายุกับประสิทธิภาพการทำงานของพนักงานในการทำนายการเลื่อนตำแหน่งของพนักงานใน logistic regression ช่วยให้พื้นที่การตัดสินใจของโมเดลทำนายแบบ logistic regression พัฒนาขึ้นมาก จากเดิมที่เป็น linear classification เป็น nonlinear classification และมีประสิทธิภาพการทำนายบนชุดข้อมูลทดสอบที่สูงมากใกล้เคียงกับการใช้ decision tree ที่เป็น nonlinear classification (อย่างไรก็ตาม decision tree มี hyperparameter ที่สามารถปรับแต่งได้อีก ซึ่งอาจเพิ่มประสิทธิภาพในการทำนายได้มากขึ้นกว่านี้) ตัวอย่างนี้เป็นตัวอย่างหนึ่งที่แสดงให้เห็นว่าการทำ feature engineering ที่เหมาะสมนั้นช่วยเพิ่มประสิทธิภาพการทำนายให้กับโมเดลได้อย่างไร\n\n## 4.2 ประเภทของ Data Preprocessing\n\nดังที่ได้กล่าวในข้างต้นว่า data preprocessing เป็นกระบวนการจัดการข้อมูลที่มีลักษณะทวนซ้ำ และไม่ได้มีขั้นตอนการดำเนินการที่แน่นอน ขั้นตอนการดำเนินการจัดการข้อมูลในแต่ละงานขึ้นอยู่กับสภาพของข้อมูล และวัตถุประสงค์ของการวิเคราะห์ในแต่ละงาน โดยทั่วไปการจัดการข้อมูลอาจจำแนกเป็น 3 ประเภทได้แก่\n\n-   **การทำความสะอาดข้อมูล (data cleaning)**\n\n-   **การแปลงข้อมูล (data transformation)**\n\n-   **การคัดเลือกตัวแปร (feature selection)**\n\nรายละเอียดมีดังนี้\n\n### การทำความสะอาดข้อมูล (data cleaning)\n\nการทำความสะอาดข้อมูลเป็นกระบวนการเพื่อสำรวจ วินิจฉัย และแก้ไขความผิดปกติที่เกิดขึ้นในข้อมูล ความผิดปกติดังกล่าวสามารถเกิดขึ้นได้จากหลายสาเหตุ เช่น การจัดเก็บหรือบันทึกข้อมูลที่ผิดพลาด หรือการวัดข้อมูลมีความคลาดเคลื่อนจากการวัด ความผิดปกติดังกล่าวมีโอกาสเกิดขึ้นได้เป็นประจำ จึงเป็นหน้าที่ของนักวิทยาการข้อมูลที่จะต้องสำรวจ และวินิจฉัยความผิดปกติดังกล่าวในชุดข้อมูล จากนั้นจึงดำเนินการแก้ไขอย่างเหมาะสม วัตถุประสงค์ของการทำความสะอาดข้อมูลคือการได้มาซึ่งชุดข้อมูลใหม่ที่มีความพร้อมในการนำไปวิเคราะห์ได้โดยไม่มีความผิดพลาด การทำความสะอาดข้อมูลจัดอยู่ในกลุ่มการเตรียมข้อมูลให้สอดคล้องกับความต้องการหรือข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้ ซึ่งเกี่ยวข้องกับการดำเนินการหรือเทคนิควิธีการหลายอย่าง ได้แก่\n\n-   **การจัดระเบียบและจัดกระทำข้อมูล (tidying and manipulating data)** ซึ่งเกี่ยวข้องกับการจัดรูปแบบของตารางข้อมูลให้อยู่ในรูปแบบที่เหมาะสมสำหรับการวิเคราะห์ เช่นการเปลี่ยนรูปแบบตารางระหว่างตารางข้อมูลรูปแบบยาว (long format) กับรูปแบบกว้าง (wide format) การเปลี่ยนสถานะของตัวแปรในชุดข้อมูลให้เหมาะสม การแยกและยุบรวมคอลัมนท์ การจัดการกับข้อมูลซ้ำซ้อน การรวมชุดข้อมูล การคัดกรองข้อมูล เป็นต้น package ของ R ที่เกี่ยวข้องกับการดำเนินการส่วนนี้ ได้แก่ tidyr และ dplyr (รายละเอียดสามารถศึกษาได้จาก สิวะโชติ ศรีสุทธิยากร (2564)) \\<\\-\\-- ไม่พูดถึงแล้วในรายวิชานี้\n\n-   **การสำรวจและจัดการกับค่าผิดปกติ** เกี่ยวข้องกับการสำรวจข้อมูล วินิจฉัยความผิดปกติของข้อมูล และการแก้ไขปัญหาความผิดปกติของข้อมูล ข้อมูลที่ผิดปกติอาจจำแนกได้เป็นสามประเภทตามสาเหตุของการเกิด เช่น outlier, anomaly และ noisy data\n\n-   **การวิเคราะห์และทดแทนค่าสูญหาย** เป็นปกติที่ชุดข้อมูลจะมีข้อมูลที่สูญหายไม่ครบถ้วน หากค่าสูญหายดังกล่าวเกิดขึ้นเป็นจำนวนมากเกินไป และมีรูปแบบการเกิดที่เป็นระบบ อาจส่งผลให้การเรียนรู้ของเครื่องมีความลำเอียงหรือมีความน่าเชื่อถือที่ลดลงได้ การวิเคราะห์รูปแบบของค่าสูญหาย และการเลือกวิธีการทดแทนค่าสูญหายที่เหมาะสมจะช่วยลดทอนผลกระทบที่เกิดจากค่าสูญหายดังกล่าว\n\n### การแปลงข้อมูล (data transformation)\n\nการแปลงข้อมูลเป็นกระบวนการเปลี่ยนลักษณะหรือรูปแบบของข้อมูลจากรูปแบบหนึ่งไปเป็นอีกรูปแบบหนึ่ง เพื่อให้เหมาะกับความต้องการหรือข้อตกลงเบื้องต้นของการวิเคราะห์ที่เลือกใช้ ได้แก่ การแปลงข้อมูลจัดประเภทให้เป็นตัวแปรตัวเลข เช่น dummy encoding หรือ one-hot encoding การแปลงข้อมูลที่ไม่สมมาตรให้สมมาตร หรือการแปลงข้อมูลจากหน่วยใด ๆ ให้อยู่ในหน่วยมาตรฐานเพื่อให้สามารถเปรียบเทียบกันได้ หรือลดผลกระทบจากหน่วยข้อมูลที่มีต่อการเรียนรู้ของเครื่องในบางอัลกอริทึม นอกจากนี้การแปลงข้อมูลยังเป็นเทคนิคที่อาจช่วยให้การวิเคราะห์มีประสิทธิภาพสูงขึ้นดังตัวอย่างที่แสดงไว้ในส่วนนำของบทเรียนนี้\n\n### การคัดเลือกตัวแปร (feature selection)\n\nเป็นกระบวนการคัดเลือกตัวแปรอิสระภายในชุดข้อมูลที่มีประสิทธิภาพสำหรับการวิเคราะห์หรือพัฒนาโมเดลทำนาย กระบวนการนี้มีความสำคัญมากโดยเฉพาะในสถานการณ์ที่ผู้วิเคราะห์มีชุดข้อมูลขนาดใหญ่และมีตัวแปรจำนวนมาก การคัดเลือกตัวแปรจะช่วยลดขนาดของชุดข้อมูลและช่วยให้ผู้วิเคราะห์ทำงานได้ง่ายขึ้น โดยทั่วไปอาจจำแนกวิธีการคัดเลือกตัวแปรได้เป็น 3 ประเภทได้แก่ filter methods, wrapper methods และ embedded methods\n\n**Filter methods** เป็นวิธีการพื้นฐานสำหรับการคัดเลือกตัวแปรอิสระ วิธีการในกลุ่มนี้จะเป็นการใช้ค่าสถิติพื้นฐาน ได้แก่ สัมประสิทธิ์สหสัมพันธ์ และใช้ความรู้จากการทบทวนวรรณกรรม ประสบการณ์ของผู้วิเคราะห์ ความคิดเห็นของผู้เกี่ยวข้องหรือผู้ทรงคุณวุฒิ เข้ามาร่วมกันเพื่อคัดเลือกชุดของตัวแปรอิสระที่เหมาะสม\n\n**Wrapper methods** เป็นวิธีการที่คัดเลือกตัวแปรอิสระในโมเดลด้วยอัลกอริทึมสำหรับคัดเลือกตัวแปรได้แก่ forward selection, backward selection, stepwise selection หรือ recursive feature elimination เป็นต้น\n\n**Embedded methods** เป็นวิธีการคัดเลือกตัวแปรอิสระที่รวมไปกับกระบวนการเรียนรู้ของอัลกอริทึมบางตัว เช่น lasso regression และ decision tree\n\n## 4.3 พื้นฐาน `recipe` สำหรับทำ Data Preprocessing\n\n![](images/image-1527588902.png){width=\"30%\"}\n\nการทำ data preprocessing เป็นกระบวนการที่มีการใช้ทั้งการจัดกระทำข้อมูล สถิติและอัลกอริทึมการเรียนรู้ จริง ๆ แล้วการดำเนินการดังกล่าวสามารถทำได้โดยใช้คำสั่งพื้นฐานปกติใน R อย่างไรก็ตามในกระบวนการพัฒนาโมเดลที่มีการดำเนินการแบบทวนซ้ำแต่ละขั้นตอนไปมาซึ่งการเขียนคำสั่งแบบปกติอาจไม่สะดวกนัก โดยเฉพาะในกรณีที่ผู้วิเคราะห์มีการใช้เทคนิคการจัดการข้อมูลหลาย ๆ เทคนิคต่อเนื่องกัน เช่น การแปลงค่า --- \\>การทดแทนค่าสูญหาย ---\\> การสร้างองค์ประกอบด้วย PCA บทเรียนนี้จะกล่าวถึงการใช้ package recipe เพื่อใช้เป็นวิธีการทางเลือกสำหรับผู้วิเคราะห์ในการทำ data preprocessing ภายใต้ package นี้ผู้วิเคราะห์สามารถดำเนินการทำ data preprocessing ที่มีหลายขั้นตอนหลายเทคนิคได้อย่างต่อเนื่องโดยใช้ piping operator คล้ายกับการทำงานใน package dplyr นอกจากนี้ยังนำกระบวนการที่กำหนดไปทำซ้ำกับชุดข้อมูลอื่นได้โดยง่าย เนื้อหาในหัวข้อนี้จะกล่าวถึงพื้นฐานการใช้ package recipe ดังกล่าวรายละเอียดมีดังนี้\n\n### การดาวน์โหลดและติดตั้ง package\n\nกรณีที่ติดตั้ง package tidymodels จะดาวน์โหลดและติดตั้ง package recipe โดยอัตโนมัติ ส่วนในกรณีที่ต้องการติดตั้งแยกสามารถพิมพ์คำสั่งดังนี้\n\n```{r eval=F}\n# CRAN version\ninstall.packages(\"recipe\")\nlibrary(recipe)\n# development version from GitHub\ndevtools::install_github(\"tidymodels/recipes\")\n```\n\n### ขั้นตอนการทำ data preprocessing ด้วย recipe\n\nการทำ data preprocessing ด้วย package recipe ประกอบด้วยขั้นตอนการดำเนินงานหลัก 4 ขั้นได้แก่\n\n1.  ขั้นตอนการกำหนดสถานะของตัวแปร ว่าภายในชุดข้อมูลที่ดำเนินการอยู่ ตัวแปรใดเป็นตัวแปรตามตัวแปรใดเป็นตัวแปรอิสระ รวมถึงพิจารณาประเภทของข้อมูลในแต่ละตัวแปรด้วย ซึ่งปกติสามารถจำแนกได้ 2 ประเภทได้แก่ ข้อมูลตัวเลข และข้อมูลแบบจัดประเภท การดำเนินการในขั้นนี้จะใช้ฟังก์ชัน `recipe()`\n\n2.  ขั้นตอนการกำหนดวิธีการจัดการข้อมูลที่ต้องการ โดยผู้วิเคราะห์สามารถกำหนดวิธีการจัดการข้อมูลที่ต้องการผ่านฟังก์ชัน `step_*()` ที่ครอบคลุมทั้งการแปลงค่าข้อมูล เช่น การแปลงให้เป็นคะแนนมาตรฐาน การแปลงด้วยฟังก์ชัน log การสร้างตัวแปรใหม่จากข้อมูลของตัวแปรเดิม หรือ การทดแทนค่าสูญหาย (missing data imputation) เป็นต้น ผู้อ่านสามารถศึกษารายละเอียดของฟังก์ชัน `step_*()` ทั้งหมดภายใต้ package recipe ได้จาก <https://recipes.tidymodels.org/reference/index.html>\n\n3.  การจัดการข้อมูลหลายตัวมีการใช้วิธีการทางสถิติหรืออัลกอริทึมการเรียนรู้ที่จะต้องใช้ผลการวิเคราะห์จากชุดข้อมูลฝึกหัดมาเป็นค่าพารามิเตอร์หรือค่าสถิติสำหรับจัดการข้อมูลที่กำหนด (แต่การจัดการข้อมูลบางตัวก็ไม่ต้องใช้) ดังนั้นเมื่อผู้วิเคราะห์กำหนดสถานะของตัวแปรและการจัดการข้อมูลเรียบร้อยแล้ว ขั้นตอนที่ 3 คือการนำตัวแปรจาก `recipe()` ข้างต้นมาผ่านการประมวลผลหรือวิเคราะห์โดยใช้ชุดข้อมูลฝึกหัดเป็นข้อมูลนำเข้า เช่น หากผู้วิเคราะห์กำหนดให้มีการแปลงคะแนนตัวแปรให้เป็นสเกลมาตรฐาน ขั้นตอนนี้จะเป็นการคำนวนค่าเฉลี่ย และส่วนเบี่ยงเบนมาตรฐานของตัวแปรในชุดข้อมูลฝึกหัดที่กำหนดเพื่อใช้ในการ centering และ scaling ตัวแปรในชุดข้อมูลที่ต้องการจะทำ data preprocessing ในอนาคต การดำเนินการใช้ขั้นตอนนี้จะใช้ฟังก์ชัน `prep()`\n\n4.  ขั้นตอนสุดท้ายคือการจัดการข้อมูลตามที่วางแผนไว้บนชุดข้อมูลที่กำหนด ซึ่งเป็นไปได้ทั้ง training dataset, test dataset หรือชุดข้อมูลอื่น ๆ ที่จะนำเข้าสู่โมเดลทำนายในอนาคต (เพราะ ML model ที่พัฒนาต้องจะต้องการข้อมูลที่มีการจัดการเหมือนกับชุดข้อมูลฝึกหัด) การดำเนินการในขั้นตอนนี้จะใช้ฟังก์ชัน `bake()`\n\nตัวอย่างต่อไปนี้แสดงทำ data preprocessing ด้วย package recipe ตามขั้นตอนข้างต้น จากชุดข้อมูล [`TeacherSalaryData.csv`](https://github.com/ssiwacho/2758688_ML/blob/main/week%201/TeacherSalaryData.csv) สมมุติว่าผู้วิจัยต้องการแปลงค่าของตัวแปร `salary` ด้วยฟังก์ชัน log สามารถดำเนินการได้ดังนี้\n\n**ขั้นที่ 0 : นำเข้าและแบ่งชุดข้อมูล**\n\n```{r}\ndat <- read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/TeacherSalaryData.csv\")\ndat <- dat[,-1] #remove X\ndat <- dat%>%mutate_if(is.character, factor)\n# data splitting\nsplit <- initial_split(data = dat, prop = 0.8)\nsalary_train <- split %>% training()\nsalary_test <- split %>% testing()\nsummary(salary_train)\n```\n\n**ขั้น 1 : กำหนดสถานะของตัวแปร และพิจารณาความถูกต้องของประเภทข้อมูลในแต่ละตัวแปร**\n\n```{r}\nsalary_rec <- recipe(salary ~., data = salary_train)\nsalary_rec\nsalary_rec %>% summary()\n```\n\nผลการวิเคราะห์ข้างต้นจะเห็นว่าภายในชุดข้อมูลประกอบด้วย 6 ตัวแปร มีตัวแปรตามคือ salary ซึ่งเป็นตัวแปรเชิงปริมาณ ตัวแปรที่เหลือเป็นตัวแปรอิสระที่ประกอบด้วยตัวแปรเชิงปริมาณจำนวน 2 ตัว และตัวแปรจัดประเภทจำนวน 3 ตัว\n\n**ขั้น 2 : กำหนดการจัดการข้อมูลให้กับตัวแปร `recipe` จากขั้นที่ 1**\n\n```{r}\nsalary_rec <- salary_rec %>%\n  step_log(salary, base = 10)\nsalary_rec\n```\n\nผลลัพธ์ในข้างต้นแสดงให้เห็นว่ามีการกำหนดให้แปลงค่าของตัวแปร `salary` ด้วยฟังก์ชัน log\n\n**ขั้น 3 : การประมวลผล preprocessing model**\n\nขั้นตอนนี้เป็นการนำกรอบการจัดการข้อมูลที่กำหนดให้ขั้นที่ 1 และ 2 มาประมวลผลบนชุดข้อมูลฝึกหัด ด้วยฟังก์ชัน `prep()` โดยฟังก์ชันดังกล่าวจะคำนวณค่าสถิติที่จำเป็นหรือให้อัลกอริทึมการเรียนรู้ทำการประมวลผลลัพธ์ที่จำเป็นสำหรับการจัดการข้อมูลตามที่กำหนดไว้ ฟังก์ชัน `prep()` มีอาร์กิวเมนท์ที่สำคัญคือ `training` ที่ใช้ระบุชุดข้อมูลฝึกหัดสำหรับการจัดการข้อมูล\n\n```{r}\nsalary_rec_prep <- salary_rec %>% prep(training = salary_train)\nsalary_rec_prep\n```\n\nจะเห็นว่าเมื่อผ่านตัวแปรของ `recipe` เข้าสู่ฟังก์ชัน `prep` แล้วจะมีการขึ้นสถานะว่า `[trained]` ซึ่งหมายถึง package recipe ได้ประมวลผลที่จำเป็นสำหรับการจัดการข้อมูลตามที่กำหนดแล้ว และเก็บผลดังกล่าวเอาไว้ในตัวแปร `salary_rec_pre`\n\n**ขั้น 4 : การจัดการข้อมูล**\n\nอย่างที่กล่าวไว้แล้วว่าขั้นที่ 1 - 3 ถือเป็นขั้นตอนการวางแผนและเตรียมการจัดการข้อมูล ส่วนขั้นที่ 4 เป็นการจัดการข้อมูลบนชุดข้อมูลที่กำหนด ด้วยฟังก์ชัน `bake()` โดยจะใช้กรอบการจัดการข้อมูลที่กำหนดในขั้นตอนที่ 1 และ 2 และจะใช้ค่าสถิติที่จำเป็นสำหรับการจัดการข้อมูลที่ได้จากขั้นตอนที่ 3 ฟังก์ชัน `bake()` มีอาร์กิวเมนท์สำคัญหนึ่งตัวคือ `new_data` ที่ใช้ระบุชุดข้อมูลที่จะต้องการดำเนินการ ในกรณีที่ต้องการจัดการข้อมูลฝึกหัดที่ใช้เป็นชุดข้อมูลฝึกหัดในขั้นตอนที่ 3 ให้กำหนด `new_data = NULL` ดังตัวอย่างต่อไปนี้\n\n```{r}\nsalary_train_baked <- salary_rec_prep %>% bake(new_data = NULL)\nsummary(salary_train_baked)\n```\n\nในกรณีที่ต้องการนำการจัดการข้อมูลที่ train ไว้ในขั้นที่ 3 ไปใช้กับชุดข้อมูลอื่นเช่น `salary_test` สามารถเขียนคำสั่งได้ดังนี้\n\n```{r}\nsalary_test_baked <- salary_rec_prep %>% bake(new_data = salary_test)\nsalary_test_baked\n```\n\nจะเห็นว่าชุดข้อมูลทั้งสองมีการจัดการข้อมูลของตัวแปร salary ตามที่กำหนดไว้เรียบร้อยแล้ว เนื้อหาในส่วนต่อไปจะกล่าวถึงเทคนิคการทำ data preprocessing สำหรับสถานการณ์ต่าง ๆ โดยจะใช้ package recipe ในการดำเนินการ\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"output-file":"02MLProcess.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","editor":"visual","urlcolor":"steelblue","linkcolor":"steelblue","theme":{"light":["pandoc","../theme.scss"]},"mainfont":"Krub","code-copy":true,"title":"Modelling Process","author":"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร","toc-title":"สารบัญ"},"extensions":{"book":{"multiFile":true}}}}}