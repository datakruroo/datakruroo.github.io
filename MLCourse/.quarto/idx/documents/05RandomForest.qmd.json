{"title":"Random Forest","markdown":{"yaml":{"title":"Random Forest","author":"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร","toc":true,"toc-depth":3,"toc-title":"สารบัญ","theme":"default"},"headingText":"บทที่ 7 : Random Forest Algorithm","containsRefs":false,"markdown":"\n\n```{r echo = F, message = F}\nlibrary(tidyverse)\nlibrary(tidymodels)\n```\n\n\nถึงแม้ว่า Decision tree จะเป็นโมเดลที่สร้างง่าย ใช้งาน และแปลผลง่าย แต่โดยทั่วไปแล้ว ประสิทธิภาพการทำนายของ decision tree มักไม่ค่อยดี และสุ่มเสี่ยงที่จะเกิดปัญหา overfitting ได้ง่ายอีกด้วย\n\n![](images/image-1695152319.png)\n\n## 7.1 Basic Concepts\n\nจากข้อจำกัดของ decision tree (รวมทั้ง ML แบบ single learner ตัวอื่น ๆ ) จึงมีการพัฒนาวิธีการสร้างโมเดลทำนายโดยใช้การรวมผลทำนายจากชุดข้อมูล bootstrap เรียกว่า bootstrap aggregation (bagging) รูปด้านล่างแสดงแนวคิดพื้นฐานของ bagging method\n\n![](images/image-1237506128.png)\n\nrandom forest ในยุคแรกใช้แนวคิดของ bagging ข้างต้นโดยตรง โดยมีขั้นตอนการดำเนินงานดังนี้\n\nกำหนดให้ training dataset ของผู้วิเคราะห์มีขนาด n หน่วย\n\n1.  สร้าง bootstrap dataset โดยใช้การสุ่มตัวอย่างแบบใส่คืน ขนาด n หน่วย (sampling with replacement) จากชุดข้อมูล trainng data\n\n2.  นำชุดข้อมูลแต่ละชุดมาสร้าง decision tree\n\n3.  ทวนซ้ำขั้นตอนที่ 1 และ 2 จนครบ bootstrap dataset ทั้งหมด\n\n4.  นำผลทำนายจาก bootstrap dataset แต่ละชุดมาหา majority vote\n\n    ![ตัวอย่าง bootstrap dataset](images/image-275986106.png){alt=\"ตัวอย่าง bootstrap dataset\"}\n\nอย่างไรก็ตาม bagging tree ข้างต้นมีข้อจำกัดกล่าวคือในแต่ละรอบของการทวนซ้ำ อัลกอริทึมมักสร้าง decision tree ที่ซ้ำซ้อนกัน ซึ่งให้ประสิทธิภาพการทำนายไม่ได้ดีขึ้นเท่าที่ควร จากข้อจำกัดนี้จึงมีการพัฒนา random forest algorithm ขึ้น ซึ่งมีรายละเอียดดังนี้\n\n    1. สร้าง training dataset\n    2. กำหนด hyperparameter ของโมเดล\n    3. สร้าง bootstrap dataset จาก traning dataset\n    4. สร้าง decision tree จาก bootstrap dataset ดังกล่าวภายใต้เงื่อนไขของ hyperparameter ที่กำหนด \n    5. นำ decision tree ใน 4. ไปคำนวณ error ใน OOB แล้วเก็บค่าไว้\n    6. ทวนซ้ำ 3 - 5 ใหม่ จนได้จำนวน tree model ครบตามกำหนด นำ OOB error ของ model ทั้งหมดมาเฉลี่ยรวมกันจะได้ error ของ random forest \n    7. ทวนซ้ำ 2. ถึง 6. ใหม่ด้วย cross-validation จนครบทั้ง hyperparameter grid นำ error ทั้งหมดมาวิเคราะห์เพื่อเลือก hyperparameter ชุดที่ดีที่สุด\n\n![สิวะโชติ ศรีสุทธิยากร (2564)](images/image-2033240077.png){alt=\"สิวะโชติ ศรีสุทธิยากร (2564)\"}\n\n## 7.2 Out-of-Bag (OOB)\n\nจากตัวอย่าง algorithm ของ random forest ข้างต้นจะเห็นว่ามี hyperparameter ที่จะต้อง fine-tune เนื่องจาก random forest สร้างขึ้นจาก bootstrap dataset การตรวจสอบประสิทธิภาพของโมเดลเพื่อ fine-tune hyperparameters จึงจะใช้การประเมินจาก out-of-bag error โดยที่ out-of-bag error จะคำนวณจากหน่วยข้อมูลที่ไม่ถูกเลือกให้อยู่ภายใต้ bootstrap dataset ในแต่ลละรอบ ซึ่งในทางทฤษฎีจะมีหน่วยข้อมูลแบบ OOB นี้คิดเป็นร้อยละประมาณ 37 ของ original dataset\n\n## 7.3 Hyperparameters ของ Random Forest\n\nhyperparameter ของ random forest เช่น\n\n1.  **n_trees** --- จำนวนต้นไม้ของแต่ละ random forest จำนวนต้นไม้มีผลโดยตรงต่อประสิทธิภาพในการทำนาย กล่าวคือหากกำหนดให้มีต้นไม้จำนวนมาก การประมาณประสิทธิภาพในการทำนายจะทำได้อย่างคงเส้นคงวา ส่งผลให้การ fine-tune hyperparameter ทำได้อย่างมีประสิทธิภาพตามไปด้วย อย่างไรก็ตามจำนวนต้นไม้ที่มากเกินไปก็จะใช้ทรัพยากรการประมวลผลที่มากตามไปด้วย\n2.  **mtry** --- จำนวนของ feature ที่จะสุ่มมาสร้าง tree model แต่ละ model ภายใต้ random forest\n3.  **cp** --- หรือ cost of complexity hyperparameter อธิบายโดยละเอียดไปแล้วใน decision tree\n4.  **minspit** --- จำนวนหน่วยข้อมูลขั้นต่ำที่ต้องมีภายในแต่ละ node (node size)\n5.  **minbucket** --- จำนวนหน่วยข้อมูลขั้นต่ำของ Terminal node\n6.  **maxdepth.** --- ความลึกสูงที่สุดของต้นไม้แต่ละต้น\n7.  **splitrule**\n\n## 7.4 ตัวอย่างการวิเคราะห์ random forest\n\nใน R มี package หลายตัวที่สามารถใช้วิเคราะห์ random forest ได้ package หนึ่งที่มีประสิทธิภาพคือ ranger ชุดคำสั่งต่อไปนี้เป็นการใช้ฟังก์ชัน `ranger` โดยตรงเพื่อวิเคราะห​ random forest\n\n```{r}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(rsample)\nlibrary(ranger)\nlibrary(vip)\nlibrary(yardstick)\n# importing and preprocessing\ndat <- read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/TeacherSalaryData.csv\")\n\ndat <- dat[,-1]\nsummary(dat)\ndat1_preproc<- dat %>%\n  mutate(salary_class = ifelse(salary>=100000,1,0),\n         salary_class = factor(salary_class,\n                               levels = c(0,1),\n                               labels = c(\"low\",\"high\"))) %>%\n  select(-salary)\nsummary(dat1_preproc)\n```\n\nขั้นตอนถัดมาคือแบ่งชุดข้อมูลเป็น training และ test dataset\n\n```{r}\nset.seed(123)\nsplit <- initial_split(dat1_preproc, prop = 0.8, strata = salary_class)\ntrain<-training(split)\ntest<-testing(split)\n\ntable(train$salary_class)\ntable(test$salary_class)\n```\n\nวิเคราะห์ random forest model ด้วยฟังก์ชัน `ranger()` ในตัวอย่างนี้จะกำหนดให้เป็นค่าเริ่มต้นทั้งหมดก่อน\n\n```{r}\nfit_rf1 <- ranger(salary_class ~ . ,\n                  data = train,\n                  importance = \"impurity\")\nfit_rf1\nvip(fit_rf1)\n```\n\nคำนวณค่าทำนายและตรวจสอบความคลาดเคลื่อนของค่าทำนายบนชุดข้อมูล test data\n\n```{r eval = F}\npred_class <- predict(fit_rf1, test, type=\"response\")$predictions\ntable(pred, test$salary_class)\n```\n\n## 7.5 fine-tune hyperparameters\n\nหัวข้อนี้จะแสดงการ fine-tune hyperparameter ของ random forest ตาม algorithm ที่ในข้างต้น โดยใช้ tidymodel framwork รายละเอียดมีดังนี้\n\n### ขั้นแรก นำเข้าข้อมูล และจัดการ label ของข้อมูล\n\nตัวอย่างนี้จะแปลงข้อมูลตัวแปรตาม `salary` ให้เป็นตัวแปรแบบจัดประเภทที่มี 2 กลุ่ม คือกลุ่มที่เป็นอาจารย์รายได้สูง (\\>= 100,000 บาท) และกลุ่มอาจารย์รายได้ต่ำ (\\< 100,000 บาท)\n\n```{r}\nlibrary(parsnip)\nlibrary(recipes)\n# importing dataset\ndat <- read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/TeacherSalaryData.csv\")\nglimpse(dat, width = 80)\ndat <- dat %>% \n  mutate(salary_class = ifelse(salary>=100000,1,0),\n         salary_class = factor(salary_class, labels=c(\"low\",\"high\")))\nglimpse(dat, width = 80)\n```\n\n### ขั้นที่สอง แบ่งชุดข้อมูล\n\nกำหนด seed number เท่ากับ 123 จากนั้นแบ่งชุดข้อมูลโดยใช้ rsample package ดังนี้\n\n```{r}\nset.seed(123)\nsplit <- initial_split(dat, prop = 0.8)\ntrain<-training(split)\ntest<-testing(split)\n```\n\n### ขั้นที่สาม สร้าง recipe object สำหรับจัดการข้อมูล\n\n```{r}\npreproc <- recipe(salary_class ~ ., data = train) %>%\n  step_select(-X, -salary)\n```\n\n### ขั้นที่ 4 กำหนดโมเดล (model specification)\n\nตัวอย่างนี้จะใช้ random forest ใน parsnip สามารถ fit random forest model ได้ด้วย engine หลายตัว ในตัวอย่างนี้จะใช้ `ranger` ที่มี hyperparameter ให้กำหนดได้ 3 ตัวได้แก่ mtry, trees และ min_n\n\n```{r}\nforest_mod <- rand_forest(mtry = tune(),\n                          trees = 500,\n                          min_n = tune()) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n```\n\n### ขั้นที่ 5 สร้าง workflow\n\nผู้วิเคราะห์ไม่จำเป็นต้องสร้าง workflow ก็สามารถใช้ `tune_grid()` เพื่อ fine-tune hyperparameter ได้ โดยใช้ parsnip object ที่สร้างขึ้นในขั้น 4 เป็น object ใน `tune_grid()` ได้เลย อย่างไรก็ตามในสถานการณ์ทั่วไปผู้วิเคราะห์จะเป็นต้อง preprocess ข้อมูลก่อนอยู่แล้ว การใช้ workflow จึงน่าจะสะดวกกว่าในกรณีทั่วไป\n\n```{r}\nrf_workflow <- workflow() %>%\n  add_recipe(preproc) %>%\n  add_model(forest_mod)\nrf_workflow\n```\n\n### ขั้นที่ 6 เตรียมทำ cross-validation และกำหนด hyperparameter grid\n\n```{r}\n# create folds\nfolds <- vfold_cv(train, repeats =5, strata = \"salary_class\")\n# create random grid\nmy_hyparams <- parameters(mtry(range=c(1,5)),\n                          min_n(range=c(10,40)))\nmy_grid <- grid_random(my_hyparams, size = 20)\nmy_grid %>% ggplot()+\n  geom_point(aes(mtry, min_n))\n# crete evaluation metrics\neval_metric <- metric_set(roc_auc, sens, spec)\n```\n\n### ขั้นที่ 7 ทำ CV เพื่อนำข้อมูลมา tune hyperparameters\n\nฟังก์ชันที่ใช้คือ `tune_grid()` มีอาร์กิวเมนท์ที่สำคัญได้แก่\n\n-   `resamples` ใช้ระบุชุดข้อมูลที่สร้างขึ้นจากกระบวนการสุ่มซ้ำ เช่น k-folds CV หรือ boostraping dataset\n\n-   `grid` ใช้สำหรับระบุ grid ของ hyperparameter ของอัลกอริทึมการเรียนรู้ที่เลือกใช้\n\n-   `control` ใช้กำหนด option สำหรับควบคุมกระบวนการสุ่มซ้ำ (resample) และปรับแต่งค่า hyperparameter การกำหนดอาร์กิวเมนท์นี้จะต้องกำหนดผ่านฟังก์ชัน `control_resamples()` หรือ `control_grid()` อีกทีหนึ่ง รายละเอียดของฟังก์ชันทั้งสองสามารถศึกษาได้จากคู่มือการใช้งาน (พิมพ์ `?control_resamples` หรือ `?control_grid`)\n\n-   `metrics` ใช้กำหนด evalution metrics ที่ผู้วิเคราะห์จะใช้เพื่อประเมินประสิทธิภาพของโมเดลระหว่างการปรับแต่งค่าพารามิเตอร์ การกำหนดอาร์กิวเมนท์นี้ให้ทำผ่านฟังก์ชัน `metric_set()` ในกรณีที่ไม่ได้กำหนดโปรแกรมจะกำหนดให้ใช้ค่าเริ่มต้น ซึ่งจะเลือกให้เหมาะสมกับ mode ของโมเดล\n\n```{r}\ntuning_results <- rf_workflow %>%\n                  tune_grid(resamples = folds,\n                            grid = my_grid,\n                            control = control_grid(verbose = FALSE,\n                                                   save_pred = TRUE),\n                            metrics = eval_metric)\n```\n\n### วิเคราะห์ tuning results\n\n```{r}\ntuning_results %>% autoplot()\ntuning_results %>% collect_metrics(summarize = TRUE)\ntuning_results %>% \n  collect_metrics(summarize = TRUE) %>%\n  filter(.metric == \"sens\") %>%\n  arrange(desc(mean))\ntuning_results %>% \n  collect_metrics(summarize = TRUE) %>%\n  filter(.metric == \"roc_auc\") %>%\n  arrange(desc(mean))\ntuning_results %>% \n  collect_metrics(summarize = TRUE) %>%\n  filter(.metric == \"sens\") %>%\n  ggplot(aes(x = std_err, y= mean))+\n  geom_point()\nbest <- show_best(tuning_results, n=6, metric = \"sens\")\nbest[1,]\n```\n\n### ขั้นที่ 8 Finalized\n\n```{r}\nRF_final <- rf_workflow %>%\n  finalize_workflow(best[1,]) %>%\n  last_fit(split,\n           metrics =eval_metric)\nRF_final %>%\n  extract_fit_engine()\nRF_final %>%\n  collect_metrics()\n```\n\n## 7.6 Grid Search methods\n\nปัจจัยสำคัญตัวหนึ่งที่มีผลโดยตรงต่อประสิทธิภาพการปรับแต่ง hyperparameter คือการกำหนด grid ของ hyperparameter ใน tidymodel สามารถจำแนกได้เป็น 2 ประเภท ได้แก่\n\n-   regular grid\n\n-   nonregular grid\n\nรายละเอียดมีดังนี้\n\n## Regular grid\n\nregular grid เป็น grid ของ hyperparameter ที่สร้างขึ้นจากส่วนผสม (combination) ของค่าที่เป็นไปได้ทั้งหมดของ hyperparameter ที่ต้องการวิเคราะห์ การสร้าง regular grid มี 2 ขั้นตอน ขั้นตอนแรกคือการกำหนดค่าที่เป็นไปได้ของ hyperparameter แต่ละตัว และขั้นที่สองคือการสร้าง grid ของค่าที่เป็นไปได้ดังกล่าว ผลลัพธ์ที่ได้คือ hyperparameter space ที่สมบูรณ์\n\nการสร้าง regular grid ใน R สามารถทำได้หลายวิธีการ วิธีการแรกคือการใช้ฟังก์ชัน `expand.grid()` วิธีการที่สองคือการใช้ฟังก์ชัน `crossing()` ของ package tidyr และวิธีการที่สามคือการใช้ฟังก์ชัน `grid_regular()` ของ package dials\n\n```{r}\nmy_grid <- expand.grid(\n  mtry = 1:5,\n  min_n = seq(10,50,5)\n)\nhead(my_grid)\ntail(my_grid)\n```\n\n```{r}\ncrossing(\n  mtry = 1:5,\n  min_n = seq(10,50,5)\n)\n```\n\n```{r}\nmy_params <- extract_parameter_set_dials(rf_workflow) %>%\n  update(mtry = mtry(range=c(1,5)),\n         min_n = min_n(range=c(20,60)))\nmy_reggrid <- grid_regular(my_params, levels = 5)\nmy_reggrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n```\n\nข้อจำกัดของ regular grid คือใช้ทรัพยากรในการประมวลผลมาก โดยเฉพาะกับโมเดลที่มี hyperparameter จำนวนมาก และมีการทวนซ้ำหลายรอบ\n\n## Irregular grid\n\nมีหลายวิธีที่จะช่วยลดการประมวลผลของ regular grid ลงได้ วิธีการแรกคือ random grid ที่ใช้วิธีการสุ่มตัวอย่าง เพื่อสุ่ม grid มาจากประชากรของ grid ที่เป็นไปได้\n\n```{r}\nmy_randomgrid <- grid_random(my_params, size = 10)\nmy_randomgrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\nmy_randomgrid <- grid_random(my_params, size = 25)\nmy_randomgrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n```\n\n```{r}\nmy_randomgrid <- grid_random(my_params, size = 50)\nmy_randomgrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n```\n\nข้อจำกัดของ random grid คือ หาก generate grid ขนาดเล็ก มีโอกาสที่จะได้ grid ที่มีความใกล้เคียงหรือซ้อนทับกันมากเกินไป กล่าวคือ hyperparameter space ที่สร้างขึ้นอาจขาดคุณสมบัติความเป็นตัวแทน ผลการวิเคราะห์ที่ได้จึงอาจทำให้การปรับแต่ง hyperparameter มีความคลาดเคลื่อน\n\nจากข้อจำกัดดังกล่าวการสร้าง grid ของ hyperparameter ที่มีประสิทธิภาพมากกว่า random grid คือการใช้วิธีในกลุ่ม space-filling design ที่มีอัลกอริทึมภายใต้วิธีการในกลุ่มนี้หลายตัว เช่น latin hypercubes, maximum entropy designs, maximum projection designs เป็นต้น\n\n```{r}\nmy_latingrid <- grid_latin_hypercube(my_params, size = 25)\nmy_latingrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n\nmy_maxentrp <- grid_max_entropy(my_params, size = 25)\nmy_maxentrp  %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n```\n\n```{r echo = F, fig.width = 9}\nmy_randomgrid <- grid_random(my_params, size = 30)\np1<-my_randomgrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))+\n  ggtitle(\"random grid\")\n\nmy_latingrid <- grid_latin_hypercube(my_params, size = 30)\np2<-my_latingrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))+\n  ggtitle(\"latin hypercube grid\")\n\nmy_maxentrp <- grid_max_entropy(my_params, size = 30)\np3<-my_maxentrp  %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))+\n  ggtitle(\"maximum entropy grid\")\n\ngrid.arrange(p1,p2,p3, ncol=3)\n```\n\n# บทที่ 8: workflow set\n\nในทางปฏิบัติเรามักจะมีโมเดลคู่แข่งขันหลายตัวที่จะนำมาพัฒนาควบคู่กัน ภายใต้ tidymodel framework ผู้วิเคราะห์สามารถสร้าง workflow set เพื่อ fine tune hyperparameter และเปรียบเทียบโมเดลหลาย ๆ ตัวไปพร้อม ๆ กันในการประมวลผลรอบเดียวได้\n\nผู้วิเคราะห์ต้องการพัฒนาโมเดลจำแนก class โดยมีโมเดลคู่แข่งขันที่เลือกมาใช้งานได้แก่\n\n-   logistic regression with regulization\n\n-   decision tree\n\n-   random forest (เป็นการบ้าน)\n\nชุดข้อมูลที่ใช้เป็นตัวอย่างคือชุดข้อมูล `parabolic` ซึ่งเป็นชุดข้อมูลตัวอย่างของ tidymodels ผลการสำรวจข้่อมูลด้านล่างจะเห็นว่า ชุดข้อมูลประกอบด้วยข้อมูลของหน่วยข้อมูลจำนวน 500 หน่วย มีตัวแปรตามแบบจัดประเภท `class` และตัวแปรอิสระเชิงปริมาณ 2 ตัวได้แก่ `x1` และ `x2` ตามลำดับ\n\n```{r}\n#importing data\ndata(parabolic)\nglimpse(parabolic)\n\n# splitting data\nsplit <- initial_split(data = parabolic)\ntrain <- training(split)\ntest <- testing(split)\n```\n\nผู้วิเคราะห์สำรวจความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระเบื้องต้น ได้ผลดังแผนภาพด้านล่าง\n\n```{r}\n#exploring\ntrain %>%\n  ggplot(aes(x = X1, y = X2, col=class))+\n  geom_point(alpha=0.7)+\n  theme_light()+\n  theme(legend.position=\"top\")\n```\n\nการวิเคราะห์นี้มีการพัฒนา ML จำนวน 2 ตัวได้แก่ regularized logistic regression และ decision tree ที่มีการทำ preprocessing แตกต่างกัน การทำ workflow set ยอมให้ผู้วิเคราะห์กำหนด preprocessing ที่แตกต่างกันกับ model specification ที่กำหนดได้ ดังตัวอย่างต่อไปนี้\n\n```{r}\n#preprocessing\nbase_recipe <- recipe(class ~ . ,data= train)\n\nnorm_recipe <- base_recipe %>%\n  step_normalize(all_numeric_predictors())\n\n\n# model specification\n## - 1 regularized logistic regression\nregular_logit <- logistic_reg(penalty= tune(),\n                              mixture = tune()) %>%\n  set_engine(\"glmnet\")%>%\n  set_mode(\"classification\")\n\n## - 2 decision tree \ntree_mod <- decision_tree(cost_complexity = tune(),\n                          min_n = tune())%>%\n  set_engine(\"rpart\")%>%\n  set_mode(\"classification\")\n\n# creat workflowset\nmy_workflowset <- workflow_set(\n  preproc = list(norm = norm_recipe,\n                 base = base_recipe),\n  models = list(reg_logit = regular_logit,\n                cart = tree_mod),\n  cross = FALSE\n)\nmy_workflowset\n```\n\nนำ workflow set ที่สร้างมาผ่านกระบวนการ tune hyperapameter โดยฟังก์ชันที่จะใช้คือ `workflow_map()` แทน `tune_grid()`\n\nตัวอย่างด้านล่างมีการระบุ `grid = 20` แปลว่าให้ฟังก์ชันสร้าง hyperparameter grid ให้โดยใช้ค่าเริ่มต้นจำนวน 25 จุด ทั้งนี้ค่าเริ่มต้นของ tidymodel จะใช้อัลกอริทึม maximum entropy ในการกำหนด grid\n\n```{r}\n# Tuning Hypeparameter\neval_metrics <- metric_set(accuracy,roc_auc, sens, spec)\nfolds <- vfold_cv(data = train, v = 10)\nall_tune <- my_workflowset %>%\n  workflow_map(resamples = folds,\n               grid = 20,\n               verbose = TRUE,\n               metrics = eval_metrics)\n\nrank_results(all_tune)\nall_tune %>% autoplot(metric = \"roc_auc\")\n```\n\nจากผลการวิเคราะห์ข้างต้นแสดงให้เห็นว่า decision tree มีประสิทธิภาพสูงกว่า regularized logistic regression เราสามารถดึงข้อมูลของ regularized logistic regression ขึ้นมาได้โดยใช้คำสั่งต่อไปนี้\n\n```{r}\nall_tune %>% autoplot(metric = \"sens\", id = \"base_cart\")\n```\n\nฟังก์ชัน `extract_workflow_set_result()` ใช้ดึงผลการ fine-tune hyperparameter ของแต่ละโมเดลภายใต้ workflow set ขึ้นมาวิเคราะห์ในเชิงลึกต่อได้อีก\n\n```{r}\nsimple_cart_results<- all_tune %>% \n  extract_workflow_set_result(id = \"base_cart\")\nsimple_cart_results\nsimple_cart_results %>% collect_metrics(summarise = T)\nsimple_cart_results %>% autoplot()\n```\n\n```{r}\nshow_best(simple_cart_results, n=5, metric = \"sens\")\n```\n\nขั้นตอนสุดท้ายคือการ finalized model ...\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"output-file":"05RandomForest.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","urlcolor":"steelblue","linkcolor":"steelblue","theme":{"light":["pandoc","../theme.scss"]},"mainfont":"Krub","code-copy":true,"title":"Random Forest","author":"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร","toc-title":"สารบัญ"},"extensions":{"book":{"multiFile":true}}}}}