{"title":"การบ้าน 3: Digit Recognition Problem","markdown":{"headingText":"การบ้าน 3: Digit Recognition Problem","containsRefs":false,"markdown":"\n## Introduction\n\nขอให้นิสิตใช้ชุดข้อมูล [`train.csv`](datasets/train.csv.zip) และ [`test.csv`](datasets/test.csv.zip) เพื่อพัฒนาโมเดลรู้จำเพื่อจำแนกตัวเลขจากลายมือ (digit recognition) เมื่อดาวน์โหลดข้อมูลมาแล้วนิสิตจะต้องแตก zip ไฟล์ข้อมูลทั้งสองก่อนที่จะวิเคราะห์จริง\n\n```{r message= F}\nlibrary(tidymodels)\n#unzip(zipfile = \"datasets/train.csv.zip\", files = \"train.csv\")\n#unzip(zipfile = \"datasets/test.csv.zip\", file = \"test.csv\")\n\ntrain <- read.csv(\"train.csv\")\ntest <- read.csv(\"test.csv\")\nhead(train[,1:10])\n```\n\n## สำรวจข้อมูล\n\nลองเรียกชื่อตัวแปรทั้งหมดในชุดข้อมูล `train` ขึ้นมาดู\n\n```{r}\nnames(train) %>% head()\nnames(train) %>% tail()\n```\n\nชุดข้อมูลทั้งสองชุดประกอบด้วยข้อมูลภาพของตัวเลข 0 - 9 ที่เขียนด้วยลายมือที่มีขนาด 28 x 28 pixels โดยรูปภาพแต่ละรูปถูกแปลงให้อยู่ในรูปของ feature จำนวน 784 ตัว (คอลัมน์) ซึ่งแทน pixels แต่ละจุดบนรูปภาพต้นฉบับ และข้อมูลภายในแต่ละ pixel ถูกแปลงให้เป็นค่าความเข้มของสีดำ ที่มีค่าอยู่ในช่วง 0 - 255 นอกจากนี้ภายในชุดข้อมูลทั้งสองชุดยังมีตัวแปร `label` ที่ใช้ระบุว่าข้อมูลภายในแต่ละแถวของชุดข้อมูลนั้นเป็นภาพของตัวเลขใด\n\n![](images/image-1842286070.png){width=\"262\"}\n\nลองดึงข้อมูลของรูปภาพรูปที่หนึ่ง ซึ่งอยู่ในแถวแรกของชุดข้อมูล `train` ขึ้นมาดู พบว่ามีลักษณะดังนี้\n\n```{r}\n#plot function\nplot_digit <- function(data, index)\n{\ntitle_lab <- data[index,\"label\"]\ndata %>%\n  slice(index) %>%\n  dplyr::select(starts_with(\"pixel\")) %>%\n  pivot_longer(starts_with(\"pixel\")) %>%\n  mutate(x = rep(1:28,28),\n         y = rep(1:28, each = 28)) %>%\n  ggplot(aes(x = x, y = y))+\n  geom_tile(aes(fill = value))+\n  scale_y_reverse()+\n  scale_fill_gradient(low = \"white\", high = \"black\")+\n  theme_light()+\n  theme(text = element_text(family = \"ChulaCharasNew\"),\n        panel.grid = element_blank()\n  )+\n  ggtitle(title_lab)+\n  labs(fill = \"Darkness\")\n}\n# -------\nlibrary(gridExtra)\np1 <- plot_digit(train, 1)\np2 <- plot_digit(train,10)\np3 <- plot_digit(train,20)\np4 <- plot_digit(train,30)\ngrid.arrange(p1,p2,p3,p4, ncol=2)\n```\n\nสุดท้ายลองแจกแจงความถี่ของ `label` ว่ามีตัวเลขอะไรบ้างในชุดข้อมูล\n\n```{r fig.height = 3.5}\nggplot(data = train, aes(x = label)) +\n  geom_bar()+\n  scale_x_continuous(breaks=seq(0,9,1))\n```\n\n## Model Training\n\nปัญหาจำแนกตัวเลขจากลายมือนี้จัดอยู่ในกลุ่มปัญหาที่เรียกว่า multi-class classfication ซึ่งเกี่ยวกับการจำแนกข้อมูลที่มีจำนวนหลาย categories อัลกอริทึมที่จะใช้ในตัวอย่างนี้ประกอบด้วย\n\n-   Multinomial logistic regression with regularization\n\n-   Decision Tree\n\n-   Random Forest\n\nรายละเอียดการพัฒนาโมเดลมีดังนี้\n\n### 1. สร้าง recipe object\n\n```{r}\n# แปลงให้ outcom เป็น factor ก่อน\ntrain$label <- factor(train$label)\ntrain <- train %>% drop_na()\n# sampling ข้อมูลบางส่วนมา train model\nset.seed(123)\nsplit <- initial_split(train, prop = 0.2, strata = \"label\")\nsample_train <- training(split)\nsample_test <- testing(split)\n\ntable(sample_train$label)\nsample_train %>%\n  ggplot(aes(x=label))+\n  geom_bar()\n```\n\n### 2. ทดลอง fit model (no tuning)\n\nกำหนดโมเดลด้วย parsnip package รายละเอียดสามารถศึกษาได้จาก <https://www.tidymodels.org/find/parsnip/> สำหรับ multinomial logistic regression สามารถกำหนดโมเดลได้ดังนี้\n\n#### Multinomial logistic regression\n\n```{r}\nstart <- Sys.time()\nmultinom_reg <- multinom_reg(penalty = 0.01,\n                             mixture = 1) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\") %>%\n  fit(label ~ . , data= sample_train)\ntime_usage <- Sys.time() - start\ntime_usage\n\n#par(mfrow = c(5,2), mar=c(5,5,1,1))\n#multinom_reg %>% extract_fit_engine() %>%plot()\n\npred_multinom_test <- predict(multinom_reg, new_data = sample_test)\n\npred_result <- sample_test %>%\n  bind_cols(pred_multinom_test) %>%\n  select(label, .pred_class)\n\nconfusion_glmnet<-pred_result %>% conf_mat(truth = label,\n                         estimate = .pred_class)\nconfusion_glmnet %>% autoplot(type = \"heatmap\")\nconfusion_glmnet %>% summary()\n```\n\n#### Decision Trees\n\n```{r}\nlibrary(rpart.plot)\nstart <- Sys.time()\ndt_fit <- decision_tree(min_n = 900,\n                    tree_depth = 30,\n                    cost_complexity = 0.0001) %>%\n  set_engine(\"rpart\") %>%\n  set_mode(\"classification\") %>%\n  fit(label ~ ., data = sample_train)\ntime_usage <- Sys.time() - start\ntime_usage\ndt_fit %>% extract_fit_engine() %>% rpart.plot(type = 4)\n\npred_dt_test <- predict(dt_fit, new_data = sample_test)\n\npred_result_dt <- sample_test %>%\n  bind_cols(pred_dt_test) %>%\n  select(label, .pred_class)\n\nconfusion_dt<-pred_result_dt %>% conf_mat(truth = label,\n                         estimate = .pred_class)\nconfusion_dt %>% autoplot(type = \"heatmap\")\nconfusion_dt %>% summary()\n```\n\n#### Random Forest\n\n```{r}\nstart <- Sys.time()\nrf_fit <- rand_forest(mtry = 46,\n                      trees = 1000,\n                      min_n = 61) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\") %>%\n  fit(label ~ ., data = sample_train)\ntime_usage <- Sys.time() - start\ntime_usage\nrf_fit\n\npred_rf_test <- predict(rf_fit, new_data = sample_test)\n\npred_result_rf <- sample_test %>%\n  bind_cols(pred_rf_test) %>%\n  select(label, .pred_class)\n\nconfusion_rf<-pred_result_rf %>% conf_mat(truth = label,\n                         estimate = .pred_class)\nconfusion_rf %>% autoplot(type = \"heatmap\")\nconfusion_rf %>% summary()\n```\n\nจากการทดลองรันโมเดลทำนายเบื้องต้นพบว่า glmnet และ random forest เป็นโมเดลที่มีประสิทธิภาพค่อนข้างดีใกล้เคียงกัน อย่างไรก็ตาม glmnet ใช้เวลาประมวลผลค่อนข้างนานมาก ดังนั้นการ fine tune hyperparameter จะทำกับโมเดล random forest อย่างเดียว รายละเอียดอยู่ในหัวข้อถัดไป\n\n### 3. สร้าง Workflow set\n\n```{r}\n## create recipe object for workflow\npreproc <- recipe(label ~. , data= sample_train)\n```\n\nกำหนด workflow เพื่อ fine tune hyperparameter ของ random forest จากการวิเคราะห์เบื้องต้นพบว่า hyperparameter ที่ค่อนข้างมีผลต่อประสิทธิภาพการทำนายคือ `mtry` ดังนั้นจึงจะ fine tune เฉพาะ hyperparameter ตัวนี้เพียงตัวเดียว\n\n```{r}\n## model specification\nrf_model <- rand_forest(mtry = tune(),\n                      trees = 200,\n                      min_n = tune()) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n\nrf_workflow <- workflow() %>%\n  add_recipe(preproc) %>%\n  add_model(rf_model)\n\nrf_workflow\n```\n\n### 4. Hyperparameters Tuning\n\nนำโมเดลทั้งหมดมา train และปรับแต่งค่า hyperparameter ของโมเดล ดังนี้\n\n```{r message = F}\n## create 10-folds CV \nboot <- bootstraps(sample_train, times = 25, strata = \"label\")\n#vfold_cv(sample_train, v = 5, repeats = 3, strata= \"label\")\n# create eval metric\neval_metrics <- metric_set(accuracy,roc_auc, sens, spec)\n# create grid\nparams <- parameters(mtry(range = c(5,50)),\n                     min_n(range = c(50,400)))\nmygrid <- grid_max_entropy(params, size = 15)\n\n## tuning with default grid\nlibrary(doMC)\nregisterDoMC(cores = parallel::detectCores())\nstart <- Sys.time()\nall_tuning_results <- rf_workflow %>%\n  tune_grid(resamples = boot,\n               grid = mygrid,\n               metrics = eval_metrics,\n               control = control_grid(save_pred = TRUE,\n                                      verbose = TRUE)\n               )\n# stop parallel\ntime_usage <- Sys.time() - start\ntime_usage\n```\n\n### 5. วิเคราะห์ hyperparameters\n\n```{r}\nall_tuning_results %>% collect_metrics(summarise = T) %>%\n  filter(.metric == \"sens\") %>%\n  arrange(desc(mean))\nall_tuning_results %>% autoplot()\nshow_best(all_tuning_results,3, metric = \"roc_auc\")\nshow_best(all_tuning_results,3, metric = \"sens\")\nshow_best(all_tuning_results,3, metric = \"spec\")\n```\n\n### 6. Finalized workflow\n\nนำโมเดลที่ดีที่สุดจากข้้างต้นมา fit ใหม่\n\n```{r}\nmybest_mod <- show_best(all_tuning_results,1, metric = \"sens\")\nset.seed(123)\nsplit <- initial_split(train, prop = 0.7, strata = \"label\")\nsample_train <- training(split)\nsample_test <- testing(split)\n\nrf_model2 <- rand_forest(mtry = tune(),\n                      trees = 1000,\n                      min_n = tune()) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n\nrf_workflow2 <- workflow() %>%\n  add_recipe(preproc) %>%\n  add_model(rf_model2)\n\nstart <- Sys.time()\nregisterDoMC(cores = parallel::detectCores())\nrf_fit_final <- rf_workflow2 %>%\n  finalize_workflow(mybest_mod) %>%\n  last_fit(split,\n           metrics = eval_metrics)\ntime_usage <- Sys.time() - start\ntime_usage\n\nrf_fit_final %>% \n  collect_metrics()\n\nrf_fit_final %>%\n  collect_predictions() %>%\n  conf_mat(truth = label,\n           estimate = .pred_class) %>%\n  summary()\n\n## mosaic plot\nrf_fit_final %>%\n  collect_predictions() %>%\n  conf_mat(truth = label,\n           estimate = .pred_class) %>%\n  autoplot()\n\n## heatmap of confusion matrix\nrf_fit_final %>%\n  collect_predictions() %>%\n  conf_mat(truth = label,\n           estimate = .pred_class) %>%\n  autoplot(type = \"heatmap\")\n```\n\n### 7. Predict a new dataset\n\n```{r}\npredict_val <- rf_fit_final %>%\n  extract_workflow() %>%\n  predict(test[1:6,])\npredict_val <- as.character(predict_val$.pred_class)\np1<-plot_digit(test,1)+\n  ggtitle(predict_val[1])\np2<-plot_digit(test,2)+\n  ggtitle(predict_val[2])\np3<-plot_digit(test,3)+\n  ggtitle(predict_val[3])\np4<-plot_digit(test,4)+\n  ggtitle(predict_val[4])\np5<-plot_digit(test,5)+\n  ggtitle(predict_val[5])\np6<-plot_digit(test,6)+\n  ggtitle(predict_val[6])\ngrid.arrange(p1,p2,p3,p4,p5,p6,ncol=3)\n```\n\n## 8. Predict new dataset (from raw)\n\n```{r}\nlibrary(EBImage)\nmyimg <- readImage(\"/Users/siwachoat/Desktop/Screenshot 2566-03-04 at 18.45.19.png\")\nmyimg\ncolorMode(myimg) <- Grayscale\nimg_resize <- resize(myimg, w=28, h=28)\ndisplay(img_resize)\nimg_neg <- max(img_resize) - img_resize\ndisplay(img_neg)\nimg_neg\nmyimg <- imageData(img_neg)[,,1]\nmyimg %>% dim()\nvector <- myimg %>% as.numeric()\ntemp <- data.frame(t(vector))\ntemp\nnames(temp) <- paste0(\"pixel\",0:783)\ntemp <-temp*255\ntemp<-round(temp,0)\n\nplot_digit(temp,1)\npredict_val <- rf_fit_final %>%\n  extract_workflow() %>%\n  predict(temp)\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"hw03.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","urlcolor":"steelblue","linkcolor":"steelblue","theme":{"light":["pandoc","../theme.scss"]},"mainfont":"Krub","code-copy":true},"extensions":{"book":{"multiFile":true}}}}}