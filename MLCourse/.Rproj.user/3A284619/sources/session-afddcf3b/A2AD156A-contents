---
title: "Modelling Process"
author: "ผศ.ดร.สิวะโชติ ศรีสุทธิยากร"
toc: true
toc-depth: 3
toc-title: สารบัญ
theme: default
---

```{r echo=F, message=F, warning = F}
library(tidyverse)
```

# บทที่ 3 กระบวนการพัฒนา Machine Learning Models

กระบวนการพัฒนา machine learning models อาจจำแนกได้เป็นสองส่วน ส่วนแรกคือส่วนของการพัฒนาโมเดล และส่วนที่สองคือส่วนของการนำโมเดลไปใช้งาน

ส่วนการพัฒนาโมเดลมีกระบวนการพัฒนาแสดงไว้ในรูป 15 จากรูปจะเห็นว่าเริ่มตั้งแต่การเก็บรวบรวมข้อมูล การจัดการข้อมูล จากนั้นจะมีการแบ่งชุดข้อมูลออกเป็นส่วน traning dataset และ test dataset ข้อมูลส่วนที่เป็น traning dataset จะถูกนำมาพัฒนาการเรียนรู้/ความสามารถในการทำนายของโมเดล ผ่านอัลกอริทึมต่าง ๆ จากนั้นจะเลือกอัลกอริทึมที่มีประสิทธิภาพสูงที่สุด (ประเมินจาก test dataset) ไปใช้งาน ทั้งนี้การจะนำโมเดลทำนายไปใช้งานได้นั้นจะต้องมีบันทึกโมเดลที่พัฒนาขึ้นเพื่อนำไปเรียกใช้ต่อไป

![Modeling Process](images/image-1728379488.png){alt="Modeling Process"}

ลักษณะเฉพาะในกระบวนการพัฒนาโมเดลทำนายคือ การดำเนินงานในหลายขั้นตอน เช่น การจัดการข้อมูล การ fit และปรับแต่งโมเดล หรือการคัดเลือกโมเดลทำนายที่ดีที่สุด ไม่ได้มีแนวทางหรือกฎเกณฑ์ที่ชัดเจนตายตัวว่าต้องดำเนินการอย่างไร นอกจากนี้กระบวนการดังกล่าวยังมีลักษณะเป็นแบบทวนซ้ำไปมา รูป 16 แสดงตัวอย่างการดำเนินงานของผู้วิเคราะห์เพื่อพัฒนาโมเดลทำนายโมเดลหนึ่ง

![ตัวอย่างขั้นตอนการพัฒนาโมเดลทำนาย (ที่มา : Max Kuhn and Kjell Johnson (2019))](images/image-1908104112.png){alt="ตัวอย่างขั้นตอนการพัฒนาโมเดลทำนาย (ที่มา : Max Kuhn and Kjell Johnson (2019))" fig-align="center" width="70%"}

จากรูปข้างต้นจะเห็นว่ากระบวนการเริ่มต้นด้วยกากการวิเคราะห์เพื่อสำรวจข้อมูล (exploratory data analysis: EDA) ก่อน (จุด a) โดยที่ EDA เป็นเทคนิคที่ผู้วิเคราะห์ใช้เพื่อทำความเข้าใจคุณลักษณะสำคัญของตัวแปรต่าง ๆ ภายในชุดข้อมูล ซึ่งประกอบด้วย (1) การวิเคราะห์สถานะและการแจกแจงของตัวแปร (2) การวิเคราะห์ความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระ รวมทั้งความสัมพันธ์ระหว่างตัวแปรอิสระ (3) การวิเคราะห์รูปแบบการสูญหายของข้อมูล และ (4) ความผิดปกติที่อาจเกิดขึ้นในข้อมูล กระบวนการในส่วนของการสำรวจนี้เป็นกระบวนการทวนซ้ำและอาจมีการสลับไปมาระหว่างการใช้ทัศนภาพข้อมูลเชิงสำรวจ และการใช้เทคนิคการวิเคราะห์เชิงปริมาณ (จุด b) เข้ามาช่วย สารสนเทศที่ได้จากกระบวนส่วนนี้จะสามารถใช้เป็นแนวทางเพื่อจัดข้อมูลของตัวแปรอิสระให้เหมาะสมและมีประสิทธิภาพสูงที่สำหรับการพัฒนาโมเดลทำนายต่อไป เรียกขั้นตอนนี้ว่า feature engineering (จุด c) เมื่อสิ้นสุดขั้นตอนนี้ผลผลิตที่ควรได้คือชุดข้อมูลต้นแบบที่ประกอบด้วยตัวแปรตาม และตัวแปรอิสระที่ผ่านการคัดเลือกหรือทำ feature engineering มาแล้ว และอยู่ในรูปแบบที่พร้อมจะนำไปวิเคราะห์

เมื่อได้ชุดข้อมูลต้นแบบมาเรียบร้อยแล้ว ผู้วิเคราะห์จะนำชุดข้อมูลดังกล่าวไปเป็นต้นแบบให้อัลกอริทึมการเรียนรู้ของเครื่องหลาย ๆ ตัวได้เรียนรู้ เพื่อพัฒนาเป็นโมเดลทำนาย (จุด d) จากรูปจะเห็นว่าอัลกอริทึมที่ถูกเลือกมาใช้จำนวน 4 อัลกอริทึม ทั้งนี้อัลกอริทึมส่วนใหญ่มักมีส่วนประกอบที่เรียกว่า hyperparameters ที่ต้องกำหนดค่าด้วยการปรับแต่ง (tuning) จากรูปจะเห็นว่าการเรียนรู้ในแต่ละอัลกอริทึมจะมีขั้นตอนของการเรียนรู้ และการปรับแต่ง hyperparameters ที่ต้องดำเนินการแบบทวนซ้ำสลับไปมาจนกระทั่งได้โมเดลที่มีประสิทธิภาพสูงสุด ทั้งนี้เมื่อได้โมเดลดังกล่าวแล้ว ผู้วิเคราะห์จะนำโมเดลที่พัฒนาได้ไปประเมินประสิทธิภาพการทำนายของโมเดล การดำเนินงานในส่วนนี้จะมีการใช้ทั้งการวิเคราะห์เชิงปริมาณผ่านค่าสถิติต่าง ๆ เช่น evaluation metrics ต่าง ๆ ที่ใช้ประเมินประสิทธิภาพการทำนาย รวมทั้งยังอาจมีการใช้ EDA อีก เพื่อวิเคราะห์ประสิทธิภาพ หรือข้อจำกัดของแต่ละโมเดลในการทำนายผลลัพธ์ที่ต้องการ (จุด e และ f)

สารสนเทศที่ได้จากการวิเคราะห์ประสิทธิภาพของโมเดลจะเป็นตัวกำหนดการดำเนินงานต่อไปของผู้วิเคราะห์ โดยอาจจำแนกเป็นสองกรณี กรณีแรกคือหากโมเดลมีประสิทธิภาพในการทำนายสูงอยู่ระดับที่สามารถนำไปใช้งานได้แล้วผู้วิเคราะห์จะหยุดการดำเนินงานไว้ที่ขั้นตอนนี้แล้วนำโมเดลดังกล่าวไปใช้งานต่อไป กรณีที่สองหากโมเดลทำนายที่พัฒนาขึ้นยังมีประสิทธิภาพไม่ถึงเกณฑ์ที่กำหนด ผู้วิเคราะห์สามารถใช้สารสนเทศจาก EDA ในจุด f ประกอบการคัดเลือกโมเดลเบื้องต้น และปรับแต่งโมเดลรวมทั้งอาจดำเนินการทำ feature engineering อีกครั้งหนึ่งเพื่อเพิ่มประสิทธิภาพการทำนายให้กับโมเดล (จุด h) เมื่อได้โมเดลสุดท้ายแล้วผู้วิเคราะห์สามารถเปรียบเทียบประสิทธิภาพระหว่างโมเดลคู่แข่งขันโดยใข้ชุดข้อมูลทดสอบ (test dataset) แล้วเลือกโมเดลที่ดีที่สุดไปใช้งาน

ส่วนของการนำโมเดลไปใช้งาน ต้องทำความเข้าใจว่า ML model ที่พัฒนาขึ้นนั้นเป็นเหมือนสมองซึ่งต้องเข้าไปอยู่ในโปรแกรมหรือ application สักตัวหนึ่ง โดยโปรแกรมดังกล่าวจะมีหน้าที่หลัก ๆ เช่นมี interface สำหรับรับข้อมูลจากผู้ใช้ เพื่อนำไปประมวลผลด้วยโมเดลทำนายที่เราสร้างขึ้น และรายงานผลการทำนาย/จำแนก ที่ได้จากโมเดลให้แก่ผู้ใช้ ทั้งนี้โปรแกรมดังกล่าวยังอาจมีส่วนอื่น ๆ ที่ยอมให้ผู้ใช้เลือกหรือปรับแต่งการทำงานของโปรแกรมได้ ทั้งนี้ขึ้นอยู่กับวัตถุประสงค์การใช้งาน ตัวอย่างด้านล่างแสดงโปรแกรมทำนายผลการเรียนของนิสิต [KruRooTeller](https://siwachoat.shinyapps.io/reportandpredict/?_ga=2.42051557.1707159165.1666195773-1113918738.1613372414&utm_source=KruRooTeller)

![ระบบ KruRooTeller](images/image-1909139629.png){alt="ระบบ KruRooTeller" width="90%"}

เนื้อหาส่วนที่เหลือของบทเรียนนี้จะกล่าวถึงกระบวนการในส่วนของการพัฒนา supervised learning models โดยจะกล่าวถึงมโนทัศน์ที่จำเป็นก่อน จากนั้นจึงกล่าวถึงกระบวนการพัฒนาโมเดลดังกล่าว รายละเอียดมีดังนี้

\newpage

## 3.1 Bias and Variance in ML models

พิจารณารูป 18 แสดงการ fit โมเดลทำนาย 3 แบบกับชุดข้อมูลฝึกหัดชุดหนึ่ง จะเห็นว่าแต่ละโมเดลมีความสามารถในการเรียนรู้ความสัมพันธ์ที่เกิดขึ้นในชุดข้อมูลแตกต่างกัน ความแตกต่างระหว่างค่าจริงของตัวแปรตามในชุดข้อมูลฝึกหัดกับค่าทำนายที่ได้จากโมเดล เรียกว่า **ความลำเอียง (bias)** **จากรูป 16 ผู้อ่านคิดว่าโมเดลใดที่มีประสิทธิภาพในการทำนายสูงที่สุดเพราะเหตุใด ?**

```{r echo=F, warning=F, fig.cap="regression model on training dataset", fig.width=3.5, fig.height=2.5,  message=F}
x<-runif(25,0,1)
y<-sin(1.2*x*pi)+rnorm(25,0,0.15)
dat<-data.frame(x,y)
dat%>%ggplot(aes(x=x,y=y))+
   geom_point(size=2,alpha=0.6)+
    theme_minimal()+
   geom_line(data=dat, 
             aes(x=x, y=y), col="maroon", size=1, alpha=0.7)+
    geom_smooth(se=F, alpha=0.7)+
    geom_smooth(method="lm", se=F, alpha=0.7, col="black")+
  annotate(geom = "text", x=0.3, y = -0.25, 
           label = "Model = Signal + Error")+
  scale_x_continuous(limits=c(0,1))

```

พิจารณารูป 19 ผู้วิเคราะห์ได้นำโมเดลทำนายทั้ง 3 แบบ ที่พัฒนาจากชุดข้อมูลฝึกหัดมาใช้ทำนายข้อมูลใหม่ที่โมเดลทั้ง 3 ไม่เคยได้เรียนรู้มาก่อน ความแตกต่างระหว่างค่าจริงของตัวแปรตามในชุดข้อมูลใหม่ (หรือชุดข้อมูลที่ไม่ได้ใช้ในขั้นการพัฒนาโมเดล) กับค่าทำนายของโมเดล เรียกว่า **ความแปรปรวน (variance)** ความแปรปรวนของโมเดลทั้ง 3 เป็นอย่างไร?

```{r echo=F, warning=F, fig.cap="regression model on new dataset", fig.width=3.5, fig.height=2.5, message=F}
x<-seq(0,1,length=10)
y<-sin(1*x*pi)+rnorm(10,0,0.15)
dat2<-data.frame(x,y)
dat$type<-1
dat2$type<-2
temp<-bind_rows(dat,dat2)
temp$type<-factor(temp$type, labels=c("training data","new data"))


ggplot()+
   geom_point(data=temp%>%filter(type=="new data"),
              aes(x=x,y=y, col=type), 
              size=2, 
              alpha=0.6, show.legend = F)+
    theme_minimal()+
   geom_line(data=temp%>%filter(type=="training data"), 
             aes(x=x, y=y), col="maroon")+
    geom_smooth(data=temp%>%filter(type=="training data"),
                aes(x=x, y=y),
                se=F, col="steelblue", alpha=0.7)+
  geom_smooth(data=temp%>%filter(type=="training data"),
                aes(x=x, y=y),
              method="lm",
                se=F, col="black", alpha=0.7)+
    scale_color_discrete(direction=-1)+
    scale_x_continuous(limits=c(0,1))+
  annotate(geom="text", x=0.8, y= 0.95, label="new data")

```

จากตัวอย่างข้างต้นจะเห็นว่า ถึงแม้จะสามารถพัฒนาโมเดลทำนายให้สามารถเรียนรู้ความสัมพันธ์ภายในชุดข้อมูลฝึกหัดได้เป็นอย่างดี (มีความลำเอียงต่ำที่สุดแล้ว) แต่ก็ไม่ใช่เงื่อนไขเพียงพอที่จะสรุปได้ว่าโมเดลทำนายดังกล่าวจะมีประสิทธิภาพในการทำนายได้ดีในกรณีทั่วไป การตรวจสอบอีกชั้นหนึ่งคือตรวจสอบความแปรปรวนของโมเดลทำนาย โดยนำโมเดลดังกล่าวไปทำนายชุดข้อมูลที่ไม่เคยได้เรียนรู้มาก่อน โมเดลที่มีทั้งความลำเอียงและความแปรปรวนต่ำจึงเป็นโมเดลที่มีประสิทธิภาพที่จะนำไปใช้ในกรณีทั่วไป

ในเชิงอุดมคติ ผู้วิเคราะห์ต้องการให้ทั้งความลำเอียง และความแปรปรวนมีค่าต่ำที่สุดเท่าที่จะสามารถต่ำได้ แต่ในความเป็นจริงความคลาดเคลื่อนทั้งสองไม่ควบคุมให้ต่ำที่สุดพร้อมกันได้ **(เพราะอะไร?)** รูป 20 ด้านล่างแสดงความสัมพันธ์ระหว่างความลำเอียง และความแปรปรวน ซึ่งจะเห็นว่ามีการแปรผกผันซึ่งกันและกัน โมเดลที่มีความลำเอียงสูงมีแนวโน้มที่จะมีความแปรปรวนต่ำ และในทางกลับกันโมเดลที่มีความลำเอียงต่ำจะมีแนวโน้มที่มีความแปรปรวนสูง **ดังนั้นวัตถุประสงค์ของการพัฒนาโมเดลจึงเป็นการหาจุดที่ดีที่สุดที่ทำให้ความคลาดเคลื่อนทั้งสองอยู่ในจุดที่ต่ำที่สุดเท่าที่จะเป็นไปได้**

![bias and variance trace-off](images/image-712567945.png){alt="bias and variance trace-off" fig-align="center" width="60%"}

## 3.2 Underfitting, Overfitting และ Good fit models

หากจำแนกโมเดลทำนายที่ถูกพัฒนาขึ้นตามประสิทธิภาพการทำนายของโมเดล อาจจำแนกได้เป็น 3 ประเภท ได้แก่

1.  underfitting models คือโมเดลที่มีความลำเอียงสูง ความลำเอียงเป็นความคลาดเคลื่อนที่เป็นระบบ อันเนื่องมาจากโมเดลทำนายที่พัฒนาขึ้นยังไม่สามารถเรียนรู้แนวโน้มหรือรูปแบบความสัมพันธ์หลักระหว่างตัวแปรภายในชุดข้อมูลฝึกหัดได้ดีเพียงพอ จากรูป 21 ซ้ายมือ จะเห็นว่าแนวโน้มความสัมพันธ์ตามธรรมชาติระหว่างตัวแปรตามกับตัวแปรอิสระคือความสัมพันธ์เชิงเส้นโค้ง แต่โมเดลทำนายที่พัฒนาขึ้นอยู่ในรูปแบบเส้นตรง ความแตกต่างระหว่างรูปแบบความสัมพันธ์ดังกล่าวก่อให้เกิดความลำเอียงขึ้น และเรียกโมเดลที่มีความลำเอียงในระดับที่มากเกินไปนี้ว่า underfitting model
2.  overfitting models คือโมเดลที่มีความแปรปรวนสูง ความแปรปรวนเกิดขึ้นจากการที่โมเดลทำนายที่พัฒนาขึ้นสามารถเรียนรู้ความสัมพันธ์ในชุดข้อมูลฝึกหัดได้ดีมากเกินไป จนขาดความยืดหยุ่นในการนำโมเดลดังกล่าวไปใช้ในกรณีทั่วไป ดังตัวอย่างในรูป 21 ขวามือ จากรูปจะเห็นว่าโมเดลสามารถเรียนรู้ความสัมพันธ์ได้เกือบสมบูรณ์ แต่หากนำโมเดลนี้ไปใช้ทำนายข้อมูลใหม่ที่อยู่นอกเหนือจากชุดข้อมูลที่โมเดลนี้ได้เรียนรู้มีแนวโน้มสูงที่จะเกิดความคลาดเคลื่อนในการทำนาย
3.  good fit models คือโมเดลที่สามารถสมดุลความลำเอียงและความแปรปรวนให้มีค่าต่ำที่สุดเท่าที่จะเป็นไปได้

![underfitting, good fit, and overfitting model](images/image-1638148101.png){alt="underfitting, good fit, and overfitting model"}

## 3.3 Training, validation, and Test Dataset

จาก concept ข้างต้นจะเห็นว่าในกระบวนการพัฒนาโมเดลผู้วิเคราะห์จะให้ความสำคัญกับประสิทธิภาพในการทำนายของโมเดลเฉพาะด้านความลำเอียงไม่ได้ ยังต้องคำนึงถึงด้านความแปรปรวนด้วย การพัฒนาโมเดลการเรียนรู้ของเครื่องจึงจะมีแค่ชุดข้อมูลฝึกหัดไม่ได้ ยังต้องมีชุดข้อมูลอีกชุดหนึ่งเพื่อเอาไว้ตรวจสอบความแปรปรวนของโมเดลด้วย ในเชิงเทคนิคเรียกชุดข้อมูลนี้ว่า **ชุดข้อมูลทดสอบ (test dataset)**

ภายในอัลกอริทึม supervised learning จะมีส่วนประกอบหลัก ๆ ได้แก่ อัลกอริทึม พารามิเตอร์ และ ไฮเปอร์พารามิเตอร์

-   **อัลกอริทึม** เป็นส่วนของวิธีการเรียนรู้ของสำหรับแต่ละการเรียนรู้ของเครื่องที่ใช้ในการเรียนรู้หรือสกัดสารสนเทศจากข้อมูลในชุดข้อมูลฝึกหัด

-   **พารามิเตอร์** **(parameters)** ส่วนที่ทำให้การเรียนรู้ของเครื่อง fit กับข้อมูล กล่าวง่าย ๆ คือค่าของพารามิเตอร์ที่เปลี่ยนแปลงไป จะทำให้รูปแบบการเรียนรู้มีการเปลี่ยนไป ค่าพารามิเตอร์นี้สามารถประมาณได้จากข้อมูลด้วยวิธีการทางสถิติ/คณิตศาสตร์ ตัวอย่างของพารามิเตอร์เช่น ใน linear regression model มีพารามิเตอร์คือ สัมประสิทธิ์จุดตัดแกน และสัมประสิทธิ์ความชัน เป็นต้น อย่างไรก็ตามบางอัลกอริทึมไม่ได้มีพารามิเตอร์ของโมเดล เช่น K-NN เป็นต้น

-   **ไฮเปอร์พารามิเตอร์ (Hyperparameters)** เป็นพารามิเตอร์ประเภทหนึ่งในอัลกอริทึมการเรียนรู้ของเครื่อง พารามิเตอร์ประเภทนี้ไม่สามารถประมาณค่าจากข้อมูลโดยตรงด้วยวิธีการทางสถิติ แต่จะใช้การกำหนด/ปรับแต่งค่าโดยตัวผู้วิเคราะห์เอง **ในเชิงเทคนิคเรียกการปรับแต่งค่าดังกล่าวว่า hyperparameter tuning** การปรับแต่งค่าของ hyperparameter ดังกล่าวจะใช้วิธีการทดลองกำหนดค่า hyperparameter จำนวนหนึ่งให้กับอัลกอริทึม จากนั้นเลือกใช้ค่า hyperparameter ที่ทำให้ค่าประสิทธิภาพของโมเดลทำนายสูงที่สุด ทั้งนี้การพิจารณาประสิทธิภาพดังกล่าวจะพิจารณาบนชุดข้อมูลอีกชุดหนึ่งที่เรียกว่า **validation dataset**

จากที่กล่าวข้างต้นจะเห็นว่าในกระบวนการพัฒนาโมเดลการเรียนรู้ของเครื่อง ต้องการชุดข้อมูลทั้งหมดจำนวน 3 ชุด ได้แก่ training, validation และ test dataset โดยที่ training และ validation dataset เป็นชุดข้อมูลที่ใช้ในระยะพัฒนาการเรียนรู้ของโมเดลให้มีประสิทธิภาพสูงสุด ส่วน test dataset เป็นชุดข้อมูลที่ใช้ตรวจสอบประสิทธิภาพด้านความเป็นนัยทั่วไปแต่จะไม่ได้มีส่วนเกี่ยวข้องกับระยะการพัฒนาการเรียนรู้ของโมเดล

\newpage

## 3.4 Data Partitioning

ในทางปฏิบัติผู้วิเคราะห์มักมีข้อมูลต้นฉบับเพียงชุดเดียวเท่านั้นแต่ละใช้การแบ่งส่วนข้อมูลโดยใช้วิธีการสุ่มตัวอย่าง (random sampling) เพื่อสร้าง training, validation และ test dataset รูปด้านล่างแสดงลักษณะการแบ่งส่วนข้อมูล

![training, validation และ testing dataset](images/image-2117384298.png){alt="training, validation และ testing dataset" fig-align="center" width="40%"}

โดยปกติการแบ่งส่วนข้อมูลดังกล่าวไม่ได้มีกฎเกณฑ์ตายตัวว่าควรแบ่งส่วนใดอย่างละเท่าไหร่ โดยปกติผู้วิเคราะห์มักกำหนดสัดส่วนระหว่าง training + validation dataset กับ test dataset เป็น 80 : 20, 75 : 25, 70 : 30, 60: 40 หรือ 50: 50 ขึ้นอยู่กับว่าชุดข้อมูลต้นฉบับที่มีนั้นมีขนาดใหญ่มากเพียงใด นอกจากนี้การแบ่งส่วนข้อมูลด้วยวิธีการสุ่มตัวอย่างอาจจำแนกเป็น 2 วิธีการ วิธีการแรกคือการสุ่มตัวอย่างแบบง่าย (simple random sampling: SRS) และวิธีการที่สองคือการสุ่มตัวอย่างแบบชั้นภูมิ (stratified random sampling)

### ชุดข้อมูล `mpg`

ชุดข้อมูลที่ใช้เป็นตัวอย่างในหัวข้อนี้จะใช้ dataset `mpg` ที่เป็นชุดข้อมูลตัวอย่างซึ่งถูกติดตั้งมาพร้อมกับการติดตั้งโปรแกรม R อยู่แล้ว ผู้วิเคราะห์สามารถเรียกดูข้อมูลภายในชุดข้อมูลดังกล่าวได้โดยใช้คำสั่งพื้นฐานต่าง ๆ เช่น `head()`, `str()`, `glimpse()` หรือ `summary()` เป็นต้น

```{r}
library(dplyr)
head(mpg)
```

\newpage

```{r}
glimpse(mpg)
```

### การแบ่งข้อมูลด้วยการสุ่มอย่างง่าย

การแบ่งด้วย simple random sampling เป็นการแบ่งโดยสุ่มข้อมูลตามจำนวนที่กำหนดออกมาเป็นชุดข้อมูล training dataset หรือ test dataset โดยการสุ่มดังกล่าวมีข้อสมมุติว่าหน่วยข้อมูลทุกหน่อยในชุดข้อมูลต้นฉบับมีโอกาสที่จะถูกสุ่มขึ้นมาเท่ากันทั้งหมด การแบ่งข้อมูลด้วยวิธีการนี้ใน R สามารถทำได้หลายวิธี แต่ในบทความนี้จะใช้วิธีที่อยู่ภายใต้ framework ของ tidymodels การแบ่งข้อมูลด้วยวิธีการดังกล่าวมีสองขั้นตอน **ขั้นแรก** คือการสร้างกรอบของการแบ่งข้อมูลออกเป็น training และ test data สามารถทำได้ด้วยฟังก์ชัน `initial_split()` ของ package rsample อาร์กิวเมนท์สำคัญที่จะต้องระบุในฟังก์ชันได้แก่ `data` และ `prop`**ขั้นที่สอง** คือการแบ่งข้อมูลตามกรอบในขั้นตอนแรก โดยจะใช้ฟังก์ชัน `training()` เพื่อแบ่งชุด training dataset ออกมา และใช้ฟังก์ชัน `testing()` เพื่อแบ่งชุดข้อมูล test dataset ออกมา

```{r}
# import rsample
library(rsample)
# generate sampling frame
mpg_split1 <- initial_split(data = mpg, prop = 0.75)
mpg_split1
# create training and test dataset
train_srs <- mpg_split1 %>% training()
test_srs <- mpg_split1 %>% testing()
```

### การแบ่งข้อมูลด้วยการสุ่มแบบชั้นภูมิ

การแบ่งชุดข้อมูลด้วยการสุ่มแบบชั้นภูมิสามารถทำได้ด้วยฟังก์ชัน `initial_split()` เช่นเดียวกัน แต่จะต้องมีการระบุอาร์กิวเมนท์ของฟังก์ชันเพิ่มเติมได้แก่ `strata` เพื่อระบุตัวแปรตามหรือตัวแปรเกณฑ์ที่จะใช้แบ่งชั้นภูมิก่อนการสุ่มตัวอย่าง และ `breaks` ใช้กำหนดจำนวนอันตรภาคชั้นของตัวแปรตามหรือตัวแปรเกณฑ์ที่จะใช้แบ่งชั้นภูมิหากตัวแปรดังกล่าวเป็นตัวแปรเชิงปริมาณ ค่าเริ่มต้นของอาร์กิวเมนท์นี้กำหนดให้ `breaks = 4`ตัวอย่างต่อไปนี้แสดงการแบ่งชุดข้อมูล training และ test ด้วยการสุ่มแบบชั้นภูมิ

```{r}
mpg_split2 <- initial_split(data = mpg, 
                            prop = 0.75,
                            strata = "hwy",
                            breaks = 10)
train_str <- mpg_split2 %>% training()
test_str <- mpg_split2 %>% testing()
```

รูปด้านล่างแสดงการเปรียบเทียบการแจกแจงของตัวแปรตามระหว่างชุดข้อมูลต้นฉบับ (full dataset), training และ test dataset ที่แบ่งด้วยวิธีการสุ่มตัวอย่างแบบง่าย และแบบชั้นภูมิ

```{r echo=F, message=F, warning=F, fig.cap="เปรียบเทียบระหว่าง SRS กับ STR", fig.height= 4.5}
library(ggplot2)
library(gridExtra)

total<-mpg%>%ggplot()+geom_histogram(aes(x=hwy))+
  scale_x_continuous(limits=c(0,50))+
  theme_minimal()+
  ggtitle("original dataset")

p1<-train_srs%>%ggplot()+
  geom_histogram(aes(x=hwy))+
  scale_x_continuous(limits=c(0,50))+
  theme_minimal()+
  ggtitle("training dataset (SRS)")+
  theme(panel.grid.minor = element_blank())


p2<-train_str%>%ggplot()+
  geom_histogram(aes(x=hwy))+
  scale_x_continuous(limits=c(0,50))+
  ggtitle("training dataset (STR)")+
  theme(panel.grid.minor = element_blank())

p3<-test_srs%>%ggplot()+
  geom_histogram(aes(x=hwy))+
  scale_x_continuous(limits=c(0,50))+
  scale_y_continuous(limits=c(0,13))+
  theme_minimal()+
  ggtitle("test dataset (SRS)")

p4<-test_str%>%ggplot()+
  geom_histogram(aes(x=hwy))+
  scale_x_continuous(limits=c(0,50))+
  scale_y_continuous(limits=c(0,13))+
  ggtitle("test dataset (STR)")+
  theme(panel.grid.minor = element_blank())

grid.arrange(total, p1 , p2, p3, p4 , layout_matrix=rbind(c(1,1),c(2,3),c(4,5)))
```

การสุ่มแบบชั้นภูมิเหมาะสำหรับการพัฒนา classification models เมื่อสัดส่วนของค่าที่เป็นไปได้ของตัวแปรตามมีความแตกต่างกันมาก ๆ หรือมีบางค่าสังเกตของตัวแปรตามที่มีสัดส่วนการเกิดที่น้อยเมื่อเปรียบเทียบกับค่าสังเกตอื่น ๆ (imbalanced outcome) นอกจากนี้ยังเหมาะกับการพัฒนา regression models เมื่อตัวแปรตามมีลักษณะการแจกแจงแบบเบ้ขวา

## 3.5 การสุ่มซ้ำ (resampling)

อัลกอริทึมการเรียนรู้ของเครื่องหลายตัวมี hyperparameters ที่หากมีการกำหนดค่าที่เหมาะสมจะช่วยพัฒนาการเรียนรู้ได้ดีขึ้นและช่วยให้โมเดลทำนายมีประสิทธิภาพการทำนายที่สูงขึ้นได้ อย่างไรก็ตาม hyperparameters ดังกล่าวไม่สามารถประมาณได้โดยตรงจากข้อมูล แต่ต้องอาศัยการกำหนดค่าเองโดยผู้วิเคราะห์ ดังนั้นในระหว่างการพัฒนาโมเดลจึงมีความจำเป็นที่ผู้วิเคราะห์จะต้องทราบประสิทธิภาพการทำนายของโมเดลเมื่อมีการกำหนดค่า hyperparameters ต่าง ๆ เพื่อใช้เป็นสารสนเทศประกอบการกำหนดค่า hyperparameters ดังกล่าว

ด้วยเหตุผลเดียวกับการประเมินประสิทธิภาพของโมเดลด้วยชุดข้อมูลทดสอบ การประเมินประสิทธิภาพในระยะของการพัฒนาโมเดลดังกล่าวไม่ช่วยใช้ข้อมูลจากชุดข้อมูลฝึกหัด เพราะจะทำให้ค่าประสิทธิภาพดังกล่าวมีค่าสูงเกินความเป็นจริงและอาจทำให้การกำหนดค่า hyperparameters มีความคลาดเคลื่อน เพื่อแก้ปัญหาดังกล่าวจึงมีการใช้เทคนิคการสุ่มซ้ำ (resampling) ในการสุ่มชุดข้อมูลย่อยจากชุดข้อมูลฝึกหัด โดยแบ่งชุดข้อมูลฝึกหัดออกเป็นสองชุดข้อมูลย่อย อาจเรียกว่าชุดข้อมูลสำหรับวิเคราะห์ (analysis) ต่อไปจะเรียกว่า traning dataset และชุดข้อมูลสำหรับสำหรับประเมินประสิทธิภาพ (assessment) ซึ่งต่อไปจะเรียกว่า validation dataset ดังรูป 24

![resampling strategy](images/image-468626522.png){alt="resampling strategy"}

เนื่องจากเทคนิคการสุ่มซ้ำเป็นการสุ่มแบบที่มีการใส่คืน (sampling with replacement) จึงทำให้ในระยะของการพัฒนาโมเดลผู้วิเคราะห์สามารถทวนซ้ำการสุ่มซ้ำดังกล่าวเพื่อสร้าง training และ validation dataset ได้จำนวนหลายชุด การดำเนินการดังกล่าวช่วยให้การประเมินประสิทธิภาพของโมเดลทำนายภายใต้เงื่อนไขของการกำหนด hyperparameters ต่าง ๆ สามารถทำได้อย่างแม่นยำ

ปัจจุบันมีเทคนิคการสุ่มซ้ำสำหรับการพัฒนาโมเดลทำนายดังกล่าวหลายตัว ได้แก่ K-fold Cross-Validation, Monte Carlo Cross-Validation, Bootstrapping และ Rolling Origin Forecasting รายละเอียดมีดังนี้

### K-fold Cross-Validation และวิธีการอื่น ๆ ที่เกี่ยวข้อง

เป็นเทคนิคการสุ่มซ้ำที่นิยมใช้กันอย่างแพร่หลาย เทคนิคนี้จะแบ่งชุดข้อมูล traning dataset โดยใช้การสุ่มแบบใส่คืนออกเป็นข้อมูลชุดย่อยจำนวน K ชุด จากนั้นจะดำเนินการวิเคราะห์และประเมินประสิทธิภาพของโมเดลจำนวน K ครั้ง โดยที่แต่ละครั้งที่จะมีการหมุนเวียนใช้ชุดข้อมูลจำนวน K-1 ชุดเพื่อวิเคราะห์ และใช้ชุดข้อมูลที่เหลืออีก 1 ชุดเพื่อประเมินประสิทธิภาพ

รูป 25 แสดงตัวอย่างของ 5-fold cross-validation จากรูปจะเห็นว่ามีการสุ่มเพื่อแบ่งชุดข้อมูลฝึกหัดออกเป็น 5 ชุดย่อย จากนั้นทวนซ้ำการดำเนินการวิเคราะห์และประเมินประสิทธิภาพของโมเดลจำนวน 5 ครั้ง โดยที่ในแต่ละครั้งจะใช้ชุดข้อมูลย่อยจำนวน 4 ชุด เป็น training dataset เพื่อสร้างโมเดลทำนาย และใช้อีก 1 ชุดที่เหลือเป็น validation dataset เพื่อตรวจสอบประสิทธิภาพของโมเดลทำนาย จากรูปจะเห็นว่าในแต่ละครั้งจะมีการหมุนเวียนชุดข้อมูลที่จะใช้เป็น training และ validation ไปเรื่อย ๆ จนครบ การดำเนินการดังกล่าวจะทำให้ผู้วิเคราะห์มีค่าสถิติที่ใช้ประเมินประสิทธิภาพของโมเดลจำนวน 5 ค่า ผู้วิเคราะห์จะใช้ผลการวิเคราะห์จากค่าสถิติดังกล่าว เช่น ค่าเฉลี่ยของ RMSE หรือ R square ในการประเมินประสิทธิภาพของโมเดลภายใต้เงื่อนไขต่าง ๆ เช่น ภายใต้การกำหนดค่า hyperparameters ต่าง ๆ เป็นต้น

![5-fold CV (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)](images/image-1150746472.png){alt="5-fold CV (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)" fig-align="center"}

เนื่องจาก K-fold CV สุ่มเพื่อแบ่งชุดข้อมูลในครั้งแรกเพียงครั้งเดียว และใช้การหมุนเวียนชุดข้อมูลย่อยที่ได้จากการสุ่มดังกล่าวเพื่อวิเคราะห์และประเมินประสิทธิภาพของโมเดล จึงทำให้หน่วยข้อมูลแต่ละหน่วยมีโอกาสที่จะปรากฎอยู่ใน validation dataset ได้เพียงครั้งเดียวดังตัวอย่างในรูป 26 ข้อจำกัดนี้ทำให้ค่าประมาณประสิทธิภาพของโมเดลทำนายที่มีแนวโน้มจะมีความแปรปรวนมากที่สุดเมื่อเปรียบเทียบกับ resampling วิธีการอื่น ๆ การที่จะลดทอนความแปรปรวนดังกล่าวให้น้อยลงสามารถทำได้ด้วยการเพิ่มจำนวน K ให้มากขึ้น โดยจากการศึกษาพบว่าการกำหนดให้ K มีค่าตั้งแต่ 10 ขึ้นไป จะช่วยลดทอนความแปรปรวนของการประเมินประสิทธิภาพได้ อย่างไรก็ตาม K-fold CV ก็ยังมีแนวโน้มที่จะมีความแปรปรวนดังกล่าวมากกว่าการใช้การสุ่มซ้ำแบบอื่นอยู่ดี

อีกข้อจำกัดหนึ่งของการทำ K-fold CV คือการกำหนดค่า K จำนวนมากจะทำให้การประมวลผลต้องดำเนินการหลายรอบและต้องใช้เวลาและทรัพยากรในการประมวลผลที่มากขึ้น ในกรณีที่ข้อมูลและโมเดลมีความซับซ้อนการประมวลผลในขั้นตอนนี้อาจใช้เวลานานหลายชั่วโมงหรือเป็นวันซึ่งอาจไม่คุ้มค่าที่จะดำเนินการในลักษณะดังกล่าว โดยในกรณีที่กำหนดให้ K = n เมื่อ n คือจำนวนหน่วยข้อมูลทั้งหมดจะเรียกการสุ่มนี้ว่า leave-one-out CV (LOOCV) ที่เป็นกรณีสุดโต่งที่สุดของการทำ K fold CV ปัจจุบัน LOOCV ไม่ค่อยถูกใช้งานแล้วเนื่องจากใช้เวลาและทรัพยากรอย่างมาก

![10-fold CV จากชุดข้อมูลที่มีหน่วยข้อมูลจำนวน 32 หน่วย (ที่มา : Boehmke, and Greenwell (2020))](images/image-998799574.png){alt="10-fold CV จากชุดข้อมูลที่มีหน่วยข้อมูลจำนวน 32 หน่วย (ที่มา : Boehmke, and Greenwell (2020))"}

เพื่อแก้ปัญหาของ K-fold CV ข้างต้นถึงมีการพัฒนาเทคนิคอีกตัวหนึ่งเรียกว่า repeated K-fold cross-validation เทคนิคดังกล่าวเป็นการทำ K-fold CV ซ้ำ ๆ หลาย ๆ รอบ วิธีการนี้ทำให้หน่วยข้อมูลแต่ละหน่วยสามารถปรากฎอยู่ใน validation dataset ได้มากกว่าหนึ่งครั้ง ซึ่งช่วยให้ความแปรปรวนในการประมาณค่าประสิทธิภาพของโมเดลทำนายลดลงได้

### Monte Carlo Cross-Validation

ในขณะที่ K-fold CV เป็นวิธีการที่ยอมให้หน่วยข้อมูลแต่ละหน่วยปรากฎใน validation dataset ได้เพียงครั้งเดียว แต่ในทางกลับกัน Monte Carlo CV (MCCV) จะสร้างชุดข้อมูลย่อย K ชุดที่ยอมให้มีหน่วยข้อมูลที่ร่วมกันได้ซึ่งทำให้หน่วยข้อมูลแต่ละหน่วยสามารถปรากฎอยู่ใน validation dataset มากกว่าหนึ่งครั้งและช่วยลดทอนความแปรปรวนในการประมาณค่าประสิทธิภาพของโมเดลลงได้ โดย MCCV มีขั้นตอนการดำเนินการดังนี้

\newpage

1.  แบ่งชุดข้อมูลที่จะนำมาพัฒนาโมเดลออกเป็นสองส่วน ได้แก่ ส่วน training dataset และ validation dataset (อาจใช้สัดส่วน 70:30, 80:20, ... ตามที่ผู้วิเคราะห์เห็นว่าเหมาะสม)
2.  นำข้อมูลใน training dataset ไปดำเนินการวิเคราะห์ และใช้ validation dataset เพื่อประเมินประสิทธิภาพของโมเดล จากนั้นเก็บค่าประสิทธิภาพดังกล่าวไว้
3.  ทวนซ้ำขั้นตอนที่ 1. ใหม่ การทวนซ้ำอาจทำเป็นจำนวน 100, 500 หรือ 1,000 รอบ ซึ่งเมื่อครบตามจำนวนรอบที่กำหนดแล้วผู้วิเคราะห์จะนำค่าประมาณประสิทธิภาพจากแต่ละรอบมาหาค่าเฉลี่ย

รูป 27 แสดงตัวอย่างของการทำ MCCV จำนวน 100 รอบ

![Monte Carlo CV จำนวน 100 รอบ (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)](images/image-103001330.png){alt="Monte Carlo CV จำนวน 100 รอบ (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)"}

รูป 28 แสดงการเปรียบเทียบผลที่ได้จากการแบ่งชุดข้อมูลระหว่าง 10-fold CV กับ 10 resample MCCV (โดยกำหนดให้สัดส่วนการสุ่มเป็น 90:10) ของชุดข้อมูลต้นฉบับที่มีจำนวน 20 หน่วย จากรูปจะเห็นว่าหน่วยข้อมูลมีโอกาสปรากฎใน validation dataset ได้เพียงครั้งเดียวเมื่อใช้ 10-fold CV แต่สามารถปรากฎได้มากกว่าหนึ่งครั้งเมื่อใช้ 10 resample MCCV

![ผลที่ได้จากการแบ่งชุดข้อมูลระหว่าง 10-fold CV กับ 10 resample MCCV (โดยกำหนดให้สัดส่วนการสุ่มเป็น 90:10) ของชุดข้อมูลต้นฉบับที่มีจำนวน 20 หน่วย (ที่มา : Max Kuhn and Kjell Johnson (2019))](images/image-1721863239.png){alt="ผลที่ได้จากการแบ่งชุดข้อมูลระหว่าง 10-fold CV กับ 10 resample MCCV (โดยกำหนดให้สัดส่วนการสุ่มเป็น 90:10) ของชุดข้อมูลต้นฉบับที่มีจำนวน 20 หน่วย (ที่มา : Max Kuhn and Kjell Johnson (2019))"}

\newpage

### Bootstraping

กำหนดให้ชุดข้อมูลต้นฉบับมีขนาด n หน่วย **bootstrap sample** คือตัวอย่างสุ่มขนาด n หน่วย (เท่ากับชุดข้อมูลต้นฉบับ) ที่ได้จากการสุ่มตัวอย่างอย่างง่ายแบบใส่คืน (simple random sampling with replacement) จากชุดข้อมูลต้นฉบับ จากลักษณะของการสุ่มตัวอย่างแบบ bootstrap ข้างต้นจะได้ว่า ความน่าจะเป็นที่หน่วยข้อมูลแต่ละหน่วยจะถูกเลือกในการสุ่มข้อมูลตัวที่ $i$ โดยที่ $i = 1,2,3,...,n$ จะมีค่าเท่ากับ $P(select_i) = \frac{1}{n}$ ซึ่งทำให้ความน่าจะเป็นที่หน่วยข้อมูลจะไม่ถูกเลือกในการสุ่มครั้งที่ $i$ เท่ากับ $P(not \ select)=1-\frac{1}{n}$ ดังนั้นความน่าจะเป็นที่หน่วยข้อมูลแต่ละหน่วยจะอยู่ในตัวอย่างแบบ bootstrap จะมีค่าเท่ากับ $(1-\frac{1}{n})^n$ เมื่อ $n \rightarrow \infty$ จะได้ว่าความน่าจะเป็นที่หน่วยข้อมูลแต่ละหน่วยจะปรากฎอยู่ในตัวอย่างแบบ bootstrap มีค่าเท่ากับ 63.2% (การพิสูจน์ใช้คุณสมบัติของ Taylor series) รูป 29 ด้านล่างแสดงลักษณะของตัวอย่างแบบ bootstrap

![](images/image-1881794685.png)

ในกระบวนการพัฒนาโมเดลทำนาย จะใช้ตัวอย่าง bootstrap เป็นชุดข้อมูลสำหรับวิเคราะห์ และใช้ชุดข้อมูลที่เหลือที่ไม่ได้ถูกสุ่มไว้ในตัวอย่าง bootstrap เป็นชุดข้อมูลสำหรับประเมินประสิทธิภาพของโมเดลทำนายระหว่างการพัฒนาโมเดล (เทียบเท่ากับ validation dataset) โดยจะเรียกตัวอย่างที่ไม่ได้ถูกสุ่มไว้ในตัวอย่าง bootstrap ในแต่ละรอบว่า **out-of-bag sample (OOB)**

จากคุณลักษณะของตัวอย่าง bootstrap ที่หน่วยข้อมูลแต่ละหน่วยมีโอกาสปรากฏอยู่ในชุดข้อมูล bootstrap ได้มากกว่า 1 ชุด จึงทำให้การประมาณค่าประสิทธิภาพของโมเดลที่ได้จากการสุ่มซ้ำแบบ bootstrap มีแนวโน้มที่จะมีความแปรปรวนต่ำกว่าการสุ่มซ้ำแบบ k-fold CV อย่างไรก็ตามในกรณีที่ข้อมูลต้นฉบับมีขนาดเล็กการสุ่มซ้ำแบบ boostrap มีแนวโน้มที่จะให้ค่าประมาณประสิทธิภาพของโมเดลที่ลำเอียง จึงควรใช้เทคนิคการสุ่มซ้ำแบบ bootstrap เมื่อข้อมูลมีขนาดใหญ่เพียงพอ (n \> 1000) (Boehmke, B., & Greenwell, B., 2020)

## 3.6 Tidymodels Framework

ปัจจุบันมีเครื่องมือที่ช่วยให้ผู้วิเคราะห์สามารถพัฒนา machine model ได้หลายตัว บทเรียนนี้จะกล่าวถึงการใช้โปรแกรม R เพื่อพัฒนา ML model ดังกล่าว ทั้งนี้ต้องทำความเข้าใจก่อนว่า การทำงานบน R แม้จะเป็นปัญหาเดียวกัน ชุดข้อมูลเดียวกัน แต่ผู้วิเคราะห์ต่างคนกันก็มีทางที่จะดำเนินการด้วยวิธีการที่แตกต่างกันได้ (ใน Python หรือโปรแกรมอื่น ๆ ก็เช่นเดียวกัน) วิธีการหนึ่งใน R ที่สามารถ modeling ได้ง่ายและมีประสิทธิภาพคือการใช้ **tidymodels framework** ดังรูป 23

![tidymodel framework](images/image-258190158.png){alt="tidymodel framework" fig-align="center" width="80%"}

-   **package-rsample** ใช้ในงาน resampling ข้อมูล เช่นการสร้าง training/validation/test dataset การสร้าง cross-validation dataset หรือการสร้าง bootstrape dataset ซึ่งได้กล่าวการใช้งานเบื้องต้นไปแล้ว

-   **package-recipes** ใช้แปลง/แก้ปัญหาที่เกิดขึ้นในข้อมูลของตัวแปรที่ใช้ในการพัฒนาโมเดล ขั้นตอนนี้เรียกว่า feature engineering

-   **package-parsnip** ใช้ fit machine learning กับข้อมูล

-   **package-Tune** และ **package-dials** มีฟังก์ชันที่อำนวยความสะดวกในการ fine tune hyperparameter ของโมเดลเพื่อเพิ่มประสิทธิภาพการทำนายของโมเดลให้สูงที่สุด

-   **package-yardstick** มีฟังก์ชันของ metric ที่ใช้ประเมินประสิทธิภาพของโมเดลทำนาย

tidymodels ถูกพัฒนาขึ้นโดยได้รับการออกแบบให้สามารถทำซ้ำกระบวนการพัฒนาโมเดลได้ง่าย โดยใช้ไวยกรณ์ของภาษาในลักษณะเดียวกัน และถูกออกแบบโดยเน้นใช้กับ supervised learning เป็นหลัก ผู้ใช้งานไม่จำเป็นต้องติดตั้งทุก package ในข้างต้นด้วยตนเอง แต่ติดตั้งเพียง package-tidymodels ก็สามารถใช้งานทุก package ภายใต้ framework ดังกล่าวได้แล้ว โดยการพิมพ์คำสั่งต่อไปนี้

```{r eval=F}
install.packages("tidymodels") # ดาวน์โหลดและติดตั้ง tidymodels
library(tidymodels) # เรียกใช้ tidymodels
```

```{r echo=F}
library(tidymodels)
```

### Fitting Linear Regression using parsnip

![](images/image-538379331.png){width="30%"}

การ fit machine learning model กับข้อมูลด้วย R ในยุคเริ่มแรกค่อนข้างมีความยากลำบากพอสมควร เพราะ R ไม่ได้มี package ที่เป็น framework รวมสำหรับการ fit ML model ดังกล่าว การที่จะ fit ML model ในงานหนึ่ง ๆ ผู้วิเคราะห์อาจจะต้องยุ่งเกี่ยวกับ package จำนวนมาก เช่น

-   package rpart สำหรับ fit decision tree

-   package glmnet สำหรับ fit regularized regression model

-   package knn สำหรับ fit K-NN model

โดย package ที่แตกต่างกันมักมีแนวคิดและไวยกรณ์การเขียนคำสั่งที่แตกต่างกัน ทำให้เป็นอุปสรรคต่อการทำงานโดยเฉพาะการทำซ้ำในอนาคต จากปัญหานี้ tidymodels จึงมีการพัฒนา package parsnip ขึ้นเพื่อเป็น interface สำหรับใช้ package ใน R ที่เกี่ยวข้องกับการ fit supervised learning ทั้งนี้ parsnip ได้ถูกออกแบบมาให้การสั่งงานทั้งหมดอยู่ภายใต้ไวยกรณ์แบบเดียวกัน ปัจจุบันการ fit ML models ใน R จึงดำเนินการได้ง่ายขึ้นอย่างมาก

ขั้นตอนการ fit ML models ด้วย parsnip มี 2 ขั้นตอน ได้แก่ การระบุโมเดล และการประมวลผล รายละเอียดมีดังนี้

#### (1) การระบุโมเดล (model specification)

การระบุโมเดลใน parsnip มีส่วนประกอบ 3 ส่วนที่จำเป็นได้แก่

-   **model type** หรืออัลกอริทึมการเรียนรู้ของเครื่องที่ผู้วิเคราะห์จะใช้ในการทำงาน

-   **engine** หรือ package ของ R ที่จะใช้สำหรับประมวลผล model type ที่เลือก

-   **mode** สำหรับกำหนดว่าปัญหาที่ทำงานด้วยอยู่นี้เป็น regression หรือ classification

รายละเอียดว่าผู้วิเคราะห์สามารถกำหนด model type, engine และ mode แบบใดได้บ้างและต้องกำหนดอย่างไร สามารถศึกษาได้จาก <https://www.tidymodels.org/find/parsnip/> รูป 24 ด้านล่างแสดงค้นหาสำหรับอัลกอริทึม linear regression จากผลการค้นหาในรูปด้านล่างจะเห็นว่าการ fit linear regression ด้วย parsnip สามารถทำได้ด้วย model type คือ `linear_reg()` เมื่อพิจารณาในคอลัมน์ engine จะเห็นว่าการ fit linear regression มี engine จำนวนมากที่สามารถใช้เพื่อประมาณค่าพารามิเตอร์ของโมเดลได้ engine ดังกล่าวจริง ๆ แล้วคือ package ต่าง ๆ ของ R ที่ใช้ประมวลผล mode type ที่เลือกไว้ได้ ผู้อ่านจะเห็นว่า model type แบบ `linear_reg` มี engine ที่สามารถใช้ประมวลผลได้จำนวนมาก ซึ่งมีความเหมือนและความแตกต่างกัน เนื้อหาส่วนนี้มีความละเอียดพอสมควรจึงจะกล่าวถึงในบท regression model ต่อไป

![parsnip manual](images/image-33185451.png){alt="parsnip manual" fig-align="center" width="70%"}

ในคู่มือข้างต้นยังมีเครื่องมือให้ค้นหาการกำหนดอาร์กิวเมนท์ของฟังก์ชัน model type ในข้างต้น จากรูป 25 จะเห็นรายละเอียดในการกำหนดอาร์กิวเมนท์ของฟังก์ชัน `linear_reg()` เมื่อกำหนด engine ในลักษณะต่าง ๆ

![argument ในฟังก์ชัน model type](images/image-1313501193.png){alt="argument ในฟังก์ชัน model type" fig-align="center" width="70%"}

\newpage

ความหมายของการกำหนดอาร์กิวเมนท์แต่ละค่าสามารถศึกษาได้จากคู่มือของฟังก์ชัน `linear_reg()` ซึ่งสามารถกด hyperlink จากคู่มือได้เลย (คู่มือ [`linear_reg()`](https://parsnip.tidymodels.org/reference/linear_reg.html))

เอกสารเพิ่มเติมเกี่ยวกับ package parsnip

-   <https://cran.r-project.org/web/packages/parsnip/parsnip.pdf>

-   <https://cran.r-project.org/web/packages/parsnip/vignettes/parsnip.html>

สมมุติว่าผู้วิเคราะห์ต้องการพัฒนาโมเดลการเรียนรู้ของเครื่องด้วยอัลกอริทึม linear regression โดยมีตัวแปรตามคือ `hwy` และตัวแปรอิสระเพียง 1 ตัวได้แก่ `cty` ตัวอย่างคำสั่งต่อไปนี้แสดงการกำหนดโมเดลการเรียนรู้ด้วย parsnip ดังกล่าว

```{r}
lm_model <- linear_reg() %>%        # model type
              set_engine("lm") %>%  # model engine
              set_mode("regression") # model mode
```

#### (2) การประมวลผล

เมื่อกำหนดโมเดลการเรียนรู้แล้วขั้นตอนถัดไปคือการนำ model specification ดังกล่าว ไปดำเนินการประมวลผล โดยส่งผ่านไปยังฟังก์ชัน `fit()` ซึ่งมีอาร์กิวเมนท์สำคัญ 2 ตัวได้แก่ model formula และ training dataset ที่จะใช้สำหรับฝึกหัดโมเดล

การเขียน model formula จะเขียนอยู่ในรูปของ `y ~ x1+x2+x3+…` โดยที่ `y` คือตัวแปรตาม ส่วน `x1, x2, x3 ,…` คือตัวแปรอิสระภายในชุดข้อมูลฝึกหัด และสัญลักษณ์ `~` หมายความว่า "regress on" ในกรณีที่ต้องการใช้ตัวแปรที่เหลือในชุดข้อมูลทั้งหมดเป็นตัวแปรทำนาย สามารถเขียน model formula สั้น ๆ ได้ดังนี้ \`y \~ .\` ตัวอย่างต่อไปนี้แสดงการส่งผ่าน model specification `lm_model` ในข้างต้นไปประมวลผล

```{r}
fit_lm <- lm_model %>%
            fit(hwy ~ cty,  # model formula
                data = train_str) # training dataset

fit_lm
```

#### (3) การเรียกดูค่าประมาณพารามิเตอร์ของ ML model

อย่างไรก็ตาม tidymodels มีฟังก์ชัน `tidy()` ซึ่งช่วยสร้างตารางสรุปผลลัพธ์จากการประมาณค่าพารามิเตอร์หรือการเรียนรู้ของโมเดลทำนายที่ใช้ให้อยู่ในรูปแบบเดียวกัน ดังนี้

```{r}
tidy(fit_lm)
```

ภายใต้ framework ของ tidymodels จะใช้ฟังก์ชันใน package parsnip เพื่อ fitting model ทำนายดังกล่าว package ดังกล่าว จุดเด่นของ parsnip คือถูกออกแบบมาเพื่อเป็น interface สำหรับ fit supervised learning model ที่มีรูปแบบการใช้คำสั่งเป็นไวยกรณ์แบบเดียว

#### (4) Prediction

ผู้วิเคราะห์สามารถนำโมเดลที่ผ่านการ train เรียบร้อยแล้วไปใช้หาค่าทำนาย โดยส่งผ่านโมเดลที่ train แล้ว (ในที่นี้คือ `fit_lm`) ไปยังฟังก์ชัน `predict()` ที่มีอาร์กิวเมนท์สำคัญคือ `new_data` ตัวอย่างด้านล่างแสดงนำ `fit_lm` ไปทำนายตัวแปร `hwy` ในชุดข้อมูลทดสอบ ผลลัพธ์ที่ได้จากการทำนายจะเป็นตารางแบบ tibble ที่แต่ละ row คือค่าทำนายของหน่วยข้อมูลใน row เดียวกันกับใน `test_str` ดังนี้

```{r}
hwy_pred <- fit_lm %>%
              predict(new_data = test_str)
hwy_pred
```

\newpage

เมื่อได้ค่าทำนายในชุดข้อมูลทดสอบมาแล้ว ขั้นตอนถัดไปคือการประเมินประสิทธิภาพของโมเดลทำนาย โดยทั่วไปผู้วิเคราะห์มักจะรวมค่าทำนายที่ได้ (ในที่นี้คือ `hwy_pred`) ไปไว้อยู่ภายในชุดข้อมูลทดสอบ การดำเนินการนี้สามารถทำได้หลายวิธีการขึ้นอยู่กับว่าถนัดจะดำเนินการแบบนี้ ในตัวอย่างนี้จะใช้ฟังก์ชัน `bind_cols()`

```{r}
test_results <- test_str %>%
                  dplyr::select(hwy, cty) %>%
                  bind_cols(hwy_pred)
test_results
```

#### (5) Evaluating models using yardstick

การคำนวณค่าประสิทธิภาพของโมเดลทำนายแบบ regression ภายใต้ tidymodels framework สามารถทำได้ง่าย ๆ โดยใช้ฟังก์ชันจาก package yardstick ได้แก่ `rmse()` และ `rsq()` ตัวอย่างต่อไปนี้แสดงการเขียนคำสั่งเพื่อคำนวณ metric ทั้งสอง

```{r}
test_results %>%
  rmse(truth = hwy, estimate = .pred)
```

\newpage

```{r}
test_results %>%
  rsq(truth = hwy, estimate = .pred)
```

ผลลัพธ์ข้างต้นเมื่อพิจารณาค่า RMSE พบว่าโมเดลทำนายที่พัฒนาขึ้นมีความคลาดเคลื่อนในการทำนายค่าของตัวแปร `hwy` โดยเฉลี่ย 1.64 หน่วย และเมื่อพิจารณาจากค่า R square พบว่ามีค่าเท่ากับ .913 แสดงว่าค่าจริงของ `hwy` กับค่าทำนายมีความผันแปรร่วมกันคิดเป็นร้อยละ 91.3 ซึ่งอยู่ในระดับที่สูงมาก ผลการวิเคราะห์นี้จึงบ่งชี้ว่าโมเดลทำนายที่พัฒนาขึ้นสามารถใช้ทำนายคะแนน `hwy` ได้ดี

นอกจาก metric ที่เป็นค่าสถิติแล้วยังมี metric ที่เป็น visualization ด้วย เช่นในกรณีของ regression model สามารถใช้ R squared plots เพื่อประเมินความสอดคล้องกันระหว่างค่าจริงของตัวแปรตามกับค่าทำนายได้ การสร้าง R squared plot ใน R สามารถทำได้หลายวิธี ทั้งการใช้ฟังก์ชัน `plot()` ของ package graphic เหมือนกับตัวอย่างในบทที่ 2 นอกจากนี้ยังสามารถใช้ package ggplot2 เพื่อสร้างแผนภาพดังกล่าวได้เหมือนกัน

```{r fig.height=3.5, fig.width=3.5, eval=T}
# create R squared plot using graphic package
plot(x = test_results$hwy, 
     y = test_results$.pred,
     pch = 16,
     xlab = "predicted value",
     ylab = "actual value")
abline(a=1,b=1, lty=3, col="steelblue")
```

ในกรณีที่ต้องการใช้ ggplot2 สามารถเขียนคำสั่งได้ดังนี้

```{r fig.height=3.5, fig.width=3.5, fig.align="center", fig.cap="R squared plot via ggplot2"}
# create R squared plot using ggplot2 package
library(ggplot2)
test_results %>% ggplot()+  # create 2D plane
  geom_point(aes(x = hwy, # create scatter plot
                 y = .pred))+
  geom_abline(intercept=1, slope=1, linetype=3, col="steelblue")+
  coord_obs_pred()+
  theme(text=element_text(size = 10))
```

ผลการวิเคราะห์จาก R square plot ข้างต้นแสดงให้เห็นว่าโมเดลสามารถทำนายค่าของตัวแปร `hwy` ได้ค่อนข้างดี อย่างไรก็ตามหากพิจารณาเปรียบเทียบความสัมพันธ์ระหว่างค่าจริงกับค่าทำนายจะพบว่าโมเดลนี้มีแนวโน้มให้ค่าทำนายที่ต่ำกว่าความเป็นจริง (underestimate)

**คำถาม เราได้เรียน** linear regression มาพอสมควรแล้ว โดยหากจำได้จะทราบว่า linear regression เป็นโมเดลทางสถิติที่มีข้อตกลงเบื้องต้นที่ค่อนข้างเข้มงวด ได้แก่ independence, homoscedasticity, normality, no multicollinearity, no outlier, ... คำถามคือในการพัฒนา ML model ดังกล่าวจำเป็นมั้ยที่จะต้องตรวจสอบข้อตกลงเบื้องต้นดังกล่าว เพราะอะไร?

\newpage

### Fitting Classification models (logistic regression) using parsnip

หัวข้อนี้จะใช้ tidymodels framework เพื่อ fit logistic regression model สำหรับทำนายชุดข้อมูล ชุดข้อมูลที่ใช้ชื่อ `classification.csv` [สามารถดาวน์โหลดได้ที่นี่](https://github.com/ssiwacho/2758688_ML/blob/79a225047656cb9a22a4e1b78835b8bdd91a1d26/week%201/classification.csv) ชุดข้อมูลนี้มีตัวแปรตามที่สนใจคือ `Class` ซึ่งเป็นสถานะการ dropout ออกจากระบบ LMS ของนักเรียน ส่วนที่เหลือเป็นตัวแปรที่คาดว่าจะนำมาเป็นตัวแปรอิสระ

#### (1) การนำเข้าและสำรวจข้อมูล

ในกรณีนี้นำเข้าข้อมูล `classfication.csv` ด้วยฟังก์ชัน `read.csv()` จากนั้นสำรวจข้อมูลเบื้องต้นด้วยฟังก์ชัน `glimpse()` ได้ผลเป็นดังนี้

```{r}
# import
dat<-read.csv("https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/classification.csv")
# explore dataset
glimpse(dat)
```

จากผลการสำรวจข้างต้น จงตอบคำถามต่อไปนี้ ชุดข้อมูล `classification.csv` ...

-   มีหน่วยข้อมูลจำนวนกี่หน่วย?

-   มีตัวแปรจำนวนกี่ตัวแปร

-   การแจกแจงของตัวแปรตามเป็นอย่างไร?

-   type ของตัวแปรที่จัดเก็บใน `dat` ข้างต้นมีแบบไหนบ้าง เหมาะสมแล้วหรือไม่ที่จะนำไปวิเคราะห์ logistic regression ต่อไป

#### (2) การแบ่งชุดข้อมูล

ในทำนองเดียวกับการพัฒนา regression models ผู้วิเคราะห์ต้องแบ่งชุดข้อมูล `dat` ออกเป็นสองส่วนได้แก่ ส่วน training dataset เพื่อพัฒนาโมเดล และ test dataset เพื่อตรวจสอบประสิทธิภาพของโมเดล

```{r}
set.seed(123)
dat$Class <- factor(dat$Class, levels=c("drop", "stay"))
class_split <- initial_split(data= dat,
                             prop=0.8,
                             strata = Class)
train <- class_split %>% training()
test <-  class_split %>% testing()
```

#### (3) การประมวลผลและสำรวจโมเดล

เมื่อแบ่งชุดข้อมูลแล้วขั้นตอนต่อมาคือการพัฒนาโมเดลทำนาย ในที่นี้จะใช้ logistic regression ก่อน

```{r}
logistic_reg <- logistic_reg(engine ="glm",
                             mode = "classification")

fit_logistic <- logistic_reg %>% 
                  fit(Class ~ . , data=train[,-1])
```

\newpage

เราสามารถวิเคราะห์สัมประสิทธิถดถอยของตัวแปรอิสระในโมเดลได้ โดยใช้ data visualization มาช่วย เช่น

```{r fig.width=3, fit.height=4, fig.cap="boxplot ของสัมประสิทธิ์การถดถอยใน logistic regression"}
fit_logistic$fit %>% 
          coef() %>% 
            data.frame(coef= .)%>%
              ggplot(aes(x="" ,y=coef))+
                geom_boxplot(alpha = 0.7, fill = "grey")+
                geom_jitter(width=0.1)+
              theme_minimal()
```

เราจะเห็นว่าโมเดลทำนายที่พัฒนาขึ้นข้างต้น มีตัวแปรอิสระที่น่าจะใช้ทำนายตัวแปรตาม `Class` ได้ เยอะมาก ปัจจัยนี้อาจเป็นสาเหตุหนึ่งที่ทำให้การประมาณค่าพารามิเตอร์ของโมเดลเกิดปัญหาไม่ลู่เข้า การแก้ปัญหาดังกล่าวอาจทำการคัดเลือกตัวแปรอิสระที่ไม่จำเป็นออกไปจากโมเดล ซึ่งจะเห็นว่าเป็นงานที่ค่อนข้างเหนื่อยเพราะมีตัวแปรอิสระเยอะพอสมควรในชุดข้อมูลนี้ อีกวิธีการหนึ่งคือใช้เทคนิค regularization ซึ่งสามารถทำได้โดยเปลี่ยน `engine = "glmnet"` เนื้อหาส่วนนี้จะกล่าวถึงอีกครั้งในบทต่อไป

\newpage

#### (4) การคำนวณค่าทำนายจากโมเดล

ในกรณีนี้สมมุติว่าโมเดลทำนาย logistic regression ไม่ได้มีปัญหาอะไรและจะนำไปสู่ขั้นตอนการตรวจสอบคุณภาพในชุดข้อมูลทดสอบ ในทำนองเดียวกับ regression models การตรวจสอบประสิทธิภาพในการทำนายของโมเดล ผู้วิเคราะห์ต้องมี (1) ค่าสังเกตจริงของตัวแปรตามในชุดข้อมูลทดสอบ และ (2) ค่าทำนายที่ได้จากโมเดลทำนายในชุดข้อมูลทดสอบ

การคำนวณค่าทำนายจากโมเดลสามารถทำได้ด้วยฟังก์ชัน `predict()` เช่นเดียวกับ regression models อย่างไรก็ตามใน classfication models สามารถคำนวณค่าทำนายได้ 2 ประเภทหลัก ได้แก่ ค่าความน่าจะเป็น (probability) ของการเกิดเหตุการณ์/ผลลัพธ์ที่สนใจในตัวแปรตามของหน่วยข้อมูล และค่าทำนายประเภท/ผลลัพธ์ในตัวแปรตามของหน่วยข้อมูล โดยในกรณีที่ต้องการค่าทำนายเป็นค่าความน่าจะเป็นให้กำหนดอาร์กิวเมนท์ `type = "prob"` ส่วนในกรณีที่ต้องการค่าทำนายเป็นประเภทในตัวแปรตามให้กำหนดอาร์กิวเมนท์ `type = "class"`

##### กรณีกำหนด `type = "prob"`

การกำหนดลักษณะนี้จะได้ค่าความน่าจะเป็นซึ่งสามารถนำไปคำนวณเป็นค่าทำนายประเภทของหน่วยข้อมูลได้โดยการกำหนดคะแนนจุดตัดหรือค่า threshold ซึ่งโดยปกติมักกำหนดให้ค่า threshold = 0.5 ตัวอย่างคำสั่งต่อไปนี้แสดงการคำนวณค่าความน่าจะเป็นดังกล่าว รวมทั้งการแปลงค่าความน่าจะเป็นที่ได้โดยการกำหนด threshold เป็น 0.2, 0.5 และ 0.8 ตามลำดับ ทั้งนี้หากโมเดลที่มีประสิทธิภาพไม่คงที่เมื่อเปลี่ยนค่า threshold จะบ่งชี้ว่าโมเดลดังกล่าวมีประสิทธิภาพการทำนายที่ไม่ดีนัก กล่าวคือ เป็นโมเดลที่ไม่ชัดเจนในการทำนาย ในทางกลับกันโมเดลที่มีค่าทำนายประเภทของหน่วยข้อมูลที่คงเส้นคงวา เมื่อกำหนดค่า threshold แตกต่างกัน บ่งชี้ว่าโมเดลดังกล่าวเป็นโมเดลที่มีประสิทธิภาพในการทำนายสูง

```{r}
# predicted value
pred_prob <- predict(fit_logistic, 
                     new_data = test[,-1],
                     type="prob")
pred_class_thres0.2 <- factor(ifelse(pred_prob[,1] >=0.2,"drop", "stay"))
pred_class_thres0.5 <- factor(ifelse(pred_prob[,1] >=0.5,"drop", "stay"))
pred_class_thres0.8 <- factor(ifelse(pred_prob[,1] >=0.8,"drop", "stay"))

table(pred_class_thres0.2)
table(pred_class_thres0.5)
table(pred_class_thres0.8)
```

ผลการวิเคราะห์ข้างต้นแสดงให้เห็นว่าค่าทำนายประเภทของหน่วยข้อมูลไม่มีการเปลี่ยนแปลงเมื่อกำหนด threshold เท่ากับ 0.2, 0.5 และ 0.8 ซึ่งบ่งชี้ว่าโมเดลทำนายมีแนวโน้มที่จะให้ค่าทำนายที่คงเส้นคงวา อย่างไรก็ตามการวิเคราะห์เพียง 3 จุดของ threshold เป็นการวิเคราะห์ที่ค่อนข้างหยาบ ส่วนท้ายของหัวข้อนี้จะกล่าวถึงการใช้ ROC curve เพื่อวิเคราะห์ประสิทธิภาพของโมเดลบนแต่ละค่าของ threshold ดังกล่าว

##### กรณีกำหนด `type = "class"`

เมื่อกำหนดให้ `type = "class"` ฟังก์ชัน `predict()` จะทำนายประเภทของหน่วยข้อมูลโดยใช้ค่า threshold = 0.5 ดังนั้นหากผู้วิเคราะห์ต้องการใช้ threshold ค่านี้อยู่แล้ว การกำหนดอาร์กิวเมนท์ลักษณะนี้จะช่วยลดขั้นตอนการทำงานลงได้

```{r}
pred_class2 <- predict(fit_logistic, 
                     new_data = test[,-1],
                     type="class")
head(pred_class2)
```

จะเห็นว่าผลการทำนายประเภทที่ได้จากฟังก์ชัน `predict()` อยู่ในรูปชุดข้อมูลแบบ tibble โดยคอลัมน์ที่เก็บค่าทำนายจะใช้ชื่อ `.pred_class` และมีสถานะเป็นตัวแปรแบบ factor

```{r}
table(pred_class2)
```

#### (5) การประเมินประสิทธิภาพการทำนายของโมเดล

package yardstick มีฟังก์ชัน `conf_mat()` ที่ทำหน้าที่เหมือนกับฟังก์ชัน `confusionMatrix()` โดยอาร์กิวเมนท์สำคัญของฟังก์ชันนี้ได้แก่ `data` ที่เป็น data.frame หรือ tibble ที่ต้องมีคอลัมน์ของค่าจริงของตัวแปรตาม และค่าทำนายของตัวแปรตามให้เรียบร้อย `truth` คืออาร์กิวเมนท์สำหรับระบุว่าคอลัมน์ไหนคือค่าจริงของตัวแปรตาม และ `estimate` คือคอลัมน์ที่ใช้ระบุว่าคอลัมน์ไหนคือค่าทำนายของตัวแปรตาม ทั้งนี้ตัวแปรตามและค่าทำนายจะต้องเก็บอยู่ในรูปแบบ factor

```{r}
# combine .pred_class column to test dataset
test_results <- test %>% dplyr::select(Class) %>%
          bind_cols(pred_class2, pred_prob)
conf_mat(data = test_results, truth = Class, estimate = .pred_class)
# accuracy
accuracy(data = test_results, truth = Class, estimate = .pred_class)
# sensitivity
sens(data = test_results, truth = Class, estimate = .pred_class)
# specificity
spec(data = test_results, truth = Class, estimate = .pred_class)
# define metric set function
custom_metric<-metric_set(accuracy, sens, spec)
custom_metric(data = test_results, truth = Class, estimate = .pred_class)
```

นอกจากนี้ยังสามารถใช้ฟังก์ชัน `summary()` กับผลลัพธ์ที่ได้จาก `conf_mat()` เพื่อเรียกดูค่าสถิติของ confusion matrix คล้ายกับฟังก์ชัน `confusionMatrix()` ของ package caret ที่ได้กล่าวถึงในหัวข้อ 2.4

```{r}
conf_mat(data = test_results, 
         truth = Class, 
         estimate = .pred_class) %>%
  summary()
```

\newpage

รายละเอียดของ metric ต่าง ๆ สามารถศึกษาเพิ่มเติมได้จากเอกสารที่เกี่ยวกับ package yardstick

-   https://cran.r-project.org/web/packages/yardstick/yardstick.pdf

-   https://yardstick.tidymodels.org/

-   https://cran.r-project.org/web/packages/yardstick/vignettes/metric-types.html

#### (6) การนำเสนอประสิทธิภาพการทำนายของโมเดลด้วยทัศนภาพข้อมูล

การวิเคราะห์ประสิทธิภาพการทำนายของ classification models สามารถทำได้ด้วยทัศนภาพข้อมูลหลายตัว ซึ่งบางตัวช่วยให้สารสนเทศเชิงลึกประกอบการปรับแต่งโมเดลทำนายแก่ผู้วิเคราะห์ได้เป็นอย่างดี เนื้อหาประกอบด้วย การใช้ heatmap แผนภาพ mosaic และ ROC Curve รายละเอียดมีดังนี้

##### แผนที่ความร้อน (heatmap) ของ confusion matrix

ทัศนภาพนี้เหมาะสำหรับ classification model ที่มีการจำแนกประเภทจำนวนหลาย ๆ ประเภท การสร้างแผนที่ความร้อนดังกล่าวสามารถสร้างได้โดยการส่งค่า confusion matrix ที่สร้างจากฟังก์ชัน `conf_mat()` ไปยังฟังก์ชัน `autoplot()` และในฟังก์ชัน `autoplot()` ให้กำหนดอาร์กิวเมนท์ `type = "heatmap"` ดังตัวอย่างต่อไปนี้

```{r fig.width=3, fig.height=3, fig.cap = "plotting the confusion matrix using Heatmap"}
conf_mat(data = test_results, 
         truth = Class, 
         estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

จากรูป 27 จะเห็นว่าแผนที่ความร้อนที่สร้างขึ้นจะใช้ความเข้มของสีแสดงความถี่ในแต่ละประเภทของการทำนาย โดยในรูปตัวอย่างพบว่าโมเดลทำนายมีแนวโน้มที่จะทำนายได้อย่างถูกต้องเป็นส่วนใหญ่

\newpage

##### แผนภาพโมเสก (mosaic plot)

ทัศนภาพนี้จะแสดงผลลัพธ์ในมิติของ sensitivity หรือ specificity การสร้างแผนภาพโมเสกจาก confusion matrix สามารถใช้ฟังก์ชัน `autoplot()` เช่นเดียวกับการสร้างแผนที่ความร้อน แต่ให้กำหนดอาร์กิวเมนท์ `type = mosaic` ดังตัวอย่างต่อไปนี้

```{r fig.width=3, fig.height=3, fig.cap = "plotting the confusion matrix using Masaic plot"}
conf_mat(data = test_results, 
         truth = Class, 
         estimate = .pred_class) %>%
  autoplot(type = "mosaic")
```

จากรูป 28 เมื่อพิจารณาในคอลัมน์แรกจะพบว่าเป็นคอลัมน์ที่แสดง sensitivity ของโมเดล (เนื่องจากโมเดลทำนายมุ่งที่จะทำนายกลุ่ม dropout ดังนั้นกลุ่มนี้จึงเป็นพวก positive ของโมเดล) ส่วนคอลัมน์ที่สองแสดง specificity ของโมเดล ซึ่งมีค่าอยู่ในระดับสูงทั้งสอง metrics

##### ROC curve

ดังที่ได้กล่าวไว้ก่อนแล้วข้างต้นว่าคุณสมบัติที่ดีของโมเดลทำนายอย่างหนึ่งคือการที่สามารถให้ค่าทำนายประเภทของหน่วยข้อมูลที่คงเส้นคงวาบนแต่ละระดับของค่า threshold การตรวจสอบประสิทธิภาพด้านนี้อย่างละเอียดควรดำเนินการวิเคราะห์ประสิทธิภาพในการทำนายของโมเดลเมื่อกำหนดค่า threshold ตั้งแต่ 0.00 ถึง 1.00 การดำเนินการดังกล่าวด้วย R ในสมัยก่อนผู้วิเคราะห์จำเป็นจะต้องเขียนฟังก์ชันเพื่อทวนซ้ำการทำนายในแต่ละค่า threshold แต่ในปัจจุบันหากใช้ package yardstick ผู้วิเคราะห์สามารถใช้ฟังก์ชัน `roc_curve()` เพื่อช่วยทำการวิเคราะห์นี้ได้ อาร์กิวเมนท์ของฟังก์ชันนี้ประกอบด้วย ค่าจริงของตัวแปรตามในชุดข้อมูลทดสอบ และค่าประมาณความน่าจะเป็นของการเกิดผลลัพธ์ที่สนใจ (positive type) ในตัวแปรตาม

\newpage

```{r}
test_results %>% 
  roc_curve(truth = Class, .pred_drop)
```

ข้อดีของฟังก์ชัน `roc_curve()` คือฟังก์ชันจะกำหนด grid หรือช่วงของค่า threshold ที่เหมาะสมกับข้อมูลซึ่งช่วย output ที่ไม่จำเป็นลงได้ จากตารางข้างต้นจะเห็นว่าถ้าไม่นับกรณีที่กำหนด threshold อย่างสุดโต่งคือ 0 หรือ 1 ประสิทธิภาพของโมเดลทำนายที่พัฒนาขึ้นนี้มีค่า sensitivity และ specificity มากกว่า 0.75 เกือบทุกกรณี

อย่างไรก็ตามในกรณีทั่วไปผลลัพธ์จากตารางข้างต้นอาจมีจำนวนมากจนเป็นการยากที่จะดำเนินการวิเคราะห์ ผู้วิเคราะห์จึงมักนิยมแปลงผลการวิเคราะห์ในตารางดังกล่าวให้เป็นแผนภาพ ROC curve ที่เป็นการพล็อตคู่อันดับของ FPR = 1 - specificity กับ sensitivity ที่คำนวณได้จากแต่ละค่าของ threshold โดยให้ค่า sensitivity อยู่บนแกน Y และค่า FPR อยู่บนแกน X รูปต่อไปนี้แสดงตัวอย่างของ ROC curve

![ตัวอย่าง ROC Curve](images/image-1255912826.png){alt="ตัวอย่าง ROC Curve"}

\newpage

โมเดลทำนายที่ดีควรมี ROC curve ที่ลู่เข้าไปใกล้คู่อันดับ (0.00,1.00) เนื่องจากคู่อันดับดังกล่าวเป็นจุดที่โมเดลมี FPR = 0.00 และมี sensitivity = 1.00 หรือเป็นจุดที่ดีที่สุดที่เป็นไปได้ (optimal point) ส่วนโมเดลที่มีประสิทธิภาพต่ำจะเป็นโมเดลที่มี Roc curve ลู่เข้าหาหรือมีลักษณะใกล้เคียงกับเส้นอ้างอิง $y=x$ ซึ่งแสดงว่าโมเดลทำนายมีประสิทธิภาพในการทำนายที่ใกล้เคียงกับการเดาสุ่มแบบโยนเหรียญหัวก้อย

จากรูป 30 จะเห็นว่าโมเดลตัวอย่างทางด้านซ้ายมีแนวโน้มที่จะมีประสิทธิภาพในการทำนายสูงกว่าโมเดลตัวอย่างทางด้านขวา ทั้งนี้เป็นเพราะ ROC curve ของโมเดลทางซ้ายมีแนวโน้มลู่เข้าไปหาคู่อันดับ (0.00,1.00) มากกว่าโมเดลทางขวามือ สำหรับการสร้าง ROC curve ด้วย R สามารถทำได้โดยส่งผ่านผลลัพธ์ที่ได้จากฟังก์ชัน `roc_curve()` ในข้างต้นไปในฟังก์ชัน `autoplot()` ดังตัวอย่างต่อไปนี้

```{r fig.width=4, fig.height=3, fig.cap="ROC Curve"}
test_results %>%
  roc_curve(truth = Class, .pred_drop) %>%
  autoplot()
```

ผลการวิเคราะห์ ROC curve จากรูป 31 สามารถสรุปได้อย่างไร?

##### Area Under Curve (AUC)

พื้นที่ใต้โค้ง ROC (area under curve: AUC) ถูกใช้เป็น metric อีกตัวหนึ่งสำหรับประเมินประสิทธิภาพในการทำนายของโมเดล ที่คำนวณจากพื้นที่ใต้โค้งของกราฟ ROC โดยโมเดลทำนายที่มีค่า AUC สูงเข้าใกล้ 1.00 จะเป็นโมเดลที่มีแนวโน้มจะมีประสิทธิภาพในการทำนายสูง ส่วนโมเดลที่มีค่า AUC เข้าใกล้ 0.5 มีแนวโน้มที่จะมีประสิทธิภาพในการทำนายต่ำใกล้เคียงกับการเดาสุ่ม จากความหมายดังกล่าวจะเห็นว่าค่า AUC สามารถใช้เป็น metric แทนการอ่านผลจากกราฟ ROC โดยตรงได้

![Area Under Curve (AUC)](images/image-1194220562.png){alt="Area Under Curve (AUC)"}

\newpage

การคำนวณค่า AUC ด้วย R สามารถทำได้โดยใช้ฟังก์ชัน `roc_auc()` ที่มีอาร์กิวเมนท์เหมือนกับฟังก์ชัน `roc_curve()` จากตัวอย่าง logistic regression จะได้ว่าผลการวิเคราะห์ AUC เป็นดังนี้

```{r}
test_results %>% roc_auc(truth = Class, .pred_drop)
```

ตารางต่อไปนี้แสดงเกณฑ์การพิจารณาค่า AUC ข้างต้น โดยจำแนกเกรดของโมเดลออกเป็น 5 ระดับตามค่าของ AUC ได้แก่ ดีมาก (A) ดี (B) ไปจนถึงยอมรับไม่ได้ (F)

| AUC           | แปลผล         |
|---------------|---------------|
| \[0.9 , 1.0\] | ดีมาก (A)      |
| \[0.8 , 0.9)  | ดี (B)         |
| \[0.7 , 0.8)  | พอใช้ (C)      |
| \[0.6 , 0.7)  | แย่ (D)        |
| \[0.5 , 0.6)  | ยอมรับไม่ได้ (F) |

: AUC criterion

## 3.6 Scikit-Learn library

scikit-learn เป็น library สำหรับวิเคราะห์ machine learning model ในโปรแกรมภาษา Python ซึ่งมีจุดเด่นคือเป็น library สำหรับพัฒนา machine learning model ที่มีประสิทธิภาพและสามารถใช้งานได้ง่าย นอกจากนี้ยังสามารถทำงานร่วมกับ library Numpy, SciPy, Pandas และ matplotlib

coming soon ...

## สรุป

บทเรียนนี้ผู้อ่านได้เห็นภาพของกระบวนการพัฒนา regression models ซึ่งเป็น supervised learning ประเภทหนึ่งโดยเป็นการดำเนินงานภายใต้ tidymodels framework เกือบทั้งหมด โดยยังขาดในส่วนของการจัดการข้อมูลหรือที่เรียกว่า feature engineering และส่วนการปรับแต่งค่า hyperparameters ของโมเดลทำนาย ซึ่งจะกล่าวรายละเอียดทั้งหมดในบทเรียนถัดไป

# บทที่ 4 การเตรียมข้อมูล (data preprocessing)

> Garbage in, garbage out ...

จากบทที่ 3 ผู้อ่านจะเห็นว่าข้อมูลเป็นปัจจัยนำเข้าที่สำคัญมากในการพัฒนาโมเดลการเรียนรู้ของเครื่อง การนำข้อมูลที่เป็นขยะเข้าสู่โมเดลผลลัพธ์ที่ได้ย่อมเป็นขยะ ข้อมูลที่เป็นขยะถึงแม้จะได้รับการจัดการที่ดีมากแค่ไหนก็ตาม เมื่อนำเข้าสู่โมเดล ผลลัพธ์ที่ได้ก็ยังเป็นขยะเหมือนเดิม นอกจากนี้ถึงแม้ผู้วิเคราะห์จะมีข้อมูลที่ดีแต่หากมีการจัดการที่ไม่ดี เมื่อนำเข้าสู่โมเดลก็อาจจะได้ผลลัพธ์ที่ไม่ดีเท่าที่ควรหรืออาจจะเป็นขยะเหมือนเดิมก็ได้ ดังนั้นการมีข้อมูลที่ดีและมีการจัดการอย่างเหมาะสมจึงเป็นสิ่งที่สำคัญที่ผู้พัฒนาโมเดลการเรียนรู้ของเครื่องควรให้ความสำคัญ

## 4.1 ภาพรวมและความสำคัญของ Data Preprocessing

**การเตรียมข้อมูล (Data preprocessing)** เป็นคำศัพท์เชิงเทคนิคที่ใช้เรียกกระบวนการต่าง ๆ ที่ผู้วิเคราะห์ดำเนินการกับข้อมูลก่อนที่จะนำข้อมูลไปวิเคราะห์ในอัลกอริทึมการเรียนรู้ โดยมีวัตถุประสงค์เพื่อให้การเรียนรู้ของอัลกอริทึมต่าง ๆ สามารถทำได้สำเร็จและมีประสิทธิภาพ การเตรียมข้อมูลมีหลายวิธีการ โดยแต่ละวิธีการเหมาะกับสถานการณ์และเงื่อนไขที่แตกต่างกัน อย่างไรก็ตามเราอาจจำแนกการเตรียมข้อมูลออกได้เป็น 2 ประเภท ได้แก่ การเตรียมข้อมูลงตามข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้ และการเตรียมเพื่อใช้ประโยชน์จากข้อมูลให้มีประสิทธิภาพสูงที่สุด

**(1) การเตรียมข้อมูลตามข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้** เป็นการจัดระเบียบหรือจัดกระทำข้อมูล (tidying and manipulating data) เพื่อให้ข้อมูลดิบมีความพร้อมหรืออยู่ในรูปแบบที่สอดคล้องกับความต้องการของอัลกอริทึมการเรียนรู้ที่เลือกใช้ การละเลยการจัดการข้อมูลดังกล่าวอาจส่งผลให้การเรียนรู้ของอัลกอริทึมมีความผิดพลาด หรือไม่สามารถเรียนรู้ชุดข้อมูลดังกล่าวได้ ตัวอย่างต่อไปนี้แสดงการเตรียมข้อมูลเพื่อให้สอดคล้องกับข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้

-   การจัดรูปแบบตารางข้อมูล (reshaping data) เพื่อให้ได้ตารางข้อมูลที่อยู่ในรูปแบ tidydata

-   การเปลี่ยนสถานะของตัวแปรตัวอักษร (character variable) ใน R ให้เป็นตัวแปรแบบ factor

-   การทดแทนค่าสูญหาย (missing value imputation) เพื่อทดแทนค่าสูญหายก่อนจะนำไปวิเคราะห์

-   ในโมเดล multiple linear regression มีข้อตกลงเบื้องต้นที่สำคัญหลายข้อ เช่น ต้องไม่มีปัญหา heteroscedasticity และ multicollinearity ซึ่งหากเกิดปัญหาดังกล่าวขึ้นอย่างน้อยหนึ่งอย่าง ผู้วิเคราะห์จำเป็นต้องดำเนินการแก้ไขปัญหาดังกล่าวให้เรียบร้อยก่อนที่จะทำการวิเคราะห์ข้อมูล เช่น (1) อาจใช้การแปลงค่าตัวแปรด้วย logarithm หรือใช้การแปลงแบบ Box-Cox transformation เพื่อแก้ปัญหา heteroscedasticity และ (2) อาจใช้การตัดตัวแปรอิสระที่มีความสัมพันธ์กันเองสูง ๆ ออกจากโมเดล หรือใช้การสกัดองค์ประกอบหลัก (PCA) เพื่อแก้ปัญหา multicollinearity เป็นต้น

-   สำหรับอัลกอริทึม K-NN และ regularized regression ผู้วิเคราะห์จำเป็นต้องแปลงคะแนนของตัวแปรอิสระทั้งหมดให้เป็นหน่วยคะแนนมาตรฐานก่อน เพื่อให้อัลกอริทึมดังกล่าวสามารถเรียนรู้รูปแบบความสัมพันธ์ระหว่างตัวแปรในชุดข้อมูลได้โดยไม่มีปัจจัยเกี่ยวกับหน่วยข้อมูลมาเป็นตัวแทรกซ้อนและก่อให้เกิดความผิดพลาดในการเรียนรู้

\newpage

ผู้อ่านจะเห็นว่าการทำ data preprocessing ประเภทนี้จำเป็นต้องทำตามข้อตกลงเบื้องต้นของโมเดล ทั้งนี้เพื่อให้โมเดลหรืออัลกอริทึมการเรียนรู้สามารถทำงานได้อย่างถูกต้อง หากผู้วิเคราะห์ละเลยการดำเนินการในส่วนนี้อาจส่งผลให้ผลการเรียนรู้ของอัลกอริทึมมีความผิดพลาด และประสบความล้มเหลวในการพัฒนาโมเดลทำนายที่ต้องการ โดยทั่วไปการจัดกระทำข้อมูลอาจจำแนกเป็น การแปลงค่าของตัวแปรจัดประเภทให้เป็นตัวแปรดัมมี (dummy) การตัดตัวแปรที่มีความแปรปรวนน้อยหรือความแปรปรวนเท่ากับ 0 ออกจากชุดข้อมูล (zv) การทดแทนค่าสูญหาย (impute) การแก้ปัญหา multicollinearity (decorrelate) การแปลงคะแนนตัวแปรให้อยู่ในสเกลมาตรฐาน (normalized) และการแปลงค่าของตัวแปรให้มีการแจกแจงที่สมมาตรหรือใกล้เคียง (transform)

ตารางต่อไปนี้แสดงตัวอย่าง checklist ของการจัดกระทำข้อมูลที่ควรดำเนินการในแต่ละอัลกอริทึมการเรียนรู้

| อัลกอริทึม              | dummy | zv    | impute | decorrelate | normalized | transform |
|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
| linear regression    | yes   | yes   | yes    | yes         | no         | maybe     |
| binary logistic      | yes   | yes   | yes    | yes         | no         | maybe     |
| multinomial logistic | yes   | yes   | yes    | yes         | no         | maybe     |
| K-NN                 | yes   | yes   | yes    | maybe       | yes        | yes       |
| naive bayes          | no    | yes   | yes    | maybe       | no         | no        |
| decision tree (CART) | no    | no    | no     | maybe       | no         | no        |
| decision tree (C5)   | no    | no    | no     | no          | no         | no        |
| pls regression       | yes   | yes   | yes    | no          | yes        | yes       |
| MARS                 | yes   | no    | yes    | maybe       | no         | maybe     |
| SVM                  | yes   | yes   | yes    | yes         | yes        | yes       |
| random forest        | no    | maybe | yes    | maybe       | no         | no        |
| bagging tree         | no    | no    | no     | maybe       | no         | no        |
| bagging MARS         | yes   | no    | yes    | maybe       | no         | maybe     |
| boosting tree        | no    | maybe | yes    | maybe       | no         | no        |

: Checklist การจัดกระทำข้อมูลของอัลกอริทึมการเรียนรู้ต่าง ๆ

**(2) การเตรียมเพื่อใช้ประโยชน์จากข้อมูลให้มีประสิทธิภาพสูงที่สุด** อาจกล่าวว่าเป็นขั้นตอนที่ทำภายหลังจากการเตรียมข้อมูลให้เป็นไปตามข้อตกลงเบื้องต้นของอัลกอริทึมแล้ว การเตรียมข้อมูลส่วนนี้ไม่ได้เป็นเงื่อนไขจำเป็นของการพัฒนาโมเดลทำนาย แต่อาจเป็นเงื่อนไขที่เพียงพอจะทำให้การพัฒนาโมเดลทำนายประสบความสำเร็จ กล่าวคือได้โมเดลทำนายที่มีประสิทธิภาพในการทำนายสูง การดำเนินการส่วนโดยปกติเป็นการจัดกระทำข้อมูลของตัวแปรอิสระ (independent variables) หรือที่นักวิทยาการข้อมูลมักใช้คำว่า features ให้มีความเหมาะสมกับบบริบทของปัญหาซึ่งจะช่วยให้การเรียนรู้ของโมเดลทำได้อย่างมีประสิทธิภาพมากขึ้น อาจเรียกการเตรียมข้อมูลประเภทนี้ว่า feature engineering

การทำ feature engineering มีลักษณะเด่นที่สำคัญคือเป็นการดำเนินการที่ไม่ได้ขึ้นกับอัลกอริทึมการเรียนรู้แต่ขึ้นกับบริบทของปัญหาหรือข้อมูลที่ผู้วิเคราะห์มี ดังนั้นการที่ผู้วิเคราะห์จะตัดสินใจเลือกว่าจะใช้การจัดการข้อมูลแบบใดกับตัวแปรอิสระภายในชุดข้อมูลอาจต้องพิจารณาในหลายมิติร่วมกัน เช่น สภาพของข้อมูล ตัวเลือกทั้งหมดที่เป็นไปได้ในการจัดกระทำข้อมูลของตัวแปร ลักษณะ/รูปแบบของความสัมพันธ์ในธรรมชาติระหว่างตัวแปรตามกับตัวแปรอิสระ ในหลาย ๆ ครั้งอาจจะต้องใช้หลักเหตุผลรวมทั้งศึกษาค้นคว้าเอกสารงานวิจัยหรือทฤษฎีที่เกี่ยวข้องกับตัวแปรที่กำลังดำเนินงานอยู่ นอกจากนี้การสัมภาษณ์หรือเก็บรวบรวมข้อมูลจากผู้เกี่ยวข้อง เจ้าของข้อมูล หรือผู้มีส่วนได้ส่วนเสีย (stakeholder) อาจให้สารสนเทศที่เป็นประโยชน์ต่อการดำเนินงานในส่วนนี้ จะเห็นว่าการเตรียมข้อมูลลักษณะนี้ต้องใช้ทักษะมากกว่าการเตรียมข้อมูลประเภทแรกค่อนข้างมาก และมีลักษณะที่เป็น data-driven ซึ่งการดำเนินงานจะมีลักษณะทวนซ้ำเพื่อสังเกตผลลัพธ์และปรับแต่งการจัดกระทำตัวแปรเพื่อให้ประสิทธิภาพในการทำนายมีค่าสูงที่สุดเท่าที่จะเป็นไปได้ ทั้งนี้เพื่อให้เข้าใจลักษณะและประสิทธิภาพของการทำ feature engineering มากขึ้น ขอให้ผู้อ่านลองพิจารณาตัวอย่างต่อไปนี้

```{r echo=F, eval=F}
# สร้างไฟล์ข้อมูล
n<-2000
age<-round(seq(18,60,length=n),2)
age<-age[sample(1:2000)]
performance <- seq(-10,10, length=n)
performance <- performance[sample(1:2000)]
g = 100*age + 200*performance + 500*age/performance -10000 + 500*rnorm(n,0,1)
y<-ifelse(g>0, 1,0)
plot(performance, g)
dat<-data.frame(age, performance, y)
dat$y<-factor(dat$y, levels=c(0,1), labels=c("not promoted","promoted"))
write.csv(dat, file="logistic.csv")
```

ชุดข้อมูล `logistic.csv` ดาวน์โหลดได้จาก <https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week2/logistic.csv> ประกอบด้วยข้อมูลของตัวแปรตาม `y` คือสถานะการเลื่อนตำแหน่งของพนักงาน (promated และ not promoted) ส่วนตัวแปรอิสระมี 2 ตัวได้แก่ อายุของพนักงาน (`age`) และประสิทธิภาพในการทำงาน (`performance`) วัตถุประสงค์ของผู้วิเคราะห์คือพัฒนาโมเดลทำนายการได้เลื่อนตำแหน่งของพนักงานด้วยตัวแปรอิสระทั้งสองตัวดังกล่าว

```{r}
dat<-read.csv("https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week2/logistic.csv")
glimpse(dat)
```

ผลการสำรวจข้อมูลเบื้องต้นพบว่าชุดข้อมูล `dat` ที่นำเข้ามามีตัวแปรที่ไม่เกี่ยวข้องคือ `X` ซึ่งควรเอาออกจากชุดข้อมูล และตัวแปรตาม `y` อยู่ในรูปแบบของตัวแปรตัวอักษรซึ่งควรเปลี่ยนให้เป็นตัวแปรแบบ factor ก่อน การดำเนินการแก้ไขปัญหาดังกล่าวเป็นการจัดกระทำข้อมูลให้สอดคล้องกับการวิเคราะห์ด้วยอัลกอริทึม logistic regression ในโปรแกรม R จัดอยู่ในกลุ่มการเตรียมข้อมูลประเภทแรกดังที่ได้กล่าวไปแล้ว คำสั่งต่อไปนี้เป็นการเตรียมข้อมูลดังกล่าว

```{r}
dat <- dat %>% dplyr::select(-X) %>%
        mutate(y = factor(y, levels=c("promoted","not promoted")))
```

เมื่อจัดการกับข้อมูลดังกล่าวแล้ว ผู้วิเคราะห์ทำการแบ่งชุดข้อมูลออกเป็นสองชุด ได้แก่ ชุดข้อมูลฝึกหัด และชุดข้อมูลทดสอบ จากนั้นดำเนินการสำรวจความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระด้วยทัศนภาพข้อมูล

```{r fig.width=6, fig.height=4, fig.cap="ผลการสำรวจข้อมูลเบื้องต้น"}
dat_split <- initial_split(dat, prop = 0.7, strata = y)
dat_split
train <- dat_split %>% training()
test <- dat_split %>% testing()
# data exploring
train %>% ggplot(aes(x=age, y=performance))+
            geom_point(aes(col=y))+
            theme_minimal()
```

ผลการสำรวจความสัมพันธ์ระหว่างตัวแปรด้วยทัศนภาพข้อมูลข้างต้น จะเห็นว่าสามารถจำแนกพนักงานด้วยสายตาออกได้เป็น 3 กลุ่มอย่างค่อนข้างชัดเจน กลุ่มแรกคือกลุ่มที่มีประสิทธิภาพในการทำงานต่ำกว่า 0 คะแนน ซึ่งเกือบทั้งหมดไม่ได้รับการเลื่อนตำแหน่ง กลุ่มที่สองคือกลุ่มพนักงานที่ประสิทธิภาพการทำงานสูงกว่า 0 คะแนน แต่ไม่ได้รับการเลื่อนตำแหน่ง ในจำนวนนี้พบว่าส่วนใหญ่เป็นพนักงานที่มีอายุยังน้อย และกลุ่มที่สามคือกลุ่มพนักงานที่ประสิทธิภาพการทำงานสูงกว่า 0 และได้รับการเลื่อนตำแหน่ง ซึ่งในจำนวนนี้พบว่าส่วนใหญ่เป็นพนักงานที่มีอายุมาก

ขั้นตอนถัดมาผู้วิเคราะห์นำชุดข้อมูลฝึกหัดที่สร้างขึ้นไปให้อัลกอริทึมเรียนรู้จากนั้นทำการตรวจสอบประสิทธิภาพการทำนายของโมเดลในชุดข้อมูลทดสอบด้วย package parsnip ดังนี้

```{r fig.width=3.5, fig.height=3.5, fig.cap="ROC Curve ของ logistic regression"}
fit_logistic1 <- logistic_reg() %>%
                    set_engine("glm") %>%
                    set_mode("classification")%>%
                    fit(y ~ ., data=train)
# calculate predicted values
pred <- predict(fit_logistic1, 
                new_data = test,
                type = "class")
pred_prob <- predict(fit_logistic1, 
                new_data = test,
                type = "prob")

test_results <- test %>% dplyr::select(y)%>%
                bind_cols(pred, pred_prob)
# evaluate model
conf_mat(data = test_results,
         truth = y,
         estimate = .pred_class)%>%
        summary()
# roc curve
test_results %>% 
  roc_curve(truth = y,
            estimate = .pred_promoted)%>%
  autoplot()

test_results %>% 
    roc_auc(truth = y,
            estimate = .pred_promoted)
```

```{r fig.height=3.5, fig.width=5.5, fig.cap="Decision Boundary ของ logistic regression"}
# decision boundary
x1 <- seq(18,60,length=100)
x2 <- seq(-10,10,length=100)
grid <- expand.grid(age = x1,performance = x2)
bg.dat<-data.frame(grid) %>%
          bind_cols(predict(fit_logistic1, grid, type="class"),
                    pred_prob = predict(fit_logistic1, grid, type="prob"))
ggplot()+
  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), 
             shape=3, size=1, alpha=0.5)+
  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+
  labs(col="test dataset", fill="Decision Boundary")+
  theme(text=element_text(family="ChulaCharasNew"))+
  theme_minimal()
```

ผลการพัฒนาโมเดลทำนายด้วยอัลกอริทึม logistic regression ในข้างต้นจะเห็นว่ายังไม่ประสบความสำเร็จ โดยจากรูปจะเห็นว่าพื้นที่การตัดสินใจของโมเดลทำนายอยู่บริเวณมุมขวาบนของ feature space ซึ่งยังมีความคลาดเคลื่อนอยู่มาก เมื่อพิจารณาผลการวิเคราะห์จาก confusion matrix ประกอบพบว่าโมเดลมีความไว (sensitivity) ในการทำนายการเลื่อนตำแหน่งเท่ากับ .324 ซึ่งอยู่ในระดับต่ำ แต่มีความจำเพาะ (specificity) เท่ากับ .955 ซึ่งอยู่ในระดับสูงมาก อย่างไรก็ตามค่าความจำเพาะที่สูงดังกล่าวเป็นผลมาจากการที่โมเดลมี sensitivity ต่ำมากนั่นเอง นอกจากนี้เมื่อพิจารณา AUC ของ ROC curve พบว่ามีค่าเท่ากับ .752 แสดงว่าในภาพรวมโมเดลมีประสิทธิภาพการทำนายอยู่ในระดับพอใช้

จากปัญหาที่พบเราสามารถแก้ปัญหาได้หลายวิธีการ วิธีการแรก ๆ ที่ควรดำเนินการคือการทำ feature engineering จากผลการสำรวจความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระในรูป 33 จะเห็นว่าการเลื่อนตำแหน่งของพนักงานไม่ได้ขึ้นกับอายุและประสิทธิภาพในการทำนายแบบเป็นเส้นตรง กล่าวคือพนักงานอายุเยอะไม่จำเป็นต้องได้เลื่อนตำแหน่งเสมอไป และพนักงานที่มีประสิทธิภาพการทำงานที่ดีก็ไม่จำเป็นที่จะต้องได้เลื่อนตำแหน่งเสมอไปเช่นกัน แต่พนักงานที่มีแนวโน้มจะได้เลื่อนตำแหน่งคือพนักงานที่มีประสิทธิภาพการทำงานดีและมีอายุ จากข้อสังเกตนี้แสดงให้เห็นว่ามีอิทธิพลปฏิสัมพันธ์ระหว่างอายุกับประสิทธิภาพการทำนายต่อการเลื่อนตำแหน่ง

```{r}
fit_logistic2 <- logistic_reg() %>%
                    set_engine("glm") %>%
                    set_mode("classification")%>%
                    fit(y ~ . + age*performance, data=train)


```

```{r echo=F, fig.width=3.5, fig.height=3.5, fig.cap="ROC Curve ของ logistic regression ที่มีอิทธิพลปฏิสัมพันธ์"}
# calculate predicted values
pred <- predict(fit_logistic2, 
                new_data = test,
                type = "class")
pred_prob <- predict(fit_logistic2, 
                new_data = test,
                type = "prob")

test_results <- test %>% dplyr::select(y)%>%
                bind_cols(pred, pred_prob)
# evaluate model
eval_metric <- metric_set(accuracy, sens, spec)
eval_metric(data = test_results,
         truth = y,
         estimate = .pred_class)
# roc curve
test_results %>% 
  roc_curve(truth = y,
            estimate = .pred_promoted)%>%
  autoplot()

test_results %>% 
    roc_auc(truth = y,
            estimate = .pred_promoted)
```

```{r fig.width=5.5, fig.height=3.5, fig.cap="Decision Boundary ของ logistic regression ที่มีอิทธิพลปฏิสัมพันธ์"}
# decision boundary
x1 <- seq(18,60,length=100)
x2 <- seq(-10,10,length=100)
grid <- expand.grid(age = x1,performance = x2)
bg.dat<-data.frame(grid) %>%
          bind_cols(predict(fit_logistic2, grid, type="class"),
                    pred_prob = predict(fit_logistic2, grid, type="prob"))
ggplot()+
  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), 
             shape=3, size=1, alpha=0.5)+
  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+
  labs(col="test dataset", fill="Decision Boundary")+
  theme(text=element_text(family="ChulaCharasNew"))+
  theme_minimal()
```

ผลการทำนายของโมเดลที่มีเทอมปฏิสัมพันธ์ระหว่างอายุกับประสิทธิภาพการทำงานพบว่าดีขึ้นเล็กน้อย แต่ยังไม่ประสบความสำเร็จ คราวนี้เราลองพิจารณาทางเลือกในการแปลงค่าของตัวแปรในลักษณะอื่นบ้าง จากผลการสำรวจที่พบว่าการเลื่อนตำแหน่งขึ้นกับปัจจัยอายุและประสิทธิภาพการทำงานผู้วิเคราะห์สร้างตัวแปรใหม่ในชุดข้อมูลเป็นอัตราส่วนอายุต่อประสิทธิภาพการทำงาน (`ratio_age_performance`) จากนั้นดำเนินการ fit โมเดลเหมือนกับสองโมเดลแรกที่ผ่านมา

```{r}
dat <- dat%>%
        mutate(ratio_age_performance = age/performance)
```

```{r echo=F, fig.width=3.5, fig.height=3.5, fig.cap="ROC Curve ของ logistic regression ที่มีการทำ feature engineering"}
dat_split <- initial_split(dat, prop = 0.7, strata = y)
dat_split
train <- dat_split %>% training()
test <- dat_split %>% testing()

fit_logistic3 <- logistic_reg() %>%
                    set_engine("glm") %>%
                    set_mode("classification")%>%
                    fit(y ~ . , data=train)

# calculate predicted values
pred <- predict(fit_logistic3, 
                new_data = test,
                type = "class")
pred_prob <- predict(fit_logistic3, 
                new_data = test,
                type = "prob")

test_results <- test %>% dplyr::select(y)%>%
                bind_cols(pred, pred_prob)
# evaluate model
conf_mat(data = test_results,
         truth = y,
         estimate = .pred_class)
eval_metric <- metric_set(accuracy, sens, spec)
eval_metric(data = test_results,
         truth = y,
         estimate = .pred_class)
# roc curve
test_results %>% 
  roc_curve(truth = y,
            estimate = .pred_promoted)%>%
  autoplot()
```

```{r fig.width=5.5, fig.height=3.5, fig.cap="Decision Boundary ของ logistic regression ที่มีการทำ Feature Engineering"}
# decision boundary
x1 <- seq(18,60,length=100)
x2 <- seq(-10,10,length=100)
grid <- expand.grid(age = x1,performance = x2)%>%
          mutate(ratio_age_performance = age/performance)

bg.dat<-data.frame(grid) %>%
          bind_cols(predict(fit_logistic3, grid, type="class"),
                    pred_prob = predict(fit_logistic3, grid, type="prob"))
ggplot()+
  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), 
             shape=3, size=1, alpha=0.5)+
  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+
  labs(col="test dataset", fill="Decision Boundary")+
  theme(text=element_text(family="ChulaCharasNew"))+
  theme_minimal()
```

คราวนี้ลองเปลี่ยนโมเดลทำนายข้างต้นเป็น decision tree แบบ CART ที่มีจุดเด่นคือเป็นโมเดลจำแนกแบบ nonlinear classification กล่าวคือโมเดล decision tree ควรมีประสิทธิภาพในการจำแนกพนักงานที่จะได้เลื่อนและไม่ได้เลื่อนตำแหน่งได้สูงกว่า logistic regression ที่ยังไม่ได้ทำ feature engineering

```{r}
fit_tree <- decision_tree() %>%
                    set_engine("rpart") %>%
                    set_mode("classification")%>%
                    fit(y ~ . , data=train)

# calculate predicted values
pred <- predict(fit_tree, 
                new_data = test,
                type = "class")
pred_prob <- predict(fit_tree, 
                new_data = test,
                type = "prob")

test_results <- test %>% dplyr::select(y)%>%
                bind_cols(pred, pred_prob)
# evaluate model
conf_mat(data = test_results,
         truth = y,
         estimate = .pred_class)
eval_metric <- metric_set(accuracy, sens, spec)
eval_metric(data = test_results,
         truth = y,
         estimate = .pred_class)

```

```{r fig.width=5.5, fig.height=3.5, fig.cap="Decision Boundary ของ Decision Tree (CART algorithm)"}
# decision boundary
x1 <- seq(18,60,length=100)
x2 <- seq(-10,10,length=100)
grid <- expand.grid(age = x1,performance = x2)%>%
          mutate(ratio_age_performance = age/performance)

bg.dat<-data.frame(grid) %>%
          bind_cols(predict(fit_tree, grid, type="class"),
                    pred_prob = predict(fit_tree, grid, type="prob"))
ggplot()+
  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), 
             shape=3, size=1, alpha=0.5)+
  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+
  labs(col="test dataset", fill="Decision Boundary")+
  theme_minimal()
```

ผู้อ่านจะเห็นว่าการทำ feature engineering โดยสร้างเทอมอัตราส่วนระหว่างอายุกับประสิทธิภาพการทำงานของพนักงานในการทำนายการเลื่อนตำแหน่งของพนักงานใน logistic regression ช่วยให้พื้นที่การตัดสินใจของโมเดลทำนายแบบ logistic regression พัฒนาขึ้นมาก จากเดิมที่เป็น linear classification เป็น nonlinear classification และมีประสิทธิภาพการทำนายบนชุดข้อมูลทดสอบที่สูงมากใกล้เคียงกับการใช้ decision tree ที่เป็น nonlinear classification (อย่างไรก็ตาม decision tree มี hyperparameter ที่สามารถปรับแต่งได้อีก ซึ่งอาจเพิ่มประสิทธิภาพในการทำนายได้มากขึ้นกว่านี้) ตัวอย่างนี้เป็นตัวอย่างหนึ่งที่แสดงให้เห็นว่าการทำ feature engineering ที่เหมาะสมนั้นช่วยเพิ่มประสิทธิภาพการทำนายให้กับโมเดลได้อย่างไร

## 4.2 ประเภทของ Data Preprocessing

ดังที่ได้กล่าวในข้างต้นว่า data preprocessing เป็นกระบวนการจัดการข้อมูลที่มีลักษณะทวนซ้ำ และไม่ได้มีขั้นตอนการดำเนินการที่แน่นอน ขั้นตอนการดำเนินการจัดการข้อมูลในแต่ละงานขึ้นอยู่กับสภาพของข้อมูล และวัตถุประสงค์ของการวิเคราะห์ในแต่ละงาน โดยทั่วไปการจัดการข้อมูลอาจจำแนกเป็น 3 ประเภทได้แก่

-   **การทำความสะอาดข้อมูล (data cleaning)**

-   **การแปลงข้อมูล (data transformation)**

-   **การคัดเลือกตัวแปร (feature selection)**

รายละเอียดมีดังนี้

### การทำความสะอาดข้อมูล (data cleaning)

การทำความสะอาดข้อมูลเป็นกระบวนการเพื่อสำรวจ วินิจฉัย และแก้ไขความผิดปกติที่เกิดขึ้นในข้อมูล ความผิดปกติดังกล่าวสามารถเกิดขึ้นได้จากหลายสาเหตุ เช่น การจัดเก็บหรือบันทึกข้อมูลที่ผิดพลาด หรือการวัดข้อมูลมีความคลาดเคลื่อนจากการวัด ความผิดปกติดังกล่าวมีโอกาสเกิดขึ้นได้เป็นประจำ จึงเป็นหน้าที่ของนักวิทยาการข้อมูลที่จะต้องสำรวจ และวินิจฉัยความผิดปกติดังกล่าวในชุดข้อมูล จากนั้นจึงดำเนินการแก้ไขอย่างเหมาะสม วัตถุประสงค์ของการทำความสะอาดข้อมูลคือการได้มาซึ่งชุดข้อมูลใหม่ที่มีความพร้อมในการนำไปวิเคราะห์ได้โดยไม่มีความผิดพลาด การทำความสะอาดข้อมูลจัดอยู่ในกลุ่มการเตรียมข้อมูลให้สอดคล้องกับความต้องการหรือข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้ ซึ่งเกี่ยวข้องกับการดำเนินการหรือเทคนิควิธีการหลายอย่าง ได้แก่

-   **การจัดระเบียบและจัดกระทำข้อมูล (tidying and manipulating data)** ซึ่งเกี่ยวข้องกับการจัดรูปแบบของตารางข้อมูลให้อยู่ในรูปแบบที่เหมาะสมสำหรับการวิเคราะห์ เช่นการเปลี่ยนรูปแบบตารางระหว่างตารางข้อมูลรูปแบบยาว (long format) กับรูปแบบกว้าง (wide format) การเปลี่ยนสถานะของตัวแปรในชุดข้อมูลให้เหมาะสม การแยกและยุบรวมคอลัมนท์ การจัดการกับข้อมูลซ้ำซ้อน การรวมชุดข้อมูล การคัดกรองข้อมูล เป็นต้น package ของ R ที่เกี่ยวข้องกับการดำเนินการส่วนนี้ ได้แก่ tidyr และ dplyr (รายละเอียดสามารถศึกษาได้จาก สิวะโชติ ศรีสุทธิยากร (2564)) \<\-\-- ไม่พูดถึงแล้วในรายวิชานี้

-   **การสำรวจและจัดการกับค่าผิดปกติ** เกี่ยวข้องกับการสำรวจข้อมูล วินิจฉัยความผิดปกติของข้อมูล และการแก้ไขปัญหาความผิดปกติของข้อมูล ข้อมูลที่ผิดปกติอาจจำแนกได้เป็นสามประเภทตามสาเหตุของการเกิด เช่น outlier, anomaly และ noisy data

-   **การวิเคราะห์และทดแทนค่าสูญหาย** เป็นปกติที่ชุดข้อมูลจะมีข้อมูลที่สูญหายไม่ครบถ้วน หากค่าสูญหายดังกล่าวเกิดขึ้นเป็นจำนวนมากเกินไป และมีรูปแบบการเกิดที่เป็นระบบ อาจส่งผลให้การเรียนรู้ของเครื่องมีความลำเอียงหรือมีความน่าเชื่อถือที่ลดลงได้ การวิเคราะห์รูปแบบของค่าสูญหาย และการเลือกวิธีการทดแทนค่าสูญหายที่เหมาะสมจะช่วยลดทอนผลกระทบที่เกิดจากค่าสูญหายดังกล่าว

### การแปลงข้อมูล (data transformation)

การแปลงข้อมูลเป็นกระบวนการเปลี่ยนลักษณะหรือรูปแบบของข้อมูลจากรูปแบบหนึ่งไปเป็นอีกรูปแบบหนึ่ง เพื่อให้เหมาะกับความต้องการหรือข้อตกลงเบื้องต้นของการวิเคราะห์ที่เลือกใช้ ได้แก่ การแปลงข้อมูลจัดประเภทให้เป็นตัวแปรตัวเลข เช่น dummy encoding หรือ one-hot encoding การแปลงข้อมูลที่ไม่สมมาตรให้สมมาตร หรือการแปลงข้อมูลจากหน่วยใด ๆ ให้อยู่ในหน่วยมาตรฐานเพื่อให้สามารถเปรียบเทียบกันได้ หรือลดผลกระทบจากหน่วยข้อมูลที่มีต่อการเรียนรู้ของเครื่องในบางอัลกอริทึม นอกจากนี้การแปลงข้อมูลยังเป็นเทคนิคที่อาจช่วยให้การวิเคราะห์มีประสิทธิภาพสูงขึ้นดังตัวอย่างที่แสดงไว้ในส่วนนำของบทเรียนนี้

### การคัดเลือกตัวแปร (feature selection)

เป็นกระบวนการคัดเลือกตัวแปรอิสระภายในชุดข้อมูลที่มีประสิทธิภาพสำหรับการวิเคราะห์หรือพัฒนาโมเดลทำนาย กระบวนการนี้มีความสำคัญมากโดยเฉพาะในสถานการณ์ที่ผู้วิเคราะห์มีชุดข้อมูลขนาดใหญ่และมีตัวแปรจำนวนมาก การคัดเลือกตัวแปรจะช่วยลดขนาดของชุดข้อมูลและช่วยให้ผู้วิเคราะห์ทำงานได้ง่ายขึ้น โดยทั่วไปอาจจำแนกวิธีการคัดเลือกตัวแปรได้เป็น 3 ประเภทได้แก่ filter methods, wrapper methods และ embedded methods

**Filter methods** เป็นวิธีการพื้นฐานสำหรับการคัดเลือกตัวแปรอิสระ วิธีการในกลุ่มนี้จะเป็นการใช้ค่าสถิติพื้นฐาน ได้แก่ สัมประสิทธิ์สหสัมพันธ์ และใช้ความรู้จากการทบทวนวรรณกรรม ประสบการณ์ของผู้วิเคราะห์ ความคิดเห็นของผู้เกี่ยวข้องหรือผู้ทรงคุณวุฒิ เข้ามาร่วมกันเพื่อคัดเลือกชุดของตัวแปรอิสระที่เหมาะสม

**Wrapper methods** เป็นวิธีการที่คัดเลือกตัวแปรอิสระในโมเดลด้วยอัลกอริทึมสำหรับคัดเลือกตัวแปรได้แก่ forward selection, backward selection, stepwise selection หรือ recursive feature elimination เป็นต้น

**Embedded methods** เป็นวิธีการคัดเลือกตัวแปรอิสระที่รวมไปกับกระบวนการเรียนรู้ของอัลกอริทึมบางตัว เช่น lasso regression และ decision tree

## 4.3 พื้นฐาน `recipe` สำหรับทำ Data Preprocessing

![](images/image-1527588902.png){width="30%"}

การทำ data preprocessing เป็นกระบวนการที่มีการใช้ทั้งการจัดกระทำข้อมูล สถิติและอัลกอริทึมการเรียนรู้ จริง ๆ แล้วการดำเนินการดังกล่าวสามารถทำได้โดยใช้คำสั่งพื้นฐานปกติใน R อย่างไรก็ตามในกระบวนการพัฒนาโมเดลที่มีการดำเนินการแบบทวนซ้ำแต่ละขั้นตอนไปมาซึ่งการเขียนคำสั่งแบบปกติอาจไม่สะดวกนัก โดยเฉพาะในกรณีที่ผู้วิเคราะห์มีการใช้เทคนิคการจัดการข้อมูลหลาย ๆ เทคนิคต่อเนื่องกัน เช่น การแปลงค่า --- \>การทดแทนค่าสูญหาย ---\> การสร้างองค์ประกอบด้วย PCA บทเรียนนี้จะกล่าวถึงการใช้ package recipe เพื่อใช้เป็นวิธีการทางเลือกสำหรับผู้วิเคราะห์ในการทำ data preprocessing ภายใต้ package นี้ผู้วิเคราะห์สามารถดำเนินการทำ data preprocessing ที่มีหลายขั้นตอนหลายเทคนิคได้อย่างต่อเนื่องโดยใช้ piping operator คล้ายกับการทำงานใน package dplyr นอกจากนี้ยังนำกระบวนการที่กำหนดไปทำซ้ำกับชุดข้อมูลอื่นได้โดยง่าย เนื้อหาในหัวข้อนี้จะกล่าวถึงพื้นฐานการใช้ package recipe ดังกล่าวรายละเอียดมีดังนี้

### การดาวน์โหลดและติดตั้ง package

กรณีที่ติดตั้ง package tidymodels จะดาวน์โหลดและติดตั้ง package recipe โดยอัตโนมัติ ส่วนในกรณีที่ต้องการติดตั้งแยกสามารถพิมพ์คำสั่งดังนี้

```{r eval=F}
# CRAN version
install.packages("recipe")
library(recipe)
# development version from GitHub
devtools::install_github("tidymodels/recipes")
```

### ขั้นตอนการทำ data preprocessing ด้วย recipe

การทำ data preprocessing ด้วย package recipe ประกอบด้วยขั้นตอนการดำเนินงานหลัก 4 ขั้นได้แก่

1.  ขั้นตอนการกำหนดสถานะของตัวแปร ว่าภายในชุดข้อมูลที่ดำเนินการอยู่ ตัวแปรใดเป็นตัวแปรตามตัวแปรใดเป็นตัวแปรอิสระ รวมถึงพิจารณาประเภทของข้อมูลในแต่ละตัวแปรด้วย ซึ่งปกติสามารถจำแนกได้ 2 ประเภทได้แก่ ข้อมูลตัวเลข และข้อมูลแบบจัดประเภท การดำเนินการในขั้นนี้จะใช้ฟังก์ชัน `recipe()`

2.  ขั้นตอนการกำหนดวิธีการจัดการข้อมูลที่ต้องการ โดยผู้วิเคราะห์สามารถกำหนดวิธีการจัดการข้อมูลที่ต้องการผ่านฟังก์ชัน `step_*()` ที่ครอบคลุมทั้งการแปลงค่าข้อมูล เช่น การแปลงให้เป็นคะแนนมาตรฐาน การแปลงด้วยฟังก์ชัน log การสร้างตัวแปรใหม่จากข้อมูลของตัวแปรเดิม หรือ การทดแทนค่าสูญหาย (missing data imputation) เป็นต้น ผู้อ่านสามารถศึกษารายละเอียดของฟังก์ชัน `step_*()` ทั้งหมดภายใต้ package recipe ได้จาก <https://recipes.tidymodels.org/reference/index.html>

3.  การจัดการข้อมูลหลายตัวมีการใช้วิธีการทางสถิติหรืออัลกอริทึมการเรียนรู้ที่จะต้องใช้ผลการวิเคราะห์จากชุดข้อมูลฝึกหัดมาเป็นค่าพารามิเตอร์หรือค่าสถิติสำหรับจัดการข้อมูลที่กำหนด (แต่การจัดการข้อมูลบางตัวก็ไม่ต้องใช้) ดังนั้นเมื่อผู้วิเคราะห์กำหนดสถานะของตัวแปรและการจัดการข้อมูลเรียบร้อยแล้ว ขั้นตอนที่ 3 คือการนำตัวแปรจาก `recipe()` ข้างต้นมาผ่านการประมวลผลหรือวิเคราะห์โดยใช้ชุดข้อมูลฝึกหัดเป็นข้อมูลนำเข้า เช่น หากผู้วิเคราะห์กำหนดให้มีการแปลงคะแนนตัวแปรให้เป็นสเกลมาตรฐาน ขั้นตอนนี้จะเป็นการคำนวนค่าเฉลี่ย และส่วนเบี่ยงเบนมาตรฐานของตัวแปรในชุดข้อมูลฝึกหัดที่กำหนดเพื่อใช้ในการ centering และ scaling ตัวแปรในชุดข้อมูลที่ต้องการจะทำ data preprocessing ในอนาคต การดำเนินการใช้ขั้นตอนนี้จะใช้ฟังก์ชัน `prep()`

4.  ขั้นตอนสุดท้ายคือการจัดการข้อมูลตามที่วางแผนไว้บนชุดข้อมูลที่กำหนด ซึ่งเป็นไปได้ทั้ง training dataset, test dataset หรือชุดข้อมูลอื่น ๆ ที่จะนำเข้าสู่โมเดลทำนายในอนาคต (เพราะ ML model ที่พัฒนาต้องจะต้องการข้อมูลที่มีการจัดการเหมือนกับชุดข้อมูลฝึกหัด) การดำเนินการในขั้นตอนนี้จะใช้ฟังก์ชัน `bake()`

ตัวอย่างต่อไปนี้แสดงทำ data preprocessing ด้วย package recipe ตามขั้นตอนข้างต้น จากชุดข้อมูล [`TeacherSalaryData.csv`](https://github.com/ssiwacho/2758688_ML/blob/main/week%201/TeacherSalaryData.csv) สมมุติว่าผู้วิจัยต้องการแปลงค่าของตัวแปร `salary` ด้วยฟังก์ชัน log สามารถดำเนินการได้ดังนี้

**ขั้นที่ 0 : นำเข้าและแบ่งชุดข้อมูล**

```{r}
dat <- read.csv("https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/TeacherSalaryData.csv")
dat <- dat[,-1] #remove X
dat <- dat%>%mutate_if(is.character, factor)
# data splitting
split <- initial_split(data = dat, prop = 0.8)
salary_train <- split %>% training()
salary_test <- split %>% testing()
summary(salary_train)
```

**ขั้น 1 : กำหนดสถานะของตัวแปร และพิจารณาความถูกต้องของประเภทข้อมูลในแต่ละตัวแปร**

```{r}
salary_rec <- recipe(salary ~., data = salary_train)
salary_rec
salary_rec %>% summary()
```

ผลการวิเคราะห์ข้างต้นจะเห็นว่าภายในชุดข้อมูลประกอบด้วย 6 ตัวแปร มีตัวแปรตามคือ salary ซึ่งเป็นตัวแปรเชิงปริมาณ ตัวแปรที่เหลือเป็นตัวแปรอิสระที่ประกอบด้วยตัวแปรเชิงปริมาณจำนวน 2 ตัว และตัวแปรจัดประเภทจำนวน 3 ตัว

**ขั้น 2 : กำหนดการจัดการข้อมูลให้กับตัวแปร `recipe` จากขั้นที่ 1**

```{r}
salary_rec <- salary_rec %>%
  step_log(salary, base = 10)
salary_rec
```

ผลลัพธ์ในข้างต้นแสดงให้เห็นว่ามีการกำหนดให้แปลงค่าของตัวแปร `salary` ด้วยฟังก์ชัน log

**ขั้น 3 : การประมวลผล preprocessing model**

ขั้นตอนนี้เป็นการนำกรอบการจัดการข้อมูลที่กำหนดให้ขั้นที่ 1 และ 2 มาประมวลผลบนชุดข้อมูลฝึกหัด ด้วยฟังก์ชัน `prep()` โดยฟังก์ชันดังกล่าวจะคำนวณค่าสถิติที่จำเป็นหรือให้อัลกอริทึมการเรียนรู้ทำการประมวลผลลัพธ์ที่จำเป็นสำหรับการจัดการข้อมูลตามที่กำหนดไว้ ฟังก์ชัน `prep()` มีอาร์กิวเมนท์ที่สำคัญคือ `training` ที่ใช้ระบุชุดข้อมูลฝึกหัดสำหรับการจัดการข้อมูล

```{r}
salary_rec_prep <- salary_rec %>% prep(training = salary_train)
salary_rec_prep
```

จะเห็นว่าเมื่อผ่านตัวแปรของ `recipe` เข้าสู่ฟังก์ชัน `prep` แล้วจะมีการขึ้นสถานะว่า `[trained]` ซึ่งหมายถึง package recipe ได้ประมวลผลที่จำเป็นสำหรับการจัดการข้อมูลตามที่กำหนดแล้ว และเก็บผลดังกล่าวเอาไว้ในตัวแปร `salary_rec_pre`

**ขั้น 4 : การจัดการข้อมูล**

อย่างที่กล่าวไว้แล้วว่าขั้นที่ 1 - 3 ถือเป็นขั้นตอนการวางแผนและเตรียมการจัดการข้อมูล ส่วนขั้นที่ 4 เป็นการจัดการข้อมูลบนชุดข้อมูลที่กำหนด ด้วยฟังก์ชัน `bake()` โดยจะใช้กรอบการจัดการข้อมูลที่กำหนดในขั้นตอนที่ 1 และ 2 และจะใช้ค่าสถิติที่จำเป็นสำหรับการจัดการข้อมูลที่ได้จากขั้นตอนที่ 3 ฟังก์ชัน `bake()` มีอาร์กิวเมนท์สำคัญหนึ่งตัวคือ `new_data` ที่ใช้ระบุชุดข้อมูลที่จะต้องการดำเนินการ ในกรณีที่ต้องการจัดการข้อมูลฝึกหัดที่ใช้เป็นชุดข้อมูลฝึกหัดในขั้นตอนที่ 3 ให้กำหนด `new_data = NULL` ดังตัวอย่างต่อไปนี้

```{r}
salary_train_baked <- salary_rec_prep %>% bake(new_data = NULL)
summary(salary_train_baked)
```

ในกรณีที่ต้องการนำการจัดการข้อมูลที่ train ไว้ในขั้นที่ 3 ไปใช้กับชุดข้อมูลอื่นเช่น `salary_test` สามารถเขียนคำสั่งได้ดังนี้

```{r}
salary_test_baked <- salary_rec_prep %>% bake(new_data = salary_test)
salary_test_baked
```

จะเห็นว่าชุดข้อมูลทั้งสองมีการจัดการข้อมูลของตัวแปร salary ตามที่กำหนดไว้เรียบร้อยแล้ว เนื้อหาในส่วนต่อไปจะกล่าวถึงเทคนิคการทำ data preprocessing สำหรับสถานการณ์ต่าง ๆ โดยจะใช้ package recipe ในการดำเนินการ
