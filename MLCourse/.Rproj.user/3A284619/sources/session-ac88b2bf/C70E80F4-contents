---
title: "Untitled"
---

## Piecewise Polynomial Regression

การวิเคราะห์สมการถดถอยพหุนามในข้างต้นเป็นการกำหนดฟังก์ชันให้กับข้อมูลทั้งชุดเหมือนกันทั้งหมด อย่างไรก็ตามมีวิธีการที่สามารถกำหนดฟังก์ชันพหุนามหลาย ๆ ตัวให้กับส่วนย่อยข้อมูลเป็นส่วน ๆ ไป ซึ่งช่วยให้ประสิทธิภาพการทำนายสูงขึ้นได้ ยกตัวอย่างในรูปด้านล่าง

```{r}
data %>% ggplot()+
  geom_point(aes(x=x, y=y),col="steelblue", alpha=0.6)+
  geom_vline(xintercept = 4, linetype=2, col="maroon", linewidth = 1.2)+
  theme_light()
```

```{r}
data %>% filter(x < 4) %>%
  lm(y~poly(x,2), data=.) %>%
  predict() -> pred1

data %>% filter(x >= 4) %>%
  lm(y~x, data=.) %>%
  predict() -> pred2

temp <- data
temp$pred<-NA
temp[temp$x>=4,"pred"]<-pred2
temp[temp$x<4,"pred"]<-pred1
head(temp)
temp %>% ggplot(aes(x=x))+
  geom_point(aes(y=y),col="steelblue", alpha=0.3)+
  geom_vline(xintercept = 4, linetype=2, col="maroon", linewidth = 1.2)+
  geom_line(aes(y=pred,col= x>4) , linewidth=1.2)+
  theme_light()
```

เรียกจุดที่ใช้แบ่งเพื่อเปลี่ยนโมเดลทำนายว่า knot อย่างไรก็ตามการ fit piecewise regression ด้วยวิธีการข้างต้นจะเปิดปัญหาความไม่ต่อเนื่องระหว่างรอยต่อ (discontinuity problem) การแก้ปัญหาดังกล่าวสามารถทำได้โดยใช้เงื่อนไขเพิ่มเติมในขั้นตอนการประมาณค่าพารามิเตอร์ โดยแทนที่จะประมาณค่าพารามิเตอร์แยกโมเดลก็ให้ประมาณค่ารวมทั้งโมเดลดังนี้

$$
y = \beta_0 + \sum_{d=1}^D \beta_d x^d + \sum_{k=1}^K \beta_k (x-\tau)^K
$$

โดยที่ $(x-\tau)^K = (x-\tau)^K \ \;x \geq \tau$ และ $(x-\tau)^K =0 \ \ ;x<\tau$

```{r}
data %>%
  mutate(d = ifelse(x>=4,1,0),
         x2 = x-4) %>%
  lm(y ~ poly(x,2) + poly(x2*d,2), data=.)%>%
  predict()->pred

temp$pred2<-pred
temp%>%ggplot(aes(x=x))+
  geom_point(aes(y=y),col="steelblue", alpha=0.3)+
  geom_vline(xintercept = 4, linetype=2, col="maroon", linewidth = 1.2)+
  geom_line(aes(y=pred2,col= x>4) , linewidth=1.2)+
  theme_light()
```

### Piecewise polynomial using tidymodels

```{r eval=F}
split <- initial_split(data, prop = 0.8)
train <- training(split)
test <- testing(split)
head(train)

base_rec <- recipe(y~., data=train)

# basis spline
bs_rec <- base_rec %>%
  step_bs(x, degree = 1, knots=1)

# natural spline
ns_rec <- base_rec %>%
  step_ns(x, deg_free = tune())

fit_spline1<-linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

fit<-fit_spline1 %>%
  fit(y~.,data=bs_rec%>%prep()%>%juice())
```

```{r eval=F}
base_rec <- recipe(y~., data=train)

# basis spline
bs_rec <- base_rec %>%
  step_bs(x, degree = tune())

# natural spline
ns_rec <- base_rec %>%
  step_ns(x, deg_free = tune())

fit_spline1<-linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

folds<-vfold_cv(train, v=5, repeats=3)
tune_results<-workflow()%>%
  add_recipe(ns_rec) %>%
  add_model(fit_spline1) %>%
  tune_grid(resamples=folds,
            grid=20,
            control = control_grid(verbose = T,
                                   save_pred = T))
tune_results %>% autoplot()

workflow()%>%
  add_recipe(ns_rec) %>%
  add_model(fit_spline1) %>%
  finalize_workflow(show_best(tune_results,1, metric = "rsq"))%>%
  last_fit(split) %>%
  collect_predictions() 
```
