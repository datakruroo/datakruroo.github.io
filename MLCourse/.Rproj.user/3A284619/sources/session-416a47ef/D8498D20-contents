dat <- read_excel("/Users/siwachoat/Downloads/การบ้าน Simple Regression (Responses) (1).xlsx",
                  sheet=2)
names(dat)[5]<-"text"

dat<-dat%>%select(result, text)
dat %>%
  ggplot(aes(x=factor(result)))+
  geom_bar()

words_per_student <- dat %>%
  unnest_tokens(input = text, output=word) %>%
  count(student_id, name = "total_words")
words_per_student %>%
  ggplot(aes(total_words)) +
  geom_histogram(fill = "midnightblue", alpha = 0.8)


set.seed(123)
split <- initial_split(dat, strata = result)
train <- training(split)
test <- testing(split)


train_rec <- recipe(result ~ ., data = train) %>%
  step_tokenize(text) %>%
  step_stopwords(text) %>%
  step_tokenfilter(text, max_tokens = 180) %>%
  step_tfidf(text) %>%
  step_normalize(all_predictors())





lasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

lasso_wf <- workflow() %>%
  add_recipe(train_rec) %>%
  add_model(lasso_spec)

lasso_wf

lambda_grid <- grid_regular(penalty(), levels = 40)

set.seed(123)
folds <- vfold_cv(train, strata = result)


doParallel::registerDoParallel()

set.seed(2020)
lasso_grid <- tune_grid(
  lasso_wf,
  resamples = folds,
  grid = lambda_grid,
  control = control_grid(save_pred = T),
  metrics = metric_set(roc_auc, sens,spec)
)

lasso_grid %>%
  collect_metrics()

lasso_grid %>%
  collect_metrics() %>%
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_line(size = 1.5, show.legend = FALSE) +
  facet_wrap(~.metric) +
  scale_x_log10()




final_lasso <- finalize_workflow(lasso_wf, best_auc)

final_lasso

final_lasso %>%
  last_fit(split) %>%
  extract_fit_engine() %>%
  vip(family="ChulaCharasNew")+
  theme(text=element_text(family="ChulaCharasNew"))



library(vip)
final_lasso %>%
  last_fit(split) %>%
  extract_fit_engine() %>%
  vi(lambda = best_auc$penalty) %>%
  group_by(Sign) %>%
  top_n(5, wt = abs(Importance)) %>%
  ungroup() %>%
  mutate(
    Importance = abs(Importance),
    Variable = str_remove(Variable, "tfidf_text_"),
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Sign, scales = "free_y") +
  labs(y = NULL)+
  theme(text=element_text(family="ChulaCharasNew"))

mod <- final_lasso %>%
  last_fit(split)

mod %>% collect_predictions() %>%
  roc_curve(truth = result, estimate = .pred_correct) %>%
  autoplot()

train_dat<- train_rec %>% prep(train) %>%
  juice() 

mod %>%
  extract_workflow() %>%
  predict(new_data= train_dat)


test_rec<-train_rec%>%prep() %>%
  bake(test)


predict(fit, test_rec)





set.seed(123)
split<-initial_split(tokenized_dat, strata = sentiment)
train<-training(split)
test<-testing(split)

train_rec <- recipe(sentiment~text, data=train) %>%
  step_tokenize(text) %>%
  step_stopwords(text) %>%
  step_tokenfilter(text) %>%
  step_tfidf(text) %>%
  step_normalize(all_numeric_predictors())


lasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

rf_spec <- rand_forest(mtry = tune(),
                       trees=300,
                       min_n=tune()) %>%
  set_engine("ranger",importance = "permutation") %>%
  set_mode("classification")


wf_set <- workflow_set(
  preproc = list(train_rec),
  models = list(lasso_spec, rf_spec)
)


doParallel::registerDoParallel()

set.seed(2020)
result <- workflow_map(
  wf_set,
  resamples = folds,
  grid = 50,
  control = control_grid(save_pred = T),
  metrics = metric_set(roc_auc, sens,spec)
)

autoplot(result)
