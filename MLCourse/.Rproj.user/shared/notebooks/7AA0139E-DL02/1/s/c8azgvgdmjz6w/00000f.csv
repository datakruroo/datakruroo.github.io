"0","# defined model"
"0","def build_model(hp):"
"0","    model = keras.Sequential()"
"0","    model.add(layers.Flatten(input_shape=(64, 64)))"
"0","    "
"0","    # Tune the number of hidden layers"
"0","    hp_num_layers = hp.Int('num_layers', min_value=1, max_value=2, step=1)"
"0","    for i in range(hp_num_layers):"
"0","        # Tune the number of units in the Dense layer"
"0","        hp_units = hp.Int('units_' + str(i), min_value=400, max_value=2000, step=200)"
"0","        "
"0","        # Tune the L1 regularization factor"
"0","      #  hp_l1 = hp.Float('l1_' + str(i), min_value=0, max_value=0.1, step=0.01)"
"0","        # Tune the L2 regularization factor"
"0","      #  hp_l2 = hp.Float('l2_' + str(i), min_value=0, max_value=0.1, step=0.01)"
"0","        model.add(layers.Dense(units=hp_units)) #kernel_regularizer=keras.regularizers.l1_l2(l1=hp_l1, l2=hp_l2)))"
"0","        model.add(layers.Activation('relu'))"
"0","        "
"0","        # Tune the dropout rate"
"0","        #hp_dropout = hp.Float('dropout_' + str(i), 0, 0.5, step=0.1)"
"0","        #model.add(layers.Dropout(hp_dropout))"
"0","      "
"0","    model.add(layers.Dense(10, activation='softmax'))"
"0","    "
"0","    # Tune the learning rate"
"0","    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])"
"0","    "
"0","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),"
"0","                  loss='categorical_crossentropy',"
"0","                  metrics=['accuracy'])"
"0","    "
"0","     # Create an ImageDataGenerator instance with the desired augmentations"
"0","    datagen = ImageDataGenerator("
"0","        rotation_range=20,"
"0","        width_shift_range=0.2,"
"0","        height_shift_range=0.2,"
"0","        zoom_range=0.2,"
"0","        horizontal_flip=True,"
"0","        fill_mode='nearest'"
"0","    )"
"0","    "
"0","    # Fit the generator on your data"
"0","    datagen.fit(train_x)"
"0","    "
"0","    # Use the generator for training your model"
"0","    history = model.fit_generator("
"0","        datagen.flow(train_x, train_y, batch_size=32),"
"0","        steps_per_epoch=len(train_x) // 32,"
"0","        epochs=50,"
"0","        validation_data=(test_x, test_y)"
"0","    )"
"0","    return model"
"0",""
