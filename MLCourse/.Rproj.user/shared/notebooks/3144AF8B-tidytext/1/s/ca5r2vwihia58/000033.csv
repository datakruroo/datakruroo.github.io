"0",""
"0","tokenized_dat <- temp %>%"
"0","  unnest_tokens(input = token, token = ""words"", "
"0","                output = word)"
"0","glimpse(tokenized_dat, width=60)"
"1","Rows: 6,493"
"1",""
"1","
"
"1","Columns: 4"
"1",""
"1","
"
"1","$ section [3m[38;5;246m<chr>[39m[23m ""sec 1"", ""sec 1"", ""sec 1"", ""sec 1"", ""sec 1‚Ä¶
$ text    [3m[38;5;246m<chr>[39m[23m ""‡∏ß‡∏¥‡∏ä‡∏≤‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏£‡∏ß‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‚Ä¶
$ id      [3m[38;5;246m<int>[39m[23m 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶
$ word    [3m[38;5;246m<chr>[39m[23m ""‡∏ß‡∏¥‡∏ä‡∏≤"", ""‡∏ß‡∏¥‡∏à‡∏±‡∏¢"", ""‡πÑ‡∏°‡πà"", ""‡∏Ñ‡∏ß‡∏£"", ""‡πÉ‡∏ä‡πâ"", ""‡∏ß‡∏¥‡∏ò‡∏µ"", ""‡∏™‡∏≠‚Ä¶"
"1",""
"1","
"
