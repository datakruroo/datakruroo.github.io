"0","pythainlp <- import(""pythainlp"")"
"0","# Define a custom tokenization function for textrecipes"
"0","tokenize_thai <- function(text) {"
"0","  tokens <- lapply(text, pythainlp$word_tokenize, engine=""newmm"")"
"0","  tokens_list <- lapply(tokens, function(x) {"
"0","                              paste(x, collapse = "" "")})"
"0","  tokens_list <- unlist(tokens_list)"
"0","return(tokens_list)"
"0","}"
"0","## tokenized via mutate function"
"0","temp<-dat %>%"
"0","  mutate(token = tokenize_thai(text))"
"0","head(temp)"
