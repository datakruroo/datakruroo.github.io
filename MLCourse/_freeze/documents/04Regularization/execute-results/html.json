{
  "hash": "e0ab2cf833af322731ed99d4a5382605",
  "result": {
    "markdown": "---\ntitle: \"Regularization\"\nauthor: \"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร\"\ntoc: true\ntoc-depth: 3\ntoc-title: สารบัญ\ntheme: default\n---\n\n::: {.cell}\n\n:::\n\n\n# บทที่ 6 : Regularized Regression\n\nLinear regression เป็นโมเดลทำนายที่มีจุดเด่นคือเป็นโมเดลอย่างง่ายที่นอกจากจะใช้ทำนายแนวโน้มของตัวแปรอิสระได้แล้ว ยังสามารถใช้ในการอธิบายความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระได้ง่ายและชัดเจนกว่าการใช้โมเดลการเรียนรู้อื่น ๆ อย่างไรก็ตามการใช้งาน linear regression นั้นอยู่ภายใต้ข้อจำกัดหรือข้อตกลงเบื้องต้นที่เคร่งครัดหลายตัว ซึ่งหากข้อตกลงเบื้องต้นดังกล่าวไม่เป็นจริงแล้วการทำนายหรือการอธิบายความสัมพันธ์ด้วย linear regression ก็อาจจะมีปัญหาและขาดความน่าเชื่อถือ\n\nบทเรียนนี้จะ focus ไปที่ปัญหาหนึ่งที่สำคัญและเกิดขึ้นบ่อยในการพัฒนาโมเดลทำนายทั้งใน linear regression และอัลกอริทึมอื่น ๆ คือการที่โมเดลทำนายมีจำนวนตัวแปรอิสระหรือเทอมของตัวแปรอิสระมากเกินไป สถานการณ์ดังกล่าวอาจก่อให้เกิดปัญหาในเชิงเทคนิคหลายประการ ดังนี้\n\n1.  overfitting model กล่าวคือการมีตัวแปรอิสระหรือเทอมของตัวแปรอิสระ เช่น เทอมพหุนาม (polynomial) หรือเทอมปฏิสัมพันธ์ (interaction) จำนวนมากเกินไปภายในโมเดล ย่อมทำให้โมเดลเรียนรู้ความสัมพันธ์ในชุดข้อมูลฝึกหัดดีเกินไป และก่อให้เกิดปัญหา overfitting ได้\n2.  infinite solution ปัญหานี้เป็นปัญหาเชิงเทคนิค กล่าวคือผู้วิเคราะห์มีจำนวนตัวแปรอิสระหรือเทอมของตัวแปรอิสระ (จำนวนคอลัมน์) ที่ต้องการนำเข้าสู่โมเดลมากกว่าจำนวนหน่วยข้อมูล (จำนวนแถว) สถานการณ์ดังกล่าวทำให้ไม่สามารถหาคำตอบเดียวของค่าประมาณพารามิเตอร์ภายในโมเดลทำนายได้\n3.  multicollinearity ปัญหานี้เป็นปัญหาในเชิงเทคนิคที่เกิดขึ้นเมื่อผู้วิเคราะห์มีตัวแปรอิสระจำนวนมากในโมเดล โดยที่ตัวแปรอิสระดังกล่าวมีความซ้ำซ้อนกัน (redundant) กล่าวคือมีความสัมพันธ์ซึ่งกันและกันเองสูงเกินไป สถานการณ์เช่นนี้จะทำให้การประมาณค่าพารามิเตอร์ในโมเดลมีแนวโน้มที่จะไม่เสถียร (unstable solution) ส่งผลให้โมเดลทำนายที่ได้มีความไม่เสถียรตามไปด้วย โมเดลทำนายที่ได้จากสถานการณ์ดังกล่าวจึงจะขาดความน่าเชื่อถือ\n\nในบทที่ 6 เราได้กล่าวถึงการคัดเลือกตัวแปรอิสระเข้าสู่โมเดลด้วยวิธีในกลุ่ม wrapper method ซึ่งผู้อ่านจะเห็นว่าวิธีการดังกล่าวนั้นมีข้อจำกัดสำคัญคือ เป็นวิธีที่ใช้ข้อมูลจากชุดข้อมูลฝึกหัดในการคัดเลือกตัวแปรอิสระแต่เพียงอย่างเดียว ซึ่งอาจทำให้มีความเสี่ยงสูงที่การพัฒนาโมเดลทำนายภายใต้ผลการคัดเลือกตัวแปรอิสระดังกล่าวจะมีปัญหา overfitting ตามมา บทเรียนนี้จะกล่าวถึงเทคนิค regularization ที่สามารถทำมาใช้เพื่อแก้ปัญหาดังกล่าว ปัจจุบันมีการนำเทคนิคนี้ไปใช้ในหลายโมเดลทั้ง linear regression, decision tree ไปจนถึง neural network โดยในบทเรียนนี้จะกล่าวถึงมโนทัศน์สำคัญของการทำ regularization และการนำเทคนิค regularization ไปใช้ในอัลกอริทึม linear regression รายละเอียดมีดังนี้\n\n## 6.1 มโนทัศน์สำคัญของ regularized regression\n\nconcept ของ regularization เป็นเรื่องเกี่ยวกับการปรับสมดุลของโมเดลทำนายเพื่อลดทอนหรือแก้ปัญหา overfitting และ/หรือ ปัญหาตัวอย่างอิสระ สำหรับโมเดล linear regression การปรับสมดุลดังกล่าวจะเป็นการปรับค่าสัมประสิทธิความชันของสมการถดถอยให้น้อยลงเพื่อ**ลดหรือลบ**ผลกระทบของตัวแปรอิสระบางตัวออกจากโมเดลอย่างเหมาะสม\n\nเพื่อให้ผู้อ่านเห็นภาพและเข้าใจมโนทัศน์ของ regularization ได้อย่างชัดเจน อยากให้ผู้อ่านลองพิจารณาตัวอย่างง่าย ๆ ต่อไปนี้\n\nสมมุติว่าผู้วิเคราะห์ต้องการสร้างโมเดลทำนายคะแนนผลสัมฤทธิ์ทางการเรียนของนักเรียน (ACH) โดยใช้จำนวนชั่วโมงการทบทวนบทเรียนต่อสัปดาห์ของนักเรียน (HOUR) เป็นตัวแปรทำนาย แผนภาพการกระจายด้านล่าง (พิจารณาเฉพาะจุด) จะเห็นว่าความสัมพันธ์ระหว่างตัวแปรทั้งสองมีลักษณะเป็นความสัมพันธ์เชิงเส้น (linear relationship) ที่ค่อนข้างชัดเจน ในกรณีนี้ผู้วิเคราะห์จึงเลือกใช้อัลกอริทึม linear regression เป็นอัลกอริทึมการเรียนรู้ เพื่อสร้างโมเดลทำนายที่ต้องการ\n\nการสร้างโมเดลทำนายด้วย linear regression อัลกอริทึมจะพยายามหาสมการเส้นตรงที่ดีที่สุด โดยการคัดเลือกชุดของสัมประสิทธิ์การถดถอย (จุดตัดแกน y และความชัน) ที่ทำให้ฟังก์ชันวัตถุประสงค์ (objective function) มีค่าสูงหรือต่ำที่สุด โดยทั่วไปฟังก์ชันวัตถุประสงค์มักใช้เป็น sum squared error (SSE) การหาค่าประมาณของสัมประสิทธิ์ถดถอยดังกล่าวจึงเป็นการหาค่าที่ทำให้ SSE มีค่าต่ำที่สุด\n\nการหาค่าประมาณพารามิเตอร์ดังกล่าวสามารถทำได้หลายวิธีการ วิธีการแรกที่มักใช้กันในฝั่ง data analysis คือการใช้การ optimization ด้วย first และ second order derivative (ใช้ขั้นตอนวิธีของ calculas) ในโมเดล linear regression ทั่วไปวิธีการนี้สามารถให้สูตรปิดของการหาค่าประมาณสัมประสิทธิ์การถดถอยดังกล่าวได้ อีกวิธีการหนึ่งคือการใช้อัลกอริทึมเชิงตัวเลข (numerical algorithm) เรียกว่า gradient descent หรือ stochastic gradient descent ซึ่งเป็นกระบวนการทวนซ้ำเพื่อหาชุดของสัมประสิทธิ์การถดถอยที่เหมาะสมที่สุดโดยอิงจากค่าของฟังก์ชันวัตถุประสงค์ที่กำหนด\n\nเมื่อกำหนดให้ข้อตกลงเบื้องต้นอื่น ๆ ของ linear regression เป็นจริง และตัวแปรอิสระที่เลือกเข้าสู่โมเดลเป็นตัวแปรอิสระที่มีคุณภาพ กล่าวคือ (1) ให้สารสนเทศในการทำนายตัวแปรตาม และ (2) ไม่ซ้ำซ้อนกันเองกับตัวแปรอิสระอื่น ๆ โมเดลทำนายที่ได้จากอัลกอริทีมจะมีคุณสมบัติที่ดีในทางสถิติกล่าวคือมีความไม่ลำเอียงและมีความแปรปรวนต่ำที่สุด หนังสือสถิติจะเขียนว่าตัวประมาณที่ได้จาก OLS regression เป็นตัวประมาณ BLUE ซึ่งย่อมาจาก Best Linear Unbised Estimator (สามารถพิสูจน์ได้โดยใช้ Gauss-Markov Theorem)\n\n![Least Squared Regression](images/image-676691868.png){alt=\"Least Squared Regression\" fig-align=\"center\" width=\"70%\"}\n\nโดยปกติ linear regression เป็นโมเดลที่ง่ายที่สุดสำหรับทำนาย กล่าวคือเป็นโมเดลที่มีแนวโน้มจะมีประสิทธิภาพในการทำนายที่ไม่สูงมากนัก แต่จุดเด่นคือมีความยืดหยุ่นในการนำไปใช้ทำนายชุดข้อมูลอื่นนอกเหนือจากชุดข้อมูลฝึกหัดสูง linear regression อย่างไรก็ตามหากหากชุดข้อมูลฝึกหัดไม่ได้เป็นตัวแทนที่ดีของประชากร หรือในขั้นตอนของการพัฒนาโมเดลผู้วิเคราะห์มีการใส่ตัวแปรอิสระหรือเทอมของตัวแปรทำนาย เช่น polynomial หรือ interaction terms ที่ไม่ให้สารสนเทศจำนวนมากเข้าไปในโมเดล สถานการณ์เช่นนี้มักเพิ่มโอกาสที่โมเดลจะเกิดปัญหา overfitting ซึ่งทำให้โมเดลทำนายที่พัฒนาได้นั้นไม่สามารถทำนายชุดข้อมูลทดสอบหรือข้อมูลอื่น ๆ ที่อยู่นอกเหนือชุดข้อมูลฝึกหัดได้อย่างมีประสิทธิภาพ\n\nรูปด้านล่างแสดงสภาพของปัญหา overfitting ที่เกิดขึ้นในโมเดลทำนาย ACH ด้วย HOUR ดังกล่าว จากรูปเมื่อพิจารณาจุดและเส้นโมเดลทำนาย (สีเขียว) จะพบว่าโมเดลเรียนรู้ความสัมพันธ์ระหว่างตัวแปรทั้งสองในชุดข้อมูลฝึกหัดได้ดี แต่เมื่อนำโมเดลดังกล่าวไปใช้ทำนาย ACH ในชุดข้อมูลทดสอบจะพบว่า สมการทำนายเส้นสีเขียวกลายเป็นสมการที่ไม่เหมาะสมในกรณีทั่วไป โดยจะให้ค่าความคลาดเคลื่อนในการทำนาย (SSE) ของชุดข้อมูลทดสอบที่สูงมากกว่า SSE ในชุดข้อมูลฝึกหัดค่อนข้างมาก เส้นสมการทำนายที่เหมาะสมควรเป็นสมการเส้นสีเทาในรูปมากกว่า\n\n![ปัญหา overfitting](images/image-849757700.png){alt=\"ปัญหา overfitting\"}\n\nการแก้ปัญหาดังกล่าวผู้วิเคราะห์จะต้องปรับแต่งโมเดลการทำนายใหม่ให้มีความสมดุลในการทำนายชุดข้อมูลที่ไม่รู้จักได้มากขึ้น เทคนิค regularization ถูกพัฒนาขึ้นเพื่อใช้สำหรับการปรับแต่งโมเดลทำนายดังกล่าว คำถามคือการปรับแต่งโมเดลทำนายนั้นควรดำเนินการอย่างไร?\n\nรูปด้านล่างแสดงแนวคิดหลักของ regularization จากรูปจะเห็นว่าโมเดลทำนายเส้นสีเขียวนั้นเกิดปัญหา overfitting ขึ้นกล่าวคือ โมเดลทำนายดังกล่าวเรียนรู้ความสัมพันธ์ในชุดข้อมูลฝึกหัด (จุดสีเขียว) ได้ดีมากเกินไป กล่าวคือโมเดลทำนายนี้มีความแปรปรวนสูงมากเกินไปนั่นเอง จากมโนทัศน์เกี่ยวกับ bias & variance trace-off เราทราบว่าความลำเอียงกับความแปรปรวนของโมเดลทำนายนั้นมีความสัมพันธ์ที่ผกผันกัน โดยโมเดลที่มีความลำเอียงต่ำมีแนวโน้มที่จะมีความแปรปรวนสูง ในทางกลับกันโมเดลที่มีความลำเอียงสูงก็มีแนวโน้มที่จะมีความแปรปรวนต่ำ ดังนั้นจากความสัมพันธ์นี้หากผู้วิเคราะห์มีโมเดลทำนายที่มีความแปรปรวนสูง ผู้วิเคราะห์อาจปรับแต่งโมเดลทำนายดังกล่าวให้มีความแปรปรวนต่ำลงได้ด้วยการเพิ่มความลำเอียงให้กับโมเดลทำนายดังกล่าวอย่างเหมาะสม ดังตัวอย่างในรูป (b) ด้านล่าง\n\n![main idea ของ regularization](images/image-343319787.png){alt=\"main idea ของ regularization\"}\n\nสำหรับ linear regression สามารถใส่ความลำเอียงให้กับโมเดลทำนายได้ในขั้นตอนของการหาค่าประมาณพารามิเตอร์ของโมเดล โดยปรับสูตรของฟังก์ชันวัตถุประสงค์ใหม่จากเดิม $SSE = \\sum_{i=1}^n(y_i-\\hat{y}_i)^2$ เป็น\n\n$$\nSSE_{reg}=\\sum_{i=1}^n(y_i-\\hat{y}_i)^2 + P = SSE + P\n$$\n\nเรียกเทอม $P$ ในสมการข้างต้นว่า penality term หนังสือบางเล่มเลยอาจใช้ชื่อ penalized regression แทน regularized regression ผู้อ่านลองสังเกตการบวกเทอม $P$ ดังกล่าวในฟังก์ชันวัตถุประสงค์ โดยจะเห็นว่าเมื่อ $P>0$ จะทำให้ค่า $SSE_{reg} > SSE$ ซึ่งเป็นการทำให้ค่าประมาณพารามิเตอร์ได้แก่ สัมประสิทธิจุดตัดแกน และความชันในโมเดลทำนายนั้น มีแนวโน้มที่มีความลำเอียงมากกว่าโมเดลทำนายที่ไม่ได้ใส่ penalty term ดังกล่าว ซึ่งหากใส่อย่างเหมาะสมจะช่วยลดความแปรปรวนของโมเดลทำนายได้อย่างที่ได้กล่าวไปแล้ว\n\nค่า$P$ ดังกล่าวไม่ใช่พารามิเตอร์ที่สามารถประมาณได้โดยตรงจากข้อมูล กล่าวคือเป็น hyperparameter ที่ต้องกำหนดโดยผู้วิเคราะห์ก่อนที่จะดำเนินการประมาณค่าพารามิเตอร์ของโมเดล **คำถามใหญ่ของการทำ regularization จึงเกิดขึ้นว่า** **การกำหนดค่า** $P$ **ดังกล่าวให้เหมาะสมควรดำเนินการอย่างไร?**\n\nแนวคิด regularization ดังกล่าวสามารถนำไปประยุกต์ใช้กับอัลกอริทึมการเรียนรู้ได้อีกหลายตัว เช่น ใน regularized logistic regression ฟังก์ชันวัตถุประสงค์จะสามารถเขียนได้เป็น $lnL + P$ เมื่อ $lnL$ คือ log-likelihood function ของโมเดล หรือใน decision tree (มักเรียกว่า pruning tree) ฟังก์ชันวัตถุประสงค์จะเขียนได้เป็น $R_{reg}(T) = R(T) + \\alpha|T|$ โดยที่ $R(T)$ คือ training error ของ decision tree ที่มีจำนวน terminal nodes เท่ากับ $T$ และจะเรียก $\\alpha$ ว่า cost complexity hyperparameter\n\n## 6.2 ประเภทของ Regularization\n\nการกำหนดค่า $P$ ให้กับฟังก์ชันวัตถุประสงค์ในข้างต้นอาจดำเนินการโดยจำแนกได้เป็น 3 วิธี ดังนี้\n\n1.  Ridge regression\n2.  Lasso regression\n3.  Elastic-Net regression\n\n### Ridge Regression\n\nฟังก์ชันวัตถุประสงค์ของ regularized regression ประเภท ridge regression สามารถเขียนได้ดังนี้\n\n$$\nSSE_{ridge} = SSE+\\lambda\\sum_{j=1}^kb_j^2\n$$\n\nจากสมการข้างต้นจะเห็นว่า $P = \\lambda\\sum_{j=1}^kb_j^2$ คือ penalty term ในกรณีนี้จะเรียกว่า ridge regression penalty หรือหนังสือบางเล่มอาจจะเรียกว่า L2 norm การกำหนด penalty term ดังกล่าวทำให้เกิดผลอย่างไรต่อการพัฒนาโมเดลทำนาย สามารถทำความเข้าใจง่าย ๆ ได้จากการพิสูจน์ด้านล่าง ผู้อ่านจะเห็นว่าตัวประมาณของสัมประสิทธิ์การถดถอยใน ridge regression จะมีเทอม $\\lambda$ เพิ่มเข้ามาในเทอมตัวหาร เมื่อเปรียบเทียบกับ linear regression แบบ OLS ธรรมดา ผู้อ่านจะเห็นได้อย่างชัดเจนว่าเมื่อ $\\lambda = 0$ ค่าประมาณของสัมประสิทธิ์ความชันจากทั้งสองวิธีการจะเท่ากัน แต่เมื่อกำหนดให้ $\\lambda>0$ ค่าประมาณของสัมประสิทธิ์ความชันที่ได้จาก ridge regression จะมีแนวโน้มที่ลดลงต่ำกว่า ols regression อย่างไรก็ตามหากลองพิจารณา $lim_{\\lambda \\rightarrow \\infty}\\frac{\\sum x_iy_i}{\\sum x_i^2+\\lambda}$ จะพบว่าค่าสัมประสิทธิ์ความชันของ ridge regression จะมีค่าลู่เข้าใกล้ 0 แต่จะไม่เท่ากับ 0\n\n![](images/image-75951276.png)\n\nจากผลในข้างต้นจะเห็นว่า ridge regression เป็นเทคนิคที่ช่วยปรับขนาดของสัมประสิทธิ์ความชันของตัวแปรอิสระในโมเดลให้มีค่าลดลง แต่จะไม่ได้ทำให้เป็น 0 ดังนั้นตัวแปรอิสระทั้งหมดที่ผู้วิเคราะห์นำเข้าในอัลกอริทึมตอนแรกนั้นจะอยู่ในโมเดลทำนายครบทุกตัว แต่จะถูกปรับลดขนาดของค่าสัมประสิทธิ์ความชันลง ดังนั้น ridge regression จึงไม่ใช่เทคนิคสำหรับคัดเลือกตัวแปรอิสระ แต่เป็นเทคนิคที่เหมาะสำหรับแก้ปัญหา multicollinearity มากกว่า ดังนั้น ridge regression จึงเหมาะที่จะใช้ในสถานการณ์ที่ผู้วิเคราะห์มีตัวแปรอิสระจำนวนมากและตัวแปรดังกล่าวมีความสัมพันธ์กันเองสูงหรือมีความซ้ำซ้อนกัน แต่ผู้วิเคราะห์ไม่ต้องการที่จะตัดตัวแปรอิสระตัวใดออกจากโมเดลทำนาย อัลกอริทึม ridge regression จะช่วยให้ผู้วิเคราะห์สามารถสร้างโมเดลทำนายที่มีตัวแปรอิสระทั้งหมดอยู่ภายในโมเดลโดยหลีกเลี่ยงหรือลดทอนผลกระทบที่เกิดจากปัญหา multicollinearity ได้\n\nข้อสังเกตหนึ่งคือถึงแม้ว่าในชุดข้อมูลของผู้วิเคราะห์จะมีตัวแปรอิสระที่ไม่ให้สารสนเทศในการทำนายอยู่ด้วย แต่ ridge regression ก็จะไม่ได้ตัดตัวแปรอิสระดังกล่าวออกจากโมเดล ภายใต้สถานการณ์ดังกล่าวการใช้อัลกอริทึม ridge regression ก็จะไม่เหมาะสมควรเปลี่ยนไปใช้ lasso หรือ elastic-net regression มากกว่า\n\n### Lasso Regression\n\nLasso regression เป็นอัลกอริทึมที่ถูกพัฒนาขึ้นโดยมีวัตถุประสงค์หลักคือการคัดเลือกตัวแปรอิสระ (feature selection) เข้าสู่โมเดลทำนาย อัลกอริทึมนี้เป็น feature selection ที่จัดอยู่ในกลุ่ม embedded method กล่าวคือเป็นอัลกอริทึมการเรียนรู้ที่มีอัลกอริทึมของการคัดเลือกตัวแปรอิสระรวมอยู่ในขั้นตอนการประมาณค่าพารามิเตอร์ของโมเดล หลักการของ lasso regression เหมือนกับ ridge regression แต่มีการใช้ penalty term ในฟังก์ชันวัตถุประสงค์ที่แตกต่างออกไปดังนี้\n\n$$\nSSE_{lasso} = SSE+\\lambda\\sum_{j=1}^k |b_j|\n$$\n\nจะเห็นว่ามีการเปลี่ยนแปลงจากการใช้ฟังก์ชันกำลังสองเป็นค่าสมบูรณ์ใน penalty term ผลกระทบที่เกิดขึ้นกับโมเดลทำนายเมื่อใช้ penalty term ดังกล่าวสามารถอธิบายได้โดยใช้การพิสูจน์ง่าย ๆ ด้านล่าง ผู้อ่านจะเห็นว่าตัวประมาณของสัมประสิทธิ์ความชันในโมเดลทำนายมีรูปแบบที่เปลี่ยนแปลงไปจาก ridge regression โดยเทอม $\\lambda$ ไม่ได้อยู่ในส่วนของตัวเศษแล้ว แต่ขึ้นมาอยู่ที่ตัวเศษแทน ดังนั้นการกำหนด $\\lambda$ ที่เหมาะสมจึงสามารถทำให้ค่าสัมประสิทธิ์ความชันดังกล่าวมีค่าเท่ากับ 0 ได้ ซึ่งหมายถึงการตัดตัวแปรอิสระดังกล่าวออกจากโมเดลทำนาย ด้วยหลักการดังกล่าวอัลกอริทึม lasso regression จึงสามารถคัดเลือกตัวแปรอิสระเข้าสู่โมเดลได้ด้วยการกำหนดค่า $\\lambda$ ดังกล่าว\n\n![](images/image-1836348765.png){width=\"50%\"}\n\n### Elastic-Net Regression\n\nอัลกอริทึมนี้เป็นการผสมกันระหว่าง ridge และ lasso regression จึงเป็นอัลกอริทึมที่สามารถใช้ทั้งแก้ปัญหา multicollineatiry และคัดเลือกตัวแปรอิสระไปพร้อม ๆ กัน ฟังก์ชันวัตถุประสงค์ของ elastic-net regression เป็นดังนี้\n\n$$\nSSE_{elasticnet}=SSE+(1-\\alpha)\\lambda_1\\sum_{j=1}^kb_j^2+\\alpha\\lambda_2\\sum_{j=1}^k|b_j|\n$$\n\nโดยที่ $\\alpha$ เรียกว่า mixing parameter ซึ่งมีค่าที่เป็นไปได้อยู่บนช่วง 0 ถึง 1 ทำหน้าที่สำหรับกำหนดน้ำหนักให้กับ penalty term ทั้งสอง\n\n$\\lambda$ และ $\\alpha$ ที่อยู่ในฟังก์ชันวัตถุประสงค์ของอัลกอริทึมทั้ง 3 ตัวเป็น hyperparameters ของอัลกอริทึม กล่าวคือผู้วิเคราะห์จะต้องกำหนดค่าของพารามิเตอร์ทั้งสองเอง ในทางปฏิบัติผู้วิเคราะห์สามารถปรับแต่งค่า hyperparameters ดังกล่าวได้โดยใช้ตัวอย่างที่ได้จากการสุ่มซ้ำ เช่น cross-validation หรือ bootstraping ในทำนองเดียวกับการปรับแต่ง hyperparameter ของ decision tree ที่กล่าวถึงในบทที่ 5\n\n## 6.3 Implement regularized regression using tidymodels\n\nการพัฒนาโมเดลทำนายโดยใช้การทำ regularization ใน R สามารถทำได้หลายวิธี เช่น การใช้ฟังก์ชัน `cv.glmnet()` ของ package glmnet หรือการใช้ `tuneGrid()` ใน package caret ในหัวข้อนี้จะกล่าวถึงการพัฒนาอัลกอริทึมดังกล่าวภายใต้ tidymodels framework ชุดข้อมูลที่ใช้เป็นตัวอย่างจะมี 2 ชุด ชุดแรกคือ [`TeacherSalaryData.csv`](https://github.com/ssiwacho/2758688_ML/blob/main/week%201/TeacherSalaryData.csv) และชุดที่สองคือ [`gpax.csv`](https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week4/gpax.csv)\n\n### โมเดลทำนายเงินเดือนครู\n\nตัวอย่างนี้จะพัฒนาโมเดลทำนายเงินเดือนครูโดยจะใช้อัลกอริทึม regularization ก่อนที่จะเริ่มพัฒนาโมเดล ผู้วิเคราะห์ควรเริ่มจากการสำรวจข้อมูลเบื้องต้นก่อน จากวัตถุประสงค์ของงานนี้อาจจำแนกการสำรวจข้อมูลออกเป็นสองส่วน ส่วนแรกคือการสำรวจรูปแบบตารางข้อมูล ขอบเขตข้อมูล และลักษณะการจัดเก็บ/บันทึกข้อมูล และส่วนที่สองคือการสำรวจลักษณะความสัมพันธ์ระหว่างตัวแปรตามคือเงินเดือนครู (salary) และตัวแปรอิสระต่างในโมเดล\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ntidymodels_prefer()\n#importing data\ndat <- read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/TeacherSalaryData.csv\")\nglimpse(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 397\nColumns: 7\n$ X             <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ rank          <chr> \"Prof\", \"Prof\", \"AsstProf\", \"Prof\", \"Prof\", \"AssocProf\",…\n$ discipline    <chr> \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"…\n$ yrs.since.phd <int> 19, 20, 4, 45, 40, 6, 30, 45, 21, 18, 12, 7, 1, 2, 20, 1…\n$ yrs.service   <int> 18, 16, 3, 39, 41, 6, 23, 45, 20, 18, 8, 2, 1, 0, 18, 3,…\n$ sex           <chr> \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", …\n$ salary        <int> 139750, 173200, 79750, 115000, 141500, 97000, 175000, 14…\n```\n:::\n:::\n\n\nจากผลการสำรวจข้อมูลข้างต้นจะเห็นว่าชุดข้อมูลดังกล่าวเป็นชุดข้อมูลขนาดเล็ก มีรูปแบบตารางเป็นแบบ tidydata แล้ว โดยมีหน่วยข้อมูลทั้งหมดจำนวน 397 หน่วย มีตัวแปรที่สามารถนำมาใช้เป็นตัวแปรอิสระในโมเดลได้ 5 ตัวแปร ได้แก่ `rank`, `discipline`, `yrs.since.phd`, `yrs.service` และ `sex` ผู้อ่านจะเห็นว่าตัวแปรอิสระดังกล่าวมีทั้งตัวแปรที่เป็นเชิงปริมาณ และตัวแปรจัดประเภท โดยในกลุ่มของตัวแปรจัดประเภทพบว่าทุกตัวแปรถูกจัดเก็บอยู่ในรูปแบบของตัวอักษร ซึ่งไม่เหมาะสมที่จะนำเข้าสู่โมเดลทำนาย\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# exploring data using statistics\nsummary(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       X           rank            discipline        yrs.since.phd  \n Min.   :  1   Length:397         Length:397         Min.   : 1.00  \n 1st Qu.:100   Class :character   Class :character   1st Qu.:12.00  \n Median :199   Mode  :character   Mode  :character   Median :21.00  \n Mean   :199                                         Mean   :22.31  \n 3rd Qu.:298                                         3rd Qu.:32.00  \n Max.   :397                                         Max.   :56.00  \n  yrs.service        sex                salary      \n Min.   : 0.00   Length:397         Min.   : 57800  \n 1st Qu.: 7.00   Class :character   1st Qu.: 91000  \n Median :16.00   Mode  :character   Median :107300  \n Mean   :17.61                      Mean   :113706  \n 3rd Qu.:27.00                      3rd Qu.:134185  \n Max.   :60.00                      Max.   :231545  \n```\n:::\n\n```{.r .cell-code}\ndat %>% \n  select(salary, yrs.since.phd, yrs.since.phd) %>% \n  cor()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 salary yrs.since.phd\nsalary        1.0000000     0.4192311\nyrs.since.phd 0.4192311     1.0000000\n```\n:::\n\n```{.r .cell-code}\n# exploring data using visualization\ndat %>% \n  select(-X) %>% \n  pivot_longer(cols=c(\"yrs.since.phd\",\"yrs.service\"),\n               names_to=\"predictor\",values_to=\"value\")%>%\n  ggplot()+\n  geom_point(aes(x=value, y=salary))+\n  facet_wrap(.~ factor(predictor),\n             scales = \"free_x\")\n```\n\n::: {.cell-output-display}\n![](04Regularization_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndat %>% \n  select(-X) %>% \n  pivot_longer(cols=c(\"discipline\",\"rank\",\"sex\"),\n               names_to=\"predictor\",values_to=\"value\")%>%\n  ggplot()+\n  geom_boxplot(aes(x=value, y=salary, fill=value))+\n  facet_wrap(.~ factor(predictor),\n             scales = \"free_x\")+\n  theme(legend.position=\"none\")\n```\n\n::: {.cell-output-display}\n![](04Regularization_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\nนอกจากนี้ผู้วิเคราะห์ยังลองตรวจสอบว่ามีอิทธิพลปฏิสัมพันธ์ระหว่างตัวแปรอิสระที่มีต่อตัวแปรตามหรือไม่ โดยใช้ visualization เป็นเครื่องมือตรวจสอบเช่นเดียวกัน\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04Regularization_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](04Regularization_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nผลการสำรวจความสัมพันธ์ระหว่างตัวแปรข้างต้นเป็นอย่างไร ?\n\nใน tidymodels framework การเรียกใช้อัลกอริทึม ridge regression, lasso regression หรือ elastic-net regression สามารถทำได้โดยเลือก model type เป็น `linear_reg()` และกำหนด engine เป็น `glmnet` เมื่อพิจารณาการกำหนดอาร์กิวเมนท์ของ glmnet ในคู่มือ <https://www.tidymodels.org/find/parsnip/> พบว่า engine ดังกล่าวสามารถใช้ได้กับ model type ทั้ง linear regression, logistic regression และ multinomial regression ซึ่งสอดคล้องกับที่ได้กล่าวในส่วนภาคทฤษฎีว่าหลักของการ regularization สามารถนำไปใช้ได้กับอัลกอริทึมการเรียนรู้ได้มากมาย\n\nจากตารางจะเห็นว่า glmnet มีอาร์กิวเมนท์ 2 ตัวได้แก่ `penalty` และ `mixture` ที่เป็น hyperparameters ของอัลกอริทึม โดยที่\n\n-   `penalty` คือ regularization hyperparameter\n\n-   `mixture` คือสัดส่วนของ lasso penalty (เท่ากับค่า $\\alpha$ ใน part ทฤษฎี) หาก $\\alpha =1$ หมายถึงกำหนดให้ใช้อัลกอริทึมแบบ lasso แต่หาก $\\alpha = 0$ หมายถึงกำหนดให้ใช้อัลกอริทึม ridge regression และหากกำหนดให้ $\\alpha \\in (0,1)$ หมายถึงกำหนดให้ใช้ elastic-net regression\n\n#### Data Preprocessing Note:\n\nผู้วิเคราะห์จะต้องแปลงค่าของตัวแปรจัดประเภทให้เป็นตัวแปร dummy หรือตัวแปรแบบ indicator (หรือที่เรียกว่า one-hot encoding) ในกรณีที่ผู้วิเคราะห์เก็บข้อมูลของตัวแปรจัดประเภทเป็นแบบ factor ฟังก์ชัน `fit()` จะแปลงข้อมูลของตัวแปรแบบ factor ให้เป็น indicator โดยอัตโนมัติ สำหรับตัวแปรเชิงปริมาณจำเป็นที่ต้องทำการแปลงให้เป็นสเกลมาตรฐานก่อน\n\nตัวอย่างต่อไปนี้จะแสดงการ fit regularized regression ด้วย parsnip โดยยังไม่มีการปรับแต่ง hyperparameter ก่อน ส่วนตัวอย่างที่แสดงการพัฒนาอัลกอริทึมเต็มรูปแบบจะแสดงในส่วนถัดไป คำสั่งในส่วนแรกแสดงการแบ่งชุดข้อมูลเป็น training และ test dataset นอกจากนี้ยังแสดงการทำ feature engineering เพื่อทำให้ข้อมูลของตัวแปรอิสระเป็นไปตามข้อตกลงเบื้องต้นของการวิเคราะห์ regularized regression ผลลัพธ์ที่ได้จากขั้นตอนนี้คือชุดข้อมูล training และ test ที่ผ่านการทำ preprocessing แล้ว\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#data splitting\nsplit <- initial_split(data = dat, prop=0.8)\ntrain <- training(split)\ntest <- testing(split)\n#data preprocessing \nrec_dat <- recipe(salary ~., data = train) %>%\n  #remove X\n  step_select(-X) %>%\n  #create dummy variable\n  step_dummy(rank, discipline, sex) %>% \n  #standarized numeric\n  step_normalize(all_numeric_predictors()) %>% \n  #create interaction term\n  step_interact(terms = ~ yrs.since.phd:starts_with(\"discipline\")) %>%\n  prep(training_data = train)\nrec_dat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          6\n\nTraining data contained 317 data points and no missing data.\n\nOperations:\n\nVariables selected rank, discipline, yrs.since.phd, yrs.servi... [trained]\nDummy variables from rank, discipline, sex [trained]\nCentering and scaling for yrs.since.phd, yrs.service, rank_AsstProf, rank... [trained]\nInteractions with yrs.since.phd:discipline_B [trained]\n```\n:::\n\n```{.r .cell-code}\n# create preprocessed train and test dataset\ntrain_preproc <- rec_dat %>% bake(NULL)\ntest_preproc <- rec_dat %>% bake(new_data = test)\nglimpse(train_preproc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 317\nColumns: 8\n$ yrs.since.phd                <dbl> -1.373480851, 0.538823391, -0.838035663, …\n$ yrs.service                  <dbl> -1.1495342, -0.7672405, -0.6143231, 1.602…\n$ salary                       <int> 73000, 204000, 83001, 151445, 124714, 675…\n$ rank_AsstProf                <dbl> 2.0453563, -0.4873701, -0.4873701, -0.487…\n$ rank_Prof                    <dbl> -1.3323229, 0.7482011, -1.3323229, 0.7482…\n$ discipline_B                 <dbl> -1.1444317, -1.1444317, -1.1444317, 0.871…\n$ sex_Male                     <dbl> 0.316823, 0.316823, 0.316823, 0.316823, 0…\n$ yrs.since.phd_x_discipline_B <dbl> 1.571855026, -0.616646570, 0.959074579, 0…\n```\n:::\n:::\n\n\nตัวอย่างต่อไปนี้แสดงการระบุโมเดลด้วย engine glmnet โดยตัวอย่างแรกนี้จะกำหนดให้อาร์กิวเมนท์ `penalty = 0` ผลการวิเคราะห์ที่ได้จากการระบุโมเดลนี้จะเท่ากับ ols regression แบบปกติ\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#model specification: ols regression\nregularized_reg <- linear_reg(mixture = 0, penalty = 0) %>% \n  set_engine(engine = \"glmnet\") %>%\n  set_mode(\"regression\")\nreg_fit <- regularized_reg %>% \n  fit(salary ~., data = train_preproc)\n#ols regression estimate\ntidy(reg_fit)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'Matrix'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoaded glmnet 4.1-6\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 3\n  term                         estimate penalty\n  <chr>                           <dbl>   <dbl>\n1 (Intercept)                   113152.       0\n2 yrs.since.phd                   3010.       0\n3 yrs.service                    -1075.       0\n4 rank_AsstProf                  -5311.       0\n5 rank_Prof                      14202.       0\n6 discipline_B                    6598.       0\n7 sex_Male                         976.       0\n8 yrs.since.phd_x_discipline_B     731.       0\n```\n:::\n:::\n\n\nการใช้ tidymodels framework ช่วยให้ผู้วิเคราะห์สามารถเรียกดูค่าประมาณของสัมประสิทธิ์ความชันของโมเดลในกรณีที่มีการกำหนด penalty hyperparameter ต่าง ๆ ได้ เช่น\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(reg_fit, penalty=10000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 3\n  term                         estimate penalty\n  <chr>                           <dbl>   <dbl>\n1 (Intercept)                   113181.   10000\n2 yrs.since.phd                   2885.   10000\n3 yrs.service                      714.   10000\n4 rank_AsstProf                  -5247.   10000\n5 rank_Prof                      10587.   10000\n6 discipline_B                    5203.   10000\n7 sex_Male                        1055.   10000\n8 yrs.since.phd_x_discipline_B     900.   10000\n```\n:::\n\n```{.r .cell-code}\n# magnitude of b\nreg_fit%>%\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](04Regularization_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nจากตัวอย่างการวิเคราะห์ข้างต้นจะเห็นว่าเมื่อกำหนดให้ penalty term มีค่ามากขึ้นเรื่อย ๆ ค่าของสัมประสิทธิ์ความชันของโมเดลจะมีแนวโน้มลู่เข้าหา 0 ดังที่ได้กล่าวไว้ในในส่วนทฤษฎี\n\nผลการวิเคราะห์ต่อไปนี้แสดงการเปรียบเทียบประสิทธิภาพของการทำนายที่ได้จากโมเดล ridge regression ที่มีการกำหนด penalty term เท่ากับ 0, 5000 และ 10000 ตามลำดับ\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred1 <- predict(reg_fit, new_data = test_preproc)\npred2 <- predict(reg_fit, new_data = test_preproc, penalty = 5000)\npred3 <- predict(reg_fit, new_data = test_preproc, penalty = 10000)\ntest_preproc %>%\n  dplyr::select(salary) %>%\n  bind_cols(pred1, pred2, pred3) %>%\n  rename( pred_ols = .pred...2 ,\n          pred_ridge5k = .pred...3,\n          pred_ridge_10k = .pred...4) %>%\n  pivot_longer(cols = starts_with(\"pred\"),\n               names_to = \"model\",\n               values_to = \"pred_value\") %>%\n  group_by(model) %>%\n  summarise(rmse = sqrt(mean((salary-pred_value)^2)),\n            rsq = cor(salary, pred_value)^2\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n• `.pred` -> `.pred...2`\n• `.pred` -> `.pred...3`\n• `.pred` -> `.pred...4`\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  model            rmse   rsq\n  <chr>           <dbl> <dbl>\n1 pred_ols       24395. 0.300\n2 pred_ridge5k   24608. 0.288\n3 pred_ridge_10k 24909. 0.272\n```\n:::\n:::\n\n\nผลลัพธ์ที่ได้ข้างต้นแสดงให้เห็นว่าการกำหนด penalty term ที่แตกต่างกันมีผลต่อประสิทธิภาพในการทำนายของโมเดล อย่างไรก็ตามวิธีการข้างต้นไม่ใช่วิธีที่มีประสิทธิภาพที่จะให้หาค่าที่ดีที่สุดของ hyperparameters ทั้งสองค่าดังกล่าว ตัวอย่างต่อไปจะแสดงการใช้ k-folds cross-validation เข้ามาช่วยเฟ้นหาค่า hyperparameters ที่เหมาะสม คำสั่งด้านล่างแสดงการใช้ workflow ของ tidymodels เข้ามาช่วยปรับแต่งค่า hyperparameters ดังกล่าว รูปด้านล่างแสดงลักษณะของ workflow ซึ่งจะเห็นว่าเป็นการรวม object สองชนิดเข้าด้วยกันคือ recipe และ parsnip\n\n![tidymodels workflow (ดัดแปลงจาก Mark Khun)](images/image-1608202707.png){alt=\"tidymodels workflow (ดัดแปลงจาก Mark Khun)\"}\n\nคำสั่งต่อไปนี้แสดงการปรับแต่ง hyperparameter ด้วย workflow ของ tidymodels ดังกล่าว\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create repeated 10-folds CV datasets\nfolds_data <- vfold_cv(data = train, \n                       v = 10, \n                       repeats = 3)\nfolds_data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#  10-fold cross-validation repeated 3 times \n# A tibble: 30 × 3\n   splits           id      id2   \n   <list>           <chr>   <chr> \n 1 <split [285/32]> Repeat1 Fold01\n 2 <split [285/32]> Repeat1 Fold02\n 3 <split [285/32]> Repeat1 Fold03\n 4 <split [285/32]> Repeat1 Fold04\n 5 <split [285/32]> Repeat1 Fold05\n 6 <split [285/32]> Repeat1 Fold06\n 7 <split [285/32]> Repeat1 Fold07\n 8 <split [286/31]> Repeat1 Fold08\n 9 <split [286/31]> Repeat1 Fold09\n10 <split [286/31]> Repeat1 Fold10\n# … with 20 more rows\n```\n:::\n:::\n\n\nจะเห็นว่า repeated 10-folds CV เป็นการทำ 10-folds CV ซ้ำจำนวน 3 ครั้ง ผลลัพธ์ข้างต้นจึงจะเห็นว่าเป็น tibble ขนาด 30 x 3\n\n### ตัวอย่างการสร้าง workflow เพื่อทำ hyperparameter tuning : Ridge Regression\n\nขั้นตอนต่อไปเป็นการสร้าง workflow สำหรับพัฒนา regularized regression จากรูปจากข้างจะเห็นว่า workflow หนึ่ง ๆ ประกอบด้วยส่วนของการเตรียมข้อมูล และ modelling ที่จัดเก็บอยู่ใน recipe และ parsnip objects รายละเอียดของชุดคำสั่งมีดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#data preprocessing specification\ndat_rec <- recipe(salary ~., data = train) %>%\n  step_select(-X) %>%\n  step_dummy(rank, discipline, sex) %>% \n  step_normalize(all_numeric_predictors()) %>% \n  step_interact(terms = ~ yrs.since.phd:starts_with(\"discipline\"))\n#model specification\nregularized_reg <- linear_reg(penalty = tune(),\n                              mixture = 0) %>% #ridge regression\n  set_mode(\"regression\") %>%\n  set_engine(\"glmnet\")\n#create a workflow object\nregularized_workflow <- workflow() %>%\n  add_recipe(dat_rec) %>%\n  add_model(regularized_reg)\nregularized_workflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_select()\n• step_dummy()\n• step_normalize()\n• step_interact()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n```\n:::\n:::\n\n\nผลลัพธ์ข้างต้นจะเห็นว่า workflow ช่วยรวบรวมส่วนของการ preprocessing และ modeling ให้อยู่ภายใต้ object เดียวกัน เมื่อสร้าง workflow เรียบร้อยแล้ว ขั้นตอนถัดไปคือการสร้าง grid ของ hyperparameters เพื่อใช้สำหรับการเฟ้นหาชุดของ hyperparameter ที่มีความเหมาะสมกล่าวคือทำให้ประสิทธิภาพการทำนายของโมเดลมีสูงที่สุด ดังที่ได้กล่าวในบทที่ 5 ว่าการกำหนด grid อาจทำได้สองวิธี วิธีการแรกคือการใช้ regular grid search ที่จะสร้าง grid จาก combination ของค่าที่เป็นไปได้ทั้งหมดของ hyperparameters ที่สนใจ การสร้าง grid ดังกล่าวสามารถทำได้หลายวิธีการ โดยใน tidymodels สามารถทำได้ด้วยฟังก์ชัน `grid_regular()` ของ package dial ดังตัวอย่างต่อไปนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\np<-parameters(penalty(range=c(-100,100)))\nregular_grid <- grid_regular(p, levels=50)\nregular_grid\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 50 × 1\n     penalty\n       <dbl>\n 1 1   e-100\n 2 1.21e- 96\n 3 1.46e- 92\n 4 1.76e- 88\n 5 2.12e- 84\n 6 2.56e- 80\n 7 3.09e- 76\n 8 3.73e- 72\n 9 4.50e- 68\n10 5.43e- 64\n# … with 40 more rows\n```\n:::\n:::\n\n\nการปรับแต่งค่าพารามิเตอร์ด้วยการดำเนินการข้างต้นมีข้อจำกัดคือเป็นวิธีการที่ใช้ทรัพยากรค่อนข้างมาก อีกวิธีการหนึ่งที่ช่วยลดการใช้ทรัพยากรของเครื่องลงได้คือการใช้ random grid search ซึ่งเป็นการสุ่มชุดของ hyperparameter มาวิเคราะห์ การดำเนินการตามวิธีการนี้สามารถทำได้ด้วยฟังก์ชัน `grid_random()` ดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrandom_grid <- grid_random(p, size = 10)\nrandom_grid\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 1\n    penalty\n      <dbl>\n 1 1.83e-83\n 2 1.23e+ 1\n 3 2.22e+96\n 4 3.14e+63\n 5 1.68e-62\n 6 1.05e-73\n 7 1.60e- 6\n 8 2.19e-50\n 9 5.97e-71\n10 1.94e-42\n```\n:::\n:::\n\n\nตัวอย่างต่อไปนี้จะเปรียบเทียบผลที่ได้จากการปรับแต่งค่า hyperparameters ด้วยการทำ repeated 10-fold CV บน grid ของ hyperparameter ที่สร้างขึ้นจากสองวิธีการข้างต้น จากตัวอย่างด้านล่างจะเห็นว่าการ fit model ในแต่ละ fold จะใช้ฟังก์ชัน `tune_grid()` เป็นตัวดำเนินการแทนฟังก์ชัน `fit()` ทั้งนี้ `tune_grid()` มีอาร์กิวเมนท์ที่สำคัญได้แก่\n\n-   `resamples` ใช้ระบุชุดข้อมูลที่สร้างขึ้นจากกระบวนการสุ่มซ้ำ เช่น k-folds CV หรือ boostraping dataset\n\n-   `grid` ใช้สำหรับระบุ grid ของ hyperparameter ของอัลกอริทึมการเรียนรู้ที่เลือกใช้\n\n-   `control` ใช้กำหนด option สำหรับควบคุมกระบวนการสุ่มซ้ำ (resample) และปรับแต่งค่า hyperparameter การกำหนดอาร์กิวเมนท์นี้จะต้องกำหนดผ่านฟังก์ชัน `control_resamples()` หรือ `control_grid()` อีกทีหนึ่ง รายละเอียดของฟังก์ชันทั้งสองสามารถศึกษาได้จากคู่มือการใช้งาน (พิมพ์ `?control_resamples` หรือ `?control_grid`)\n\n-   `metrics` ใช้กำหนด evalution metrics ที่ผู้วิเคราะห์จะใช้เพื่อประเมินประสิทธิภาพของโมเดลระหว่างการปรับแต่งค่าพารามิเตอร์ การกำหนดอาร์กิวเมนท์นี้ให้ทำผ่านฟังก์ชัน `metric_set()` ในกรณีที่ไม่ได้กำหนดโปรแกรมจะกำหนดให้ใช้ค่าเริ่มต้น ซึ่งจะเลือกให้เหมาะสมกับ mode ของโมเดล\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrol_options <- control_grid(verbose = TRUE, save_pred = TRUE)\neval_metric <- metric_set(rsq, rmse, mae)\n#regular grid search \nstart <- Sys.time()\ntune_regular <- regularized_workflow %>%\n  tune_grid(resamples = folds_data,\n            grid = regular_grid,\n            control = control_options,\n            metrics = eval_metric)\nend <- Sys.time()\npaste(\"time usage (regular grid search) = \", round(end - start,1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"time usage (regular grid search) =  23.1\"\n```\n:::\n\n```{.r .cell-code}\n#random grid search \nstart <- Sys.time()\ntune_random <- regularized_workflow %>%\n  tune_grid(resamples = folds_data,\n            grid = random_grid,\n            control = control_options,\n            metrics = eval_metric)\nend <- Sys.time()\npaste(\"time usage (random grid search) = \", round(end - start,1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"time usage (random grid search) =  21.7\"\n```\n:::\n:::\n\n\n**การประมวลผลข้างต้นการปรับแต่งค่า hyperparameters แต่ละวิธีการใช้เวลาเท่าไหร่ และผลที่ได้จากการปรับแต่งค่า hyperparameters มีความเหมือนหรือแตกต่างกันอย่างไร?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_regular %>% autoplot()\n```\n\n::: {.cell-output-display}\n![](04Regularization_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntune_random %>% autoplot()\n```\n\n::: {.cell-output-display}\n![](04Regularization_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n:::\n\n\nจากการทำ workflow ข้างต้นผู้วิเคราะห์สามารถเรียกดูผลการประเมินประสิทธิภาพของโมเดลทำนายที่คำนวณจากการทำ cross-validation โดยใช้ฟังก์ชัน `collect_metric()` ฟังก์ชันนี้มีอาร์กิวเมนท์ที่ควรรู้จักคือ `summarize` ค่าเริ่มต้นจะกำหนดให้เป็น `TRUE` ผลลัพธ์ที่ได้จะเป็นค่าสรุปประสิทธิภาพการทำนายของโมเดลในแต่ละ grid แต่ถ้ากำหนดให้เป็น `FALSE` ผลลัพธ์ที่ได้จะลงรายละเอียดของประสิทธิภาพเป็นราย validation dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_regular %>% \n  collect_metrics(summarize = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 150 × 7\n     penalty .metric .estimator      mean     n  std_err .config              \n       <dbl> <chr>   <chr>          <dbl> <int>    <dbl> <chr>                \n 1 1   e-100 mae     standard   16495.       30 432.     Preprocessor1_Model01\n 2 1   e-100 rmse    standard   22130.       30 691.     Preprocessor1_Model01\n 3 1   e-100 rsq     standard       0.482    30   0.0156 Preprocessor1_Model01\n 4 1.21e- 96 mae     standard   16495.       30 432.     Preprocessor1_Model02\n 5 1.21e- 96 rmse    standard   22130.       30 691.     Preprocessor1_Model02\n 6 1.21e- 96 rsq     standard       0.482    30   0.0156 Preprocessor1_Model02\n 7 1.46e- 92 mae     standard   16495.       30 432.     Preprocessor1_Model03\n 8 1.46e- 92 rmse    standard   22130.       30 691.     Preprocessor1_Model03\n 9 1.46e- 92 rsq     standard       0.482    30   0.0156 Preprocessor1_Model03\n10 1.76e- 88 mae     standard   16495.       30 432.     Preprocessor1_Model04\n# … with 140 more rows\n```\n:::\n\n```{.r .cell-code}\ntune_regular %>% \n  collect_metrics(summarize = TRUE)%>%\n  ggplot(aes(x=penalty, y=mean, col=.metric))+\n  geom_line()+\n  geom_point(aes(shape = .metric))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 23 rows containing missing values (`geom_line()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 23 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](04Regularization_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntune_random %>% \n  collect_metrics(summarize = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 900 × 7\n   id      id2     penalty .metric .estimator .estimate .config              \n   <chr>   <chr>     <dbl> <chr>   <chr>          <dbl> <chr>                \n 1 Repeat1 Fold01 1.83e-83 rsq     standard       0.433 Preprocessor1_Model01\n 2 Repeat1 Fold01 1.83e-83 rmse    standard   28590.    Preprocessor1_Model01\n 3 Repeat1 Fold01 1.83e-83 mae     standard   21296.    Preprocessor1_Model01\n 4 Repeat1 Fold02 1.83e-83 rsq     standard       0.558 Preprocessor1_Model01\n 5 Repeat1 Fold02 1.83e-83 rmse    standard   30395.    Preprocessor1_Model01\n 6 Repeat1 Fold02 1.83e-83 mae     standard   20117.    Preprocessor1_Model01\n 7 Repeat1 Fold03 1.83e-83 rsq     standard       0.497 Preprocessor1_Model01\n 8 Repeat1 Fold03 1.83e-83 rmse    standard   21288.    Preprocessor1_Model01\n 9 Repeat1 Fold03 1.83e-83 mae     standard   17092.    Preprocessor1_Model01\n10 Repeat1 Fold04 1.83e-83 rsq     standard       0.482 Preprocessor1_Model01\n# … with 890 more rows\n```\n:::\n:::\n\n\nนอกจากนี้ยังมีฟังก์ชัน `collect_predictions()` ที่สามารถใช้เรียกค่าทำนายของตัวแปรตามที่ได้จากแต่ละ resample และชุดของ hyperparameter ภายใน grid การใช้ฟังก์ชันนี้ทำในทำนองเดียวกับ `collect_metrics()` ดังตัวอย่างต่อไปนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_regular %>%\n  collect_predictions()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 47,550 × 7\n   id      id2      .pred  .row penalty salary .config              \n   <chr>   <chr>    <dbl> <int>   <dbl>  <int> <chr>                \n 1 Repeat1 Fold01 117612.     2  1e-100 204000 Preprocessor1_Model01\n 2 Repeat1 Fold01 130035.     8  1e-100 106639 Preprocessor1_Model01\n 3 Repeat1 Fold01 117428.    11  1e-100 110515 Preprocessor1_Model01\n 4 Repeat1 Fold01  74480.    81  1e-100  74000 Preprocessor1_Model01\n 5 Repeat1 Fold01 133449.    92  1e-100 162221 Preprocessor1_Model01\n 6 Repeat1 Fold01  85921.    97  1e-100  78000 Preprocessor1_Model01\n 7 Repeat1 Fold01 133197.   102  1e-100  91412 Preprocessor1_Model01\n 8 Repeat1 Fold01 117961.   109  1e-100  94350 Preprocessor1_Model01\n 9 Repeat1 Fold01 118684.   116  1e-100 134690 Preprocessor1_Model01\n10 Repeat1 Fold01  70538.   120  1e-100  72500 Preprocessor1_Model01\n# … with 47,540 more rows\n```\n:::\n:::\n\n\nนอกจากการวิเคราะห์ข้างต้นแล้วยังสามารถใช้ฟังก์ชัน `show_best()` เพื่อคัดเลือกโมเดลทำนายที่ดีที่สุดจาก grid ที่ผู้วิเคราะห์วิเคราะห์ไว้ในข้างต้น ฟังก์ชันนี้ยังมีอาร์กิวเมนท์ `n` สำหรับกำหนดว่าต้องการให้เลือกโมเดลที่ดีที่สุดกี่อันดับแรกขึ้นมาให้ผู้วิเคราะห์ และอาร์กิวเมนท์ `metric` ใชัสำหรับระบุ evaluation metric ที่จะใช้คัดเลือกโมเดลทำนายดังกล่าว ตัวอย่างต่อไปนี้แสดงผลคัดเลือกโมเดลทำนายจากวิธีการสร้าง grid ทั้งสองวิธี จะเห็นว่าผลลัพธ์ที่ได้สอดคล้องกัน\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(tune_regular, n=5, metric=\"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 7\n    penalty .metric .estimator   mean     n std_err .config              \n      <dbl> <chr>   <chr>       <dbl> <int>   <dbl> <chr>                \n1 1   e-100 rmse    standard   22130.    30    691. Preprocessor1_Model01\n2 1.21e- 96 rmse    standard   22130.    30    691. Preprocessor1_Model02\n3 1.46e- 92 rmse    standard   22130.    30    691. Preprocessor1_Model03\n4 1.76e- 88 rmse    standard   22130.    30    691. Preprocessor1_Model04\n5 2.12e- 84 rmse    standard   22130.    30    691. Preprocessor1_Model05\n```\n:::\n\n```{.r .cell-code}\nshow_best(tune_random, n=5, metric=\"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 7\n   penalty .metric .estimator   mean     n std_err .config              \n     <dbl> <chr>   <chr>       <dbl> <int>   <dbl> <chr>                \n1 1.83e-83 rmse    standard   22130.    30    691. Preprocessor1_Model01\n2 1.05e-73 rmse    standard   22130.    30    691. Preprocessor1_Model02\n3 5.97e-71 rmse    standard   22130.    30    691. Preprocessor1_Model03\n4 1.68e-62 rmse    standard   22130.    30    691. Preprocessor1_Model04\n5 2.19e-50 rmse    standard   22130.    30    691. Preprocessor1_Model05\n```\n:::\n:::\n\n\n#### กิจกรรม 1 :\n\nขอให้นิสิตทดลอง plot R square plot ของโมเดลที่ดีที่สุดข้างต้น ผลลัพธ์ที่ได้เป็นอย่างไร นิสิตที่ข้อเสนอแนะในการพัฒนาโมเดลทำนายดังกล่าวอย่างไร?\n\n\n::: {.cell}\n\n:::\n\n\n#### กิจกรรม 2 :\n\nขอให้นิสิตลองใช้อัลกอริทึม regularized regression ตัวอื่นเพื่อพัฒนาโมเดลทำนายเงินเดือนอาจารย์มหาวิทยาลัย โดยใช้ชุดข้อมูล `TeacherSalaryData.csv` ผลลัพธ์ที่ได้เป็นอย่างไร\n\n## 6.4 Tuning and Comparing Models\n\nโดยทั่วไปในการพัฒนาโมเดลทำนาย ผู้วิเคราะห์จำเป็นต้องทดลองพัฒนาโมเดลทำนายจากอัลกริทึมการเรียนรู้หลายตัว การดำเนินงานดังกล่าวจึงต้องมีทั้งส่วนของการปรับแต่งค่า hyperparameters ของแต่ละอัลกอริทึม และต้องมีส่วนของการเปรียบเทียบประสิทธิภาพการทำนายของโมเดลในชุดข้อมูลทดสอบ จะเห็นว่าการดำเนินการดังกล่าวค่อนข้างมีความซับซ้อน และต้องมีการเขียนชุดคำสั่งเป็นจำนวนมาก\n\nใน tidymodels มีตัวแปรอีกประเภทที่เรียกว่า workflow set ที่ใช้เก็บ workflow หลาย ๆ ตัวเข้ามารวมไว้ในตัวแปรเดียว ซึ่งทำให้การทำ data preprocessing การปรับแต่งค่า hyperparameters และการเปรียบเทียบประสิทธิภาพระหว่างโมเดลทำนายที่พัฒนาจากอัลกอริทึมที่แตกต่างกันหลาย ๆ ตัวสามารถทำได้ง่ายมากขึ้น\n\nตัวอย่างต่อไปนี้จะแสดงการพัฒนาโมเดลทำนายโดยใช้อัลกอริทึมได้แก่ regularized logistic regression และ decision tree โดยจะใช้ชุดข้อมูลตัวอย่างจาก package modeldata\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#importing data\ndata(parabolic)\nglimpse(parabolic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 500\nColumns: 3\n$ X1    <dbl> 3.291779227, 1.465839693, 1.660986913, 1.602301296, 2.165003287,…\n$ X2    <dbl> 1.66108928, 0.41398566, 0.79147013, 0.27639110, 3.16557011, 3.82…\n$ class <fct> Class1, Class2, Class2, Class2, Class1, Class1, Class2, Class1, …\n```\n:::\n\n```{.r .cell-code}\n# splitting data\nsplit <- initial_split(data = parabolic)\ntrain <- training(split)\ntest <- testing(split)\n```\n:::\n\n\nชุดข้อมูล parabolic ประกอบด้วยตัวแปร 3 ตัว โดยตัวแปรตามเป็นตัวแปรจัดประเภทที่มี 2 categories และตัวแปรอิสระประกอบด้วย X1 และ X2\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain %>%\n  ggplot(aes(x = X1, y = X2, col=class))+\n  geom_point(alpha=0.7)+\n  theme_light()+\n  theme(legend.position=\"top\")\n```\n\n::: {.cell-output-display}\n![](04Regularization_files/figure-html/unnamed-chunk-21-1.png){width=384}\n:::\n:::\n\n\n### Model Specification\n\nสร้าง model specification ทั้งหมดที่ต้องการ\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic_mod <- logistic_reg(penalty= tune(),\n                             mixture = tune()) %>%\n  set_engine(\"glmnet\")%>%\n  set_mode(\"classification\")\n\ntree_mod <- decision_tree(cost_complexity = tune(),\n                            min_n = tune())%>%\n  set_engine(\"rpart\")%>%\n  set_mode(\"classification\")\n```\n:::\n\n\n### สร้าง workflowset และวิเคราะห์ hyperparemeters\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create workflowset\nmod_specs <- workflow_set(\n  preproc = list(\"formula\" = class ~ .),\n  models = list(glmnet = logistic_mod,\n                cart = tree_mod)\n)\n#create resamples\nresamples <- bootstraps(data = train)\n\n# tunegrid using workflowmap\ntune_results<- mod_specs %>% \n  workflow_map(\"tune_grid\",\n                           resamples = resamples,\n                           grid = 10,\n                           metrics = metric_set(roc_auc, sens, spec),\n               verbose = TRUE)%>%\n    option_add(control = control_grid(save_pred=T, parallel_over =\"resamples\"))\n# rankmodels\nrank_results(tune_results, rank_metric =\"roc_auc\")\nautoplot(tune_results)\n```\n:::\n",
    "supporting": [
      "04Regularization_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}