{
  "hash": "e9489d827fd63b9f733e02ce2f69e024",
  "result": {
    "markdown": "---\ntitle: \"Midterm Examination\"\ndate: \"6 Apr 2023\"\ntoc: true\ntoc-depth: 3\ntoc-title: สารบัญ\ntheme: default\n---\n\n\n## สถานการณ์\n\nจงใช้สถานการณ์ที่กำหนดให้เพื่อตอบคำถาม\n\nสมมุติว่าหน่วยงานทางการศึกษาแห่งหนึ่งได้มาขอคำปรึกษากับนิสิตเกี่ยวกับการใช้ประโยชน์จากฐานข้อมูลนักเรียนของหน่วยงาน ฐานข้อมูลดังกล่าวประกอบด้วยข้อมูลด้านภูมิหลัง พฤติกรรมการเรียนรู้และผลการเรียนของนักเรียนในรายวิชา คณิตศาสตร์ และภาษาอังกฤษ ทั้งนี้หน่วยงานได้ export ชุดข้อมูลออกมาเป็นไฟล์ CSV\n\n### 1.1 นำชุดข้อมูลเข้าและสำรวจข้อมูลเบื้องต้น\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndat1<-read.csv(\"Math_miss.csv\")\ndat2<-read.csv(\"Eng_miss.csv\")\n```\n:::\n\n\nสำรวจชุดข้อมูลเบื้องต้น พบว่าข้อมูลทั้งสองชุดเก็บข้อมูลของตัวแปรเดียวกัน (ลองเขียนคำสั่ง `table(names(dat1)==names(dat2))`ส่วนที่แตกต่างกันคือคะแนน `PreTest` และ `Ach` ที่เป็นความรู้พื้นฐานและผลสัมฤทธิ์ทางการเรียนคนละรายวิชากัน\n\nคราวนี้มาพิจารณาตัวแปรภายในชุดข้อมูล จะเห็นว่าสามารถจัดกลุ่มตัวแปร โดยใช้บริบทของข้อมูลเป็นเกณฑ์ดังนี้\n\n+--------------------------------------------+--------------------------------------------------+\n| **กลุ่ม**                                    | **ตัวแปร**                                        |\n+--------------------------------------------+--------------------------------------------------+\n| 1.  **ภูมิหลังทางบ้านของนักเรียน**               | -   ภูมิลำเนา (`location`)                         |\n|                                            |                                                  |\n|                                            | -   จำนวนพี่น้อง (`famsize`)                        |\n|                                            |                                                  |\n|                                            | -   สถานะครอบครัว (`ParentStat`)                  |\n|                                            |                                                  |\n|                                            | -   ผู้ปกครองของนักเรียน (`StuParent`)               |\n|                                            |                                                  |\n|                                            | -   การศึกษาของมารดา (`MomEdu`)                   |\n|                                            |                                                  |\n|                                            | -   การศึกษาของบิดา (`DadEdu`)                     |\n|                                            |                                                  |\n|                                            | -   อาชีพมารดา (`MomJob`)                         |\n|                                            |                                                  |\n|                                            | -   อาชีพบิดา (`DadJob`)                           |\n|                                            |                                                  |\n|                                            | -   ความสัมพันธ์ภายในครอบครัว (`fam_relation`)       |\n|                                            |                                                  |\n|                                            | -   บ้านมี internet มั้ย (`internet`)                |\n|                                            |                                                  |\n|                                            | -   ระยะเวลาเดินทางจากบ้านมาโรงเรียน (`traveltime`) |\n+--------------------------------------------+--------------------------------------------------+\n| 2.  **ภูมิหลังและการสนับสนุนของโรงเรียน**        | -   โรงเรียนที่นักเรียนสังกัด (`school`)                |\n|                                            |                                                  |\n|                                            | -   การได้รับทุนสนับสนุนทางการศึกษา (`scholarship`)    |\n+--------------------------------------------+--------------------------------------------------+\n| 3.  **ภูมิหลังและพฤติกรรมด้านการเรียนของนักเรียน** | -   เพศ (`gender`)                               |\n|                                            |                                                  |\n|                                            | -   อายุ (`age`)                                  |\n|                                            |                                                  |\n|                                            | -   เวลาที่ใช้ทบทวนบทเรียน (`readingtime`)           |\n|                                            |                                                  |\n|                                            | -   จำนวนเวลาว่างหลังเลิกเรียน (`freetime`)          |\n|                                            |                                                  |\n|                                            | -   จำนวนครั้งที่เคยสอบตก (`fail`)                   |\n|                                            |                                                  |\n|                                            | -   การมีทำกิจกรรมชมรม/งานอดิเรก (`club_act`)       |\n|                                            |                                                  |\n|                                            | -   เคยเรียนอนุบาลหรือไม่ (`nursery`)                |\n|                                            |                                                  |\n|                                            | -   อยากเรียนต่อระดับอุดมศึกษามั้ย (`higher`)           |\n|                                            |                                                  |\n|                                            | -   กำลังมีแฟนมั้ย (`InLove`)                        |\n|                                            |                                                  |\n|                                            | -   ความบ่อยในการไปเที่ยวกับเพื่อน (`goout`)           |\n|                                            |                                                  |\n|                                            | -   การดื่มสุรา (`Drink_alc`)                       |\n|                                            |                                                  |\n|                                            | -   สุขภาพโดยรวม (`health`)                       |\n|                                            |                                                  |\n|                                            | -   การขาดเรียน (`absences`)                      |\n|                                            |                                                  |\n|                                            | -   ความรู้พื้นฐาน (`PreTest`)                       |\n+--------------------------------------------+--------------------------------------------------+\n| 4.  **ผลการเรียน**                          | -   ผลสัมฤทธิ์ทางการเรียน (`Ach`)                    |\n+--------------------------------------------+--------------------------------------------------+\n\n### 1.2 รวมชุดข้อมูลเข้าด้วยกัน\n\nความรู้พื้นฐานและผลสัมฤทธิ์ในรายวิชา Math และ Eng ไม่เหมือนกันดังนั้นต้องสร้างตัวแปรใหม่อีกตัวเพื่อแยกคะแนนของรายวิชาทั้งสอง ดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1$subject <- \"Math\"\ndat2$subject <- \"Eng\"\n### merge dat1 and dat2 together using `bind_rows()`\ndat <- bind_rows(dat1, dat2)\nglimpse(dat, width=50)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,044\nColumns: 29\n$ school       <chr> \"obec.sec\", \"obec.sec\", \"ob…\n$ gender       <chr> \"F\", \"F\", \"F\", \"F\", \"F\", \"M…\n$ age          <int> 14, 13, 11, 11, 12, 12, 12,…\n$ location     <chr> \"U\", \"U\", \"U\", \"U\", \"U\", \"U…\n$ famsize      <chr> \"GT3\", \"GT3\", \"LE3\", \"GT3\",…\n$ ParentStat   <chr> \"A\", \"T\", \"T\", \"T\", \"T\", \"T…\n$ MomEdu       <int> 4, 1, 1, 4, 3, 4, 2, 4, 3, …\n$ DadEdi       <int> 4, 1, 1, 2, 3, 3, 2, 4, 2, …\n$ MomJob       <chr> \"at_home\", \"at_home\", \"at_h…\n$ DadJob       <chr> \"teacher\", \"other\", \"other\"…\n$ StuParent    <chr> \"mother\", \"father\", \"mother…\n$ traveltime   <int> 2, 1, NA, NA, 1, 1, 1, 2, N…\n$ readingtime  <int> 2, 2, 2, 3, 2, 2, 2, 2, 2, …\n$ fail         <int> 0, 0, 3, 0, 0, 0, 0, 0, 0, …\n$ scholarship  <chr> \"yes\", \"no\", \"yes\", \"no\", \"…\n$ club_act     <chr> \"no\", \"no\", \"no\", \"yes\", \"n…\n$ nursery      <chr> \"yes\", \"no\", \"yes\", \"yes\", …\n$ higher       <chr> \"yes\", \"yes\", \"yes\", \"yes\",…\n$ internet     <chr> \"no\", \"yes\", \"yes\", \"yes\", …\n$ InLove       <chr> \"no\", \"no\", \"no\", \"yes\", \"n…\n$ fam_relation <int> NA, 5, 4, 3, 4, NA, NA, 4, …\n$ freetime     <int> 3, 3, 3, 2, 3, 4, 4, 1, 2, …\n$ goout        <int> 4, 3, 2, 2, 2, 2, 4, 4, 2, …\n$ Drink_alc    <int> 1, 1, 2, 1, 1, 1, 1, 1, 1, …\n$ health       <int> 3, 3, 3, 5, 5, 5, 3, 1, 1, …\n$ absences     <int> 6, 4, 10, 2, 4, 10, 0, 6, 0…\n$ PreTest      <int> 5, 5, 7, 15, 6, 15, 12, 6, …\n$ Ach          <int> 6, 6, 10, 15, 10, 15, 11, 6…\n$ subject      <chr> \"Math\", \"Math\", \"Math\", \"Ma…\n```\n:::\n:::\n\n\nจากการสำรวจชุดข้อมูลข้างต้นจะเห็นว่าสถานะของตัวแปรจัดประเภทภายในชุดข้อมูลยังไม่เหมาะสม จึงมีการปรับสถานะให้เหมาะสม ดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ndat_preproc <- recipe(Ach~., data=dat) %>%\n  step_string2factor(all_string_predictors()) %>%\n  prep(NULL) %>%\n  juice()\ndat_preproc %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 29\n  school   gender   age location famsize ParentStat MomEdu DadEdi MomJob  DadJob\n  <fct>    <fct>  <int> <fct>    <fct>   <fct>       <int>  <int> <fct>   <fct> \n1 obec.sec F         14 U        GT3     A               4      4 at_home teach…\n2 obec.sec F         13 U        GT3     T               1      1 at_home other \n3 obec.sec F         11 U        LE3     T               1      1 at_home other \n4 obec.sec F         11 U        GT3     T               4      2 health  servi…\n5 obec.sec F         12 U        GT3     T               3      3 other   other \n6 obec.sec M         12 U        LE3     T               4      3 servic… other \n# … with 19 more variables: StuParent <fct>, traveltime <int>,\n#   readingtime <int>, fail <int>, scholarship <fct>, club_act <fct>,\n#   nursery <fct>, higher <fct>, internet <fct>, InLove <fct>,\n#   fam_relation <int>, freetime <int>, goout <int>, Drink_alc <int>,\n#   health <int>, absences <int>, PreTest <int>, subject <fct>, Ach <int>\n```\n:::\n:::\n\n\n### 1.3 ตรวจสอบค่าสูญหายภายในชุดข้อมูล\n\nการตรวจสอบค่าสูญหายสามารถทำได้หลายวิธีการ ตั้งแต่การใช้ฟังก์ชันทางสถิติพื้นฐานของ R ใช้ทัศนภาพข้อมูล รวมไปถึงมี package เฉพาะหลายตัวที่ถูกพัฒนาขึ้นเพื่อแก้ปัญหาดังกล่าว เนื้อหาส่วนนี้จะใช้ package naniar\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"naniar\")\nlibrary(naniar)\n```\n:::\n\n\n#### ภายในชุดข้อมูลมี missing values เกิดขึ้นมั้ย?\n\nฟังก์ชันง่าย ๆ สำหรับสำรวจค่าสูญหาย เช่น `miss_var_summary()` หรือ `miss_var_table()` เพื่อสำรวจค่าสูญหายในตัวแปร หรือ `miss_case_summary()` หรือ `miss_case_table()` เพื่อสำรวจค่าสูญหายในหน่วยข้อมูล ดังผลการวิเคราะห์ด้านล่าง\n\nจากผลการวิเคราะห์จะเห็นว่ามีตัวแปรจำนวน 3 ตัวในชุดข้อมูลที่พบค่าสูญหาย ได้แก่ `traveltime`, `fam_relation` และ `PreTest` โดยพบค่าสูญหายในแต่ละตัวแปรคิดเป็นร้อยละ 14.2, 12.5 และ 11.3 ตามลำดับ นอกจากนี้เมื่อพิจารณาในมิติของหน่วยข้อมูลพบว่า รูปแบบการสูญหายของข้อมูลในหน่วยข้อมูลมีแบบเดียวคือ มีการสูญหายหนึ่งตัวแปรต่อหน่วยข้อมูล โดยมีหน่วยข้อมูลที่พบค่าสูญหายทั้งหมด 396 หน่วย คิดเป็นร้อยละ 37.93\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmiss_var_summary(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 29 × 3\n   variable     n_miss pct_miss\n   <chr>         <int>    <dbl>\n 1 traveltime      148     14.2\n 2 fam_relation    130     12.5\n 3 PreTest         118     11.3\n 4 school            0      0  \n 5 gender            0      0  \n 6 age               0      0  \n 7 location          0      0  \n 8 famsize           0      0  \n 9 ParentStat        0      0  \n10 MomEdu            0      0  \n# … with 19 more rows\n```\n:::\n\n```{.r .cell-code}\nmiss_case_table(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  n_miss_in_case n_cases pct_cases\n           <int>   <int>     <dbl>\n1              0     648      62.1\n2              1     396      37.9\n```\n:::\n:::\n\n\nฟังก์ชัน `vis_miss()` สามารถใช้เพื่อสร้างทัศนภาพของเมทริกซ์ค่าสูญหาย ซึ่งช่วยให้เห็นภาพรวมของค่าสูญหายภายในชุดข้อมูลทั้งในมิติของตัวแปรและหน่วยข้อมูลไปพร้อม ๆ กัน ดังนี้ จากรูปจะเห็นว่า มีค่าสูญหายเกิดขึ้นคิดเป็นร้อยละ 1.3 ของค่าสังเกตทั้งหมดในชุดข้อมูล\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvis_miss(dat, cluster = TRUE, sort_miss = TRUE)\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nจากสภาพข้างต้นจะเห็นว่าหากผู้วิเคราะห์มีการใช้ตัวแปร ได้แก่ `traveltime`, `fam_relation` และ `PreTest` ในการวิเคราะห์และเลือกใช้วิธีการแก้ปัญหาค่าสูญหายด้วยการตัดข้อมูล ได้แก่ listwise หรือ pairwise deletion จะทำให้ผู้วิเคราะห์สูญเสียหน่วยข้อมูลในการวิเคราะห์ไปได้มากที่สุดถึง 396 หน่วย (ร้อยละ 37.93) ซึ่งเป็นปริมาณที่มีนัยสำคัญต่อความถูกต้องของผลการวิเคราะห์ที่จะได้\n\n### 1.4 ตรวจสอบกลไกการสูญหายของข้อมูล\n\nจากสภาพการสูญหายของข้อมูลข้างต้น จึงจำเป็นที่จะต้องมีการวิเคราะห์และแก้ไขด้วยการทดแทนค่าสูญหาย เนื้อหาส่วนนี้จะใช้การตรวจสอบ 2 วิธีการ วิธีการแรกจะตรวจสอบกลไกการสูญหายด้วย PCA และวิธีการที่สองจะใช้ logistic regression เพื่อตรวจสอบ รายละเอียดมีดังนี้ั\n\n#### การตรวจสอบกลไกค่าสูญหายด้วย PCA\n\nผู้วิเคราะห์แปลงข้อมูลตัวแปรทั้งหมดในชุดข้อมูลให้เป็นตัวแปรแบบให้คะแนนสองค่า โดยมีค่าเท่ากับ 1 เมื่อมีข้อมูล และมีค่าเท่ากับ 0 เมื่อเป็นข้อมูลสูญหาย ผลลัพธ์ที่ได้จะได้เมทริกซ์ค่าสูญหาย (D) ดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(dat_preproc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 29\n  school   gender   age location famsize ParentStat MomEdu DadEdi MomJob  DadJob\n  <fct>    <fct>  <int> <fct>    <fct>   <fct>       <int>  <int> <fct>   <fct> \n1 obec.sec F         14 U        GT3     A               4      4 at_home teach…\n2 obec.sec F         13 U        GT3     T               1      1 at_home other \n3 obec.sec F         11 U        LE3     T               1      1 at_home other \n4 obec.sec F         11 U        GT3     T               4      2 health  servi…\n5 obec.sec F         12 U        GT3     T               3      3 other   other \n6 obec.sec M         12 U        LE3     T               4      3 servic… other \n# … with 19 more variables: StuParent <fct>, traveltime <int>,\n#   readingtime <int>, fail <int>, scholarship <fct>, club_act <fct>,\n#   nursery <fct>, higher <fct>, internet <fct>, InLove <fct>,\n#   fam_relation <int>, freetime <int>, goout <int>, Drink_alc <int>,\n#   health <int>, absences <int>, PreTest <int>, subject <fct>, Ach <int>\n```\n:::\n\n```{.r .cell-code}\nglimpse(dat_preproc, width=50)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,044\nColumns: 29\n$ school       <fct> obec.sec, obec.sec, obec.se…\n$ gender       <fct> F, F, F, F, F, M, M, F, M, …\n$ age          <int> 14, 13, 11, 11, 12, 12, 12,…\n$ location     <fct> U, U, U, U, U, U, U, U, U, …\n$ famsize      <fct> GT3, GT3, LE3, GT3, GT3, LE…\n$ ParentStat   <fct> A, T, T, T, T, T, T, A, A, …\n$ MomEdu       <int> 4, 1, 1, 4, 3, 4, 2, 4, 3, …\n$ DadEdi       <int> 4, 1, 1, 2, 3, 3, 2, 4, 2, …\n$ MomJob       <fct> at_home, at_home, at_home, …\n$ DadJob       <fct> teacher, other, other, serv…\n$ StuParent    <fct> mother, father, mother, mot…\n$ traveltime   <int> 2, 1, NA, NA, 1, 1, 1, 2, N…\n$ readingtime  <int> 2, 2, 2, 3, 2, 2, 2, 2, 2, …\n$ fail         <int> 0, 0, 3, 0, 0, 0, 0, 0, 0, …\n$ scholarship  <fct> yes, no, yes, no, no, no, n…\n$ club_act     <fct> no, no, no, yes, no, yes, n…\n$ nursery      <fct> yes, no, yes, yes, yes, yes…\n$ higher       <fct> yes, yes, yes, yes, yes, ye…\n$ internet     <fct> no, yes, yes, yes, no, yes,…\n$ InLove       <fct> no, no, no, yes, no, no, no…\n$ fam_relation <int> NA, 5, 4, 3, 4, NA, NA, 4, …\n$ freetime     <int> 3, 3, 3, 2, 3, 4, 4, 1, 2, …\n$ goout        <int> 4, 3, 2, 2, 2, 2, 4, 4, 2, …\n$ Drink_alc    <int> 1, 1, 2, 1, 1, 1, 1, 1, 1, …\n$ health       <int> 3, 3, 3, 5, 5, 5, 3, 1, 1, …\n$ absences     <int> 6, 4, 10, 2, 4, 10, 0, 6, 0…\n$ PreTest      <int> 5, 5, 7, 15, 6, 15, 12, 6, …\n$ subject      <fct> Math, Math, Math, Math, Mat…\n$ Ach          <int> 6, 6, 10, 15, 10, 15, 11, 6…\n```\n:::\n\n```{.r .cell-code}\nmiss_var_summary(dat_preproc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 29 × 3\n   variable     n_miss pct_miss\n   <chr>         <int>    <dbl>\n 1 traveltime      148     14.2\n 2 fam_relation    130     12.5\n 3 PreTest         118     11.3\n 4 school            0      0  \n 5 gender            0      0  \n 6 age               0      0  \n 7 location          0      0  \n 8 famsize           0      0  \n 9 ParentStat        0      0  \n10 MomEdu            0      0  \n# … with 19 more rows\n```\n:::\n\n```{.r .cell-code}\ndat_preproc %>%\n  bind_shadow() %>%\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,044\nColumns: 58\n$ school          <fct> obec.sec, obec.sec, obec.sec, obec.sec, obec.sec, obec…\n$ gender          <fct> F, F, F, F, F, M, M, F, M, M, F, F, M, M, M, F, F, F, …\n$ age             <int> 14, 13, 11, 11, 12, 12, 12, 13, 11, 11, 11, 11, 11, 11…\n$ location        <fct> U, U, U, U, U, U, U, U, U, U, U, U, U, U, U, U, U, U, …\n$ famsize         <fct> GT3, GT3, LE3, GT3, GT3, LE3, LE3, GT3, LE3, GT3, GT3,…\n$ ParentStat      <fct> A, T, T, T, T, T, T, A, A, T, T, T, T, T, A, T, T, T, …\n$ MomEdu          <int> 4, 1, 1, 4, 3, 4, 2, 4, 3, 3, 4, 2, 4, 4, 2, 4, 4, 3, …\n$ DadEdi          <int> 4, 1, 1, 2, 3, 3, 2, 4, 2, 4, 4, 1, 4, 3, 2, 4, 4, 3, …\n$ MomJob          <fct> at_home, at_home, at_home, health, other, services, ot…\n$ DadJob          <fct> teacher, other, other, services, other, other, other, …\n$ StuParent       <fct> mother, father, mother, mother, father, mother, mother…\n$ traveltime      <int> 2, 1, NA, NA, 1, 1, 1, 2, NA, 1, 1, 3, NA, NA, 1, 1, 1…\n$ readingtime     <int> 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 1, 3, 2, …\n$ fail            <int> 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ scholarship     <fct> yes, no, yes, no, no, no, no, yes, no, no, no, no, no,…\n$ club_act        <fct> no, no, no, yes, no, yes, no, no, no, yes, no, yes, ye…\n$ nursery         <fct> yes, no, yes, yes, yes, yes, yes, yes, yes, yes, yes, …\n$ higher          <fct> yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, yes,…\n$ internet        <fct> no, yes, yes, yes, no, yes, yes, no, yes, yes, yes, ye…\n$ InLove          <fct> no, no, no, yes, no, no, no, no, no, no, no, no, no, n…\n$ fam_relation    <int> NA, 5, 4, 3, 4, NA, NA, 4, 4, NA, NA, NA, 4, 5, 4, 4, …\n$ freetime        <int> 3, 3, 3, 2, 3, 4, 4, 1, 2, 5, 3, 2, 3, 4, 5, 4, 2, 3, …\n$ goout           <int> 4, 3, 2, 2, 2, 2, 4, 4, 2, 1, 3, 2, 3, 3, 2, 4, 3, 2, …\n$ Drink_alc       <int> 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ health          <int> 3, 3, 3, 5, 5, 5, 3, 1, 1, 5, 2, 4, 5, 3, 3, 2, 2, 4, …\n$ absences        <int> 6, 4, 10, 2, 4, 10, 0, 6, 0, 0, 0, 4, 2, 2, 0, 4, 6, 4…\n$ PreTest         <int> 5, 5, 7, 15, 6, 15, 12, 6, 16, 14, 10, 10, 14, 10, 14,…\n$ subject         <fct> Math, Math, Math, Math, Math, Math, Math, Math, Math, …\n$ Ach             <int> 6, 6, 10, 15, 10, 15, 11, 6, 19, 15, 9, 12, 14, 11, 16…\n$ school_NA       <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ gender_NA       <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ age_NA          <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ location_NA     <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ famsize_NA      <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ ParentStat_NA   <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ MomEdu_NA       <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ DadEdi_NA       <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ MomJob_NA       <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ DadJob_NA       <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ StuParent_NA    <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ traveltime_NA   <fct> !NA, !NA, NA, NA, !NA, !NA, !NA, !NA, NA, !NA, !NA, !N…\n$ readingtime_NA  <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ fail_NA         <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ scholarship_NA  <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ club_act_NA     <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ nursery_NA      <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ higher_NA       <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ internet_NA     <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ InLove_NA       <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ fam_relation_NA <fct> NA, !NA, !NA, !NA, !NA, NA, NA, !NA, !NA, NA, NA, NA, …\n$ freetime_NA     <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ goout_NA        <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ Drink_alc_NA    <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ health_NA       <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ absences_NA     <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ PreTest_NA      <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ subject_NA      <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n$ Ach_NA          <fct> !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA, !NA,…\n```\n:::\n\n```{.r .cell-code}\nna<-function(x){\n  y<-ifelse(x==\"NA\",1,0)\n  return(y)\n}\nmissing <- dat_preproc %>% \n  bind_shadow() %>%\n  dplyr::select(contains(\"NA\")) %>%\n  mutate_all(na)\nmissing %>% dplyr::select(traveltime_NA, fam_relation_NA, PreTest_NA) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,044 × 3\n   traveltime_NA fam_relation_NA PreTest_NA\n           <dbl>           <dbl>      <dbl>\n 1             0               1          0\n 2             0               0          0\n 3             1               0          0\n 4             1               0          0\n 5             0               0          0\n 6             0               1          0\n 7             0               1          0\n 8             0               0          0\n 9             1               0          0\n10             0               1          0\n# … with 1,034 more rows\n```\n:::\n:::\n\n\nจากนั้นดำเนินการวิเคราะห์องค์ประกอบหลัก (PCA) โดยใช้ binary matrix ดังกล่าวเป็นข้อมูลนำเข้า ผลการวิเคราะห์ที่ใช้พิจารณามีด้านล่างได้แก่ biplot และ factor score plot ผลการวิเคราะห์สรุปได้ดังนี้\n\nจากค่า eigen value และ biplot พบว่า องค์ประกอบหลักทั้งสองสามารถอธิบายความแปรปรวนของค่าสูญหายในตัวแปรทั้ง 3 ได้คิดเป็นร้อยละ 76.29 โดยที่องค์ประกอบหลักที่ 1 สร้างจากการสูญหายใน `travel_time` เป็นหลัก คิดเป็นร้อยละ 71.79 รองลงมาคือการสูญหายใน `fam_relation` (ร้อยละ 36.578304) ส่วนองค์ประกอบหลักที่ 2 สร้างจากการสูญหายใน `PreTest` เป็นหลัก คิดเป็นร้อยละ 70.140625\n\nจาก factor score plot พบว่า หน่วยข้อมูลมีค่า factor score ที่รวมกลุ่มกันโดยจำแนกเป็น 4 กลุ่ม กลุ่มแรกอยู่บริเวณจุดกำเนิดแสดงถึงหน่วยข้อมูลที่มีข้อมูลสมบูรณ์ อีก 3 กลุ่มที่เหลือมีค่า factor score ที่แตกต่างจาก 0 แสดงถึงการมีค่าสูญหาย ซึ่งจำแนกเป็น 3 รูปแบบตามตัวแปรที่มีค่าสูญหาย ผลการวิเคราะห์นี้ยังบ่งชี้ว่ากลไกการสูญหายของข้อมูลมีแนวโน้มเป็นแบบ MAR\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen = 999)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(FactoMineR)\nlibrary(gridExtra)\n# do PCA\npca_result<-PCA(missing, graph = F)\npca_result$eig\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                      eigenvalue\ncomp 1  1.15520122462094221305051178205758333206\ncomp 2  1.13358974607055085215279177646152675152\ncomp 3  0.71120902930847162970451336150290444493\ncomp 4  0.00000000000000000000000000000001840140\ncomp 5  0.00000000000000000000000000000001140040\ncomp 6  0.00000000000000000000000000000001140040\ncomp 7  0.00000000000000000000000000000001140040\ncomp 8  0.00000000000000000000000000000001140040\ncomp 9  0.00000000000000000000000000000001140040\ncomp 10 0.00000000000000000000000000000001140040\ncomp 11 0.00000000000000000000000000000001140040\ncomp 12 0.00000000000000000000000000000001140040\ncomp 13 0.00000000000000000000000000000001140040\ncomp 14 0.00000000000000000000000000000001140040\ncomp 15 0.00000000000000000000000000000001140040\ncomp 16 0.00000000000000000000000000000001140040\ncomp 17 0.00000000000000000000000000000001140040\ncomp 18 0.00000000000000000000000000000001140040\ncomp 19 0.00000000000000000000000000000001140040\ncomp 20 0.00000000000000000000000000000001140040\ncomp 21 0.00000000000000000000000000000001140040\ncomp 22 0.00000000000000000000000000000001140040\ncomp 23 0.00000000000000000000000000000001140040\ncomp 24 0.00000000000000000000000000000001140040\ncomp 25 0.00000000000000000000000000000001140040\ncomp 26 0.00000000000000000000000000000001140040\ncomp 27 0.00000000000000000000000000000001140040\ncomp 28 0.00000000000000000000000000000001140040\ncomp 29 0.00000000000000000000000000000001128006\n                          percentage of variance\ncomp 1  38.5067074873651904454163741320371627808\ncomp 2  37.7863248690188129330636002123355865479\ncomp 3  23.7069676436160001742337044561281800270\ncomp 4   0.0000000000000000000000000000006133800\ncomp 5   0.0000000000000000000000000000003800133\ncomp 6   0.0000000000000000000000000000003800133\ncomp 7   0.0000000000000000000000000000003800133\ncomp 8   0.0000000000000000000000000000003800133\ncomp 9   0.0000000000000000000000000000003800133\ncomp 10  0.0000000000000000000000000000003800133\ncomp 11  0.0000000000000000000000000000003800133\ncomp 12  0.0000000000000000000000000000003800133\ncomp 13  0.0000000000000000000000000000003800133\ncomp 14  0.0000000000000000000000000000003800133\ncomp 15  0.0000000000000000000000000000003800133\ncomp 16  0.0000000000000000000000000000003800133\ncomp 17  0.0000000000000000000000000000003800133\ncomp 18  0.0000000000000000000000000000003800133\ncomp 19  0.0000000000000000000000000000003800133\ncomp 20  0.0000000000000000000000000000003800133\ncomp 21  0.0000000000000000000000000000003800133\ncomp 22  0.0000000000000000000000000000003800133\ncomp 23  0.0000000000000000000000000000003800133\ncomp 24  0.0000000000000000000000000000003800133\ncomp 25  0.0000000000000000000000000000003800133\ncomp 26  0.0000000000000000000000000000003800133\ncomp 27  0.0000000000000000000000000000003800133\ncomp 28  0.0000000000000000000000000000003800133\ncomp 29  0.0000000000000000000000000000003760021\n        cumulative percentage of variance\ncomp 1                           38.50671\ncomp 2                           76.29303\ncomp 3                          100.00000\ncomp 4                          100.00000\ncomp 5                          100.00000\ncomp 6                          100.00000\ncomp 7                          100.00000\ncomp 8                          100.00000\ncomp 9                          100.00000\ncomp 10                         100.00000\ncomp 11                         100.00000\ncomp 12                         100.00000\ncomp 13                         100.00000\ncomp 14                         100.00000\ncomp 15                         100.00000\ncomp 16                         100.00000\ncomp 17                         100.00000\ncomp 18                         100.00000\ncomp 19                         100.00000\ncomp 20                         100.00000\ncomp 21                         100.00000\ncomp 22                         100.00000\ncomp 23                         100.00000\ncomp 24                         100.00000\ncomp 25                         100.00000\ncomp 26                         100.00000\ncomp 27                         100.00000\ncomp 28                         100.00000\ncomp 29                         100.00000\n```\n:::\n\n```{.r .cell-code}\n# eigen values and Cumulative percentage of variance\nround(pca_result$eig %>% head(),4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       eigenvalue percentage of variance cumulative percentage of variance\ncomp 1     1.1552                38.5067                           38.5067\ncomp 2     1.1336                37.7863                           76.2930\ncomp 3     0.7112                23.7070                          100.0000\ncomp 4     0.0000                 0.0000                          100.0000\ncomp 5     0.0000                 0.0000                          100.0000\ncomp 6     0.0000                 0.0000                          100.0000\n```\n:::\n\n```{.r .cell-code}\n# factor loading matrix\nround(pca_result$var$coord %>% data.frame() %>% drop_na(),4) %>%\n  filter(Dim.1!=0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Dim.1   Dim.2  Dim.3 Dim.4 Dim.5\ntraveltime_NA   -0.8473 -0.1859 0.4975     0     0\nfam_relation_NA  0.6048 -0.6306 0.4863     0     0\nPreTest_NA       0.2674  0.8375 0.4766     0     0\n```\n:::\n\n```{.r .cell-code}\n# access factor scores (coordinate of individuals)\np1 <- plot(pca_result, choix = \"var\")\nmissing_factorscore <- pca_result$ind$coord\np2 <- missing_factorscore %>% data.frame() %>%\n  ggplot(aes(x = Dim.1, y=Dim.2))+\n  geom_jitter(width=0.3, height=0.3, alpha=0.5)+\n  ggtitle(\"factor score plot\")\ngrid.arrange(p1,p2,ncol=2)\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-9-1.png){width=864}\n:::\n:::\n\n\nตัวแรกเรียกว่า biplot ใช้นำเสนอความสัมพันธ์ระหว่างองค์ประกอบหลัก (2 องค์ประกอบแรก) กับตัวแปรเดิม ว่ามีความหมายอย่างไร การพิจารณาแผนภาพดังกล่าวให้พิจารณาจาก\n\n1.  **ความยาวของ factor loading vecto**r ของตัวแปรบ่งบอกความสำคัญของตัวแปรสังเกตได้แต่ละตัวในการสร้างองค์ประกอบหลัก\n2.  **ภาพฉาย (projection) ของ factor loading vector บนแกนขององค์ประกอบหลัก** ใช้แสดงความสำคัญของตัวแปรสังเกตได้แต่ละตัวภายในแต่ละองค์ประกอบ\n3.  **มุมระหว่างเวกเตอร์ของ factor loading** แสดงความสัมพันธ์ระหว่างตัวแปรสังเกตได้ จากรูปจะเห็นว่าการสูญหายในตัวแปรทั้งสามมีแนวโน้มที่จะไม่สัมพันธ์กัน\n4.  **การรวมกลุ่มของตำแหน่งของ factor loading บนแผนภาพ** ตัวแปรสังเกตได้ที่อยู่ใกล้กันบนแผนภาพมีแนวโน้มที่จะสัมพันธ์กัน\n\nผู้วิเคราะห์ดำเนินการวิเคราะห์เพื่อยืนยันกลไกลการสูญหายแบบ MAR โดยใช้ logistic regression อีกครั้งหนึ่ง การวิเคราะห์นี้จำแนกเป็น 3 โมเดล ตามตัวแปรที่มีค่าสูญหายแต่ละตัว ดังนี้\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# defined preprocess\nrec1 <- recipe(PreTest_NA ~., data=dat_na) %>%\n  step_rm(traveltime_NA,fam_relation_NA, PreTest) %>%\n  step_normalize(all_numeric_predictors()) %>%\n  step_impute_knn(traveltime, fam_relation) %>%\n  step_dummy(all_nominal_predictors())\nrec2 <- recipe(traveltime_NA ~., data=dat_na) %>%\n  step_rm(PreTest_NA, fam_relation_NA, traveltime) %>%\n  step_normalize(all_numeric_predictors())%>%\n  step_impute_knn(PreTest, fam_relation) %>%\n  step_dummy(all_nominal_predictors())\nrec3<- recipe(fam_relation_NA ~., data=dat_na) %>%\n  step_rm(PreTest_NA, traveltime_NA, fam_relation) %>%\n  step_normalize(all_numeric_predictors())%>%\n  step_impute_knn(traveltime, PreTest) %>%\n  step_dummy(all_nominal_predictors())\n# defined model\nlogistic_mod <- logistic_reg(penalty = tune(),\n                             mixture = tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n# defined workflow\nfolds<-vfold_cv(data = dat_na, v=10)\nlibrary(doMC)\nregisterDoMC(cores=15)\nna_result1 <- workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(logistic_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\nna_result2 <- workflow() %>%\n  add_recipe(rec2) %>%\n  add_model(logistic_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\nna_result3 <- workflow() %>%\n  add_recipe(rec3) %>%\n  add_model(logistic_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\n\nbest1<-show_best(na_result1, n=1, metric = \"roc_auc\")\nbest2<-show_best(na_result2, n=1, metric = \"roc_auc\")\nbest3<-show_best(na_result3, n=1, metric = \"roc_auc\")\nbest1 %>% bind_rows(best2,best3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 8\n   penalty mixture .metric .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1 0.000166   0.469 roc_auc binary     0.615    10  0.0274 Preprocessor1_Model23\n2 0.0101     0.499 roc_auc binary     0.696    10  0.0254 Preprocessor1_Model24\n3 0.00679    0.709 roc_auc binary     0.666    10  0.0156 Preprocessor1_Model35\n```\n:::\n:::\n\n\nผลการวิเคราะห์ข้างต้นแสดงให้เห็นว่าโมเดลทำนายค่าสูญหายในตัวแปรทั้งสามมีประสิทธิภาพการทำนายพิจารณาจากค่า roc_auc อยู่ในช่วงร้อยละ 57 - 69 ซึ่งแสดงว่ามีตัวแปรในชุดข้อมูลที่สามารถทำได้การสูญหายในตัวแปรทั้งสามได้พอสมควร นอกจากนี้เมื่อพิจารณาผลการวิเคราะห์ด้วย Variable Importance Plots พบว่ามีตัวแปรหลายตัวที่มีความสัมพันธ์กับการสูญหายในตัวแปรทั้ง 3 อย่างมีนัยสำคัญ ([vip package](https://cran.r-project.org/web/packages/vip/vignettes/vip-introduction.pdf)) จากผลการวิเคราะห์ส่วนนี้สรุปได้ว่า การสูญหายในตัวแปรทั้ง 3 มีแนวโน้มเป็นแบบ MAR\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## finalized best model\nna1 <-  workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(logistic_mod) %>%\n  finalize_workflow(best1) %>%\n  fit(dat_na)\n\nna2 <-  workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(logistic_mod) %>%\n  finalize_workflow(best1) %>%\n  fit(dat_na)\n\nna3 <-  workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(logistic_mod) %>%\n  finalize_workflow(best1) %>%\n  fit(dat_na)\n\n# create Variable Importance Plots\nlibrary(vip)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'vip'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:utils':\n\n    vi\n```\n:::\n\n```{.r .cell-code}\np1<-vip(na1%>%extract_fit_engine(),geom=\"point\")+\n  theme(text = element_text(size=5))\np2<-vip(na2%>%extract_fit_engine(),geom=\"point\")+\n  theme(text = element_text(size=5))\np3<-vip(na3%>%extract_fit_engine(),geom=\"point\")+\n  theme(text = element_text(size=5))\ngrid.arrange(p1,p2,p3, ncol=3)\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n### 1.5 การทดแทนค่าสูญหาย (แถม)\n\nในกรณีที่ค่าสูญหายมีจำนวนมาก วิธีการตัดข้อมูลออกจากการวิเคราะห์ หรือการทดแทนค่าสูญหายด้วยค่าเฉลี่ยจะไม่ใช่วิธีการที่ควรนำมาใช้แก้ปัญหา ภายใต้สถานการณ์นี้ผู้วิเคราะห์ควรพิจารณาปัจจัยตัวที่สองประกอบการเลือกวิธีการแก้ปัญหาที่เหมาะสมด้วย ได้แก่ กลไกการสูญหายของข้อมูล โดยหากกลไกการสูญหายเป็นแบบ MAR ผู้วิเคราะห์สามารถเลือกใช้เทคนิคได้หลายตัว เช่น การทดแทนค่าสูญหายด้วยการวิเคราะห์การถดถอย การทดแทนค่าสูญหายด้วยอัลกอริทึม K-nearest neighbors การทดแทนค่าสูญหายแบบหลายค่า การทดแทนค่าสูญหายด้วยวิธีการแบบเบย์ และการทดแทนค่าสูญหายด้วยอัลกอริทึมการเรียนรู้ของเครื่องอื่น ๆ\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(simputation)\nimputed_knn <- recipe(Ach ~., data=dat_na) %>%\n  step_rm(traveltime_NA,fam_relation_NA, PreTest_NA) %>%\n  step_impute_knn(traveltime, fam_relation, PreTest) %>%\n  prep(NULL) %>%\n  juice()\n\nimputed_bag <- recipe(Ach ~., data=dat_na) %>%\n  step_rm(traveltime_NA,fam_relation_NA, PreTest_NA) %>%\n  step_impute_bag(traveltime, fam_relation, PreTest) %>%\n  prep(NULL) %>%\n  juice()\n```\n:::\n\n::: {.cell}\n\n:::\n\n\nผู้วิเคราะห์ทดลองเปรียบเทียบผลการทดแทนค่าสูญหายจากวิธี Bagged Tree\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(full_preproc$PreTest, imputed_bag$PreTest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.963384\n```\n:::\n\n```{.r .cell-code}\ntable(full_preproc$traveltime, imputed_bag$traveltime)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            <15mins 15-30mins 30-60mins >60mins\n  <15mins       608        15         0       0\n  15-30mins       9       311         0       0\n  30-60mins       4         1        72       0\n  >60mins         1         3         0      20\n```\n:::\n\n```{.r .cell-code}\ntable(full_preproc$fam_relation, imputed_bag$fam_relation)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            worst bad fair good very good\n  worst        30   0    0    0         0\n  bad           0  45    0    2         0\n  fair          0   0  162    4         3\n  good          0   0    5  505         2\n  very good     0   0    0   11       275\n```\n:::\n:::\n\n\n### 2.1 จัดกลุ่มนักเรียนด้วยตัวแปรที่มี\n\nผลการวิเคราะห์ส่วนนี้แสดงการจัดกลุ่มนักเรียนด้วยอัลกอริทึม kprototype อัลกอริทึมดังกล่าวใช้สำหรับจัดกลุ่มข้อมูลเหมือนกับ kmeans แต่มีจุดเด่นคือสามารถใช้จัดกลุ่มข้อมูลโดยอิงกับข้อมูลหลากหลายประเภทพร้อมกัน แตกต่างจาก kmeans ที่สามารถใช้กับข้อมูลเชิงปริมาณเท่านั้น อัลกอริทึมนี้นำเสนอโดย Zhexue Huang (1997) สามารถมองเป็นอัลกอริทึมที่รวมกันระหว่าง kmeans และ kmodes clustering รายละเอียดของอัลกอริทึมเป็นดังนี้\n\n1.  กำหนดจำนวนกลุ่ม ให้มีค่าเท่ากับ k\n2.  แบ่งชุดข้อมูลออกเป็น k ส่วนอย่างสุ่ม (เรียกว่า initial prototype)\n3.  คำนวณคะแนนความแตกต่าง (dissimilarity) ระหว่างหน่วยข้อมูลแต่ละหน่วยกับ initial prototype ที่สร้างขึ้นในข้อ 2. ทั้งนี้คะแนนความแตกต่างดังกล่าวจะต้องคำนวณจากข้อมูลเชิงปริมาณและจัดประเภท คะแนนจึงคำนวณจากค่าเฉลี่ยถ่วงน้ำหนักระหว่างระยะห่างของข้อมูลเชิงปริมาณ เช่น euclidean distance กับระยะห่างของข้อมูลจัดประเภท เช่น Hamming distance คะแนนความแตกต่างดังกล่าวเป็นดังนี้ $Dis(x1,x2) = w \\times Euclid(x1_{cont},x2_{cont}) + (1-w) \\times Hamming(x1_{cat}, x2_{cat})$\n4.  ย้ายกลุ่มให้กับหน่วยข้อมูลไปยัง prototype ที่มีคะแนนความแตกต่างต่ำที่สุด\n5.  ทวนซ้ำขั้น 3 และ 4 จนกระทั้งไม่มีการเปลี่ยนกลุ่มของหน่วยข้อมูล หรือครบจำนวนรอบการทวนซ้ำที่กำหนด\n\n**หมายเหตุ** การคำนวณคะแนนความแตกต่างในขั้นที่ 3 สามารถเลือกใช้ระยะห่างแบบ Gower ก็ได้ ระยะห่างนี้ถูกนำเสนอโดย John C. Gower (1971) เพื่อใช้เปรียบเทียบความแตกต่างระหว่างหน่วยข้อมูลจากตัวแปรที่มีหลายประเภท\n\n**Gower distance (x, y)** = $\\frac{\\sum w_i * d_i(x, y)}{\\sum w_i}$\n\nเมื่อ $x$ และ $y$ คือหน่วยข้อมูล, $w_i$ คือน้ำหนักของตัวแปรที่ i (ค่าเริ่มต้นเท่ากับ 1.00) และ $d_i(x,y)$ คือความแตกต่าง/ระยะห่าง ระหว่าง $x$ กับ $y$ ภายใต้ตัวแปรที่ i\n\n> The dissimilarity \\$d_i(x, y)\\$ is calculated differently for different data types:\n>\n> 1.  **Continuous variables**: The dissimilarity is the normalized absolute difference between the two data points:\n>\n>     $d_i(x, y)$ = $\\frac{|x_i - y_i|}{\\max(x_i) - \\min(x_i)}$\n>\n> 2.  **Ordinal variables**: The dissimilarity is the normalized absolute difference between the two data points, considering the variable's rank:\n>\n>     $d_i(x, y)$ = $\\frac{|\\text{rank}(x_i) - \\text{rank}(y_i)|}{\\max(\\text{rank}(x_i)) - \\min(\\text{rank}(x_i))}$\n>\n> 3.  **Categorical variables**: The dissimilarity is 0 if $x_i = y_i$, and 1 otherwise:\n>\n>     $d_i(x, y)$ = $\\begin{cases} 1 & \\text{if } x_i \\neq y_i \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(FactoMineR)\nlibrary(factoextra)\nlibrary(ggrepel)\nlibrary(cluster)\n#do cluster analysis with mixed variable\nlibrary(clustMixType)\n\nk_range <- 2:10\ntot_withinSS <- numeric(length(k_range))\nsil_scores <- numeric(length(k_range))\n\nimputed_bag_scaled<-recipe(Ach~.,data=imputed_bag) %>%\n  step_normalize(all_numeric()) %>%\n  prep(NULL) %>%\n  juice()\n\ngower_dist <- daisy(imputed_bag_scaled, metric = \"gower\")\n\nfor(k in k_range){\n  kproto_res <- kproto(imputed_bag_scaled, k)\n  tot_withinSS[k-1]<-kproto_res$tot.withinss\n  sil_scores[k-1]<-mean(silhouette(kproto_res$cluster,\n                                   gower_dist)[,3])\n}\n# Plot the total within-cluster sum of squares for each k\nplot(k_range, tot_withinSS, type = \"b\", xlab = \"Number of clusters (k)\", ylab = \"Total within-cluster sum of squares\", main = \"Elbow Method\")\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plot the average silhouette width for each k\nplot(k_range, sil_scores, type = \"b\", xlab = \"Number of clusters (k)\", ylab = \"Average silhouette width\", main = \"Silhouette Method\")\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-16-2.png){width=672}\n:::\n:::\n\n\nผลการวิเคราะห์ข้างต้นแสดงให้เห็นว่า จำนวนกลุ่มที่เหมาะสมน่าจะอยู่ในช่วง 2-4 กลุ่ม ขั้นตอนต่อไปคือการวิเคราะห์ profile ของแต่ละกลุ่ม เพื่อพิจารณาเลือกจำนวนกลุ่มที่เหมาะสมอีกครั้งหนึ่ง ผลการวิเคราะห์ที่ได้พบว่า...\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_result2 <- kproto(imputed_bag, k=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# NAs in variables:\n      school       gender          age     location      famsize   ParentStat \n           0            0            0            0            0            0 \n      MomEdu       DadEdi       MomJob       DadJob    StuParent   traveltime \n           0            0            0            0            0            0 \n readingtime         fail  scholarship     club_act      nursery       higher \n           0            0            0            0            0            0 \n    internet       InLove fam_relation     freetime        goout    Drink_alc \n           0            0            0            0            0            0 \n      health     absences      PreTest      subject          Ach \n           0            0            0            0            0 \n0 observation(s) with NAs.\n\nEstimated lambda: 25.08972 \n\n0 observation(s) with NAs.\n```\n:::\n\n```{.r .cell-code}\ncluster_result3 <- kproto(imputed_bag, k=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# NAs in variables:\n      school       gender          age     location      famsize   ParentStat \n           0            0            0            0            0            0 \n      MomEdu       DadEdi       MomJob       DadJob    StuParent   traveltime \n           0            0            0            0            0            0 \n readingtime         fail  scholarship     club_act      nursery       higher \n           0            0            0            0            0            0 \n    internet       InLove fam_relation     freetime        goout    Drink_alc \n           0            0            0            0            0            0 \n      health     absences      PreTest      subject          Ach \n           0            0            0            0            0 \n0 observation(s) with NAs.\n\nEstimated lambda: 25.08972 \n\n0 observation(s) with NAs.\n```\n:::\n\n```{.r .cell-code}\ncluster_result4 <- kproto(imputed_bag, k=4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# NAs in variables:\n      school       gender          age     location      famsize   ParentStat \n           0            0            0            0            0            0 \n      MomEdu       DadEdi       MomJob       DadJob    StuParent   traveltime \n           0            0            0            0            0            0 \n readingtime         fail  scholarship     club_act      nursery       higher \n           0            0            0            0            0            0 \n    internet       InLove fam_relation     freetime        goout    Drink_alc \n           0            0            0            0            0            0 \n      health     absences      PreTest      subject          Ach \n           0            0            0            0            0 \n0 observation(s) with NAs.\n\nEstimated lambda: 25.08972 \n\n0 observation(s) with NAs.\n```\n:::\n\n```{.r .cell-code}\nimputed_bag$clus2 <- cluster_result2$cluster\nimputed_bag$clus3 <- cluster_result3$cluster\nimputed_bag$clus4 <- cluster_result4$cluster\n\n# preprocessing\nrec_cluster2 <- recipe(clus2 ~., data=imputed_bag) %>%\n  step_rm(clus3, clus4) %>%\n  step_mutate(clus2 = factor(clus2)) %>%\n  step_normalize(all_numeric_predictors())\n\nrec_cluster3 <- recipe(clus3 ~., data=imputed_bag) %>%\n  step_rm(clus2, clus4) %>%\n  step_mutate(clus3 = factor(clus3)) %>%\n  step_normalize(all_numeric_predictors())\n\nrec_cluster4 <- recipe(clus4 ~., data=imputed_bag) %>%\n  step_rm(clus2, clus3) %>%\n  step_mutate(clus4 = factor(clus4)) %>%\n  step_normalize(all_numeric_predictors())\n\n# defined model\nrf_mod <- rand_forest(mtry=tune(),\n                      trees = 500,\n                      min_n = tune()) %>%\n  set_engine(\"ranger\", importance = \"permutation\") %>%\n  set_mode(\"classification\")\n\n# defined workflow\nfolds<-vfold_cv(data = imputed_bag, v=10)\nlibrary(doMC)\nregisterDoMC(cores=15)\ncluster2_result <- workflow() %>%\n  add_recipe(rec_cluster2) %>%\n  add_model(rf_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n:::\n\n```{.r .cell-code}\ncluster3_result <- workflow() %>%\n  add_recipe(rec_cluster3) %>%\n  add_model(rf_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n:::\n\n```{.r .cell-code}\ncluster4_result <- workflow() %>%\n  add_recipe(rec_cluster4) %>%\n  add_model(rf_mod) %>%\n  tune_grid(resamples = folds,\n            grid=50)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n:::\n\n```{.r .cell-code}\nbest1<-show_best(cluster2_result, n=1, metric = \"roc_auc\")\nbest2<-show_best(cluster3_result , n=1, metric = \"roc_auc\")\nbest3<-show_best(cluster4_result , n=1, metric = \"roc_auc\")\n\nbest1 %>% bind_rows(best2, best3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 8\n   mtry min_n .metric .estimator  mean     n  std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>    <dbl> <chr>                \n1     9     7 roc_auc binary     0.996    10 0.000964 Preprocessor1_Model22\n2    13     3 roc_auc hand_till  0.991    10 0.00224  Preprocessor1_Model22\n3     7     7 roc_auc hand_till  0.968    10 0.00478  Preprocessor1_Model30\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## finalized best model\nclus2 <-  workflow() %>%\n  add_recipe(rec_cluster2) %>%\n  add_model(rf_mod) %>%\n  finalize_workflow(best1) %>%\n  fit(imputed_bag)\n\nclus3 <-  workflow() %>%\n  add_recipe(rec_cluster3) %>%\n  add_model(rf_mod) %>%\n  finalize_workflow(best2) %>%\n  fit(imputed_bag)\n\nclus4 <-  workflow() %>%\n  add_recipe(rec_cluster4) %>%\n  add_model(rf_mod) %>%\n  finalize_workflow(best3) %>%\n  fit(imputed_bag)\n\n# create Variable Importance Plots\np1<-vip(clus2%>%extract_fit_engine(),geom=\"point\", num_features = 15)+\n  theme(text = element_text(size=7))+\n  ggtitle(\"2 clusters\")\np2<-vip(clus3%>%extract_fit_engine(),geom=\"point\", num_features = 15)+\n  theme(text = element_text(size=7))+\n  ggtitle(\"3 clusters\")\np3<-vip(clus4%>%extract_fit_engine(),geom=\"point\", num_features = 15)+\n  theme(text = element_text(size=7))+\n  ggtitle(\"4 clusters\")\ngrid.arrange(p1,p2,p3, ncol=3)\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 3 clusters\np1<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=absences))+\n  geom_boxplot()\np2<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=Ach))+\n  geom_boxplot()\np3<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=PreTest))+\n  geom_boxplot()\np4<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=as.numeric(gender)))+\n  geom_jitter(aes(col = gender))\np5<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=as.numeric(subject)))+\n  geom_jitter(aes(col = subject))\np6<-imputed_bag %>%\n  ggplot(aes(x=factor(clus3), y=as.numeric(goout)))+\n  geom_jitter(aes(col = goout))\ngrid.arrange(p1,p2,p3,p4,p5,p6,ncol=2)\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 4 clusters\np1<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=absences))+\n  geom_boxplot()\np2<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=Ach))+\n  geom_boxplot()\np3<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=PreTest))+\n  geom_boxplot()\np4<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=as.numeric(MomEdu)))+\n  geom_jitter(aes(col = MomEdu))\np5<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=as.numeric(DadEdi)))+\n  geom_jitter(aes(col = DadEdi))\np6<-imputed_bag %>%\n  ggplot(aes(x=factor(clus4), y=as.numeric(school)))+\n  geom_jitter(aes(col = school))\ngrid.arrange(p1,p2,p3,p4,p5,p6,ncol=2)\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nผลการวิเคราะห์ข้างต้นควรเลือกกี่กลุ่ม และแต่ละกลุ่มมี profile เป็นอย่างไร?\n\n### 2.2 พัฒนาโมเดลทำนายผลสัมฤทธิ์ทางการเรียน\n\nการวิเคราะห์ส่วนนี้ผู้วิเคราะห์เลือกอัลกอริทึมมาเปรียบเทียบกัน 3 ตัวได้แก่\n\n-   regularized logistic regression\n\n-   random forest\n\n-   gradient boosting\n\n#### Data Preprocessing\n\nผลวิเคราะห์ส่วนนี้ผู้วิเคราะห์ออกแบบให้ใช้ classification model ทั้งนี้เพื่อให้ผลการทำนายมีความหมายที่เป็นรูปธรรมมากกว่าการทำนายด้วยคะแนนสอบปกติ\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemp <- imputed_bag %>%\n  mutate(Ach_class = factor(ifelse(Ach>=15,3,ifelse(Ach<=5,1,2))))\ntable(temp$Ach_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  1   2   3 \n 63 777 204 \n```\n:::\n:::\n\n\nการแบ่งระดับผลสัมฤทธิ์ข้างต้นจะเห็นว่าก่อให้เกิดปัญหา **Imbalance class** ขึ้น สภาพดังกล่าวอาจทำให้การวิเคราะห์มีประสิทธิภาพการทำนายที่ต่ำกว่าที่ควรจะเป็น ดังนั้น job แรกของการวิเคราะห์จะพิจารณาผลกระทบของ imbalance class ดังกล่าวก่อน วิธีการแก้ไขที่ใช้ในตัวอย่างจะใช้ SMOTE (synthetic minority over-sampling) ซึ่งเป็นวิธีการพื้นฐานตัวหนึ่งที่ใช้แก้ปัญหา imbalance class ดังกล่าว\n\nSMOTE จะสร้างข้อมูลสังเคราะห์ (synthetic data) ให้กับ minority class โดยใช้การ interpolate ระหว่างหน่วยข้อมูลของกลุ่ม minority ภายใต้ปริภูมิของ feature หลักสำคัญของการสร้างข้อมูลสังเคราะห์คือ จะสร้างข้อมูลใหม่ที่เหมือนกับหน่วยข้อมูลเดิมในกลุ่ม minority แต่จะไม่เท่ากับหน่วยข้อมูลเดิมดังกล่าว ทั้งนี้เพื่อลดความลำเอียงที่จะเกิดขึ้นจากการบิดเบือนการแจกแจงของข้อมูล อัลกอริทึมดังกล่าวจะดำเนินไปเพื่อสร้างข้อมูลสังเคราะห์ให้กับหน่วยข้อมูลแต่ละหน่วยของ minority class มีขั้นตอนดำเนินการในแต่ละหน่วยข้อมูล (x) ดังนี้\n\n1.  กำหนด hyperparameter k (nearest neightbors)\n2.  เลือกหน่วยข้อมูลใน minority class ภายใต้ k nearest neightbors ของ x อย่างสุ่มขึ้นมา 1 ตัว\n3.  สร้างข้อมูลสังเคราะห์โดยใช้การ interpolate ระหว่างหน่วยข้อมูล x กับหน่วยข้อมูลที่เลือกมาในขั้นที่ 2\n4.  ทวนซ้ำ 2 - 3 จนได้จำนวนข้อมูลสังเคราะห์ตามที่ต้องการ\n\nผลลัพธ์ด้านล่างแสดงให้เห็นว่าการทำ smote ช่วยให้ประสิทธิภาพการทำนายดีกว่า\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(themis)\nrec_nosmote <- recipe(Ach_class ~. , data= temp) %>%\n  step_rm(clus2:clus4, Ach) %>%\n  step_normalize(all_numeric_predictors()) %>%\n  step_dummy(all_nominal_predictors())\n\n\nrec_smote <- recipe(Ach_class ~. , data= temp) %>%\n  step_rm(clus2:clus4, Ach) %>%\n  step_normalize(all_numeric_predictors()) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_smote(Ach_class, neighbors = 5) \n\nlogit_mod1 <- multinom_reg(penalty=tune(),\n                          mixture=tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\nlogit_mod2 <- multinom_reg(penalty=tune(),\n                          mixture=tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\nwfset <- workflow_set(\n  preproc = list(rec_nosmote, rec_smote),\n  models = list(logit_mod1, logit_mod2),\n  cross=F\n)\n\nfold<-vfold_cv(temp, v=5, repeats=3, strata = Ach_class)\nlibrary(doMC)\nregisterDoMC(cores=15)\neval_metrics <- metric_set(roc_auc, sens, spec)\nresult_smote<-wfset %>%\n  workflow_map(resamples=fold,\n               grid=50,\n               metrics = eval_metrics)\nresult_smote %>% collect_metrics(summarise=T) %>%\n  filter(.metric %in% c(\"roc_auc\")) %>%\n  arrange(desc(mean)) %>%\n  dplyr::select(wflow_id, .metric, mean, n, std_err)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 100 × 5\n   wflow_id                .metric  mean     n std_err\n   <chr>                   <chr>   <dbl> <int>   <dbl>\n 1 recipe_2_multinom_reg_2 roc_auc 0.920    15 0.00519\n 2 recipe_2_multinom_reg_2 roc_auc 0.918    15 0.00471\n 3 recipe_2_multinom_reg_2 roc_auc 0.918    15 0.00572\n 4 recipe_2_multinom_reg_2 roc_auc 0.917    15 0.00496\n 5 recipe_2_multinom_reg_2 roc_auc 0.913    15 0.00627\n 6 recipe_1_multinom_reg_1 roc_auc 0.907    15 0.00499\n 7 recipe_1_multinom_reg_1 roc_auc 0.905    15 0.00581\n 8 recipe_2_multinom_reg_2 roc_auc 0.904    15 0.00726\n 9 recipe_1_multinom_reg_1 roc_auc 0.902    15 0.00749\n10 recipe_1_multinom_reg_1 roc_auc 0.901    15 0.00703\n# … with 90 more rows\n```\n:::\n\n```{.r .cell-code}\nresult_smote %>% collect_metrics(summarise=T) %>%\n  filter(.metric %in% c(\"sens\")) %>%\n  arrange(desc(mean)) %>%\n  dplyr::select(wflow_id, .metric, mean, n, std_err)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 100 × 5\n   wflow_id                .metric  mean     n std_err\n   <chr>                   <chr>   <dbl> <int>   <dbl>\n 1 recipe_2_multinom_reg_2 sens    0.791    15 0.0102 \n 2 recipe_2_multinom_reg_2 sens    0.789    15 0.00819\n 3 recipe_2_multinom_reg_2 sens    0.782    15 0.00700\n 4 recipe_2_multinom_reg_2 sens    0.775    15 0.0101 \n 5 recipe_2_multinom_reg_2 sens    0.770    15 0.0134 \n 6 recipe_2_multinom_reg_2 sens    0.754    15 0.0139 \n 7 recipe_2_multinom_reg_2 sens    0.743    15 0.0173 \n 8 recipe_2_multinom_reg_2 sens    0.740    15 0.0179 \n 9 recipe_2_multinom_reg_2 sens    0.722    15 0.0157 \n10 recipe_2_multinom_reg_2 sens    0.712    15 0.0154 \n# … with 90 more rows\n```\n:::\n:::\n\n\nผลการสร้างข้อมูลสังเคราะห์ด้วย SMOTE\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nAch_class\n  1   2   3 \n777 777 777 \n```\n:::\n:::\n\n\n#### Training\n\nขั้นตอนต่อไปคือการ train โมเดลทั้งสามในข้างต้น ดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsplit <- initial_split(temp, prop=0.75, strata=Ach_class)\ntrain <- training(split)\ntest <- testing(split)\n\n# preprocessing\nrec_smote <- recipe(Ach_class ~. , data= train) %>%\n  step_rm(clus2:clus4, Ach) %>%\n  step_normalize(all_numeric_predictors()) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_smote(Ach_class, neighbors = 5) \n\n# model specification\n### regularized logistic regression\nlogit_mod <- multinom_reg(penalty=tune(),\n                          mixture=tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\n### random forest (ุ6.3 secs)\nrf_mod <- rand_forest(trees=300,\n                      mtry=tune(),\n                      min_n=tune()\n                      ) %>%\n  set_engine(\"ranger\", importance = \"permutation\") %>%\n  set_mode(\"classification\")\n\n### KNN (4.44 sec per round)\nknn_mod <- nearest_neighbor(neighbors = tune(),\n                            weight_func = tune(),\n                            dist_power = 2) %>%\n  set_engine(\"kknn\") %>%\n  set_mode(\"classification\")\n\n### gradient boosting (10.42 secs per round)\nlibrary(xgboost)\nboost_mod <- boost_tree(trees=300,\n                        min_n = tune(),\n                        tree_depth = tune(),\n                        learn_rate = tune()\n                      ) %>%\n  set_engine(\"xgboost\") %>%\n  set_mode(\"classification\")\n\n# create workflowset\nwfset <- workflow_set(\n  preproc = list(rec_smote),\n  models = list(logit_mod, knn_mod, rf_mod)\n)\nfold<-vfold_cv(train, v=5, repeats=2, strata = Ach_class)\n\n# tuning hyperparameters\neval_metrics <- metric_set(roc_auc, sens, spec)\nlibrary(doMC)\nregisterDoMC(cores=15)\nstart <- Sys.time()\nresult <- wfset %>%\n  workflow_map(resamples = fold,\n               grid = 50,\n               control = control_grid(save_pred = TRUE),\n               metrics = eval_metrics)\npaste(\"time usage\", round(Sys.time() - start,2), \"mins\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"time usage 6.93 mins\"\n```\n:::\n:::\n\n\nผลการปรับแต่ง hyperparameter ของโมเดลข้างต้นเป็นดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresult\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 3 × 4\n  wflow_id                info             option    result   \n  <chr>                   <list>           <list>    <list>   \n1 recipe_multinom_reg     <tibble [1 × 4]> <opts[4]> <tune[+]>\n2 recipe_nearest_neighbor <tibble [1 × 4]> <opts[4]> <tune[+]>\n3 recipe_rand_forest      <tibble [1 × 4]> <opts[4]> <tune[+]>\n```\n:::\n\n```{.r .cell-code}\nresult %>% autoplot()\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n```{.r .cell-code}\nresult %>% extract_workflow_set_result(id = \"recipe_multinom_reg\") %>%\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n:::\n\n\n### 2.3 ปัจจัยที่มีความสำคัญหรือปัจจัยเสี่ยงต่อความสำเร็จในการเรียน\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest <- show_best(result %>% extract_workflow_set_result(id = \"recipe_multinom_reg\"),\n                  n=1, metric = \"sens\")\nbest\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  penalty mixture .metric .estimator  mean     n std_err .config              \n    <dbl>   <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1   0.108   0.401 sens    macro      0.787    10  0.0163 Preprocessor1_Model21\n```\n:::\n\n```{.r .cell-code}\n## last fit\nlogit_result <- workflow() %>%\n  add_recipe(rec_smote) %>%\n  add_model(logit_mod) %>%\n  finalize_workflow(best) %>%\n  last_fit(split)\n\nlogit_result %>% collect_metrics(summarise=T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy multiclass     0.660 Preprocessor1_Model1\n2 roc_auc  hand_till      0.920 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\nlogit_result %>% collect_predictions() %>%\n  conf_mat(truth = Ach_class , estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Truth\nPrediction   1   2   3\n         1  11  36   0\n         2   2 113   3\n         3   0  48  49\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlogit_result %>% extract_fit_engine() %>% vip(num_feature=20)+\n  scale_y_continuous(breaks=seq(0,18,1))+\n  theme(panel.grid.minor = element_blank())\n```\n\n::: {.cell-output-display}\n![](MidtermExam_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "MidtermExam_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}