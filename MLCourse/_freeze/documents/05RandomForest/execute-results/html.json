{
  "hash": "8ec2979a00f2ad8fabb2cc9314114e18",
  "result": {
    "markdown": "---\ntitle: \"Random Forest\"\nauthor: \"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร\"\ntoc: true\ntoc-depth: 3\ntoc-title: สารบัญ\ntheme: default\n---\n\n::: {.cell}\n\n:::\n\n\n# บทที่ 7 : Random Forest Algorithm\n\nถึงแม้ว่า Decision tree จะเป็นโมเดลที่สร้างง่าย ใช้งาน และแปลผลง่าย แต่โดยทั่วไปแล้ว ประสิทธิภาพการทำนายของ decision tree มักไม่ค่อยดี และสุ่มเสี่ยงที่จะเกิดปัญหา overfitting ได้ง่ายอีกด้วย\n\n![](images/image-1695152319.png)\n\n## 7.1 Basic Concepts\n\nจากข้อจำกัดของ decision tree (รวมทั้ง ML แบบ single learner ตัวอื่น ๆ ) จึงมีการพัฒนาวิธีการสร้างโมเดลทำนายโดยใช้การรวมผลทำนายจากชุดข้อมูล bootstrap เรียกว่า bootstrap aggregation (bagging) รูปด้านล่างแสดงแนวคิดพื้นฐานของ bagging method\n\n![](images/image-1237506128.png)\n\nrandom forest ในยุคแรกใช้แนวคิดของ bagging ข้างต้นโดยตรง โดยมีขั้นตอนการดำเนินงานดังนี้\n\nกำหนดให้ training dataset ของผู้วิเคราะห์มีขนาด n หน่วย\n\n1.  สร้าง bootstrap dataset โดยใช้การสุ่มตัวอย่างแบบใส่คืน ขนาด n หน่วย (sampling with replacement) จากชุดข้อมูล trainng data\n\n2.  นำชุดข้อมูลแต่ละชุดมาสร้าง decision tree\n\n3.  ทวนซ้ำขั้นตอนที่ 1 และ 2 จนครบ bootstrap dataset ทั้งหมด\n\n4.  นำผลทำนายจาก bootstrap dataset แต่ละชุดมาหา majority vote\n\n    ![ตัวอย่าง bootstrap dataset](images/image-275986106.png){alt=\"ตัวอย่าง bootstrap dataset\"}\n\nอย่างไรก็ตาม bagging tree ข้างต้นมีข้อจำกัดกล่าวคือในแต่ละรอบของการทวนซ้ำ อัลกอริทึมมักสร้าง decision tree ที่ซ้ำซ้อนกัน ซึ่งให้ประสิทธิภาพการทำนายไม่ได้ดีขึ้นเท่าที่ควร จากข้อจำกัดนี้จึงมีการพัฒนา random forest algorithm ขึ้น ซึ่งมีรายละเอียดดังนี้\n\n    1. สร้าง training dataset\n    2. กำหนด hyperparameter ของโมเดล\n    3. สร้าง bootstrap dataset จาก traning dataset\n    4. สร้าง decision tree จาก bootstrap dataset ดังกล่าวภายใต้เงื่อนไขของ hyperparameter ที่กำหนด \n    5. นำ decision tree ใน 4. ไปคำนวณ error ใน OOB แล้วเก็บค่าไว้\n    6. ทวนซ้ำ 3 - 5 ใหม่ จนได้จำนวน tree model ครบตามกำหนด นำ OOB error ของ model ทั้งหมดมาเฉลี่ยรวมกันจะได้ error ของ random forest \n    7. ทวนซ้ำ 2. ถึง 6. ใหม่ด้วย cross-validation จนครบทั้ง hyperparameter grid นำ error ทั้งหมดมาวิเคราะห์เพื่อเลือก hyperparameter ชุดที่ดีที่สุด\n\n![สิวะโชติ ศรีสุทธิยากร (2564)](images/image-2033240077.png){alt=\"สิวะโชติ ศรีสุทธิยากร (2564)\"}\n\n## 7.2 Out-of-Bag (OOB)\n\nจากตัวอย่าง algorithm ของ random forest ข้างต้นจะเห็นว่ามี hyperparameter ที่จะต้อง fine-tune เนื่องจาก random forest สร้างขึ้นจาก bootstrap dataset การตรวจสอบประสิทธิภาพของโมเดลเพื่อ fine-tune hyperparameters จึงจะใช้การประเมินจาก out-of-bag error โดยที่ out-of-bag error จะคำนวณจากหน่วยข้อมูลที่ไม่ถูกเลือกให้อยู่ภายใต้ bootstrap dataset ในแต่ลละรอบ ซึ่งในทางทฤษฎีจะมีหน่วยข้อมูลแบบ OOB นี้คิดเป็นร้อยละประมาณ 37 ของ original dataset\n\n## 7.3 Hyperparameters ของ Random Forest\n\nhyperparameter ของ random forest เช่น\n\n1.  **n_trees** --- จำนวนต้นไม้ของแต่ละ random forest จำนวนต้นไม้มีผลโดยตรงต่อประสิทธิภาพในการทำนาย กล่าวคือหากกำหนดให้มีต้นไม้จำนวนมาก การประมาณประสิทธิภาพในการทำนายจะทำได้อย่างคงเส้นคงวา ส่งผลให้การ fine-tune hyperparameter ทำได้อย่างมีประสิทธิภาพตามไปด้วย อย่างไรก็ตามจำนวนต้นไม้ที่มากเกินไปก็จะใช้ทรัพยากรการประมวลผลที่มากตามไปด้วย\n2.  **mtry** --- จำนวนของ feature ที่จะสุ่มมาสร้าง tree model แต่ละ model ภายใต้ random forest\n3.  **cp** --- หรือ cost of complexity hyperparameter อธิบายโดยละเอียดไปแล้วใน decision tree\n4.  **minspit** --- จำนวนหน่วยข้อมูลขั้นต่ำที่ต้องมีภายในแต่ละ node (node size)\n5.  **minbucket** --- จำนวนหน่วยข้อมูลขั้นต่ำของ Terminal node\n6.  **maxdepth.** --- ความลึกสูงที่สุดของต้นไม้แต่ละต้น\n7.  **splitrule**\n\n## 7.4 ตัวอย่างการวิเคราะห์ random forest\n\nใน R มี package หลายตัวที่สามารถใช้วิเคราะห์ random forest ได้ package หนึ่งที่มีประสิทธิภาพคือ ranger ชุดคำสั่งต่อไปนี้เป็นการใช้ฟังก์ชัน `ranger` โดยตรงเพื่อวิเคราะห​ random forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(rsample)\nlibrary(ranger)\nlibrary(vip)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'vip'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:utils':\n\n    vi\n```\n:::\n\n```{.r .cell-code}\nlibrary(yardstick)\n# importing and preprocessing\ndat <- read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/TeacherSalaryData.csv\")\n\ndat <- dat[,-1]\nsummary(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     rank            discipline        yrs.since.phd    yrs.service   \n Length:397         Length:397         Min.   : 1.00   Min.   : 0.00  \n Class :character   Class :character   1st Qu.:12.00   1st Qu.: 7.00  \n Mode  :character   Mode  :character   Median :21.00   Median :16.00  \n                                       Mean   :22.31   Mean   :17.61  \n                                       3rd Qu.:32.00   3rd Qu.:27.00  \n                                       Max.   :56.00   Max.   :60.00  \n     sex                salary      \n Length:397         Min.   : 57800  \n Class :character   1st Qu.: 91000  \n Mode  :character   Median :107300  \n                    Mean   :113706  \n                    3rd Qu.:134185  \n                    Max.   :231545  \n```\n:::\n\n```{.r .cell-code}\ndat1_preproc<- dat %>%\n  mutate(salary_class = ifelse(salary>=100000,1,0),\n         salary_class = factor(salary_class,\n                               levels = c(0,1),\n                               labels = c(\"low\",\"high\"))) %>%\n  select(-salary)\nsummary(dat1_preproc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     rank            discipline        yrs.since.phd    yrs.service   \n Length:397         Length:397         Min.   : 1.00   Min.   : 0.00  \n Class :character   Class :character   1st Qu.:12.00   1st Qu.: 7.00  \n Mode  :character   Mode  :character   Median :21.00   Median :16.00  \n                                       Mean   :22.31   Mean   :17.61  \n                                       3rd Qu.:32.00   3rd Qu.:27.00  \n                                       Max.   :56.00   Max.   :60.00  \n     sex            salary_class\n Length:397         low :140    \n Class :character   high:257    \n Mode  :character               \n                                \n                                \n                                \n```\n:::\n:::\n\n\nขั้นตอนถัดมาคือแบ่งชุดข้อมูลเป็น training และ test dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nsplit <- initial_split(dat1_preproc, prop = 0.8, strata = salary_class)\ntrain<-training(split)\ntest<-testing(split)\n\ntable(train$salary_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n low high \n 112  205 \n```\n:::\n\n```{.r .cell-code}\ntable(test$salary_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n low high \n  28   52 \n```\n:::\n:::\n\n\nวิเคราะห์ random forest model ด้วยฟังก์ชัน `ranger()` ในตัวอย่างนี้จะกำหนดให้เป็นค่าเริ่มต้นทั้งหมดก่อน\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_rf1 <- ranger(salary_class ~ . ,\n                  data = train,\n                  importance = \"impurity\")\nfit_rf1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRanger result\n\nCall:\n ranger(salary_class ~ ., data = train, importance = \"impurity\") \n\nType:                             Classification \nNumber of trees:                  500 \nSample size:                      317 \nNumber of independent variables:  5 \nMtry:                             2 \nTarget node size:                 1 \nVariable importance mode:         impurity \nSplitrule:                        gini \nOOB prediction error:             15.14 % \n```\n:::\n\n```{.r .cell-code}\nvip(fit_rf1)\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nคำนวณค่าทำนายและตรวจสอบความคลาดเคลื่อนของค่าทำนายบนชุดข้อมูล test data\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_class <- predict(fit_rf1, test, type=\"response\")$predictions\ntable(pred, test$salary_class)\n```\n:::\n\n\n## 7.5 fine-tune hyperparameters\n\nหัวข้อนี้จะแสดงการ fine-tune hyperparameter ของ random forest ตาม algorithm ที่ในข้างต้น โดยใช้ tidymodel framwork รายละเอียดมีดังนี้\n\n### ขั้นแรก นำเข้าข้อมูล และจัดการ label ของข้อมูล\n\nตัวอย่างนี้จะแปลงข้อมูลตัวแปรตาม `salary` ให้เป็นตัวแปรแบบจัดประเภทที่มี 2 กลุ่ม คือกลุ่มที่เป็นอาจารย์รายได้สูง (\\>= 100,000 บาท) และกลุ่มอาจารย์รายได้ต่ำ (\\< 100,000 บาท)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parsnip)\nlibrary(recipes)\n# importing dataset\ndat <- read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/TeacherSalaryData.csv\")\nglimpse(dat, width = 80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 397\nColumns: 7\n$ X             <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ rank          <chr> \"Prof\", \"Prof\", \"AsstProf\", \"Prof\", \"Prof\", \"AssocProf\",…\n$ discipline    <chr> \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"…\n$ yrs.since.phd <int> 19, 20, 4, 45, 40, 6, 30, 45, 21, 18, 12, 7, 1, 2, 20, 1…\n$ yrs.service   <int> 18, 16, 3, 39, 41, 6, 23, 45, 20, 18, 8, 2, 1, 0, 18, 3,…\n$ sex           <chr> \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", …\n$ salary        <int> 139750, 173200, 79750, 115000, 141500, 97000, 175000, 14…\n```\n:::\n\n```{.r .cell-code}\ndat <- dat %>% \n  mutate(salary_class = ifelse(salary>=100000,1,0),\n         salary_class = factor(salary_class, labels=c(\"low\",\"high\")))\nglimpse(dat, width = 80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 397\nColumns: 8\n$ X             <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ rank          <chr> \"Prof\", \"Prof\", \"AsstProf\", \"Prof\", \"Prof\", \"AssocProf\",…\n$ discipline    <chr> \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"…\n$ yrs.since.phd <int> 19, 20, 4, 45, 40, 6, 30, 45, 21, 18, 12, 7, 1, 2, 20, 1…\n$ yrs.service   <int> 18, 16, 3, 39, 41, 6, 23, 45, 20, 18, 8, 2, 1, 0, 18, 3,…\n$ sex           <chr> \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", …\n$ salary        <int> 139750, 173200, 79750, 115000, 141500, 97000, 175000, 14…\n$ salary_class  <fct> high, high, low, high, high, low, high, high, high, high…\n```\n:::\n:::\n\n\n### ขั้นที่สอง แบ่งชุดข้อมูล\n\nกำหนด seed number เท่ากับ 123 จากนั้นแบ่งชุดข้อมูลโดยใช้ rsample package ดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nsplit <- initial_split(dat, prop = 0.8)\ntrain<-training(split)\ntest<-testing(split)\n```\n:::\n\n\n### ขั้นที่สาม สร้าง recipe object สำหรับจัดการข้อมูล\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreproc <- recipe(salary_class ~ ., data = train) %>%\n  step_select(-X, -salary)\n```\n:::\n\n\n### ขั้นที่ 4 กำหนดโมเดล (model specification)\n\nตัวอย่างนี้จะใช้ random forest ใน parsnip สามารถ fit random forest model ได้ด้วย engine หลายตัว ในตัวอย่างนี้จะใช้ `ranger` ที่มี hyperparameter ให้กำหนดได้ 3 ตัวได้แก่ mtry, trees และ min_n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforest_mod <- rand_forest(mtry = tune(),\n                          trees = 500,\n                          min_n = tune()) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n```\n:::\n\n\n### ขั้นที่ 5 สร้าง workflow\n\nผู้วิเคราะห์ไม่จำเป็นต้องสร้าง workflow ก็สามารถใช้ `tune_grid()` เพื่อ fine-tune hyperparameter ได้ โดยใช้ parsnip object ที่สร้างขึ้นในขั้น 4 เป็น object ใน `tune_grid()` ได้เลย อย่างไรก็ตามในสถานการณ์ทั่วไปผู้วิเคราะห์จะเป็นต้อง preprocess ข้อมูลก่อนอยู่แล้ว การใช้ workflow จึงน่าจะสะดวกกว่าในกรณีทั่วไป\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_workflow <- workflow() %>%\n  add_recipe(preproc) %>%\n  add_model(forest_mod)\nrf_workflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_select()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 500\n  min_n = tune()\n\nComputational engine: ranger \n```\n:::\n:::\n\n\n### ขั้นที่ 6 เตรียมทำ cross-validation และกำหนด hyperparameter grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create folds\nfolds <- vfold_cv(train, repeats =5, strata = \"salary_class\")\n# create random grid\nmy_hyparams <- parameters(mtry(range=c(1,5)),\n                          min_n(range=c(10,40)))\nmy_grid <- grid_random(my_hyparams, size = 20)\nmy_grid %>% ggplot()+\n  geom_point(aes(mtry, min_n))\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# crete evaluation metrics\neval_metric <- metric_set(roc_auc, sens, spec)\n```\n:::\n\n\n### ขั้นที่ 7 ทำ CV เพื่อนำข้อมูลมา tune hyperparameters\n\nฟังก์ชันที่ใช้คือ `tune_grid()` มีอาร์กิวเมนท์ที่สำคัญได้แก่\n\n-   `resamples` ใช้ระบุชุดข้อมูลที่สร้างขึ้นจากกระบวนการสุ่มซ้ำ เช่น k-folds CV หรือ boostraping dataset\n\n-   `grid` ใช้สำหรับระบุ grid ของ hyperparameter ของอัลกอริทึมการเรียนรู้ที่เลือกใช้\n\n-   `control` ใช้กำหนด option สำหรับควบคุมกระบวนการสุ่มซ้ำ (resample) และปรับแต่งค่า hyperparameter การกำหนดอาร์กิวเมนท์นี้จะต้องกำหนดผ่านฟังก์ชัน `control_resamples()` หรือ `control_grid()` อีกทีหนึ่ง รายละเอียดของฟังก์ชันทั้งสองสามารถศึกษาได้จากคู่มือการใช้งาน (พิมพ์ `?control_resamples` หรือ `?control_grid`)\n\n-   `metrics` ใช้กำหนด evalution metrics ที่ผู้วิเคราะห์จะใช้เพื่อประเมินประสิทธิภาพของโมเดลระหว่างการปรับแต่งค่าพารามิเตอร์ การกำหนดอาร์กิวเมนท์นี้ให้ทำผ่านฟังก์ชัน `metric_set()` ในกรณีที่ไม่ได้กำหนดโปรแกรมจะกำหนดให้ใช้ค่าเริ่มต้น ซึ่งจะเลือกให้เหมาะสมกับ mode ของโมเดล\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntuning_results <- rf_workflow %>%\n                  tune_grid(resamples = folds,\n                            grid = my_grid,\n                            control = control_grid(verbose = FALSE,\n                                                   save_pred = TRUE),\n                            metrics = eval_metric)\n```\n:::\n\n\n### วิเคราะห์ tuning results\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntuning_results %>% autoplot()\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntuning_results %>% collect_metrics(summarize = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 57 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1     5    18 roc_auc binary     0.859    50 0.0113  Preprocessor1_Model01\n 2     5    18 sens    binary     0.688    50 0.0205  Preprocessor1_Model01\n 3     5    18 spec    binary     0.955    50 0.00658 Preprocessor1_Model01\n 4     1    21 roc_auc binary     0.877    50 0.0100  Preprocessor1_Model02\n 5     1    21 sens    binary     0.669    50 0.0199  Preprocessor1_Model02\n 6     1    21 spec    binary     0.964    50 0.00570 Preprocessor1_Model02\n 7     4    14 roc_auc binary     0.856    50 0.0117  Preprocessor1_Model03\n 8     4    14 sens    binary     0.708    50 0.0195  Preprocessor1_Model03\n 9     4    14 spec    binary     0.950    50 0.00827 Preprocessor1_Model03\n10     4    33 roc_auc binary     0.864    50 0.0110  Preprocessor1_Model04\n# … with 47 more rows\n```\n:::\n\n```{.r .cell-code}\ntuning_results %>% \n  collect_metrics(summarize = TRUE) %>%\n  filter(.metric == \"sens\") %>%\n  arrange(desc(mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 19 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1     3    38 sens    binary     0.726    50  0.0189 Preprocessor1_Model14\n 2     3    35 sens    binary     0.726    50  0.0189 Preprocessor1_Model19\n 3     2    11 sens    binary     0.721    50  0.0195 Preprocessor1_Model18\n 4     3    37 sens    binary     0.721    50  0.0187 Preprocessor1_Model07\n 5     3    11 sens    binary     0.719    50  0.0191 Preprocessor1_Model08\n 6     2    33 sens    binary     0.713    50  0.0205 Preprocessor1_Model16\n 7     4    14 sens    binary     0.708    50  0.0195 Preprocessor1_Model03\n 8     4    20 sens    binary     0.705    50  0.0195 Preprocessor1_Model12\n 9     4    13 sens    binary     0.704    50  0.0196 Preprocessor1_Model06\n10     4    36 sens    binary     0.704    50  0.0202 Preprocessor1_Model15\n11     4    33 sens    binary     0.692    50  0.0208 Preprocessor1_Model04\n12     5    10 sens    binary     0.690    50  0.0197 Preprocessor1_Model09\n13     5    18 sens    binary     0.688    50  0.0205 Preprocessor1_Model01\n14     5    28 sens    binary     0.672    50  0.0212 Preprocessor1_Model10\n15     1    14 sens    binary     0.671    50  0.0198 Preprocessor1_Model17\n16     1    21 sens    binary     0.669    50  0.0199 Preprocessor1_Model02\n17     1    16 sens    binary     0.669    50  0.0199 Preprocessor1_Model13\n18     1    25 sens    binary     0.661    50  0.0192 Preprocessor1_Model11\n19     1    39 sens    binary     0.659    50  0.0197 Preprocessor1_Model05\n```\n:::\n\n```{.r .cell-code}\ntuning_results %>% \n  collect_metrics(summarize = TRUE) %>%\n  filter(.metric == \"roc_auc\") %>%\n  arrange(desc(mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 19 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1     1    14 roc_auc binary     0.880    50 0.00963 Preprocessor1_Model17\n 2     1    16 roc_auc binary     0.879    50 0.00997 Preprocessor1_Model13\n 3     1    21 roc_auc binary     0.877    50 0.0100  Preprocessor1_Model02\n 4     1    25 roc_auc binary     0.876    50 0.0101  Preprocessor1_Model11\n 5     1    39 roc_auc binary     0.875    50 0.00991 Preprocessor1_Model05\n 6     2    33 roc_auc binary     0.868    50 0.0107  Preprocessor1_Model16\n 7     2    11 roc_auc binary     0.866    50 0.00979 Preprocessor1_Model18\n 8     4    36 roc_auc binary     0.866    50 0.0109  Preprocessor1_Model15\n 9     3    35 roc_auc binary     0.865    50 0.0108  Preprocessor1_Model19\n10     3    37 roc_auc binary     0.865    50 0.0107  Preprocessor1_Model07\n11     4    33 roc_auc binary     0.864    50 0.0110  Preprocessor1_Model04\n12     3    38 roc_auc binary     0.864    50 0.0109  Preprocessor1_Model14\n13     5    28 roc_auc binary     0.863    50 0.0110  Preprocessor1_Model10\n14     4    20 roc_auc binary     0.861    50 0.0111  Preprocessor1_Model12\n15     5    18 roc_auc binary     0.859    50 0.0113  Preprocessor1_Model01\n16     3    11 roc_auc binary     0.858    50 0.0108  Preprocessor1_Model08\n17     4    13 roc_auc binary     0.857    50 0.0115  Preprocessor1_Model06\n18     4    14 roc_auc binary     0.856    50 0.0117  Preprocessor1_Model03\n19     5    10 roc_auc binary     0.852    50 0.0116  Preprocessor1_Model09\n```\n:::\n\n```{.r .cell-code}\ntuning_results %>% \n  collect_metrics(summarize = TRUE) %>%\n  filter(.metric == \"sens\") %>%\n  ggplot(aes(x = std_err, y= mean))+\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n\n```{.r .cell-code}\nbest <- show_best(tuning_results, n=6, metric = \"sens\")\nbest[1,]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     3    38 sens    binary     0.726    50  0.0189 Preprocessor1_Model14\n```\n:::\n:::\n\n\n### ขั้นที่ 8 Finalized\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRF_final <- rf_workflow %>%\n  finalize_workflow(best[1,]) %>%\n  last_fit(split,\n           metrics =eval_metric)\nRF_final %>%\n  extract_fit_engine()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~3L,      x), num.trees = ~500, min.node.size = min_rows(~38L, x),      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  500 \nSample size:                      317 \nNumber of independent variables:  5 \nMtry:                             3 \nTarget node size:                 38 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.1078116 \n```\n:::\n\n```{.r .cell-code}\nRF_final %>%\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 sens    binary         0.706 Preprocessor1_Model1\n2 spec    binary         0.891 Preprocessor1_Model1\n3 roc_auc binary         0.850 Preprocessor1_Model1\n```\n:::\n:::\n\n\n## 7.6 Grid Search methods\n\nปัจจัยสำคัญตัวหนึ่งที่มีผลโดยตรงต่อประสิทธิภาพการปรับแต่ง hyperparameter คือการกำหนด grid ของ hyperparameter ใน tidymodel สามารถจำแนกได้เป็น 2 ประเภท ได้แก่\n\n-   regular grid\n\n-   nonregular grid\n\nรายละเอียดมีดังนี้\n\n## Regular grid\n\nregular grid เป็น grid ของ hyperparameter ที่สร้างขึ้นจากส่วนผสม (combination) ของค่าที่เป็นไปได้ทั้งหมดของ hyperparameter ที่ต้องการวิเคราะห์ การสร้าง regular grid มี 2 ขั้นตอน ขั้นตอนแรกคือการกำหนดค่าที่เป็นไปได้ของ hyperparameter แต่ละตัว และขั้นที่สองคือการสร้าง grid ของค่าที่เป็นไปได้ดังกล่าว ผลลัพธ์ที่ได้คือ hyperparameter space ที่สมบูรณ์\n\nการสร้าง regular grid ใน R สามารถทำได้หลายวิธีการ วิธีการแรกคือการใช้ฟังก์ชัน `expand.grid()` วิธีการที่สองคือการใช้ฟังก์ชัน `crossing()` ของ package tidyr และวิธีการที่สามคือการใช้ฟังก์ชัน `grid_regular()` ของ package dials\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_grid <- expand.grid(\n  mtry = 1:5,\n  min_n = seq(10,50,5)\n)\nhead(my_grid)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  mtry min_n\n1    1    10\n2    2    10\n3    3    10\n4    4    10\n5    5    10\n6    1    15\n```\n:::\n\n```{.r .cell-code}\ntail(my_grid)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   mtry min_n\n40    5    45\n41    1    50\n42    2    50\n43    3    50\n44    4    50\n45    5    50\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncrossing(\n  mtry = 1:5,\n  min_n = seq(10,50,5)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 45 × 2\n    mtry min_n\n   <int> <dbl>\n 1     1    10\n 2     1    15\n 3     1    20\n 4     1    25\n 5     1    30\n 6     1    35\n 7     1    40\n 8     1    45\n 9     1    50\n10     2    10\n# … with 35 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_params <- extract_parameter_set_dials(rf_workflow) %>%\n  update(mtry = mtry(range=c(1,5)),\n         min_n = min_n(range=c(20,60)))\nmy_reggrid <- grid_regular(my_params, levels = 5)\nmy_reggrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nข้อจำกัดของ regular grid คือใช้ทรัพยากรในการประมวลผลมาก โดยเฉพาะกับโมเดลที่มี hyperparameter จำนวนมาก และมีการทวนซ้ำหลายรอบ\n\n## Irregular grid\n\nมีหลายวิธีที่จะช่วยลดการประมวลผลของ regular grid ลงได้ วิธีการแรกคือ random grid ที่ใช้วิธีการสุ่มตัวอย่าง เพื่อสุ่ม grid มาจากประชากรของ grid ที่เป็นไปได้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_randomgrid <- grid_random(my_params, size = 10)\nmy_randomgrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmy_randomgrid <- grid_random(my_params, size = 25)\nmy_randomgrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_randomgrid <- grid_random(my_params, size = 50)\nmy_randomgrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nข้อจำกัดของ random grid คือ หาก generate grid ขนาดเล็ก มีโอกาสที่จะได้ grid ที่มีความใกล้เคียงหรือซ้อนทับกันมากเกินไป กล่าวคือ hyperparameter space ที่สร้างขึ้นอาจขาดคุณสมบัติความเป็นตัวแทน ผลการวิเคราะห์ที่ได้จึงอาจทำให้การปรับแต่ง hyperparameter มีความคลาดเคลื่อน\n\nจากข้อจำกัดดังกล่าวการสร้าง grid ของ hyperparameter ที่มีประสิทธิภาพมากกว่า random grid คือการใช้วิธีในกลุ่ม space-filling design ที่มีอัลกอริทึมภายใต้วิธีการในกลุ่มนี้หลายตัว เช่น latin hypercubes, maximum entropy designs, maximum projection designs เป็นต้น\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_latingrid <- grid_latin_hypercube(my_params, size = 25)\nmy_latingrid %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmy_maxentrp <- grid_max_entropy(my_params, size = 25)\nmy_maxentrp  %>%\n  ggplot()+\n  geom_point(aes(x = mtry, y = min_n))\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-20-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-21-1.png){width=864}\n:::\n:::\n\n\n# บทที่ 8: workflow set\n\nในทางปฏิบัติเรามักจะมีโมเดลคู่แข่งขันหลายตัวที่จะนำมาพัฒนาควบคู่กัน ภายใต้ tidymodel framework ผู้วิเคราะห์สามารถสร้าง workflow set เพื่อ fine tune hyperparameter และเปรียบเทียบโมเดลหลาย ๆ ตัวไปพร้อม ๆ กันในการประมวลผลรอบเดียวได้\n\nผู้วิเคราะห์ต้องการพัฒนาโมเดลจำแนก class โดยมีโมเดลคู่แข่งขันที่เลือกมาใช้งานได้แก่\n\n-   logistic regression with regulization\n\n-   decision tree\n\n-   random forest (เป็นการบ้าน)\n\nชุดข้อมูลที่ใช้เป็นตัวอย่างคือชุดข้อมูล `parabolic` ซึ่งเป็นชุดข้อมูลตัวอย่างของ tidymodels ผลการสำรวจข้่อมูลด้านล่างจะเห็นว่า ชุดข้อมูลประกอบด้วยข้อมูลของหน่วยข้อมูลจำนวน 500 หน่วย มีตัวแปรตามแบบจัดประเภท `class` และตัวแปรอิสระเชิงปริมาณ 2 ตัวได้แก่ `x1` และ `x2 ` ตามลำดับ \n\n::: {.cell}\n\n```{.r .cell-code}\n#importing data\ndata(parabolic)\nglimpse(parabolic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 500\nColumns: 3\n$ X1    <dbl> 3.291779227, 1.465839693, 1.660986913, 1.602301296, 2.165003287,…\n$ X2    <dbl> 1.66108928, 0.41398566, 0.79147013, 0.27639110, 3.16557011, 3.82…\n$ class <fct> Class1, Class2, Class2, Class2, Class1, Class1, Class2, Class1, …\n```\n:::\n\n```{.r .cell-code}\n# splitting data\nsplit <- initial_split(data = parabolic)\ntrain <- training(split)\ntest <- testing(split)\n```\n:::\n\n\n\nผู้วิเคราะห์สำรวจความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระเบื้องต้น ได้ผลดังแผนภาพด้านล่าง\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#exploring\ntrain %>%\n  ggplot(aes(x = X1, y = X2, col=class))+\n  geom_point(alpha=0.7)+\n  theme_light()+\n  theme(legend.position=\"top\")\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nการวิเคราะห์นี้มีการพัฒนา ML จำนวน 2 ตัวได้แก่ regularized logistic regression และ decision tree ที่มีการทำ preprocessing แตกต่างกัน การทำ workflow set ยอมให้ผู้วิเคราะห์กำหนด preprocessing ที่แตกต่างกันกับ model specification ที่กำหนดได้ ดังตัวอย่างต่อไปนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#preprocessing\nbase_recipe <- recipe(class ~ . ,data= train)\n\nnorm_recipe <- base_recipe %>%\n  step_normalize(all_numeric_predictors())\n\n\n# model specification\n## - 1 regularized logistic regression\nregular_logit <- logistic_reg(penalty= tune(),\n                              mixture = tune()) %>%\n  set_engine(\"glmnet\")%>%\n  set_mode(\"classification\")\n\n## - 2 decision tree \ntree_mod <- decision_tree(cost_complexity = tune(),\n                          min_n = tune())%>%\n  set_engine(\"rpart\")%>%\n  set_mode(\"classification\")\n\n# creat workflowset\nmy_workflowset <- workflow_set(\n  preproc = list(norm = norm_recipe,\n                 base = base_recipe),\n  models = list(reg_logit = regular_logit,\n                cart = tree_mod),\n  cross = FALSE\n)\nmy_workflowset\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 2 × 4\n  wflow_id       info             option    result    \n  <chr>          <list>           <list>    <list>    \n1 norm_reg_logit <tibble [1 × 4]> <opts[0]> <list [0]>\n2 base_cart      <tibble [1 × 4]> <opts[0]> <list [0]>\n```\n:::\n:::\n\n\nนำ workflow set ที่สร้างมาผ่านกระบวนการ tune hyperapameter โดยฟังก์ชันที่จะใช้คือ `workflow_map()` แทน `tune_grid()`\n\nตัวอย่างด้านล่างมีการระบุ `grid = 20` แปลว่าให้ฟังก์ชันสร้าง hyperparameter grid ให้โดยใช้ค่าเริ่มต้นจำนวน 25 จุด ทั้งนี้ค่าเริ่มต้นของ tidymodel จะใช้อัลกอริทึม maximum entropy ในการกำหนด grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tuning Hypeparameter\neval_metrics <- metric_set(accuracy,roc_auc, sens, spec)\nfolds <- vfold_cv(data = train, v = 10)\nall_tune <- my_workflowset %>%\n  workflow_map(resamples = folds,\n               grid = 20,\n               verbose = TRUE,\n               metrics = eval_metrics)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni 1 of 2 tuning:     norm_reg_logit\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ 1 of 2 tuning:     norm_reg_logit (54.9s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\ni 2 of 2 tuning:     base_cart\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ 2 of 2 tuning:     base_cart (51.1s)\n```\n:::\n\n```{.r .cell-code}\nrank_results(all_tune)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 160 × 9\n   wflow_id  .config             .metric  mean std_err     n prepr…¹ model  rank\n   <chr>     <chr>               <chr>   <dbl>   <dbl> <int> <chr>   <chr> <int>\n 1 base_cart Preprocessor1_Mode… accura… 0.901  0.0142    10 recipe  deci…     1\n 2 base_cart Preprocessor1_Mode… roc_auc 0.923  0.0203    10 recipe  deci…     1\n 3 base_cart Preprocessor1_Mode… sens    0.891  0.0132    10 recipe  deci…     1\n 4 base_cart Preprocessor1_Mode… spec    0.909  0.0215    10 recipe  deci…     1\n 5 base_cart Preprocessor1_Mode… accura… 0.901  0.0142    10 recipe  deci…     2\n 6 base_cart Preprocessor1_Mode… roc_auc 0.932  0.0184    10 recipe  deci…     2\n 7 base_cart Preprocessor1_Mode… sens    0.896  0.0143    10 recipe  deci…     2\n 8 base_cart Preprocessor1_Mode… spec    0.905  0.0243    10 recipe  deci…     2\n 9 base_cart Preprocessor1_Mode… accura… 0.901  0.0142    10 recipe  deci…     3\n10 base_cart Preprocessor1_Mode… roc_auc 0.932  0.0184    10 recipe  deci…     3\n# … with 150 more rows, and abbreviated variable name ¹​preprocessor\n```\n:::\n\n```{.r .cell-code}\nall_tune %>% autoplot(metric = \"roc_auc\")\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\nจากผลการวิเคราะห์ข้างต้นแสดงให้เห็นว่า decision tree มีประสิทธิภาพสูงกว่า regularized logistic regression เราสามารถดึงข้อมูลของ regularized logistic regression ขึ้นมาได้โดยใช้คำสั่งต่อไปนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_tune %>% autoplot(metric = \"sens\", id = \"base_cart\")\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nฟังก์ชัน `extract_workflow_set_result()` ใช้ดึงผลการ fine-tune hyperparameter ของแต่ละโมเดลภายใต้ workflow set ขึ้นมาวิเคราะห์ในเชิงลึกต่อได้อีก\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_cart_results<- all_tune %>% \n  extract_workflow_set_result(id = \"base_cart\")\nsimple_cart_results\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics          .notes          \n   <list>           <chr>  <list>            <list>          \n 1 <split [337/38]> Fold01 <tibble [80 × 6]> <tibble [0 × 3]>\n 2 <split [337/38]> Fold02 <tibble [80 × 6]> <tibble [0 × 3]>\n 3 <split [337/38]> Fold03 <tibble [80 × 6]> <tibble [0 × 3]>\n 4 <split [337/38]> Fold04 <tibble [80 × 6]> <tibble [0 × 3]>\n 5 <split [337/38]> Fold05 <tibble [80 × 6]> <tibble [0 × 3]>\n 6 <split [338/37]> Fold06 <tibble [80 × 6]> <tibble [0 × 3]>\n 7 <split [338/37]> Fold07 <tibble [80 × 6]> <tibble [0 × 3]>\n 8 <split [338/37]> Fold08 <tibble [80 × 6]> <tibble [0 × 3]>\n 9 <split [338/37]> Fold09 <tibble [80 × 6]> <tibble [0 × 3]>\n10 <split [338/37]> Fold10 <tibble [80 × 6]> <tibble [0 × 3]>\n```\n:::\n\n```{.r .cell-code}\nsimple_cart_results %>% collect_metrics(summarise = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 80 × 8\n   cost_complexity min_n .metric  .estimator  mean     n std_err .config        \n             <dbl> <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>          \n 1    0.00000300       9 accuracy binary     0.883    10  0.0126 Preprocessor1_…\n 2    0.00000300       9 roc_auc  binary     0.908    10  0.0254 Preprocessor1_…\n 3    0.00000300       9 sens     binary     0.876    10  0.0125 Preprocessor1_…\n 4    0.00000300       9 spec     binary     0.887    10  0.0208 Preprocessor1_…\n 5    0.0000000334    13 accuracy binary     0.893    10  0.0158 Preprocessor1_…\n 6    0.0000000334    13 roc_auc  binary     0.914    10  0.0225 Preprocessor1_…\n 7    0.0000000334    13 sens     binary     0.891    10  0.0132 Preprocessor1_…\n 8    0.0000000334    13 spec     binary     0.894    10  0.0225 Preprocessor1_…\n 9    0.000000211     28 accuracy binary     0.891    10  0.0159 Preprocessor1_…\n10    0.000000211     28 roc_auc  binary     0.936    10  0.0188 Preprocessor1_…\n# … with 70 more rows\n```\n:::\n\n```{.r .cell-code}\nsimple_cart_results %>% autoplot()\n```\n\n::: {.cell-output-display}\n![](05RandomForest_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(simple_cart_results, n=5, metric = \"sens\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 8\n  cost_complexity min_n .metric .estimator  mean     n std_err .config          \n            <dbl> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>            \n1        9.95e- 5    32 sens    binary     0.925    10  0.0195 Preprocessor1_Mo…\n2        4.83e-10    34 sens    binary     0.925    10  0.0195 Preprocessor1_Mo…\n3        1.02e- 8    38 sens    binary     0.920    10  0.0224 Preprocessor1_Mo…\n4        3.87e- 3    17 sens    binary     0.896    10  0.0143 Preprocessor1_Mo…\n5        2.00e-10    17 sens    binary     0.896    10  0.0143 Preprocessor1_Mo…\n```\n:::\n:::\n\n\nขั้นตอนสุดท้ายคือการ finalized model ...\n",
    "supporting": [
      "05RandomForest_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}