model <- models$Sequential()
# add input and the first hidden layers
model$add(layers$Dense(units = 10,
activation = 'relu',
input_dim = ncol(train_x)))
# add output layer
model$add(layers$Dense(units = 1, activation = 'linear'))
# model summary
model$summary()
model$compile(optimizer = 'adam',
loss = 'mse', metrics = c('accuracy'))
model$compile(optimizer = 'adam',
loss = 'mean_squared_error', metrics = c('accuracy'))
result <- model$fit(train_x, train_y)
result
sqrt(13602624512.0000)
# access the "layers" and "models" modules from keras
layers <- keras$layers
models <- keras$models
# create sequential model
model <- models$Sequential()
# add input and the first hidden layers
model$add(layers$Dense(units = 10,
activation = 'linear',
input_dim = ncol(train_x)))
model$add(layers$Dense(units = 10,
activation = 'linear'))
# add output layer
model$add(layers$Dense(units = 1, activation = 'linear'))
# model summary
model$summary()
model$compile(optimizer = 'adam',
loss = 'mean_squared_error', metrics = c('accuracy'))
result <- model$fit(train_x, train_y)
class(train_x)
result <- model$fit(as.matrix(train_x), as.matrix(train_y))
model$evaluate(as.matrix(test_x), as.matrix(test_y))
model$evaluate(as.matrix(test_x), as.matrix(test_y))
model$evaluate(as.matrix(test_x), as.matrix(test_y))
plot(result$history)
class(result$history)
result$history
result <- model$fit(as.matrix(train_x), as.matrix(train_y),
epochs = 10, verbose = 1)
result <- model$fit(as.matrix(train_x), as.matrix(train_y),
epochs = 10)
model$compile(optimizer = 'adam',
loss = 'mean_squared_error', metrics = c('accuracy'))
# access the "layers" and "models" modules from keras
layers <- keras$layers
models <- keras$models
# create sequential model
model <- models$Sequential()
# add input and the first hidden layers
model$add(layers$Dense(units = 10,
activation = 'linear',
input_dim = ncol(train_x)))
model$add(layers$Dense(units = 10,
activation = 'linear'))
# add output layer
model$add(layers$Dense(units = 1, activation = 'linear'))
# model summary
model$summary()
library(tidymodels)
dat_preproc <- recipe(salary~., data= dat) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(rank, discipline, sex) %>%
step_select(-X) %>%
prep(NULL) %>%
juice()
glimpse(dat_preproc, 60)
## data spliting
split <- initial_split(dat_preproc, prop = 0.8)
train <- training(split)
test <- testing(split)
train_x <- train %>% select(-salary)
train_y <- train %>% select(salary)
test_x <- test %>% select(-salary)
test_y <- test %>% select(-salary)
model$compile(optimizer = 'adam',
loss = 'mean_squared_error', metrics = c('accuracy'))
result <- model$fit(as.matrix(train_x), as.matrix(train_y),
epochs = 10)
train_y
as.matrix(train_y)
result <- model$fit(as.matrix(train_x), as.matrix(train_y))
result <- model$fit(as.matrix(train_x), as.matrix(train_y),
epochs=2,
valisation_split = 0.1)
result <- model$fit(as.matrix(train_x), as.matrix(train_y),
epochs=2,
validation_split = 0.1)
result <- model$fit(as.matrix(train_x), train_y,
epochs=2,
validation_split = 0.1)
result <- model$fit(as.matrix(train_x), as.numeric(as.matrix(train_y)),
epochs=2,
validation_split = 0.1)
as.numeric(as.matrix(train_y))
result <- model$fit(as.matrix(train_x), as.matrix(train_y),
epochs=2,
validation_split = 0.1)
model$fit
help(model$fit)
# create sequential model
model <- keras_model_sequential()
# Load keras
library(keras)
install.packages("keras")
# Load keras
library(keras)
# Load keras
library(reticulate)
use_virtualenv("r-tensorflow")
# Load keras
library(reticulate)
library(keras)
install.packages("keras")
install_keras()
library(keras)
remove.packages("keras")
install.packages("keras")
library(keras)
reticulate::repl_python()
setwd("~/Library/CloudStorage/OneDrive-ChulalongkornUniversity/Documents/ML/MLcourse/MLCourse/documents/Deeplearning")
?write_csv
library(tidymodels)
dat_preproc <- recipe(salary~., data= dat) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(rank, discipline, sex) %>%
step_select(-X) %>%
prep(NULL) %>%
juice()
glimpse(dat_preproc, 60)
## data spliting
split <- initial_split(dat_preproc, prop = 0.8)
train <- training(split)
test <- testing(split)
write.csv(train, file="train.csv")
write.csv(test, file="test.csv")
reticulate::repl_python()
# Making the Confusion Matrix
cm = table(test_set[, 11], y_pred)
# Load keras
library(reticulate)
py_run_file("ann_model01.py")
model <- keras$models$load_model_hdf5("model.h5")
library(keras)
keras<-import("keras")
model <- keras$models$load_model_hdf5("model.h5")
keras<-import("keras")
model <- keras$models$load_model("model.h5")
model
class(model)
keras$Model$evaluate(test_x, test_y)
keras$Model$evaluate(as.matrix(test_x), as.matrix(test_y))
import("mathplotlib")
import("matplotlib")
keras$Model$evaluate(as.matrix(test_x), as.matrix(test_y))
reticulate::repl_python()
plt<-import("matplotlib")
plt<-import("matplotlib")
plt$pyplot$plot(model$history['mse'])
plt<-import("matplotlib")
plt$pyplot$plot(model$history['loss'])
reticulate::repl_python()
keras <- import('keras')
keras_model <- keras$models$load_model('my_model.h5')
keras_model <- keras$models$load_model('model.h5')
keras_model.summary()
keras_model$summary()
keras_model$history %>% plot()
plot(keras_model$history)
keras_model$history
reticulate::repl_python()
# Load keras
library(reticulate)
py_run_file("ann_model01.py")
keras <- import('keras')
keras_model <- keras$models$load_model('model.h5')
keras_model$history
py_run_file("ann_model01.py")
keras <- import('keras')
keras_model <- keras$models$load_model('model.h5')
keras_model$history
# load the pickle file and get the history object
history_file <- py_load_object('history.pkl')
# load the pickle file and get the history object
history_file <- py_load_object('history.pkl')
history <- history_file$`history`
# load the pickle file and get the history object
history_file <- py_load_object('history.pkl')
reticulate::repl_python()
keras <- import("keras")
model <- keras$models$Sequential()
model <- keras$Sequential()
library(reticulate)
keras <- import("keras")
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 32, activation = 'linear', input_dim = 6))
library(reticulate)
keras <- import("keras")
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 32, activation = 'linear', input_dim = int(6)))
# add layers
model$add(keras$layers$Dense(units = 32, activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 10, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse')
model$summary()
train_x <- train %>% select(-salary) %>% as.matrix()
train_y <- train %>% select(salary) %>% as.matrix()
result <- model$fit(X = train_x, Y =train_y,
epochs=10)
result <- model$fit(x = train_x, y =train_y,
epochs=10)
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = as.integer(32), activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = as.integer(10), activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse')
model$summary()
result <- model$fit(x = train_x, y =train_y,
epochs=10)
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 32, activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 10, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse')
model$summary()
result <- model$keras$fit(x = train_x, y =train_y,
epochs=10)
result <- model$fit(x = train_x, y =train_y,
epochs=10)
result <- model$fit(x = train_x, y =train_y)
result <- model$fit(x = train_x, y =train_y,
epochs=as.integer(10))
result <- model$fit(x = train_x, y =train_y,
epochs=as.integer(10),
validation_split = 0.1)
plot(result$history)
plot(result$history$loss)
plot(result$history$epoch)
result$history$mse
plot(1:10,result$history$mse, type="l",col="steelblue")
class(result$history$mse)
data.frame(epoch = 1:10, rmse = sqrt(result$history$mse)) %>%
ggplot(aes(x=epoch, y=rmse))+
geom_line()
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 32, activation = 'relu', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 10, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse')
model$summary()
result <- model$fit(x = train_x, y =train_y,
epochs=as.integer(10),
validation_split = 0.1)
data.frame(epoch = 1:10, rmse = sqrt(result$history$mse)) %>%
ggplot(aes(x=epoch, y=rmse))+
geom_line()
plot(1:10,result$history$mse, type="l",col="steelblue")
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 10, activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 5, activation = 'linear')
model$add(keras$layers$Dense(units = 1, activation = 'linear'))
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 10, activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 5, activation = 'linear'))
model$add(keras$layers$Dense(units = 1, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse')
model$summary()
result <- model$fit(x = train_x, y =train_y,
epochs=as.integer(10),
validation_split = 0.1)
data.frame(epoch = 1:10, rmse = sqrt(result$history$mse)) %>%
ggplot(aes(x=epoch, y=rmse))+
geom_line()
data.frame(epoch = 1:10, rmse_train = sqrt(result$history$mse),
rmse_validate = result$history$val_mse) %>%
ggplot(aes(x=epoch))+
geom_line(aes(y=rmse_train), col="steelblue")+
geom_line(aes(y=rmse_validate), col="orange")
result$history$val_mse
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 6, activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 1, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse', lr = 0.01)
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 10, activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 1, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse', lr = 0.01)
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 10, activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 1, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse', lr = as.integer(0.01))
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 10, activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 1, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01), metrics = 'mse')
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 10, activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 1, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse')
model$summary()
result <- model$fit(x = train_x, y =train_y,
epochs=as.integer(10),
validation_split = 0.1, verbose=F)
result <- model$fit(x = train_x, y =train_y,
epochs=as.integer(10),
validation_split = 0.1, verbose=F)
data.frame(epoch = 1:10, rmse_train = sqrt(result$history$mse),
rmse_validate = result$history$val_mse) %>%
ggplot(aes(x=epoch))+
geom_line(aes(y=rmse_train), col="steelblue")+
geom_line(aes(y=rmse_validate), col="orange")
getwd()
library(tidyverse)
dat <- read.csv("criminal.csv")
head(dat[,-1])
glimpse(dat[,-1])
library(tidyverse)
dat <- read.csv("criminal.csv")
head(dat[,-1])
glimpse(dat[,-1], 60)
library(tidyverse)
dat <- read.csv("criminal.csv")
head(dat[,-1])
glimpse(dat[,-1], 60)
dat_preproc <- recipe(TheifperPop~., data= dat) %>%
step_normalize(all_numeric_predictors()) %>%
prep(NULL) %>%
juice()
glimpse(dat_preproc, 60)
dat_preproc <- recipe(TheifperPop~., data= dat) %>%
step_normalize(all_numeric_predictors()) %>%
step_select(-X) %>%
prep(NULL) %>%
juice()
glimpse(dat_preproc, 60)
## data spliting
split <- initial_split(dat_preproc, prop = 0.8)
train <- training(split)
test <- testing(split)
train_x <- train %>% select(-salary) %>% as.matrix()
train_y <- train %>% select(salary) %>% as.matrix()
library(tidymodels)
dat_preproc <- recipe(TheifperPop~., data= dat) %>%
step_normalize(all_numeric_predictors()) %>%
step_select(-X) %>%
prep(NULL) %>%
juice()
glimpse(dat_preproc, 60)
## data spliting
split <- initial_split(dat_preproc, prop = 0.8)
train <- training(split)
test <- testing(split)
train_x <- train %>% select(-TheifperPop) %>% as.matrix()
train_y <- train %>% select(TheifperPop) %>% as.matrix()
#write.csv(train, file="train.csv")
#write.csv(test, file="test.csv")
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 10, activation = 'linear', input_dim = as.integer(6)))
model$add(keras$layers$Dense(units = 1, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse')
model$summary()
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 10, activation = 'linear', input_dim = ncol(train_x)))
model$add(keras$layers$Dense(units = 10, activation = 'linear'))
model$add(keras$layers$Dense(units = 1, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse')
model$summary()
result <- model$fit(x = train_x, y =train_y,
epochs=as.integer(10),
validation_split = 0.1, verbose=F)
data.frame(epoch = 1:10, rmse_train = sqrt(result$history$mse),
rmse_validate = result$history$val_mse) %>%
ggplot(aes(x=epoch))+
geom_line(aes(y=rmse_train), col="steelblue")+
geom_line(aes(y=rmse_validate), col="orange")
result$history$mse
train_x
train_y
dat_preproc <- recipe(TheifperPop~., data= dat) %>%
step_naomit() %>%
step_normalize(all_numeric_predictors()) %>%
step_select(-X) %>%
prep(NULL) %>%
juice()
glimpse(dat_preproc, 60)
## data spliting
split <- initial_split(dat_preproc, prop = 0.8)
train <- training(split)
test <- testing(split)
train_x <- train %>% select(-TheifperPop) %>% as.matrix()
train_y <- train %>% select(TheifperPop) %>% as.matrix()
library(reticulate)
keras <- import("keras")
# create sequential model
model <- keras$Sequential()
# add layers
model$add(keras$layers$Dense(units = 10, activation = 'linear', input_dim = ncol(train_x)))
model$add(keras$layers$Dense(units = 10, activation = 'linear'))
model$add(keras$layers$Dense(units = 1, activation = 'linear'))
# Compile the model
model$compile(loss = 'mse', optimizer = 'adam', metrics = 'mse')
model$summary()
result <- model$fit(x = train_x, y =train_y,
epochs=as.integer(10),
validation_split = 0.1, verbose=F)
data.frame(epoch = 1:10, rmse_train = sqrt(result$history$mse),
rmse_validate = result$history$val_mse) %>%
ggplot(aes(x=epoch))+
geom_line(aes(y=rmse_train), col="steelblue")+
geom_line(aes(y=rmse_validate), col="orange")
result$history$mse
train_x
result
result$model
write.csv(train, file="train.csv")
write.csv(test, file="test.csv")
reticulate::repl_python()
library(tidymodels)
ncol(train_x)
reticulate::repl_python()
dat <- read.csv("criminal.csv")
head(dat[,-1])
head(dat[,-1])
glimpse(dat[,-1], 60)
library(tidymodels)
dat_preproc <- recipe(TheifperPop~., data= dat) %>%
step_naomit() %>%
step_normalize(all_numeric_predictors()) %>%
step_select(-X) %>%
prep(NULL) %>%
juice()
glimpse(dat_preproc, 60)
dat <- dat %>% drop_na()
summary(dat)
dat_preproc <- recipe(TheifperPop~., data= dat) %>%
step_normalize(all_numeric_predictors()) %>%
step_select(-X) %>%
prep(NULL) %>%
juice()
glimpse(dat_preproc, 60)
## data spliting
split <- initial_split(dat_preproc, prop = 0.8)
train <- training(split)
test <- testing(split)
train_x <- train %>% select(-TheifperPop) %>% as.matrix()
train_y <- train %>% select(TheifperPop) %>% as.matrix()
write.csv(train, file="train.csv")
write.csv(test, file="test.csv")
reticulate::repl_python()
