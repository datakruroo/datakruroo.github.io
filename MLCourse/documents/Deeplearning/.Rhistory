gridExtra::grid.arrange(p1_notune, p2_notune,p1_tune,p2_tune,ncol=2)
reticulate::repl_python()
best_model <- py$best_model
best_model_fit<-best_model$fit(train_x, train_y,
epochs = 500L,
validation_split = 0.3,
batch_size = 256L,
callbacks = list(early_stopping)
)
reticulate::repl_python()
best_model <- py$best_model
best_model_fit<-best_model$fit(train_x, train_y,
epochs = 500L,
validation_split = 0.3,
batch_size = 256L,
callbacks = list(early_stopping)
)
data.frame(epoch = best_model_fit$epoch, acc_train = best_model_fit$history$accuracy,
acc_test = best_model_fit$history$val_accuracy) %>%
gather(acc_train, acc_test, key = "dataset", value = "accuracy") %>%
ggplot(aes(x = epoch, y= accuracy, col=dataset))+
geom_line()+
scale_y_continuous(limits=c(0,1))
backend <- keras$backend
## calculate predicted class
pred_prob <- best_model$predict(test_x)
pred_class <- apply(pred_prob, 1, which.max)-1
pred_class <- as.matrix(pred_class) # convert R array to matrix
## frequency distribution of predicted class
table(pred_class)
# create confusion matrix
test_y_class <- apply(test_y, 1, which.max)-1
test_y_class <- as.matrix(test_y_class) # convert R array to matrix
table(pred_class, test_y_class)
true_val <- factor(test_y_class)
pred_class <- factor(pred_class, levels=0:9)
eval_dat <- data.frame(true = true_val,
predict = pred_class)
p1_tune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
autoplot()
p2_tune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
autoplot("heatmap")
gridExtra::grid.arrange(p1_notune, p2_notune,p1_tune,p2_tune,ncol=2)
eff_tune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
summary()
eff_tune
factor(test_y_class)
true_val <- factor(test_y_class)
pred_class <- factor(pred_class)
eval_dat <- data.frame(true = true_val,
predict = pred_class)
p1_notune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
autoplot()
# normalized data
X <- images/255
# create label data (in one hot encoding format)
y <- data.frame(y = factor(labels)) %>%
recipe(y~., data=.) %>%
step_dummy(y, one_hot = TRUE) %>%
prep(NULL) %>%
juice()
y <- y %>% as.matrix()
colnames(y)<-as.character(0:9)
# data splitting
set.seed(123)
train_id <- sample(1:dim(X)[1], ceiling(0.8*dim(X)[1]))
train_x <- X[train_id,,]
train_y <- y[train_id,]
test_x <- X[-train_id,,]
test_y <- y[-train_id,]
keras <- import("keras")
## create sequential model
model_nn1 <- keras$Sequential()
## add layers
### 1. flatten layer (input layer)
model_nn1$add(keras$layers$Flatten(input_shape = c(64L,64L)))
### 2. hidden layer
model_nn1$add(keras$layers$Dense(units = 200,
activation = "relu"))
### 2. output layer
model_nn1$add(keras$layers$Dense(10, activation = "softmax"))
## compling
model_nn1$compile(optimizer = "adam",
loss = "categorical_crossentropy",
metrics = 'accuracy')
model_nn1$summary()
set.seed(123)
## set early stopping
early_stopping <- keras$callbacks$EarlyStopping(monitor = "val_loss",
patience = 8L)
## fit the predictive model
ann_result_notune <- model_nn1$fit(x = train_x,
y = train_y,
validation_split = 0.3,
epochs = 500L,
callbacks = list(early_stopping))
eval_result <- model_nn1$evaluate(test_x, test_y %>% as.matrix())
cat("Test loss:",eval_result[[1]], "\n")
cat("Test accuracy:", eval_result[[2]], "\n")
data.frame(epoch = ann_result_notune$epoch, acc_train = ann_result_notune$history$accuracy,
acc_test = ann_result_notune$history$val_accuracy) %>%
gather(acc_train, acc_test, key = "dataset", value = "accuracy") %>%
ggplot(aes(x = epoch, y= accuracy, col=dataset))+
geom_line()+
scale_y_continuous(limits=c(0,1))
backend <- keras$backend
## calculate predicted class
pred_prob <- model_nn1$predict(test_x)
pred_class <- apply(pred_prob, 1, which.max)
pred_class <- as.matrix(pred_class) # convert R array to matrix
## frequency distribution of predicted class
table(pred_class)
# create confusion matrix
test_y_class <- apply(test_y, 1, which.max)
test_y_class <- as.matrix(test_y_class) # convert R array to matrix
table(pred_class, test_y_class)
backend <- keras$backend
## calculate predicted class
pred_prob <- model_nn1$predict(test_x)
pred_class <- apply(pred_prob, 1, which.max)-1
pred_class <- as.matrix(pred_class) # convert R array to matrix
## frequency distribution of predicted class
table(pred_class)
# create confusion matrix
test_y_class <- apply(test_y, 1, which.max)-1
test_y_class <- as.matrix(test_y_class) # convert R array to matrix
table(pred_class, test_y_class)
true_val <- factor(test_y_class, levels=0:9)
pred_class <- factor(pred_class, levels=0:9)
eval_dat <- data.frame(true = true_val,
predict = pred_class)
p1_notune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
autoplot()
p2_notune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
autoplot("heatmap")
gridExtra::grid.arrange(p1_notune,p2_notune,ncol=2)
# normalized data
X <- images[1:(205+206),,]/255
dim(X)
# create label data
y <- c(rep(0,205),rep(1,206))
# data splitting
set.seed(123)
train_id <- sample(1:411, ceiling(0.8*411))
train_x <- X[train_id,,]
train_y <- y[train_id]
test_x <- X[-train_id,,]
test_y <- y[-train_id]
dim(train_x)
model_logistic$compile(optimizer = "adam",
loss = "binary_crossentropy",
metrics = 'accuracy')
model_logistic$summary()
tf <- import("tensorflow")
keras <- import("keras")
## create sequential model
model_logistic <- keras$Sequential()
## add layers
### 1. flatten layer (input layer)
model_logistic$add(keras$layers$Flatten(input_shape = c(64L,64L)))
### 2. output layer
model_logistic$add(keras$layers$Dense(1, activation = "sigmoid"))
set.seed(123)
## set early stopping
early_stopping <- keras$callbacks$EarlyStopping(monitor = "val_loss",
patience = 5L)
## fit the predictive model
logistic_result_notune <- model_logistic$fit(x = train_x,
y = train_y %>% as.matrix(),
validation_split = 0.3,
epochs = 500L,
callbacks = list(early_stopping))
model_logistic$compile(optimizer = "adam",
loss = "binary_crossentropy",
metrics = 'accuracy')
model_logistic$summary()
set.seed(123)
## set early stopping
early_stopping <- keras$callbacks$EarlyStopping(monitor = "val_loss",
patience = 5L)
## fit the predictive model
logistic_result_notune <- model_logistic$fit(x = train_x,
y = train_y %>% as.matrix(),
validation_split = 0.3,
epochs = 500L,
callbacks = list(early_stopping))
set.seed(123)
## set early stopping
early_stopping <- keras$callbacks$EarlyStopping(monitor = "val_loss",
patience = 10L)
## fit the predictive model
logistic_result_notune <- model_logistic$fit(x = train_x,
y = train_y %>% as.matrix(),
validation_split = 0.3,
epochs = 500L,
callbacks = list(early_stopping))
data.frame(epoch = logistic_result_notune$epoch, acc_train = logistic_result_notune$history$accuracy,
acc_test = logistic_result_notune$history$val_accuracy) %>%
gather(acc_train, acc_test, key = "dataset", value = "accuracy") %>%
ggplot(aes(x = epoch, y= accuracy, col=dataset))+
geom_line()+
scale_y_continuous(limits=c(0,1))
eval_result <- model_logistic$evaluate(test_x, test_y %>% as.matrix())
cat("Test loss:",eval_result[[1]], "\n")
cat("Test accuracy:", eval_result[[2]], "\n")
prob_one <- model_logistic$predict(test_x)
head(prob_one)
pred_one <- ifelse(prob_one>0.5,1,0)
# create confusion matrix
table(pred_one, test_y)
library(tidymodels)
# calculate confusion matrix on test data
data.frame(test = factor(test_y), pred = factor(pred_one)) %>%
conf_mat(truth = test, estimate = pred)
# calculate evaluation metrics from confusion matrix
data.frame(test = factor(test_y), pred = factor(pred_one)) %>%
conf_mat(truth = test, estimate = pred) %>%
summary()
# normalized data
X <- images/255
# create label data (in one hot encoding format)
y <- data.frame(y = factor(labels)) %>%
recipe(y~., data=.) %>%
step_dummy(y, one_hot = TRUE) %>%
prep(NULL) %>%
juice()
y <- y %>% as.matrix()
colnames(y)<-as.character(0:9)
# data splitting
set.seed(123)
train_id <- sample(1:dim(X)[1], ceiling(0.8*dim(X)[1]))
train_x <- X[train_id,,]
train_y <- y[train_id,]
test_x <- X[-train_id,,]
test_y <- y[-train_id,]
keras <- import("keras")
## create sequential model
model_nn1 <- keras$Sequential()
## add layers
### 1. flatten layer (input layer)
model_nn1$add(keras$layers$Flatten(input_shape = c(64L,64L)))
### 2. hidden layer
model_nn1$add(keras$layers$Dense(units = 200,
activation = "relu"))
### 2. output layer
model_nn1$add(keras$layers$Dense(10, activation = "softmax"))
## compling
model_nn1$compile(optimizer = "adam",
loss = "categorical_crossentropy",
metrics = 'accuracy')
model_nn1$summary()
(10+4096)/2
keras <- import("keras")
## create sequential model
model_nn1 <- keras$Sequential()
## add layers
### 1. flatten layer (input layer)
model_nn1$add(keras$layers$Flatten(input_shape = c(64L,64L)))
### 2. hidden layer
model_nn1$add(keras$layers$Dense(units = 2053,
activation = "relu"))
### 2. output layer
model_nn1$add(keras$layers$Dense(10, activation = "softmax"))
## compling
model_nn1$compile(optimizer = "adam",
loss = "categorical_crossentropy",
metrics = 'accuracy')
model_nn1$summary()
keras <- import("keras")
## create sequential model
model_nn1 <- keras$Sequential()
## add layers
### 1. flatten layer (input layer)
model_nn1$add(keras$layers$Flatten(input_shape = c(64L,64L)))
### 2. hidden layer
model_nn1$add(keras$layers$Dense(units = 2000,
activation = "relu"))
### 2. output layer
model_nn1$add(keras$layers$Dense(10, activation = "softmax"))
## compling
model_nn1$compile(optimizer = "adam",
loss = "categorical_crossentropy",
metrics = 'accuracy')
model_nn1$summary()
set.seed(123)
## set early stopping
early_stopping <- keras$callbacks$EarlyStopping(monitor = "val_loss",
patience = 10L)
## fit the predictive model
ann_result_notune <- model_nn1$fit(x = train_x,
y = train_y,
validation_split = 0.3,
epochs = 500L,
callbacks = list(early_stopping))
keras <- import("keras")
## create sequential model
model_nn1 <- keras$Sequential()
## add layers
### 1. flatten layer (input layer)
model_nn1$add(keras$layers$Flatten(input_shape = c(64L,64L)))
### 2. hidden layer
model_nn1$add(keras$layers$Dense(units = 400,
activation = "relu"))
### 2. output layer
model_nn1$add(keras$layers$Dense(10, activation = "softmax"))
## compling
model_nn1$compile(optimizer = "adam",
loss = "categorical_crossentropy",
metrics = 'accuracy')
model_nn1$summary()
set.seed(123)
## set early stopping
early_stopping <- keras$callbacks$EarlyStopping(monitor = "val_loss",
patience = 10L)
## fit the predictive model
ann_result_notune <- model_nn1$fit(x = train_x,
y = train_y,
validation_split = 0.3,
epochs = 500L,
callbacks = list(early_stopping))
eval_result <- model_nn1$evaluate(test_x, test_y %>% as.matrix())
cat("Test loss:",eval_result[[1]], "\n")
cat("Test accuracy:", eval_result[[2]], "\n")
data.frame(epoch = ann_result_notune$epoch, acc_train = ann_result_notune$history$accuracy,
acc_test = ann_result_notune$history$val_accuracy) %>%
gather(acc_train, acc_test, key = "dataset", value = "accuracy") %>%
ggplot(aes(x = epoch, y= accuracy, col=dataset))+
geom_line()+
scale_y_continuous(limits=c(0,1))
set.seed(123)
## set early stopping
early_stopping <- keras$callbacks$EarlyStopping(monitor = "val_loss",
patience = 10L)
## fit the predictive model
ann_result_notune <- model_nn1$fit(x = train_x,
y = train_y,
validation_split = 0.4,
epochs = 500L,
callbacks = list(early_stopping))
eval_result <- model_nn1$evaluate(test_x, test_y %>% as.matrix())
cat("Test loss:",eval_result[[1]], "\n")
cat("Test accuracy:", eval_result[[2]], "\n")
data.frame(epoch = ann_result_notune$epoch, acc_train = ann_result_notune$history$accuracy,
acc_test = ann_result_notune$history$val_accuracy) %>%
gather(acc_train, acc_test, key = "dataset", value = "accuracy") %>%
ggplot(aes(x = epoch, y= accuracy, col=dataset))+
geom_line()+
scale_y_continuous(limits=c(0,1))
backend <- keras$backend
## calculate predicted class
pred_prob <- model_nn1$predict(test_x)
pred_class <- apply(pred_prob, 1, which.max)-1
pred_class <- as.matrix(pred_class) # convert R array to matrix
## frequency distribution of predicted class
table(pred_class)
# create confusion matrix
test_y_class <- apply(test_y, 1, which.max)-1
test_y_class <- as.matrix(test_y_class) # convert R array to matrix
table(pred_class, test_y_class)
true_val <- factor(test_y_class, levels=0:9)
pred_class <- factor(pred_class, levels=0:9)
eval_dat <- data.frame(true = true_val,
predict = pred_class)
p1_notune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
autoplot()
p2_notune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
autoplot("heatmap")
gridExtra::grid.arrange(p1_notune,p2_notune,ncol=2)
eff_notune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
summary()
eff_notune
# normalized data
X <- images/255
# create label data (in one hot encoding format)
y <- data.frame(y = factor(labels)) %>%
recipe(y~., data=.) %>%
step_dummy(y, one_hot = TRUE) %>%
prep(NULL) %>%
juice()
y <- y %>% as.matrix()
# data splitting
set.seed(123)
train_id <- sample(1:dim(X)[1], ceiling(0.8*dim(X)[1]))
train_x <- X[train_id,,]
train_y <- y[train_id,]
test_x <- X[-train_id,,]
test_y <- y[-train_id,]
reticulate::repl_python()
best_model <- py$best_model
best_model_fit<-best_model$fit(train_x, train_y,
epochs = 500L,
validation_split = 0.3,
batch_size = 256L,
callbacks = list(early_stopping)
)
reticulate::repl_python()
library(caret)
# Create a confusion matrix
conf_matrix <- confusionMatrix(eval_dat$true, eval_dat$predict)
# Print the confusion matrix
print(conf_matrix)
# Get the classification summary
class_summary <- conf_matrix$byClass
# Print the classification summary
print(class_summary)
# normalized data
X <- images/255
# create label data (in one hot encoding format)
y <- data.frame(y = factor(labels)) %>%
recipe(y~., data=.) %>%
step_dummy(y, one_hot = TRUE) %>%
prep(NULL) %>%
juice()
y <- y %>% as.matrix()
# data splitting
set.seed(123)
train_id <- sample(1:dim(X)[1], ceiling(0.8*dim(X)[1]))
train_x <- X[train_id,,]
train_y <- y[train_id,]
test_x <- X[-train_id,,]
test_y <- y[-train_id,]
reticulate::repl_python()
# normalized data
X <- images/255
# create label data (in one hot encoding format)
y <- data.frame(y = factor(labels)) %>%
recipe(y~., data=.) %>%
step_dummy(y, one_hot = TRUE) %>%
prep(NULL) %>%
juice()
y <- y %>% as.matrix()
# data splitting
set.seed(123)
train_id <- sample(1:dim(X)[1], ceiling(0.8*dim(X)[1]))
train_x <- X[train_id,,]
train_y <- y[train_id,]
test_x <- X[-train_id,,]
test_y <- y[-train_id,]
reticulate::repl_python()
# normalized data
X <- images/255
# create label data (in one hot encoding format)
y <- data.frame(y = factor(labels)) %>%
recipe(y~., data=.) %>%
step_dummy(y, one_hot = TRUE) %>%
prep(NULL) %>%
juice()
y <- y %>% as.matrix()
# data splitting
set.seed(123)
train_id <- sample(1:dim(X)[1], ceiling(0.8*dim(X)[1]))
train_x <- X[train_id,,]
train_y <- y[train_id,]
test_x <- X[-train_id,,]
test_y <- y[-train_id,]
reticulate::repl_python()
best_model <- py$best_model
best_model_fit<-best_model$fit(train_x, train_y,
epochs = 500L,
validation_split = 0.3,
batch_size = 256L,
callbacks = list(early_stopping)
)
data.frame(epoch = best_model_fit$epoch, acc_train = best_model_fit$history$accuracy,
acc_test = best_model_fit$history$val_accuracy) %>%
gather(acc_train, acc_test, key = "dataset", value = "accuracy") %>%
ggplot(aes(x = epoch, y= accuracy, col=dataset))+
geom_line()+
scale_y_continuous(limits=c(0,1))
backend <- keras$backend
## calculate predicted class
pred_prob <- best_model$predict(test_x)
pred_class <- apply(pred_prob, 1, which.max)-1
pred_class <- as.matrix(pred_class) # convert R array to matrix
## frequency distribution of predicted class
table(pred_class)
# create confusion matrix
test_y_class <- apply(test_y, 1, which.max)-1
test_y_class <- as.matrix(test_y_class) # convert R array to matrix
table(pred_class, test_y_class)
true_val <- factor(test_y_class)
pred_class <- factor(pred_class, levels=0:9)
eval_dat <- data.frame(true = true_val,
predict = pred_class)
p1_tune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
autoplot()
p2_tune<-eval_dat %>%
conf_mat(truth = true,
estimate = predict) %>%
autoplot("heatmap")
gridExtra::grid.arrange(p1_notune, p2_notune,p1_tune,p2_tune,ncol=2)
reticulate::repl_python()
