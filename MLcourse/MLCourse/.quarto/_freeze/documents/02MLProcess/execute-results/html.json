{
  "hash": "f11bbfb50d30063caa16809ce63018f3",
  "result": {
    "markdown": "---\ntitle: \"Modelling Process\"\nauthor: \"ผศ.ดร.สิวะโชติ ศรีสุทธิยากร\"\ntoc: true\ntoc-depth: 3\ntoc-title: สารบัญ\ntheme: default\n---\n\n::: {.cell}\n\n:::\n\n\n# บทที่ 3 กระบวนการพัฒนา Machine Learning Models\n\nกระบวนการพัฒนา machine learning models อาจจำแนกได้เป็นสองส่วน ส่วนแรกคือส่วนของการพัฒนาโมเดล และส่วนที่สองคือส่วนของการนำโมเดลไปใช้งาน\n\nส่วนการพัฒนาโมเดลมีกระบวนการพัฒนาแสดงไว้ในรูป 15 จากรูปจะเห็นว่าเริ่มตั้งแต่การเก็บรวบรวมข้อมูล การจัดการข้อมูล จากนั้นจะมีการแบ่งชุดข้อมูลออกเป็นส่วน traning dataset และ test dataset ข้อมูลส่วนที่เป็น traning dataset จะถูกนำมาพัฒนาการเรียนรู้/ความสามารถในการทำนายของโมเดล ผ่านอัลกอริทึมต่าง ๆ จากนั้นจะเลือกอัลกอริทึมที่มีประสิทธิภาพสูงที่สุด (ประเมินจาก test dataset) ไปใช้งาน ทั้งนี้การจะนำโมเดลทำนายไปใช้งานได้นั้นจะต้องมีบันทึกโมเดลที่พัฒนาขึ้นเพื่อนำไปเรียกใช้ต่อไป\n\n![Modeling Process](images/image-1728379488.png){alt=\"Modeling Process\"}\n\nลักษณะเฉพาะในกระบวนการพัฒนาโมเดลทำนายคือ การดำเนินงานในหลายขั้นตอน เช่น การจัดการข้อมูล การ fit และปรับแต่งโมเดล หรือการคัดเลือกโมเดลทำนายที่ดีที่สุด ไม่ได้มีแนวทางหรือกฎเกณฑ์ที่ชัดเจนตายตัวว่าต้องดำเนินการอย่างไร นอกจากนี้กระบวนการดังกล่าวยังมีลักษณะเป็นแบบทวนซ้ำไปมา รูป 16 แสดงตัวอย่างการดำเนินงานของผู้วิเคราะห์เพื่อพัฒนาโมเดลทำนายโมเดลหนึ่ง\n\n![ตัวอย่างขั้นตอนการพัฒนาโมเดลทำนาย (ที่มา : Max Kuhn and Kjell Johnson (2019))](images/image-1908104112.png){alt=\"ตัวอย่างขั้นตอนการพัฒนาโมเดลทำนาย (ที่มา : Max Kuhn and Kjell Johnson (2019))\" fig-align=\"center\" width=\"70%\"}\n\nจากรูปข้างต้นจะเห็นว่ากระบวนการเริ่มต้นด้วยกากการวิเคราะห์เพื่อสำรวจข้อมูล (exploratory data analysis: EDA) ก่อน (จุด a) โดยที่ EDA เป็นเทคนิคที่ผู้วิเคราะห์ใช้เพื่อทำความเข้าใจคุณลักษณะสำคัญของตัวแปรต่าง ๆ ภายในชุดข้อมูล ซึ่งประกอบด้วย (1) การวิเคราะห์สถานะและการแจกแจงของตัวแปร (2) การวิเคราะห์ความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระ รวมทั้งความสัมพันธ์ระหว่างตัวแปรอิสระ (3) การวิเคราะห์รูปแบบการสูญหายของข้อมูล และ (4) ความผิดปกติที่อาจเกิดขึ้นในข้อมูล กระบวนการในส่วนของการสำรวจนี้เป็นกระบวนการทวนซ้ำและอาจมีการสลับไปมาระหว่างการใช้ทัศนภาพข้อมูลเชิงสำรวจ และการใช้เทคนิคการวิเคราะห์เชิงปริมาณ (จุด b) เข้ามาช่วย สารสนเทศที่ได้จากกระบวนส่วนนี้จะสามารถใช้เป็นแนวทางเพื่อจัดข้อมูลของตัวแปรอิสระให้เหมาะสมและมีประสิทธิภาพสูงที่สำหรับการพัฒนาโมเดลทำนายต่อไป เรียกขั้นตอนนี้ว่า feature engineering (จุด c) เมื่อสิ้นสุดขั้นตอนนี้ผลผลิตที่ควรได้คือชุดข้อมูลต้นแบบที่ประกอบด้วยตัวแปรตาม และตัวแปรอิสระที่ผ่านการคัดเลือกหรือทำ feature engineering มาแล้ว และอยู่ในรูปแบบที่พร้อมจะนำไปวิเคราะห์\n\nเมื่อได้ชุดข้อมูลต้นแบบมาเรียบร้อยแล้ว ผู้วิเคราะห์จะนำชุดข้อมูลดังกล่าวไปเป็นต้นแบบให้อัลกอริทึมการเรียนรู้ของเครื่องหลาย ๆ ตัวได้เรียนรู้ เพื่อพัฒนาเป็นโมเดลทำนาย (จุด d) จากรูปจะเห็นว่าอัลกอริทึมที่ถูกเลือกมาใช้จำนวน 4 อัลกอริทึม ทั้งนี้อัลกอริทึมส่วนใหญ่มักมีส่วนประกอบที่เรียกว่า hyperparameters ที่ต้องกำหนดค่าด้วยการปรับแต่ง (tuning) จากรูปจะเห็นว่าการเรียนรู้ในแต่ละอัลกอริทึมจะมีขั้นตอนของการเรียนรู้ และการปรับแต่ง hyperparameters ที่ต้องดำเนินการแบบทวนซ้ำสลับไปมาจนกระทั่งได้โมเดลที่มีประสิทธิภาพสูงสุด ทั้งนี้เมื่อได้โมเดลดังกล่าวแล้ว ผู้วิเคราะห์จะนำโมเดลที่พัฒนาได้ไปประเมินประสิทธิภาพการทำนายของโมเดล การดำเนินงานในส่วนนี้จะมีการใช้ทั้งการวิเคราะห์เชิงปริมาณผ่านค่าสถิติต่าง ๆ เช่น evaluation metrics ต่าง ๆ ที่ใช้ประเมินประสิทธิภาพการทำนาย รวมทั้งยังอาจมีการใช้ EDA อีก เพื่อวิเคราะห์ประสิทธิภาพ หรือข้อจำกัดของแต่ละโมเดลในการทำนายผลลัพธ์ที่ต้องการ (จุด e และ f)\n\nสารสนเทศที่ได้จากการวิเคราะห์ประสิทธิภาพของโมเดลจะเป็นตัวกำหนดการดำเนินงานต่อไปของผู้วิเคราะห์ โดยอาจจำแนกเป็นสองกรณี กรณีแรกคือหากโมเดลมีประสิทธิภาพในการทำนายสูงอยู่ระดับที่สามารถนำไปใช้งานได้แล้วผู้วิเคราะห์จะหยุดการดำเนินงานไว้ที่ขั้นตอนนี้แล้วนำโมเดลดังกล่าวไปใช้งานต่อไป กรณีที่สองหากโมเดลทำนายที่พัฒนาขึ้นยังมีประสิทธิภาพไม่ถึงเกณฑ์ที่กำหนด ผู้วิเคราะห์สามารถใช้สารสนเทศจาก EDA ในจุด f ประกอบการคัดเลือกโมเดลเบื้องต้น และปรับแต่งโมเดลรวมทั้งอาจดำเนินการทำ feature engineering อีกครั้งหนึ่งเพื่อเพิ่มประสิทธิภาพการทำนายให้กับโมเดล (จุด h) เมื่อได้โมเดลสุดท้ายแล้วผู้วิเคราะห์สามารถเปรียบเทียบประสิทธิภาพระหว่างโมเดลคู่แข่งขันโดยใข้ชุดข้อมูลทดสอบ (test dataset) แล้วเลือกโมเดลที่ดีที่สุดไปใช้งาน\n\nส่วนของการนำโมเดลไปใช้งาน ต้องทำความเข้าใจว่า ML model ที่พัฒนาขึ้นนั้นเป็นเหมือนสมองซึ่งต้องเข้าไปอยู่ในโปรแกรมหรือ application สักตัวหนึ่ง โดยโปรแกรมดังกล่าวจะมีหน้าที่หลัก ๆ เช่นมี interface สำหรับรับข้อมูลจากผู้ใช้ เพื่อนำไปประมวลผลด้วยโมเดลทำนายที่เราสร้างขึ้น และรายงานผลการทำนาย/จำแนก ที่ได้จากโมเดลให้แก่ผู้ใช้ ทั้งนี้โปรแกรมดังกล่าวยังอาจมีส่วนอื่น ๆ ที่ยอมให้ผู้ใช้เลือกหรือปรับแต่งการทำงานของโปรแกรมได้ ทั้งนี้ขึ้นอยู่กับวัตถุประสงค์การใช้งาน ตัวอย่างด้านล่างแสดงโปรแกรมทำนายผลการเรียนของนิสิต [KruRooTeller](https://siwachoat.shinyapps.io/reportandpredict/?_ga=2.42051557.1707159165.1666195773-1113918738.1613372414&utm_source=KruRooTeller)\n\n![ระบบ KruRooTeller](images/image-1909139629.png){alt=\"ระบบ KruRooTeller\" width=\"90%\"}\n\nเนื้อหาส่วนที่เหลือของบทเรียนนี้จะกล่าวถึงกระบวนการในส่วนของการพัฒนา supervised learning models โดยจะกล่าวถึงมโนทัศน์ที่จำเป็นก่อน จากนั้นจึงกล่าวถึงกระบวนการพัฒนาโมเดลดังกล่าว รายละเอียดมีดังนี้\n\n\\newpage\n\n## 3.1 Bias and Variance in ML models\n\nพิจารณารูป 18 แสดงการ fit โมเดลทำนาย 3 แบบกับชุดข้อมูลฝึกหัดชุดหนึ่ง จะเห็นว่าแต่ละโมเดลมีความสามารถในการเรียนรู้ความสัมพันธ์ที่เกิดขึ้นในชุดข้อมูลแตกต่างกัน ความแตกต่างระหว่างค่าจริงของตัวแปรตามในชุดข้อมูลฝึกหัดกับค่าทำนายที่ได้จากโมเดล เรียกว่า **ความลำเอียง (bias)** **จากรูป 16 ผู้อ่านคิดว่าโมเดลใดที่มีประสิทธิภาพในการทำนายสูงที่สุดเพราะเหตุใด ?**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![regression model on training dataset](02MLProcess_files/figure-html/unnamed-chunk-2-1.png){width=336}\n:::\n:::\n\n\nพิจารณารูป 19 ผู้วิเคราะห์ได้นำโมเดลทำนายทั้ง 3 แบบ ที่พัฒนาจากชุดข้อมูลฝึกหัดมาใช้ทำนายข้อมูลใหม่ที่โมเดลทั้ง 3 ไม่เคยได้เรียนรู้มาก่อน ความแตกต่างระหว่างค่าจริงของตัวแปรตามในชุดข้อมูลใหม่ (หรือชุดข้อมูลที่ไม่ได้ใช้ในขั้นการพัฒนาโมเดล) กับค่าทำนายของโมเดล เรียกว่า **ความแปรปรวน (variance)** ความแปรปรวนของโมเดลทั้ง 3 เป็นอย่างไร?\n\n\n::: {.cell}\n::: {.cell-output-display}\n![regression model on new dataset](02MLProcess_files/figure-html/unnamed-chunk-3-1.png){width=336}\n:::\n:::\n\n\nจากตัวอย่างข้างต้นจะเห็นว่า ถึงแม้จะสามารถพัฒนาโมเดลทำนายให้สามารถเรียนรู้ความสัมพันธ์ภายในชุดข้อมูลฝึกหัดได้เป็นอย่างดี (มีความลำเอียงต่ำที่สุดแล้ว) แต่ก็ไม่ใช่เงื่อนไขเพียงพอที่จะสรุปได้ว่าโมเดลทำนายดังกล่าวจะมีประสิทธิภาพในการทำนายได้ดีในกรณีทั่วไป การตรวจสอบอีกชั้นหนึ่งคือตรวจสอบความแปรปรวนของโมเดลทำนาย โดยนำโมเดลดังกล่าวไปทำนายชุดข้อมูลที่ไม่เคยได้เรียนรู้มาก่อน โมเดลที่มีทั้งความลำเอียงและความแปรปรวนต่ำจึงเป็นโมเดลที่มีประสิทธิภาพที่จะนำไปใช้ในกรณีทั่วไป\n\nในเชิงอุดมคติ ผู้วิเคราะห์ต้องการให้ทั้งความลำเอียง และความแปรปรวนมีค่าต่ำที่สุดเท่าที่จะสามารถต่ำได้ แต่ในความเป็นจริงความคลาดเคลื่อนทั้งสองไม่ควบคุมให้ต่ำที่สุดพร้อมกันได้ **(เพราะอะไร?)** รูป 20 ด้านล่างแสดงความสัมพันธ์ระหว่างความลำเอียง และความแปรปรวน ซึ่งจะเห็นว่ามีการแปรผกผันซึ่งกันและกัน โมเดลที่มีความลำเอียงสูงมีแนวโน้มที่จะมีความแปรปรวนต่ำ และในทางกลับกันโมเดลที่มีความลำเอียงต่ำจะมีแนวโน้มที่มีความแปรปรวนสูง **ดังนั้นวัตถุประสงค์ของการพัฒนาโมเดลจึงเป็นการหาจุดที่ดีที่สุดที่ทำให้ความคลาดเคลื่อนทั้งสองอยู่ในจุดที่ต่ำที่สุดเท่าที่จะเป็นไปได้**\n\n![bias and variance trace-off](images/image-712567945.png){alt=\"bias and variance trace-off\" fig-align=\"center\" width=\"60%\"}\n\n## 3.2 Underfitting, Overfitting และ Good fit models\n\nหากจำแนกโมเดลทำนายที่ถูกพัฒนาขึ้นตามประสิทธิภาพการทำนายของโมเดล อาจจำแนกได้เป็น 3 ประเภท ได้แก่\n\n1.  underfitting models คือโมเดลที่มีความลำเอียงสูง ความลำเอียงเป็นความคลาดเคลื่อนที่เป็นระบบ อันเนื่องมาจากโมเดลทำนายที่พัฒนาขึ้นยังไม่สามารถเรียนรู้แนวโน้มหรือรูปแบบความสัมพันธ์หลักระหว่างตัวแปรภายในชุดข้อมูลฝึกหัดได้ดีเพียงพอ จากรูป 21 ซ้ายมือ จะเห็นว่าแนวโน้มความสัมพันธ์ตามธรรมชาติระหว่างตัวแปรตามกับตัวแปรอิสระคือความสัมพันธ์เชิงเส้นโค้ง แต่โมเดลทำนายที่พัฒนาขึ้นอยู่ในรูปแบบเส้นตรง ความแตกต่างระหว่างรูปแบบความสัมพันธ์ดังกล่าวก่อให้เกิดความลำเอียงขึ้น และเรียกโมเดลที่มีความลำเอียงในระดับที่มากเกินไปนี้ว่า underfitting model\n2.  overfitting models คือโมเดลที่มีความแปรปรวนสูง ความแปรปรวนเกิดขึ้นจากการที่โมเดลทำนายที่พัฒนาขึ้นสามารถเรียนรู้ความสัมพันธ์ในชุดข้อมูลฝึกหัดได้ดีมากเกินไป จนขาดความยืดหยุ่นในการนำโมเดลดังกล่าวไปใช้ในกรณีทั่วไป ดังตัวอย่างในรูป 21 ขวามือ จากรูปจะเห็นว่าโมเดลสามารถเรียนรู้ความสัมพันธ์ได้เกือบสมบูรณ์ แต่หากนำโมเดลนี้ไปใช้ทำนายข้อมูลใหม่ที่อยู่นอกเหนือจากชุดข้อมูลที่โมเดลนี้ได้เรียนรู้มีแนวโน้มสูงที่จะเกิดความคลาดเคลื่อนในการทำนาย\n3.  good fit models คือโมเดลที่สามารถสมดุลความลำเอียงและความแปรปรวนให้มีค่าต่ำที่สุดเท่าที่จะเป็นไปได้\n\n![underfitting, good fit, and overfitting model](images/image-1638148101.png){alt=\"underfitting, good fit, and overfitting model\"}\n\n## 3.3 Training, validation, and Test Dataset\n\nจาก concept ข้างต้นจะเห็นว่าในกระบวนการพัฒนาโมเดลผู้วิเคราะห์จะให้ความสำคัญกับประสิทธิภาพในการทำนายของโมเดลเฉพาะด้านความลำเอียงไม่ได้ ยังต้องคำนึงถึงด้านความแปรปรวนด้วย การพัฒนาโมเดลการเรียนรู้ของเครื่องจึงจะมีแค่ชุดข้อมูลฝึกหัดไม่ได้ ยังต้องมีชุดข้อมูลอีกชุดหนึ่งเพื่อเอาไว้ตรวจสอบความแปรปรวนของโมเดลด้วย ในเชิงเทคนิคเรียกชุดข้อมูลนี้ว่า **ชุดข้อมูลทดสอบ (test dataset)**\n\nภายในอัลกอริทึม supervised learning จะมีส่วนประกอบหลัก ๆ ได้แก่ อัลกอริทึม พารามิเตอร์ และ ไฮเปอร์พารามิเตอร์\n\n-   **อัลกอริทึม** เป็นส่วนของวิธีการเรียนรู้ของสำหรับแต่ละการเรียนรู้ของเครื่องที่ใช้ในการเรียนรู้หรือสกัดสารสนเทศจากข้อมูลในชุดข้อมูลฝึกหัด\n\n-   **พารามิเตอร์** **(parameters)** ส่วนที่ทำให้การเรียนรู้ของเครื่อง fit กับข้อมูล กล่าวง่าย ๆ คือค่าของพารามิเตอร์ที่เปลี่ยนแปลงไป จะทำให้รูปแบบการเรียนรู้มีการเปลี่ยนไป ค่าพารามิเตอร์นี้สามารถประมาณได้จากข้อมูลด้วยวิธีการทางสถิติ/คณิตศาสตร์ ตัวอย่างของพารามิเตอร์เช่น ใน linear regression model มีพารามิเตอร์คือ สัมประสิทธิ์จุดตัดแกน และสัมประสิทธิ์ความชัน เป็นต้น อย่างไรก็ตามบางอัลกอริทึมไม่ได้มีพารามิเตอร์ของโมเดล เช่น K-NN เป็นต้น\n\n-   **ไฮเปอร์พารามิเตอร์ (Hyperparameters)** เป็นพารามิเตอร์ประเภทหนึ่งในอัลกอริทึมการเรียนรู้ของเครื่อง พารามิเตอร์ประเภทนี้ไม่สามารถประมาณค่าจากข้อมูลโดยตรงด้วยวิธีการทางสถิติ แต่จะใช้การกำหนด/ปรับแต่งค่าโดยตัวผู้วิเคราะห์เอง **ในเชิงเทคนิคเรียกการปรับแต่งค่าดังกล่าวว่า hyperparameter tuning** การปรับแต่งค่าของ hyperparameter ดังกล่าวจะใช้วิธีการทดลองกำหนดค่า hyperparameter จำนวนหนึ่งให้กับอัลกอริทึม จากนั้นเลือกใช้ค่า hyperparameter ที่ทำให้ค่าประสิทธิภาพของโมเดลทำนายสูงที่สุด ทั้งนี้การพิจารณาประสิทธิภาพดังกล่าวจะพิจารณาบนชุดข้อมูลอีกชุดหนึ่งที่เรียกว่า **validation dataset**\n\nจากที่กล่าวข้างต้นจะเห็นว่าในกระบวนการพัฒนาโมเดลการเรียนรู้ของเครื่อง ต้องการชุดข้อมูลทั้งหมดจำนวน 3 ชุด ได้แก่ training, validation และ test dataset โดยที่ training และ validation dataset เป็นชุดข้อมูลที่ใช้ในระยะพัฒนาการเรียนรู้ของโมเดลให้มีประสิทธิภาพสูงสุด ส่วน test dataset เป็นชุดข้อมูลที่ใช้ตรวจสอบประสิทธิภาพด้านความเป็นนัยทั่วไปแต่จะไม่ได้มีส่วนเกี่ยวข้องกับระยะการพัฒนาการเรียนรู้ของโมเดล\n\n\\newpage\n\n## 3.4 Data Partitioning\n\nในทางปฏิบัติผู้วิเคราะห์มักมีข้อมูลต้นฉบับเพียงชุดเดียวเท่านั้นแต่ละใช้การแบ่งส่วนข้อมูลโดยใช้วิธีการสุ่มตัวอย่าง (random sampling) เพื่อสร้าง training, validation และ test dataset รูปด้านล่างแสดงลักษณะการแบ่งส่วนข้อมูล\n\n![training, validation และ testing dataset](images/image-2117384298.png){alt=\"training, validation และ testing dataset\" fig-align=\"center\" width=\"40%\"}\n\nโดยปกติการแบ่งส่วนข้อมูลดังกล่าวไม่ได้มีกฎเกณฑ์ตายตัวว่าควรแบ่งส่วนใดอย่างละเท่าไหร่ โดยปกติผู้วิเคราะห์มักกำหนดสัดส่วนระหว่าง training + validation dataset กับ test dataset เป็น 80 : 20, 75 : 25, 70 : 30, 60: 40 หรือ 50: 50 ขึ้นอยู่กับว่าชุดข้อมูลต้นฉบับที่มีนั้นมีขนาดใหญ่มากเพียงใด นอกจากนี้การแบ่งส่วนข้อมูลด้วยวิธีการสุ่มตัวอย่างอาจจำแนกเป็น 2 วิธีการ วิธีการแรกคือการสุ่มตัวอย่างแบบง่าย (simple random sampling: SRS) และวิธีการที่สองคือการสุ่มตัวอย่างแบบชั้นภูมิ (stratified random sampling)\n\n### ชุดข้อมูล `mpg`\n\nชุดข้อมูลที่ใช้เป็นตัวอย่างในหัวข้อนี้จะใช้ dataset `mpg` ที่เป็นชุดข้อมูลตัวอย่างซึ่งถูกติดตั้งมาพร้อมกับการติดตั้งโปรแกรม R อยู่แล้ว ผู้วิเคราะห์สามารถเรียกดูข้อมูลภายในชุดข้อมูลดังกล่าวได้โดยใช้คำสั่งพื้นฐานต่าง ๆ เช่น `head()`, `str()`, `glimpse()` หรือ `summary()` เป็นต้น\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nhead(mpg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  <chr>        <chr> <dbl> <int> <int> <chr>      <chr> <int> <int> <chr> <chr> \n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa…\n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa…\n3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa…\n4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa…\n5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa…\n6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p     compa…\n```\n:::\n:::\n\n\n\\newpage\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(mpg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 234\nColumns: 11\n$ manufacturer <chr> \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        <chr> \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        <dbl> 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         <int> 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          <int> 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        <chr> \"auto(l5)\", \"manual(m5)\", \"manual(m6)\", \"auto(av)\", \"auto…\n$ drv          <chr> \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"4\", \"4\", \"4\", \"4\", \"4…\n$ cty          <int> 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          <int> 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           <chr> \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p…\n$ class        <chr> \"compact\", \"compact\", \"compact\", \"compact\", \"compact\", \"c…\n```\n:::\n:::\n\n\n### การแบ่งข้อมูลด้วยการสุ่มอย่างง่าย\n\nการแบ่งด้วย simple random sampling เป็นการแบ่งโดยสุ่มข้อมูลตามจำนวนที่กำหนดออกมาเป็นชุดข้อมูล training dataset หรือ test dataset โดยการสุ่มดังกล่าวมีข้อสมมุติว่าหน่วยข้อมูลทุกหน่อยในชุดข้อมูลต้นฉบับมีโอกาสที่จะถูกสุ่มขึ้นมาเท่ากันทั้งหมด การแบ่งข้อมูลด้วยวิธีการนี้ใน R สามารถทำได้หลายวิธี แต่ในบทความนี้จะใช้วิธีที่อยู่ภายใต้ framework ของ tidymodels การแบ่งข้อมูลด้วยวิธีการดังกล่าวมีสองขั้นตอน **ขั้นแรก** คือการสร้างกรอบของการแบ่งข้อมูลออกเป็น training และ test data สามารถทำได้ด้วยฟังก์ชัน `initial_split()` ของ package rsample อาร์กิวเมนท์สำคัญที่จะต้องระบุในฟังก์ชันได้แก่ `data` และ `prop`**ขั้นที่สอง** คือการแบ่งข้อมูลตามกรอบในขั้นตอนแรก โดยจะใช้ฟังก์ชัน `training()` เพื่อแบ่งชุด training dataset ออกมา และใช้ฟังก์ชัน `testing()` เพื่อแบ่งชุดข้อมูล test dataset ออกมา\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# import rsample\nlibrary(rsample)\n# generate sampling frame\nmpg_split1 <- initial_split(data = mpg, prop = 0.75)\nmpg_split1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Training/Testing/Total>\n<175/59/234>\n```\n:::\n\n```{.r .cell-code}\n# create training and test dataset\ntrain_srs <- mpg_split1 %>% training()\ntest_srs <- mpg_split1 %>% testing()\n```\n:::\n\n\n### การแบ่งข้อมูลด้วยการสุ่มแบบชั้นภูมิ\n\nการแบ่งชุดข้อมูลด้วยการสุ่มแบบชั้นภูมิสามารถทำได้ด้วยฟังก์ชัน `initial_split()` เช่นเดียวกัน แต่จะต้องมีการระบุอาร์กิวเมนท์ของฟังก์ชันเพิ่มเติมได้แก่ `strata` เพื่อระบุตัวแปรตามหรือตัวแปรเกณฑ์ที่จะใช้แบ่งชั้นภูมิก่อนการสุ่มตัวอย่าง และ `breaks` ใช้กำหนดจำนวนอันตรภาคชั้นของตัวแปรตามหรือตัวแปรเกณฑ์ที่จะใช้แบ่งชั้นภูมิหากตัวแปรดังกล่าวเป็นตัวแปรเชิงปริมาณ ค่าเริ่มต้นของอาร์กิวเมนท์นี้กำหนดให้ `breaks = 4`ตัวอย่างต่อไปนี้แสดงการแบ่งชุดข้อมูล training และ test ด้วยการสุ่มแบบชั้นภูมิ\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmpg_split2 <- initial_split(data = mpg, \n                            prop = 0.75,\n                            strata = \"hwy\",\n                            breaks = 10)\ntrain_str <- mpg_split2 %>% training()\ntest_str <- mpg_split2 %>% testing()\n```\n:::\n\n\nรูปด้านล่างแสดงการเปรียบเทียบการแจกแจงของตัวแปรตามระหว่างชุดข้อมูลต้นฉบับ (full dataset), training และ test dataset ที่แบ่งด้วยวิธีการสุ่มตัวอย่างแบบง่าย และแบบชั้นภูมิ\n\n\n::: {.cell}\n::: {.cell-output-display}\n![เปรียบเทียบระหว่าง SRS กับ STR](02MLProcess_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nการสุ่มแบบชั้นภูมิเหมาะสำหรับการพัฒนา classification models เมื่อสัดส่วนของค่าที่เป็นไปได้ของตัวแปรตามมีความแตกต่างกันมาก ๆ หรือมีบางค่าสังเกตของตัวแปรตามที่มีสัดส่วนการเกิดที่น้อยเมื่อเปรียบเทียบกับค่าสังเกตอื่น ๆ (imbalanced outcome) นอกจากนี้ยังเหมาะกับการพัฒนา regression models เมื่อตัวแปรตามมีลักษณะการแจกแจงแบบเบ้ขวา\n\n## 3.5 การสุ่มซ้ำ (resampling)\n\nอัลกอริทึมการเรียนรู้ของเครื่องหลายตัวมี hyperparameters ที่หากมีการกำหนดค่าที่เหมาะสมจะช่วยพัฒนาการเรียนรู้ได้ดีขึ้นและช่วยให้โมเดลทำนายมีประสิทธิภาพการทำนายที่สูงขึ้นได้ อย่างไรก็ตาม hyperparameters ดังกล่าวไม่สามารถประมาณได้โดยตรงจากข้อมูล แต่ต้องอาศัยการกำหนดค่าเองโดยผู้วิเคราะห์ ดังนั้นในระหว่างการพัฒนาโมเดลจึงมีความจำเป็นที่ผู้วิเคราะห์จะต้องทราบประสิทธิภาพการทำนายของโมเดลเมื่อมีการกำหนดค่า hyperparameters ต่าง ๆ เพื่อใช้เป็นสารสนเทศประกอบการกำหนดค่า hyperparameters ดังกล่าว\n\nด้วยเหตุผลเดียวกับการประเมินประสิทธิภาพของโมเดลด้วยชุดข้อมูลทดสอบ การประเมินประสิทธิภาพในระยะของการพัฒนาโมเดลดังกล่าวไม่ช่วยใช้ข้อมูลจากชุดข้อมูลฝึกหัด เพราะจะทำให้ค่าประสิทธิภาพดังกล่าวมีค่าสูงเกินความเป็นจริงและอาจทำให้การกำหนดค่า hyperparameters มีความคลาดเคลื่อน เพื่อแก้ปัญหาดังกล่าวจึงมีการใช้เทคนิคการสุ่มซ้ำ (resampling) ในการสุ่มชุดข้อมูลย่อยจากชุดข้อมูลฝึกหัด โดยแบ่งชุดข้อมูลฝึกหัดออกเป็นสองชุดข้อมูลย่อย อาจเรียกว่าชุดข้อมูลสำหรับวิเคราะห์ (analysis) ต่อไปจะเรียกว่า traning dataset และชุดข้อมูลสำหรับสำหรับประเมินประสิทธิภาพ (assessment) ซึ่งต่อไปจะเรียกว่า validation dataset ดังรูป 24\n\n![resampling strategy](images/image-468626522.png){alt=\"resampling strategy\"}\n\nเนื่องจากเทคนิคการสุ่มซ้ำเป็นการสุ่มแบบที่มีการใส่คืน (sampling with replacement) จึงทำให้ในระยะของการพัฒนาโมเดลผู้วิเคราะห์สามารถทวนซ้ำการสุ่มซ้ำดังกล่าวเพื่อสร้าง training และ validation dataset ได้จำนวนหลายชุด การดำเนินการดังกล่าวช่วยให้การประเมินประสิทธิภาพของโมเดลทำนายภายใต้เงื่อนไขของการกำหนด hyperparameters ต่าง ๆ สามารถทำได้อย่างแม่นยำ\n\nปัจจุบันมีเทคนิคการสุ่มซ้ำสำหรับการพัฒนาโมเดลทำนายดังกล่าวหลายตัว ได้แก่ K-fold Cross-Validation, Monte Carlo Cross-Validation, Bootstrapping และ Rolling Origin Forecasting รายละเอียดมีดังนี้\n\n### K-fold Cross-Validation และวิธีการอื่น ๆ ที่เกี่ยวข้อง\n\nเป็นเทคนิคการสุ่มซ้ำที่นิยมใช้กันอย่างแพร่หลาย เทคนิคนี้จะแบ่งชุดข้อมูล traning dataset โดยใช้การสุ่มแบบใส่คืนออกเป็นข้อมูลชุดย่อยจำนวน K ชุด จากนั้นจะดำเนินการวิเคราะห์และประเมินประสิทธิภาพของโมเดลจำนวน K ครั้ง โดยที่แต่ละครั้งที่จะมีการหมุนเวียนใช้ชุดข้อมูลจำนวน K-1 ชุดเพื่อวิเคราะห์ และใช้ชุดข้อมูลที่เหลืออีก 1 ชุดเพื่อประเมินประสิทธิภาพ\n\nรูป 25 แสดงตัวอย่างของ 5-fold cross-validation จากรูปจะเห็นว่ามีการสุ่มเพื่อแบ่งชุดข้อมูลฝึกหัดออกเป็น 5 ชุดย่อย จากนั้นทวนซ้ำการดำเนินการวิเคราะห์และประเมินประสิทธิภาพของโมเดลจำนวน 5 ครั้ง โดยที่ในแต่ละครั้งจะใช้ชุดข้อมูลย่อยจำนวน 4 ชุด เป็น training dataset เพื่อสร้างโมเดลทำนาย และใช้อีก 1 ชุดที่เหลือเป็น validation dataset เพื่อตรวจสอบประสิทธิภาพของโมเดลทำนาย จากรูปจะเห็นว่าในแต่ละครั้งจะมีการหมุนเวียนชุดข้อมูลที่จะใช้เป็น training และ validation ไปเรื่อย ๆ จนครบ การดำเนินการดังกล่าวจะทำให้ผู้วิเคราะห์มีค่าสถิติที่ใช้ประเมินประสิทธิภาพของโมเดลจำนวน 5 ค่า ผู้วิเคราะห์จะใช้ผลการวิเคราะห์จากค่าสถิติดังกล่าว เช่น ค่าเฉลี่ยของ RMSE หรือ R square ในการประเมินประสิทธิภาพของโมเดลภายใต้เงื่อนไขต่าง ๆ เช่น ภายใต้การกำหนดค่า hyperparameters ต่าง ๆ เป็นต้น\n\n![5-fold CV (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)](images/image-1150746472.png){alt=\"5-fold CV (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)\" fig-align=\"center\"}\n\nเนื่องจาก K-fold CV สุ่มเพื่อแบ่งชุดข้อมูลในครั้งแรกเพียงครั้งเดียว และใช้การหมุนเวียนชุดข้อมูลย่อยที่ได้จากการสุ่มดังกล่าวเพื่อวิเคราะห์และประเมินประสิทธิภาพของโมเดล จึงทำให้หน่วยข้อมูลแต่ละหน่วยมีโอกาสที่จะปรากฎอยู่ใน validation dataset ได้เพียงครั้งเดียวดังตัวอย่างในรูป 26 ข้อจำกัดนี้ทำให้ค่าประมาณประสิทธิภาพของโมเดลทำนายที่มีแนวโน้มจะมีความแปรปรวนมากที่สุดเมื่อเปรียบเทียบกับ resampling วิธีการอื่น ๆ การที่จะลดทอนความแปรปรวนดังกล่าวให้น้อยลงสามารถทำได้ด้วยการเพิ่มจำนวน K ให้มากขึ้น โดยจากการศึกษาพบว่าการกำหนดให้ K มีค่าตั้งแต่ 10 ขึ้นไป จะช่วยลดทอนความแปรปรวนของการประเมินประสิทธิภาพได้ อย่างไรก็ตาม K-fold CV ก็ยังมีแนวโน้มที่จะมีความแปรปรวนดังกล่าวมากกว่าการใช้การสุ่มซ้ำแบบอื่นอยู่ดี\n\nอีกข้อจำกัดหนึ่งของการทำ K-fold CV คือการกำหนดค่า K จำนวนมากจะทำให้การประมวลผลต้องดำเนินการหลายรอบและต้องใช้เวลาและทรัพยากรในการประมวลผลที่มากขึ้น ในกรณีที่ข้อมูลและโมเดลมีความซับซ้อนการประมวลผลในขั้นตอนนี้อาจใช้เวลานานหลายชั่วโมงหรือเป็นวันซึ่งอาจไม่คุ้มค่าที่จะดำเนินการในลักษณะดังกล่าว โดยในกรณีที่กำหนดให้ K = n เมื่อ n คือจำนวนหน่วยข้อมูลทั้งหมดจะเรียกการสุ่มนี้ว่า leave-one-out CV (LOOCV) ที่เป็นกรณีสุดโต่งที่สุดของการทำ K fold CV ปัจจุบัน LOOCV ไม่ค่อยถูกใช้งานแล้วเนื่องจากใช้เวลาและทรัพยากรอย่างมาก\n\n![10-fold CV จากชุดข้อมูลที่มีหน่วยข้อมูลจำนวน 32 หน่วย (ที่มา : Boehmke, and Greenwell (2020))](images/image-998799574.png){alt=\"10-fold CV จากชุดข้อมูลที่มีหน่วยข้อมูลจำนวน 32 หน่วย (ที่มา : Boehmke, and Greenwell (2020))\"}\n\nเพื่อแก้ปัญหาของ K-fold CV ข้างต้นถึงมีการพัฒนาเทคนิคอีกตัวหนึ่งเรียกว่า repeated K-fold cross-validation เทคนิคดังกล่าวเป็นการทำ K-fold CV ซ้ำ ๆ หลาย ๆ รอบ วิธีการนี้ทำให้หน่วยข้อมูลแต่ละหน่วยสามารถปรากฎอยู่ใน validation dataset ได้มากกว่าหนึ่งครั้ง ซึ่งช่วยให้ความแปรปรวนในการประมาณค่าประสิทธิภาพของโมเดลทำนายลดลงได้\n\n### Monte Carlo Cross-Validation\n\nในขณะที่ K-fold CV เป็นวิธีการที่ยอมให้หน่วยข้อมูลแต่ละหน่วยปรากฎใน validation dataset ได้เพียงครั้งเดียว แต่ในทางกลับกัน Monte Carlo CV (MCCV) จะสร้างชุดข้อมูลย่อย K ชุดที่ยอมให้มีหน่วยข้อมูลที่ร่วมกันได้ซึ่งทำให้หน่วยข้อมูลแต่ละหน่วยสามารถปรากฎอยู่ใน validation dataset มากกว่าหนึ่งครั้งและช่วยลดทอนความแปรปรวนในการประมาณค่าประสิทธิภาพของโมเดลลงได้ โดย MCCV มีขั้นตอนการดำเนินการดังนี้\n\n\\newpage\n\n1.  แบ่งชุดข้อมูลที่จะนำมาพัฒนาโมเดลออกเป็นสองส่วน ได้แก่ ส่วน training dataset และ validation dataset (อาจใช้สัดส่วน 70:30, 80:20, ... ตามที่ผู้วิเคราะห์เห็นว่าเหมาะสม)\n2.  นำข้อมูลใน training dataset ไปดำเนินการวิเคราะห์ และใช้ validation dataset เพื่อประเมินประสิทธิภาพของโมเดล จากนั้นเก็บค่าประสิทธิภาพดังกล่าวไว้\n3.  ทวนซ้ำขั้นตอนที่ 1. ใหม่ การทวนซ้ำอาจทำเป็นจำนวน 100, 500 หรือ 1,000 รอบ ซึ่งเมื่อครบตามจำนวนรอบที่กำหนดแล้วผู้วิเคราะห์จะนำค่าประมาณประสิทธิภาพจากแต่ละรอบมาหาค่าเฉลี่ย\n\nรูป 27 แสดงตัวอย่างของการทำ MCCV จำนวน 100 รอบ\n\n![Monte Carlo CV จำนวน 100 รอบ (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)](images/image-103001330.png){alt=\"Monte Carlo CV จำนวน 100 รอบ (ที่มา : https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b)\"}\n\nรูป 28 แสดงการเปรียบเทียบผลที่ได้จากการแบ่งชุดข้อมูลระหว่าง 10-fold CV กับ 10 resample MCCV (โดยกำหนดให้สัดส่วนการสุ่มเป็น 90:10) ของชุดข้อมูลต้นฉบับที่มีจำนวน 20 หน่วย จากรูปจะเห็นว่าหน่วยข้อมูลมีโอกาสปรากฎใน validation dataset ได้เพียงครั้งเดียวเมื่อใช้ 10-fold CV แต่สามารถปรากฎได้มากกว่าหนึ่งครั้งเมื่อใช้ 10 resample MCCV\n\n![ผลที่ได้จากการแบ่งชุดข้อมูลระหว่าง 10-fold CV กับ 10 resample MCCV (โดยกำหนดให้สัดส่วนการสุ่มเป็น 90:10) ของชุดข้อมูลต้นฉบับที่มีจำนวน 20 หน่วย (ที่มา : Max Kuhn and Kjell Johnson (2019))](images/image-1721863239.png){alt=\"ผลที่ได้จากการแบ่งชุดข้อมูลระหว่าง 10-fold CV กับ 10 resample MCCV (โดยกำหนดให้สัดส่วนการสุ่มเป็น 90:10) ของชุดข้อมูลต้นฉบับที่มีจำนวน 20 หน่วย (ที่มา : Max Kuhn and Kjell Johnson (2019))\"}\n\n\\newpage\n\n### Bootstraping\n\nกำหนดให้ชุดข้อมูลต้นฉบับมีขนาด n หน่วย **bootstrap sample** คือตัวอย่างสุ่มขนาด n หน่วย (เท่ากับชุดข้อมูลต้นฉบับ) ที่ได้จากการสุ่มตัวอย่างอย่างง่ายแบบใส่คืน (simple random sampling with replacement) จากชุดข้อมูลต้นฉบับ จากลักษณะของการสุ่มตัวอย่างแบบ bootstrap ข้างต้นจะได้ว่า ความน่าจะเป็นที่หน่วยข้อมูลแต่ละหน่วยจะถูกเลือกในการสุ่มข้อมูลตัวที่ $i$ โดยที่ $i = 1,2,3,...,n$ จะมีค่าเท่ากับ $P(select_i) = \\frac{1}{n}$ ซึ่งทำให้ความน่าจะเป็นที่หน่วยข้อมูลจะไม่ถูกเลือกในการสุ่มครั้งที่ $i$ เท่ากับ $P(not \\ select)=1-\\frac{1}{n}$ ดังนั้นความน่าจะเป็นที่หน่วยข้อมูลแต่ละหน่วยจะอยู่ในตัวอย่างแบบ bootstrap จะมีค่าเท่ากับ $(1-\\frac{1}{n})^n$ เมื่อ $n \\rightarrow \\infty$ จะได้ว่าความน่าจะเป็นที่หน่วยข้อมูลแต่ละหน่วยจะปรากฎอยู่ในตัวอย่างแบบ bootstrap มีค่าเท่ากับ 63.2% (การพิสูจน์ใช้คุณสมบัติของ Taylor series) รูป 29 ด้านล่างแสดงลักษณะของตัวอย่างแบบ bootstrap\n\n![](images/image-1881794685.png)\n\nในกระบวนการพัฒนาโมเดลทำนาย จะใช้ตัวอย่าง bootstrap เป็นชุดข้อมูลสำหรับวิเคราะห์ และใช้ชุดข้อมูลที่เหลือที่ไม่ได้ถูกสุ่มไว้ในตัวอย่าง bootstrap เป็นชุดข้อมูลสำหรับประเมินประสิทธิภาพของโมเดลทำนายระหว่างการพัฒนาโมเดล (เทียบเท่ากับ validation dataset) โดยจะเรียกตัวอย่างที่ไม่ได้ถูกสุ่มไว้ในตัวอย่าง bootstrap ในแต่ละรอบว่า **out-of-bag sample (OOB)**\n\nจากคุณลักษณะของตัวอย่าง bootstrap ที่หน่วยข้อมูลแต่ละหน่วยมีโอกาสปรากฏอยู่ในชุดข้อมูล bootstrap ได้มากกว่า 1 ชุด จึงทำให้การประมาณค่าประสิทธิภาพของโมเดลที่ได้จากการสุ่มซ้ำแบบ bootstrap มีแนวโน้มที่จะมีความแปรปรวนต่ำกว่าการสุ่มซ้ำแบบ k-fold CV อย่างไรก็ตามในกรณีที่ข้อมูลต้นฉบับมีขนาดเล็กการสุ่มซ้ำแบบ boostrap มีแนวโน้มที่จะให้ค่าประมาณประสิทธิภาพของโมเดลที่ลำเอียง จึงควรใช้เทคนิคการสุ่มซ้ำแบบ bootstrap เมื่อข้อมูลมีขนาดใหญ่เพียงพอ (n \\> 1000) (Boehmke, B., & Greenwell, B., 2020)\n\n## 3.6 Tidymodels Framework\n\nปัจจุบันมีเครื่องมือที่ช่วยให้ผู้วิเคราะห์สามารถพัฒนา machine model ได้หลายตัว บทเรียนนี้จะกล่าวถึงการใช้โปรแกรม R เพื่อพัฒนา ML model ดังกล่าว ทั้งนี้ต้องทำความเข้าใจก่อนว่า การทำงานบน R แม้จะเป็นปัญหาเดียวกัน ชุดข้อมูลเดียวกัน แต่ผู้วิเคราะห์ต่างคนกันก็มีทางที่จะดำเนินการด้วยวิธีการที่แตกต่างกันได้ (ใน Python หรือโปรแกรมอื่น ๆ ก็เช่นเดียวกัน) วิธีการหนึ่งใน R ที่สามารถ modeling ได้ง่ายและมีประสิทธิภาพคือการใช้ **tidymodels framework** ดังรูป 23\n\n![tidymodel framework](images/image-258190158.png){alt=\"tidymodel framework\" fig-align=\"center\" width=\"80%\"}\n\n-   **package-rsample** ใช้ในงาน resampling ข้อมูล เช่นการสร้าง training/validation/test dataset การสร้าง cross-validation dataset หรือการสร้าง bootstrape dataset ซึ่งได้กล่าวการใช้งานเบื้องต้นไปแล้ว\n\n-   **package-recipes** ใช้แปลง/แก้ปัญหาที่เกิดขึ้นในข้อมูลของตัวแปรที่ใช้ในการพัฒนาโมเดล ขั้นตอนนี้เรียกว่า feature engineering\n\n-   **package-parsnip** ใช้ fit machine learning กับข้อมูล\n\n-   **package-Tune** และ **package-dials** มีฟังก์ชันที่อำนวยความสะดวกในการ fine tune hyperparameter ของโมเดลเพื่อเพิ่มประสิทธิภาพการทำนายของโมเดลให้สูงที่สุด\n\n-   **package-yardstick** มีฟังก์ชันของ metric ที่ใช้ประเมินประสิทธิภาพของโมเดลทำนาย\n\ntidymodels ถูกพัฒนาขึ้นโดยได้รับการออกแบบให้สามารถทำซ้ำกระบวนการพัฒนาโมเดลได้ง่าย โดยใช้ไวยกรณ์ของภาษาในลักษณะเดียวกัน และถูกออกแบบโดยเน้นใช้กับ supervised learning เป็นหลัก ผู้ใช้งานไม่จำเป็นต้องติดตั้งทุก package ในข้างต้นด้วยตนเอง แต่ติดตั้งเพียง package-tidymodels ก็สามารถใช้งานทุก package ภายใต้ framework ดังกล่าวได้แล้ว โดยการพิมพ์คำสั่งต่อไปนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"tidymodels\") # ดาวน์โหลดและติดตั้ง tidymodels\nlibrary(tidymodels) # เรียกใช้ tidymodels\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ broom        1.0.3     ✔ recipes      1.0.2\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ gridExtra::combine() masks dplyr::combine()\n✖ scales::discard()    masks purrr::discard()\n✖ dplyr::filter()      masks stats::filter()\n✖ recipes::fixed()     masks stringr::fixed()\n✖ dplyr::lag()         masks stats::lag()\n✖ yardstick::spec()    masks readr::spec()\n✖ recipes::step()      masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n```\n:::\n:::\n\n\n### Fitting Linear Regression using parsnip\n\n![](images/image-538379331.png){width=\"30%\"}\n\nการ fit machine learning model กับข้อมูลด้วย R ในยุคเริ่มแรกค่อนข้างมีความยากลำบากพอสมควร เพราะ R ไม่ได้มี package ที่เป็น framework รวมสำหรับการ fit ML model ดังกล่าว การที่จะ fit ML model ในงานหนึ่ง ๆ ผู้วิเคราะห์อาจจะต้องยุ่งเกี่ยวกับ package จำนวนมาก เช่น\n\n-   package rpart สำหรับ fit decision tree\n\n-   package glmnet สำหรับ fit regularized regression model\n\n-   package knn สำหรับ fit K-NN model\n\nโดย package ที่แตกต่างกันมักมีแนวคิดและไวยกรณ์การเขียนคำสั่งที่แตกต่างกัน ทำให้เป็นอุปสรรคต่อการทำงานโดยเฉพาะการทำซ้ำในอนาคต จากปัญหานี้ tidymodels จึงมีการพัฒนา package parsnip ขึ้นเพื่อเป็น interface สำหรับใช้ package ใน R ที่เกี่ยวข้องกับการ fit supervised learning ทั้งนี้ parsnip ได้ถูกออกแบบมาให้การสั่งงานทั้งหมดอยู่ภายใต้ไวยกรณ์แบบเดียวกัน ปัจจุบันการ fit ML models ใน R จึงดำเนินการได้ง่ายขึ้นอย่างมาก\n\nขั้นตอนการ fit ML models ด้วย parsnip มี 2 ขั้นตอน ได้แก่ การระบุโมเดล และการประมวลผล รายละเอียดมีดังนี้\n\n#### (1) การระบุโมเดล (model specification)\n\nการระบุโมเดลใน parsnip มีส่วนประกอบ 3 ส่วนที่จำเป็นได้แก่\n\n-   **model type** หรืออัลกอริทึมการเรียนรู้ของเครื่องที่ผู้วิเคราะห์จะใช้ในการทำงาน\n\n-   **engine** หรือ package ของ R ที่จะใช้สำหรับประมวลผล model type ที่เลือก\n\n-   **mode** สำหรับกำหนดว่าปัญหาที่ทำงานด้วยอยู่นี้เป็น regression หรือ classification\n\nรายละเอียดว่าผู้วิเคราะห์สามารถกำหนด model type, engine และ mode แบบใดได้บ้างและต้องกำหนดอย่างไร สามารถศึกษาได้จาก <https://www.tidymodels.org/find/parsnip/> รูป 24 ด้านล่างแสดงค้นหาสำหรับอัลกอริทึม linear regression จากผลการค้นหาในรูปด้านล่างจะเห็นว่าการ fit linear regression ด้วย parsnip สามารถทำได้ด้วย model type คือ `linear_reg()` เมื่อพิจารณาในคอลัมน์ engine จะเห็นว่าการ fit linear regression มี engine จำนวนมากที่สามารถใช้เพื่อประมาณค่าพารามิเตอร์ของโมเดลได้ engine ดังกล่าวจริง ๆ แล้วคือ package ต่าง ๆ ของ R ที่ใช้ประมวลผล mode type ที่เลือกไว้ได้ ผู้อ่านจะเห็นว่า model type แบบ `linear_reg` มี engine ที่สามารถใช้ประมวลผลได้จำนวนมาก ซึ่งมีความเหมือนและความแตกต่างกัน เนื้อหาส่วนนี้มีความละเอียดพอสมควรจึงจะกล่าวถึงในบท regression model ต่อไป\n\n![parsnip manual](images/image-33185451.png){alt=\"parsnip manual\" fig-align=\"center\" width=\"70%\"}\n\nในคู่มือข้างต้นยังมีเครื่องมือให้ค้นหาการกำหนดอาร์กิวเมนท์ของฟังก์ชัน model type ในข้างต้น จากรูป 25 จะเห็นรายละเอียดในการกำหนดอาร์กิวเมนท์ของฟังก์ชัน `linear_reg()` เมื่อกำหนด engine ในลักษณะต่าง ๆ\n\n![argument ในฟังก์ชัน model type](images/image-1313501193.png){alt=\"argument ในฟังก์ชัน model type\" fig-align=\"center\" width=\"70%\"}\n\n\\newpage\n\nความหมายของการกำหนดอาร์กิวเมนท์แต่ละค่าสามารถศึกษาได้จากคู่มือของฟังก์ชัน `linear_reg()` ซึ่งสามารถกด hyperlink จากคู่มือได้เลย (คู่มือ [`linear_reg()`](https://parsnip.tidymodels.org/reference/linear_reg.html))\n\nเอกสารเพิ่มเติมเกี่ยวกับ package parsnip\n\n-   <https://cran.r-project.org/web/packages/parsnip/parsnip.pdf>\n\n-   <https://cran.r-project.org/web/packages/parsnip/vignettes/parsnip.html>\n\nสมมุติว่าผู้วิเคราะห์ต้องการพัฒนาโมเดลการเรียนรู้ของเครื่องด้วยอัลกอริทึม linear regression โดยมีตัวแปรตามคือ `hwy` และตัวแปรอิสระเพียง 1 ตัวได้แก่ `cty` ตัวอย่างคำสั่งต่อไปนี้แสดงการกำหนดโมเดลการเรียนรู้ด้วย parsnip ดังกล่าว\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_model <- linear_reg() %>%        # model type\n              set_engine(\"lm\") %>%  # model engine\n              set_mode(\"regression\") # model mode\n```\n:::\n\n\n#### (2) การประมวลผล\n\nเมื่อกำหนดโมเดลการเรียนรู้แล้วขั้นตอนถัดไปคือการนำ model specification ดังกล่าว ไปดำเนินการประมวลผล โดยส่งผ่านไปยังฟังก์ชัน `fit()` ซึ่งมีอาร์กิวเมนท์สำคัญ 2 ตัวได้แก่ model formula และ training dataset ที่จะใช้สำหรับฝึกหัดโมเดล\n\nการเขียน model formula จะเขียนอยู่ในรูปของ `y ~ x1+x2+x3+…` โดยที่ `y` คือตัวแปรตาม ส่วน `x1, x2, x3 ,…` คือตัวแปรอิสระภายในชุดข้อมูลฝึกหัด และสัญลักษณ์ `~` หมายความว่า \"regress on\" ในกรณีที่ต้องการใช้ตัวแปรที่เหลือในชุดข้อมูลทั้งหมดเป็นตัวแปรทำนาย สามารถเขียน model formula สั้น ๆ ได้ดังนี้ \\`y \\~ .\\` ตัวอย่างต่อไปนี้แสดงการส่งผ่าน model specification `lm_model` ในข้างต้นไปประมวลผล\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_lm <- lm_model %>%\n            fit(hwy ~ cty,  # model formula\n                data = train_str) # training dataset\n\nfit_lm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nparsnip model object\n\n\nCall:\nstats::lm(formula = hwy ~ cty, data = data)\n\nCoefficients:\n(Intercept)          cty  \n      1.056        1.324  \n```\n:::\n:::\n\n\n#### (3) การเรียกดูค่าประมาณพารามิเตอร์ของ ML model\n\nอย่างไรก็ตาม tidymodels มีฟังก์ชัน `tidy()` ซึ่งช่วยสร้างตารางสรุปผลลัพธ์จากการประมาณค่าพารามิเตอร์หรือการเรียนรู้ของโมเดลทำนายที่ใช้ให้อยู่ในรูปแบบเดียวกัน ดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(fit_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     1.06    0.537       1.97 5.10e- 2\n2 cty             1.32    0.0307     43.1  3.64e-94\n```\n:::\n:::\n\n\nภายใต้ framework ของ tidymodels จะใช้ฟังก์ชันใน package parsnip เพื่อ fitting model ทำนายดังกล่าว package ดังกล่าว จุดเด่นของ parsnip คือถูกออกแบบมาเพื่อเป็น interface สำหรับ fit supervised learning model ที่มีรูปแบบการใช้คำสั่งเป็นไวยกรณ์แบบเดียว\n\n#### (4) Prediction\n\nผู้วิเคราะห์สามารถนำโมเดลที่ผ่านการ train เรียบร้อยแล้วไปใช้หาค่าทำนาย โดยส่งผ่านโมเดลที่ train แล้ว (ในที่นี้คือ `fit_lm`) ไปยังฟังก์ชัน `predict()` ที่มีอาร์กิวเมนท์สำคัญคือ `new_data` ตัวอย่างด้านล่างแสดงนำ `fit_lm` ไปทำนายตัวแปร `hwy` ในชุดข้อมูลทดสอบ ผลลัพธ์ที่ได้จากการทำนายจะเป็นตารางแบบ tibble ที่แต่ละ row คือค่าทำนายของหน่วยข้อมูลใน row เดียวกันกับใน `test_str` ดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhwy_pred <- fit_lm %>%\n              predict(new_data = test_str)\nhwy_pred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 1\n   .pred\n   <dbl>\n 1  28.9\n 2  27.5\n 3  20.9\n 4  23.6\n 5  19.6\n 6  19.6\n 7  24.9\n 8  23.6\n 9  20.9\n10  20.9\n# … with 50 more rows\n```\n:::\n:::\n\n\n\\newpage\n\nเมื่อได้ค่าทำนายในชุดข้อมูลทดสอบมาแล้ว ขั้นตอนถัดไปคือการประเมินประสิทธิภาพของโมเดลทำนาย โดยทั่วไปผู้วิเคราะห์มักจะรวมค่าทำนายที่ได้ (ในที่นี้คือ `hwy_pred`) ไปไว้อยู่ภายในชุดข้อมูลทดสอบ การดำเนินการนี้สามารถทำได้หลายวิธีการขึ้นอยู่กับว่าถนัดจะดำเนินการแบบนี้ ในตัวอย่างนี้จะใช้ฟังก์ชัน `bind_cols()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_results <- test_str %>%\n                  dplyr::select(hwy, cty) %>%\n                  bind_cols(hwy_pred)\ntest_results\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 3\n     hwy   cty .pred\n   <int> <int> <dbl>\n 1    29    21  28.9\n 2    28    20  27.5\n 3    24    15  20.9\n 4    25    17  23.6\n 5    20    14  19.6\n 6    17    14  19.6\n 7    29    18  24.9\n 8    24    17  23.6\n 9    22    15  20.9\n10    21    15  20.9\n# … with 50 more rows\n```\n:::\n:::\n\n\n#### (5) Evaluating models using yardstick\n\nการคำนวณค่าประสิทธิภาพของโมเดลทำนายแบบ regression ภายใต้ tidymodels framework สามารถทำได้ง่าย ๆ โดยใช้ฟังก์ชันจาก package yardstick ได้แก่ `rmse()` และ `rsq()` ตัวอย่างต่อไปนี้แสดงการเขียนคำสั่งเพื่อคำนวณ metric ทั้งสอง\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_results %>%\n  rmse(truth = hwy, estimate = .pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.63\n```\n:::\n:::\n\n\n\\newpage\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_results %>%\n  rsq(truth = hwy, estimate = .pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rsq     standard       0.911\n```\n:::\n:::\n\n\nผลลัพธ์ข้างต้นเมื่อพิจารณาค่า RMSE พบว่าโมเดลทำนายที่พัฒนาขึ้นมีความคลาดเคลื่อนในการทำนายค่าของตัวแปร `hwy` โดยเฉลี่ย 1.64 หน่วย และเมื่อพิจารณาจากค่า R square พบว่ามีค่าเท่ากับ .913 แสดงว่าค่าจริงของ `hwy` กับค่าทำนายมีความผันแปรร่วมกันคิดเป็นร้อยละ 91.3 ซึ่งอยู่ในระดับที่สูงมาก ผลการวิเคราะห์นี้จึงบ่งชี้ว่าโมเดลทำนายที่พัฒนาขึ้นสามารถใช้ทำนายคะแนน `hwy` ได้ดี\n\nนอกจาก metric ที่เป็นค่าสถิติแล้วยังมี metric ที่เป็น visualization ด้วย เช่นในกรณีของ regression model สามารถใช้ R squared plots เพื่อประเมินความสอดคล้องกันระหว่างค่าจริงของตัวแปรตามกับค่าทำนายได้ การสร้าง R squared plot ใน R สามารถทำได้หลายวิธี ทั้งการใช้ฟังก์ชัน `plot()` ของ package graphic เหมือนกับตัวอย่างในบทที่ 2 นอกจากนี้ยังสามารถใช้ package ggplot2 เพื่อสร้างแผนภาพดังกล่าวได้เหมือนกัน\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create R squared plot using graphic package\nplot(x = test_results$hwy, \n     y = test_results$.pred,\n     pch = 16,\n     xlab = \"predicted value\",\n     ylab = \"actual value\")\nabline(a=1,b=1, lty=3, col=\"steelblue\")\n```\n\n::: {.cell-output-display}\n![](02MLProcess_files/figure-html/unnamed-chunk-18-1.png){width=336}\n:::\n:::\n\n\nในกรณีที่ต้องการใช้ ggplot2 สามารถเขียนคำสั่งได้ดังนี้\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# create R squared plot using ggplot2 package\nlibrary(ggplot2)\ntest_results %>% ggplot()+  # create 2D plane\n  geom_point(aes(x = hwy, # create scatter plot\n                 y = .pred))+\n  geom_abline(intercept=1, slope=1, linetype=3, col=\"steelblue\")+\n  coord_obs_pred()+\n  theme(text=element_text(size = 10))\n```\n\n::: {.cell-output-display}\n![R squared plot via ggplot2](02MLProcess_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=336}\n:::\n:::\n\n\nผลการวิเคราะห์จาก R square plot ข้างต้นแสดงให้เห็นว่าโมเดลสามารถทำนายค่าของตัวแปร `hwy` ได้ค่อนข้างดี อย่างไรก็ตามหากพิจารณาเปรียบเทียบความสัมพันธ์ระหว่างค่าจริงกับค่าทำนายจะพบว่าโมเดลนี้มีแนวโน้มให้ค่าทำนายที่ต่ำกว่าความเป็นจริง (underestimate)\n\n**คำถาม เราได้เรียน** linear regression มาพอสมควรแล้ว โดยหากจำได้จะทราบว่า linear regression เป็นโมเดลทางสถิติที่มีข้อตกลงเบื้องต้นที่ค่อนข้างเข้มงวด ได้แก่ independence, homoscedasticity, normality, no multicollinearity, no outlier, ... คำถามคือในการพัฒนา ML model ดังกล่าวจำเป็นมั้ยที่จะต้องตรวจสอบข้อตกลงเบื้องต้นดังกล่าว เพราะอะไร?\n\n\\newpage\n\n### Fitting Classification models (logistic regression) using parsnip\n\nหัวข้อนี้จะใช้ tidymodels framework เพื่อ fit logistic regression model สำหรับทำนายชุดข้อมูล ชุดข้อมูลที่ใช้ชื่อ `classification.csv` [สามารถดาวน์โหลดได้ที่นี่](https://github.com/ssiwacho/2758688_ML/blob/79a225047656cb9a22a4e1b78835b8bdd91a1d26/week%201/classification.csv) ชุดข้อมูลนี้มีตัวแปรตามที่สนใจคือ `Class` ซึ่งเป็นสถานะการ dropout ออกจากระบบ LMS ของนักเรียน ส่วนที่เหลือเป็นตัวแปรที่คาดว่าจะนำมาเป็นตัวแปรอิสระ\n\n#### (1) การนำเข้าและสำรวจข้อมูล\n\nในกรณีนี้นำเข้าข้อมูล `classfication.csv` ด้วยฟังก์ชัน `read.csv()` จากนั้นสำรวจข้อมูลเบื้องต้นด้วยฟังก์ชัน `glimpse()` ได้ผลเป็นดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# import\ndat<-read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/classification.csv\")\n# explore dataset\nglimpse(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 208\nColumns: 62\n$ X     <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1…\n$ V1    <dbl> 0.0200, 0.0453, 0.0262, 0.0100, 0.0762, 0.0286, 0.0317, 0.0519, …\n$ V2    <dbl> 0.0371, 0.0523, 0.0582, 0.0171, 0.0666, 0.0453, 0.0956, 0.0548, …\n$ V3    <dbl> 0.0428, 0.0843, 0.1099, 0.0623, 0.0481, 0.0277, 0.1321, 0.0842, …\n$ V4    <dbl> 0.0207, 0.0689, 0.1083, 0.0205, 0.0394, 0.0174, 0.1408, 0.0319, …\n$ V5    <dbl> 0.0954, 0.1183, 0.0974, 0.0205, 0.0590, 0.0384, 0.1674, 0.1158, …\n$ V6    <dbl> 0.0986, 0.2583, 0.2280, 0.0368, 0.0649, 0.0990, 0.1710, 0.0922, …\n$ V7    <dbl> 0.1539, 0.2156, 0.2431, 0.1098, 0.1209, 0.1201, 0.0731, 0.1027, …\n$ V8    <dbl> 0.1601, 0.3481, 0.3771, 0.1276, 0.2467, 0.1833, 0.1401, 0.0613, …\n$ V9    <dbl> 0.3109, 0.3337, 0.5598, 0.0598, 0.3564, 0.2105, 0.2083, 0.1465, …\n$ V10   <dbl> 0.2111, 0.2872, 0.6194, 0.1264, 0.4459, 0.3039, 0.3513, 0.2838, …\n$ V11   <dbl> 0.1609, 0.4918, 0.6333, 0.0881, 0.4152, 0.2988, 0.1786, 0.2802, …\n$ V12   <dbl> 0.1582, 0.6552, 0.7060, 0.1992, 0.3952, 0.4250, 0.0658, 0.3086, …\n$ V13   <dbl> 0.2238, 0.6919, 0.5544, 0.0184, 0.4256, 0.6343, 0.0513, 0.2657, …\n$ V14   <dbl> 0.0645, 0.7797, 0.5320, 0.2261, 0.4135, 0.8198, 0.3752, 0.3801, …\n$ V15   <dbl> 0.0660, 0.7464, 0.6479, 0.1729, 0.4528, 1.0000, 0.5419, 0.5626, …\n$ V16   <dbl> 0.2273, 0.9444, 0.6931, 0.2131, 0.5326, 0.9988, 0.5440, 0.4376, …\n$ V17   <dbl> 0.3100, 1.0000, 0.6759, 0.0693, 0.7306, 0.9508, 0.5150, 0.2617, …\n$ V18   <dbl> 0.2999, 0.8874, 0.7551, 0.2281, 0.6193, 0.9025, 0.4262, 0.1199, …\n$ V19   <dbl> 0.5078, 0.8024, 0.8929, 0.4060, 0.2032, 0.7234, 0.2024, 0.6676, …\n$ V20   <dbl> 0.4797, 0.7818, 0.8619, 0.3973, 0.4636, 0.5122, 0.4233, 0.9402, …\n$ V21   <dbl> 0.5783, 0.5212, 0.7974, 0.2741, 0.4148, 0.2074, 0.7723, 0.7832, …\n$ V22   <dbl> 0.5071, 0.4052, 0.6737, 0.3690, 0.4292, 0.3985, 0.9735, 0.5352, …\n$ V23   <dbl> 0.4328, 0.3957, 0.4293, 0.5556, 0.5730, 0.5890, 0.9390, 0.6809, …\n$ V24   <dbl> 0.5550, 0.3914, 0.3648, 0.4846, 0.5399, 0.2872, 0.5559, 0.9174, …\n$ V25   <dbl> 0.6711, 0.3250, 0.5331, 0.3140, 0.3161, 0.2043, 0.5268, 0.7613, …\n$ V26   <dbl> 0.6415, 0.3200, 0.2413, 0.5334, 0.2285, 0.5782, 0.6826, 0.8220, …\n$ V27   <dbl> 0.7104, 0.3271, 0.5070, 0.5256, 0.6995, 0.5389, 0.5713, 0.8872, …\n$ V28   <dbl> 0.8080, 0.2767, 0.8533, 0.2520, 1.0000, 0.3750, 0.5429, 0.6091, …\n$ V29   <dbl> 0.6791, 0.4423, 0.6036, 0.2090, 0.7262, 0.3411, 0.2177, 0.2967, …\n$ V30   <dbl> 0.3857, 0.2028, 0.8514, 0.3559, 0.4724, 0.5067, 0.2149, 0.1103, …\n$ V31   <dbl> 0.1307, 0.3788, 0.8512, 0.6260, 0.5103, 0.5580, 0.5811, 0.1318, …\n$ V32   <dbl> 0.2604, 0.2947, 0.5045, 0.7340, 0.5459, 0.4778, 0.6323, 0.0624, …\n$ V33   <dbl> 0.5121, 0.1984, 0.1862, 0.6120, 0.2881, 0.3299, 0.2965, 0.0990, …\n$ V34   <dbl> 0.7547, 0.2341, 0.2709, 0.3497, 0.0981, 0.2198, 0.1873, 0.4006, …\n$ V35   <dbl> 0.8537, 0.1306, 0.4232, 0.3953, 0.1951, 0.1407, 0.2969, 0.3666, …\n$ V36   <dbl> 0.8507, 0.4182, 0.3043, 0.3012, 0.4181, 0.2856, 0.5163, 0.1050, …\n$ V37   <dbl> 0.6692, 0.3835, 0.6116, 0.5408, 0.4604, 0.3807, 0.6153, 0.1915, …\n$ V38   <dbl> 0.6097, 0.1057, 0.6756, 0.8814, 0.3217, 0.4158, 0.4283, 0.3930, …\n$ V39   <dbl> 0.4943, 0.1840, 0.5375, 0.9857, 0.2828, 0.4054, 0.5479, 0.4288, …\n$ V40   <dbl> 0.2744, 0.1970, 0.4719, 0.9167, 0.2430, 0.3296, 0.6133, 0.2546, …\n$ V41   <dbl> 0.0510, 0.1674, 0.4647, 0.6121, 0.1979, 0.2707, 0.5017, 0.1151, …\n$ V42   <dbl> 0.2834, 0.0583, 0.2587, 0.5006, 0.2444, 0.2650, 0.2377, 0.2196, …\n$ V43   <dbl> 0.2825, 0.1401, 0.2129, 0.3210, 0.1847, 0.0723, 0.1957, 0.1879, …\n$ V44   <dbl> 0.4256, 0.1628, 0.2222, 0.3202, 0.0841, 0.1238, 0.1749, 0.1437, …\n$ V45   <dbl> 0.2641, 0.0621, 0.2111, 0.4295, 0.0692, 0.1192, 0.1304, 0.2146, …\n$ V46   <dbl> 0.1386, 0.0203, 0.0176, 0.3654, 0.0528, 0.1089, 0.0597, 0.2360, …\n$ V47   <dbl> 0.1051, 0.0530, 0.1348, 0.2655, 0.0357, 0.0623, 0.1124, 0.1125, …\n$ V48   <dbl> 0.1343, 0.0742, 0.0744, 0.1576, 0.0085, 0.0494, 0.1047, 0.0254, …\n$ V49   <dbl> 0.0383, 0.0409, 0.0130, 0.0681, 0.0230, 0.0264, 0.0507, 0.0285, …\n$ V50   <dbl> 0.0324, 0.0061, 0.0106, 0.0294, 0.0046, 0.0081, 0.0159, 0.0178, …\n$ V51   <dbl> 0.0232, 0.0125, 0.0033, 0.0241, 0.0156, 0.0104, 0.0195, 0.0052, …\n$ V52   <dbl> 0.0027, 0.0084, 0.0232, 0.0121, 0.0031, 0.0045, 0.0201, 0.0081, …\n$ V53   <dbl> 0.0065, 0.0089, 0.0166, 0.0036, 0.0054, 0.0014, 0.0248, 0.0120, …\n$ V54   <dbl> 0.0159, 0.0048, 0.0095, 0.0150, 0.0105, 0.0038, 0.0131, 0.0045, …\n$ V55   <dbl> 0.0072, 0.0094, 0.0180, 0.0085, 0.0110, 0.0013, 0.0070, 0.0121, …\n$ V56   <dbl> 0.0167, 0.0191, 0.0244, 0.0073, 0.0015, 0.0089, 0.0138, 0.0097, …\n$ V57   <dbl> 0.0180, 0.0140, 0.0316, 0.0050, 0.0072, 0.0057, 0.0092, 0.0085, …\n$ V58   <dbl> 0.0084, 0.0049, 0.0164, 0.0044, 0.0048, 0.0027, 0.0143, 0.0047, …\n$ V59   <dbl> 0.0090, 0.0052, 0.0095, 0.0040, 0.0107, 0.0051, 0.0036, 0.0048, …\n$ V60   <dbl> 0.0032, 0.0044, 0.0078, 0.0117, 0.0094, 0.0062, 0.0103, 0.0053, …\n$ Class <chr> \"drop\", \"drop\", \"drop\", \"drop\", \"drop\", \"drop\", \"drop\", \"drop\", …\n```\n:::\n:::\n\n\nจากผลการสำรวจข้างต้น จงตอบคำถามต่อไปนี้ ชุดข้อมูล `classification.csv` ...\n\n-   มีหน่วยข้อมูลจำนวนกี่หน่วย?\n\n-   มีตัวแปรจำนวนกี่ตัวแปร\n\n-   การแจกแจงของตัวแปรตามเป็นอย่างไร?\n\n-   type ของตัวแปรที่จัดเก็บใน `dat` ข้างต้นมีแบบไหนบ้าง เหมาะสมแล้วหรือไม่ที่จะนำไปวิเคราะห์ logistic regression ต่อไป\n\n#### (2) การแบ่งชุดข้อมูล\n\nในทำนองเดียวกับการพัฒนา regression models ผู้วิเคราะห์ต้องแบ่งชุดข้อมูล `dat` ออกเป็นสองส่วนได้แก่ ส่วน training dataset เพื่อพัฒนาโมเดล และ test dataset เพื่อตรวจสอบประสิทธิภาพของโมเดล\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ndat$Class <- factor(dat$Class, levels=c(\"drop\", \"stay\"))\nclass_split <- initial_split(data= dat,\n                             prop=0.8,\n                             strata = Class)\ntrain <- class_split %>% training()\ntest <-  class_split %>% testing()\n```\n:::\n\n\n#### (3) การประมวลผลและสำรวจโมเดล\n\nเมื่อแบ่งชุดข้อมูลแล้วขั้นตอนต่อมาคือการพัฒนาโมเดลทำนาย ในที่นี้จะใช้ logistic regression ก่อน\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic_reg <- logistic_reg(engine =\"glm\",\n                             mode = \"classification\")\n\nfit_logistic <- logistic_reg %>% \n                  fit(Class ~ . , data=train[,-1])\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: glm.fit: algorithm did not converge\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n```\n:::\n:::\n\n\n\\newpage\n\nเราสามารถวิเคราะห์สัมประสิทธิถดถอยของตัวแปรอิสระในโมเดลได้ โดยใช้ data visualization มาช่วย เช่น\n\n\n::: {.cell fit.height='4'}\n\n```{.r .cell-code}\nfit_logistic$fit %>% \n          coef() %>% \n            data.frame(coef= .)%>%\n              ggplot(aes(x=\"\" ,y=coef))+\n                geom_boxplot(alpha = 0.7, fill = \"grey\")+\n                geom_jitter(width=0.1)+\n              theme_minimal()\n```\n\n::: {.cell-output-display}\n![boxplot ของสัมประสิทธิ์การถดถอยใน logistic regression](02MLProcess_files/figure-html/unnamed-chunk-23-1.png){width=288}\n:::\n:::\n\n\nเราจะเห็นว่าโมเดลทำนายที่พัฒนาขึ้นข้างต้น มีตัวแปรอิสระที่น่าจะใช้ทำนายตัวแปรตาม `Class` ได้ เยอะมาก ปัจจัยนี้อาจเป็นสาเหตุหนึ่งที่ทำให้การประมาณค่าพารามิเตอร์ของโมเดลเกิดปัญหาไม่ลู่เข้า การแก้ปัญหาดังกล่าวอาจทำการคัดเลือกตัวแปรอิสระที่ไม่จำเป็นออกไปจากโมเดล ซึ่งจะเห็นว่าเป็นงานที่ค่อนข้างเหนื่อยเพราะมีตัวแปรอิสระเยอะพอสมควรในชุดข้อมูลนี้ อีกวิธีการหนึ่งคือใช้เทคนิค regularization ซึ่งสามารถทำได้โดยเปลี่ยน `engine = \"glmnet\"` เนื้อหาส่วนนี้จะกล่าวถึงอีกครั้งในบทต่อไป\n\n\\newpage\n\n#### (4) การคำนวณค่าทำนายจากโมเดล\n\nในกรณีนี้สมมุติว่าโมเดลทำนาย logistic regression ไม่ได้มีปัญหาอะไรและจะนำไปสู่ขั้นตอนการตรวจสอบคุณภาพในชุดข้อมูลทดสอบ ในทำนองเดียวกับ regression models การตรวจสอบประสิทธิภาพในการทำนายของโมเดล ผู้วิเคราะห์ต้องมี (1) ค่าสังเกตจริงของตัวแปรตามในชุดข้อมูลทดสอบ และ (2) ค่าทำนายที่ได้จากโมเดลทำนายในชุดข้อมูลทดสอบ\n\nการคำนวณค่าทำนายจากโมเดลสามารถทำได้ด้วยฟังก์ชัน `predict()` เช่นเดียวกับ regression models อย่างไรก็ตามใน classfication models สามารถคำนวณค่าทำนายได้ 2 ประเภทหลัก ได้แก่ ค่าความน่าจะเป็น (probability) ของการเกิดเหตุการณ์/ผลลัพธ์ที่สนใจในตัวแปรตามของหน่วยข้อมูล และค่าทำนายประเภท/ผลลัพธ์ในตัวแปรตามของหน่วยข้อมูล โดยในกรณีที่ต้องการค่าทำนายเป็นค่าความน่าจะเป็นให้กำหนดอาร์กิวเมนท์ `type = \"prob\"` ส่วนในกรณีที่ต้องการค่าทำนายเป็นประเภทในตัวแปรตามให้กำหนดอาร์กิวเมนท์ `type = \"class\"`\n\n##### กรณีกำหนด `type = \"prob\"`\n\nการกำหนดลักษณะนี้จะได้ค่าความน่าจะเป็นซึ่งสามารถนำไปคำนวณเป็นค่าทำนายประเภทของหน่วยข้อมูลได้โดยการกำหนดคะแนนจุดตัดหรือค่า threshold ซึ่งโดยปกติมักกำหนดให้ค่า threshold = 0.5 ตัวอย่างคำสั่งต่อไปนี้แสดงการคำนวณค่าความน่าจะเป็นดังกล่าว รวมทั้งการแปลงค่าความน่าจะเป็นที่ได้โดยการกำหนด threshold เป็น 0.2, 0.5 และ 0.8 ตามลำดับ ทั้งนี้หากโมเดลที่มีประสิทธิภาพไม่คงที่เมื่อเปลี่ยนค่า threshold จะบ่งชี้ว่าโมเดลดังกล่าวมีประสิทธิภาพการทำนายที่ไม่ดีนัก กล่าวคือ เป็นโมเดลที่ไม่ชัดเจนในการทำนาย ในทางกลับกันโมเดลที่มีค่าทำนายประเภทของหน่วยข้อมูลที่คงเส้นคงวา เมื่อกำหนดค่า threshold แตกต่างกัน บ่งชี้ว่าโมเดลดังกล่าวเป็นโมเดลที่มีประสิทธิภาพในการทำนายสูง\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# predicted value\npred_prob <- predict(fit_logistic, \n                     new_data = test[,-1],\n                     type=\"prob\")\npred_class_thres0.2 <- factor(ifelse(pred_prob[,1] >=0.2,\"drop\", \"stay\"))\npred_class_thres0.5 <- factor(ifelse(pred_prob[,1] >=0.5,\"drop\", \"stay\"))\npred_class_thres0.8 <- factor(ifelse(pred_prob[,1] >=0.8,\"drop\", \"stay\"))\n\ntable(pred_class_thres0.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npred_class_thres0.2\ndrop stay \n  18   25 \n```\n:::\n\n```{.r .cell-code}\ntable(pred_class_thres0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npred_class_thres0.5\ndrop stay \n  18   25 \n```\n:::\n\n```{.r .cell-code}\ntable(pred_class_thres0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npred_class_thres0.8\ndrop stay \n  18   25 \n```\n:::\n:::\n\n\nผลการวิเคราะห์ข้างต้นแสดงให้เห็นว่าค่าทำนายประเภทของหน่วยข้อมูลไม่มีการเปลี่ยนแปลงเมื่อกำหนด threshold เท่ากับ 0.2, 0.5 และ 0.8 ซึ่งบ่งชี้ว่าโมเดลทำนายมีแนวโน้มที่จะให้ค่าทำนายที่คงเส้นคงวา อย่างไรก็ตามการวิเคราะห์เพียง 3 จุดของ threshold เป็นการวิเคราะห์ที่ค่อนข้างหยาบ ส่วนท้ายของหัวข้อนี้จะกล่าวถึงการใช้ ROC curve เพื่อวิเคราะห์ประสิทธิภาพของโมเดลบนแต่ละค่าของ threshold ดังกล่าว\n\n##### กรณีกำหนด `type = \"class\"`\n\nเมื่อกำหนดให้ `type = \"class\"` ฟังก์ชัน `predict()` จะทำนายประเภทของหน่วยข้อมูลโดยใช้ค่า threshold = 0.5 ดังนั้นหากผู้วิเคราะห์ต้องการใช้ threshold ค่านี้อยู่แล้ว การกำหนดอาร์กิวเมนท์ลักษณะนี้จะช่วยลดขั้นตอนการทำงานลงได้\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_class2 <- predict(fit_logistic, \n                     new_data = test[,-1],\n                     type=\"class\")\nhead(pred_class2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 1\n  .pred_class\n  <fct>      \n1 stay       \n2 drop       \n3 stay       \n4 drop       \n5 drop       \n6 stay       \n```\n:::\n:::\n\n\nจะเห็นว่าผลการทำนายประเภทที่ได้จากฟังก์ชัน `predict()` อยู่ในรูปชุดข้อมูลแบบ tibble โดยคอลัมน์ที่เก็บค่าทำนายจะใช้ชื่อ `.pred_class` และมีสถานะเป็นตัวแปรแบบ factor\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(pred_class2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.pred_class\ndrop stay \n  18   25 \n```\n:::\n:::\n\n\n#### (5) การประเมินประสิทธิภาพการทำนายของโมเดล\n\npackage yardstick มีฟังก์ชัน `conf_mat()` ที่ทำหน้าที่เหมือนกับฟังก์ชัน `confusionMatrix()` โดยอาร์กิวเมนท์สำคัญของฟังก์ชันนี้ได้แก่ `data` ที่เป็น data.frame หรือ tibble ที่ต้องมีคอลัมน์ของค่าจริงของตัวแปรตาม และค่าทำนายของตัวแปรตามให้เรียบร้อย `truth` คืออาร์กิวเมนท์สำหรับระบุว่าคอลัมน์ไหนคือค่าจริงของตัวแปรตาม และ `estimate` คือคอลัมน์ที่ใช้ระบุว่าคอลัมน์ไหนคือค่าทำนายของตัวแปรตาม ทั้งนี้ตัวแปรตามและค่าทำนายจะต้องเก็บอยู่ในรูปแบบ factor\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# combine .pred_class column to test dataset\ntest_results <- test %>% dplyr::select(Class) %>%\n          bind_cols(pred_class2, pred_prob)\nconf_mat(data = test_results, truth = Class, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Truth\nPrediction drop stay\n      drop   15    3\n      stay    5   20\n```\n:::\n\n```{.r .cell-code}\n# accuracy\naccuracy(data = test_results, truth = Class, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.814\n```\n:::\n\n```{.r .cell-code}\n# sensitivity\nsens(data = test_results, truth = Class, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 sens    binary          0.75\n```\n:::\n\n```{.r .cell-code}\n# specificity\nspec(data = test_results, truth = Class, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 spec    binary         0.870\n```\n:::\n\n```{.r .cell-code}\n# define metric set function\ncustom_metric<-metric_set(accuracy, sens, spec)\ncustom_metric(data = test_results, truth = Class, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.814\n2 sens     binary         0.75 \n3 spec     binary         0.870\n```\n:::\n:::\n\n\nนอกจากนี้ยังสามารถใช้ฟังก์ชัน `summary()` กับผลลัพธ์ที่ได้จาก `conf_mat()` เพื่อเรียกดูค่าสถิติของ confusion matrix คล้ายกับฟังก์ชัน `confusionMatrix()` ของ package caret ที่ได้กล่าวถึงในหัวข้อ 2.4\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(data = test_results, \n         truth = Class, \n         estimate = .pred_class) %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   <chr>                <chr>          <dbl>\n 1 accuracy             binary         0.814\n 2 kap                  binary         0.624\n 3 sens                 binary         0.75 \n 4 spec                 binary         0.870\n 5 ppv                  binary         0.833\n 6 npv                  binary         0.8  \n 7 mcc                  binary         0.626\n 8 j_index              binary         0.620\n 9 bal_accuracy         binary         0.810\n10 detection_prevalence binary         0.419\n11 precision            binary         0.833\n12 recall               binary         0.75 \n13 f_meas               binary         0.789\n```\n:::\n:::\n\n\n\\newpage\n\nรายละเอียดของ metric ต่าง ๆ สามารถศึกษาเพิ่มเติมได้จากเอกสารที่เกี่ยวกับ package yardstick\n\n-   https://cran.r-project.org/web/packages/yardstick/yardstick.pdf\n\n-   https://yardstick.tidymodels.org/\n\n-   https://cran.r-project.org/web/packages/yardstick/vignettes/metric-types.html\n\n#### (6) การนำเสนอประสิทธิภาพการทำนายของโมเดลด้วยทัศนภาพข้อมูล\n\nการวิเคราะห์ประสิทธิภาพการทำนายของ classification models สามารถทำได้ด้วยทัศนภาพข้อมูลหลายตัว ซึ่งบางตัวช่วยให้สารสนเทศเชิงลึกประกอบการปรับแต่งโมเดลทำนายแก่ผู้วิเคราะห์ได้เป็นอย่างดี เนื้อหาประกอบด้วย การใช้ heatmap แผนภาพ mosaic และ ROC Curve รายละเอียดมีดังนี้\n\n##### แผนที่ความร้อน (heatmap) ของ confusion matrix\n\nทัศนภาพนี้เหมาะสำหรับ classification model ที่มีการจำแนกประเภทจำนวนหลาย ๆ ประเภท การสร้างแผนที่ความร้อนดังกล่าวสามารถสร้างได้โดยการส่งค่า confusion matrix ที่สร้างจากฟังก์ชัน `conf_mat()` ไปยังฟังก์ชัน `autoplot()` และในฟังก์ชัน `autoplot()` ให้กำหนดอาร์กิวเมนท์ `type = \"heatmap\"` ดังตัวอย่างต่อไปนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(data = test_results, \n         truth = Class, \n         estimate = .pred_class) %>%\n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![plotting the confusion matrix using Heatmap](02MLProcess_files/figure-html/unnamed-chunk-29-1.png){width=288}\n:::\n:::\n\n\nจากรูป 27 จะเห็นว่าแผนที่ความร้อนที่สร้างขึ้นจะใช้ความเข้มของสีแสดงความถี่ในแต่ละประเภทของการทำนาย โดยในรูปตัวอย่างพบว่าโมเดลทำนายมีแนวโน้มที่จะทำนายได้อย่างถูกต้องเป็นส่วนใหญ่\n\n\\newpage\n\n##### แผนภาพโมเสก (mosaic plot)\n\nทัศนภาพนี้จะแสดงผลลัพธ์ในมิติของ sensitivity หรือ specificity การสร้างแผนภาพโมเสกจาก confusion matrix สามารถใช้ฟังก์ชัน `autoplot()` เช่นเดียวกับการสร้างแผนที่ความร้อน แต่ให้กำหนดอาร์กิวเมนท์ `type = mosaic` ดังตัวอย่างต่อไปนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(data = test_results, \n         truth = Class, \n         estimate = .pred_class) %>%\n  autoplot(type = \"mosaic\")\n```\n\n::: {.cell-output-display}\n![plotting the confusion matrix using Masaic plot](02MLProcess_files/figure-html/unnamed-chunk-30-1.png){width=288}\n:::\n:::\n\n\nจากรูป 28 เมื่อพิจารณาในคอลัมน์แรกจะพบว่าเป็นคอลัมน์ที่แสดง sensitivity ของโมเดล (เนื่องจากโมเดลทำนายมุ่งที่จะทำนายกลุ่ม dropout ดังนั้นกลุ่มนี้จึงเป็นพวก positive ของโมเดล) ส่วนคอลัมน์ที่สองแสดง specificity ของโมเดล ซึ่งมีค่าอยู่ในระดับสูงทั้งสอง metrics\n\n##### ROC curve\n\nดังที่ได้กล่าวไว้ก่อนแล้วข้างต้นว่าคุณสมบัติที่ดีของโมเดลทำนายอย่างหนึ่งคือการที่สามารถให้ค่าทำนายประเภทของหน่วยข้อมูลที่คงเส้นคงวาบนแต่ละระดับของค่า threshold การตรวจสอบประสิทธิภาพด้านนี้อย่างละเอียดควรดำเนินการวิเคราะห์ประสิทธิภาพในการทำนายของโมเดลเมื่อกำหนดค่า threshold ตั้งแต่ 0.00 ถึง 1.00 การดำเนินการดังกล่าวด้วย R ในสมัยก่อนผู้วิเคราะห์จำเป็นจะต้องเขียนฟังก์ชันเพื่อทวนซ้ำการทำนายในแต่ละค่า threshold แต่ในปัจจุบันหากใช้ package yardstick ผู้วิเคราะห์สามารถใช้ฟังก์ชัน `roc_curve()` เพื่อช่วยทำการวิเคราะห์นี้ได้ อาร์กิวเมนท์ของฟังก์ชันนี้ประกอบด้วย ค่าจริงของตัวแปรตามในชุดข้อมูลทดสอบ และค่าประมาณความน่าจะเป็นของการเกิดผลลัพธ์ที่สนใจ (positive type) ในตัวแปรตาม\n\n\\newpage\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_results %>% \n  roc_curve(truth = Class, .pred_drop)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\nℹ The deprecated feature was likely used in the yardstick package.\n  Please report the issue at <\u001b]8;;https://github.com/tidymodels/yardstick/issues\u0007https://github.com/tidymodels/yardstick/issues\u001b]8;;\u0007>.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 3\n    .threshold specificity sensitivity\n         <dbl>       <dbl>       <dbl>\n 1 -Inf              0            1   \n 2    2.22e-16       0            1   \n 3    8.95e- 9       0.783        0.75\n 4    6.23e- 6       0.826        0.75\n 5    9.00e- 1       0.870        0.75\n 6    9.81e- 1       0.913        0.75\n 7    1.00e+ 0       0.913        0.7 \n 8    1.00e+ 0       0.913        0.65\n 9    1   e+ 0       0.913        0.6 \n10  Inf              1            0   \n```\n:::\n:::\n\n\nข้อดีของฟังก์ชัน `roc_curve()` คือฟังก์ชันจะกำหนด grid หรือช่วงของค่า threshold ที่เหมาะสมกับข้อมูลซึ่งช่วย output ที่ไม่จำเป็นลงได้ จากตารางข้างต้นจะเห็นว่าถ้าไม่นับกรณีที่กำหนด threshold อย่างสุดโต่งคือ 0 หรือ 1 ประสิทธิภาพของโมเดลทำนายที่พัฒนาขึ้นนี้มีค่า sensitivity และ specificity มากกว่า 0.75 เกือบทุกกรณี\n\nอย่างไรก็ตามในกรณีทั่วไปผลลัพธ์จากตารางข้างต้นอาจมีจำนวนมากจนเป็นการยากที่จะดำเนินการวิเคราะห์ ผู้วิเคราะห์จึงมักนิยมแปลงผลการวิเคราะห์ในตารางดังกล่าวให้เป็นแผนภาพ ROC curve ที่เป็นการพล็อตคู่อันดับของ FPR = 1 - specificity กับ sensitivity ที่คำนวณได้จากแต่ละค่าของ threshold โดยให้ค่า sensitivity อยู่บนแกน Y และค่า FPR อยู่บนแกน X รูปต่อไปนี้แสดงตัวอย่างของ ROC curve\n\n![ตัวอย่าง ROC Curve](images/image-1255912826.png){alt=\"ตัวอย่าง ROC Curve\"}\n\n\\newpage\n\nโมเดลทำนายที่ดีควรมี ROC curve ที่ลู่เข้าไปใกล้คู่อันดับ (0.00,1.00) เนื่องจากคู่อันดับดังกล่าวเป็นจุดที่โมเดลมี FPR = 0.00 และมี sensitivity = 1.00 หรือเป็นจุดที่ดีที่สุดที่เป็นไปได้ (optimal point) ส่วนโมเดลที่มีประสิทธิภาพต่ำจะเป็นโมเดลที่มี Roc curve ลู่เข้าหาหรือมีลักษณะใกล้เคียงกับเส้นอ้างอิง $y=x$ ซึ่งแสดงว่าโมเดลทำนายมีประสิทธิภาพในการทำนายที่ใกล้เคียงกับการเดาสุ่มแบบโยนเหรียญหัวก้อย\n\nจากรูป 30 จะเห็นว่าโมเดลตัวอย่างทางด้านซ้ายมีแนวโน้มที่จะมีประสิทธิภาพในการทำนายสูงกว่าโมเดลตัวอย่างทางด้านขวา ทั้งนี้เป็นเพราะ ROC curve ของโมเดลทางซ้ายมีแนวโน้มลู่เข้าไปหาคู่อันดับ (0.00,1.00) มากกว่าโมเดลทางขวามือ สำหรับการสร้าง ROC curve ด้วย R สามารถทำได้โดยส่งผ่านผลลัพธ์ที่ได้จากฟังก์ชัน `roc_curve()` ในข้างต้นไปในฟังก์ชัน `autoplot()` ดังตัวอย่างต่อไปนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_results %>%\n  roc_curve(truth = Class, .pred_drop) %>%\n  autoplot()\n```\n\n::: {.cell-output-display}\n![ROC Curve](02MLProcess_files/figure-html/unnamed-chunk-32-1.png){width=384}\n:::\n:::\n\n\nผลการวิเคราะห์ ROC curve จากรูป 31 สามารถสรุปได้อย่างไร?\n\n##### Area Under Curve (AUC)\n\nพื้นที่ใต้โค้ง ROC (area under curve: AUC) ถูกใช้เป็น metric อีกตัวหนึ่งสำหรับประเมินประสิทธิภาพในการทำนายของโมเดล ที่คำนวณจากพื้นที่ใต้โค้งของกราฟ ROC โดยโมเดลทำนายที่มีค่า AUC สูงเข้าใกล้ 1.00 จะเป็นโมเดลที่มีแนวโน้มจะมีประสิทธิภาพในการทำนายสูง ส่วนโมเดลที่มีค่า AUC เข้าใกล้ 0.5 มีแนวโน้มที่จะมีประสิทธิภาพในการทำนายต่ำใกล้เคียงกับการเดาสุ่ม จากความหมายดังกล่าวจะเห็นว่าค่า AUC สามารถใช้เป็น metric แทนการอ่านผลจากกราฟ ROC โดยตรงได้\n\n![Area Under Curve (AUC)](images/image-1194220562.png){alt=\"Area Under Curve (AUC)\"}\n\n\\newpage\n\nการคำนวณค่า AUC ด้วย R สามารถทำได้โดยใช้ฟังก์ชัน `roc_auc()` ที่มีอาร์กิวเมนท์เหมือนกับฟังก์ชัน `roc_curve()` จากตัวอย่าง logistic regression จะได้ว่าผลการวิเคราะห์ AUC เป็นดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_results %>% roc_auc(truth = Class, .pred_drop)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.809\n```\n:::\n:::\n\n\nตารางต่อไปนี้แสดงเกณฑ์การพิจารณาค่า AUC ข้างต้น โดยจำแนกเกรดของโมเดลออกเป็น 5 ระดับตามค่าของ AUC ได้แก่ ดีมาก (A) ดี (B) ไปจนถึงยอมรับไม่ได้ (F)\n\n| AUC           | แปลผล         |\n|---------------|---------------|\n| \\[0.9 , 1.0\\] | ดีมาก (A)      |\n| \\[0.8 , 0.9)  | ดี (B)         |\n| \\[0.7 , 0.8)  | พอใช้ (C)      |\n| \\[0.6 , 0.7)  | แย่ (D)        |\n| \\[0.5 , 0.6)  | ยอมรับไม่ได้ (F) |\n\n: AUC criterion\n\n## 3.6 Scikit-Learn library\n\nscikit-learn เป็น library สำหรับวิเคราะห์ machine learning model ในโปรแกรมภาษา Python ซึ่งมีจุดเด่นคือเป็น library สำหรับพัฒนา machine learning model ที่มีประสิทธิภาพและสามารถใช้งานได้ง่าย นอกจากนี้ยังสามารถทำงานร่วมกับ library Numpy, SciPy, Pandas และ matplotlib\n\ncoming soon ...\n\n## สรุป\n\nบทเรียนนี้ผู้อ่านได้เห็นภาพของกระบวนการพัฒนา regression models ซึ่งเป็น supervised learning ประเภทหนึ่งโดยเป็นการดำเนินงานภายใต้ tidymodels framework เกือบทั้งหมด โดยยังขาดในส่วนของการจัดการข้อมูลหรือที่เรียกว่า feature engineering และส่วนการปรับแต่งค่า hyperparameters ของโมเดลทำนาย ซึ่งจะกล่าวรายละเอียดทั้งหมดในบทเรียนถัดไป\n\n# บทที่ 4 การเตรียมข้อมูล (data preprocessing)\n\n> Garbage in, garbage out ...\n\nจากบทที่ 3 ผู้อ่านจะเห็นว่าข้อมูลเป็นปัจจัยนำเข้าที่สำคัญมากในการพัฒนาโมเดลการเรียนรู้ของเครื่อง การนำข้อมูลที่เป็นขยะเข้าสู่โมเดลผลลัพธ์ที่ได้ย่อมเป็นขยะ ข้อมูลที่เป็นขยะถึงแม้จะได้รับการจัดการที่ดีมากแค่ไหนก็ตาม เมื่อนำเข้าสู่โมเดล ผลลัพธ์ที่ได้ก็ยังเป็นขยะเหมือนเดิม นอกจากนี้ถึงแม้ผู้วิเคราะห์จะมีข้อมูลที่ดีแต่หากมีการจัดการที่ไม่ดี เมื่อนำเข้าสู่โมเดลก็อาจจะได้ผลลัพธ์ที่ไม่ดีเท่าที่ควรหรืออาจจะเป็นขยะเหมือนเดิมก็ได้ ดังนั้นการมีข้อมูลที่ดีและมีการจัดการอย่างเหมาะสมจึงเป็นสิ่งที่สำคัญที่ผู้พัฒนาโมเดลการเรียนรู้ของเครื่องควรให้ความสำคัญ\n\n## 4.1 ภาพรวมและความสำคัญของ Data Preprocessing\n\n**การเตรียมข้อมูล (Data preprocessing)** เป็นคำศัพท์เชิงเทคนิคที่ใช้เรียกกระบวนการต่าง ๆ ที่ผู้วิเคราะห์ดำเนินการกับข้อมูลก่อนที่จะนำข้อมูลไปวิเคราะห์ในอัลกอริทึมการเรียนรู้ โดยมีวัตถุประสงค์เพื่อให้การเรียนรู้ของอัลกอริทึมต่าง ๆ สามารถทำได้สำเร็จและมีประสิทธิภาพ การเตรียมข้อมูลมีหลายวิธีการ โดยแต่ละวิธีการเหมาะกับสถานการณ์และเงื่อนไขที่แตกต่างกัน อย่างไรก็ตามเราอาจจำแนกการเตรียมข้อมูลออกได้เป็น 2 ประเภท ได้แก่ การเตรียมข้อมูลงตามข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้ และการเตรียมเพื่อใช้ประโยชน์จากข้อมูลให้มีประสิทธิภาพสูงที่สุด\n\n**(1) การเตรียมข้อมูลตามข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้** เป็นการจัดระเบียบหรือจัดกระทำข้อมูล (tidying and manipulating data) เพื่อให้ข้อมูลดิบมีความพร้อมหรืออยู่ในรูปแบบที่สอดคล้องกับความต้องการของอัลกอริทึมการเรียนรู้ที่เลือกใช้ การละเลยการจัดการข้อมูลดังกล่าวอาจส่งผลให้การเรียนรู้ของอัลกอริทึมมีความผิดพลาด หรือไม่สามารถเรียนรู้ชุดข้อมูลดังกล่าวได้ ตัวอย่างต่อไปนี้แสดงการเตรียมข้อมูลเพื่อให้สอดคล้องกับข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้\n\n-   การจัดรูปแบบตารางข้อมูล (reshaping data) เพื่อให้ได้ตารางข้อมูลที่อยู่ในรูปแบ tidydata\n\n-   การเปลี่ยนสถานะของตัวแปรตัวอักษร (character variable) ใน R ให้เป็นตัวแปรแบบ factor\n\n-   การทดแทนค่าสูญหาย (missing value imputation) เพื่อทดแทนค่าสูญหายก่อนจะนำไปวิเคราะห์\n\n-   ในโมเดล multiple linear regression มีข้อตกลงเบื้องต้นที่สำคัญหลายข้อ เช่น ต้องไม่มีปัญหา heteroscedasticity และ multicollinearity ซึ่งหากเกิดปัญหาดังกล่าวขึ้นอย่างน้อยหนึ่งอย่าง ผู้วิเคราะห์จำเป็นต้องดำเนินการแก้ไขปัญหาดังกล่าวให้เรียบร้อยก่อนที่จะทำการวิเคราะห์ข้อมูล เช่น (1) อาจใช้การแปลงค่าตัวแปรด้วย logarithm หรือใช้การแปลงแบบ Box-Cox transformation เพื่อแก้ปัญหา heteroscedasticity และ (2) อาจใช้การตัดตัวแปรอิสระที่มีความสัมพันธ์กันเองสูง ๆ ออกจากโมเดล หรือใช้การสกัดองค์ประกอบหลัก (PCA) เพื่อแก้ปัญหา multicollinearity เป็นต้น\n\n-   สำหรับอัลกอริทึม K-NN และ regularized regression ผู้วิเคราะห์จำเป็นต้องแปลงคะแนนของตัวแปรอิสระทั้งหมดให้เป็นหน่วยคะแนนมาตรฐานก่อน เพื่อให้อัลกอริทึมดังกล่าวสามารถเรียนรู้รูปแบบความสัมพันธ์ระหว่างตัวแปรในชุดข้อมูลได้โดยไม่มีปัจจัยเกี่ยวกับหน่วยข้อมูลมาเป็นตัวแทรกซ้อนและก่อให้เกิดความผิดพลาดในการเรียนรู้\n\n\\newpage\n\nผู้อ่านจะเห็นว่าการทำ data preprocessing ประเภทนี้จำเป็นต้องทำตามข้อตกลงเบื้องต้นของโมเดล ทั้งนี้เพื่อให้โมเดลหรืออัลกอริทึมการเรียนรู้สามารถทำงานได้อย่างถูกต้อง หากผู้วิเคราะห์ละเลยการดำเนินการในส่วนนี้อาจส่งผลให้ผลการเรียนรู้ของอัลกอริทึมมีความผิดพลาด และประสบความล้มเหลวในการพัฒนาโมเดลทำนายที่ต้องการ โดยทั่วไปการจัดกระทำข้อมูลอาจจำแนกเป็น การแปลงค่าของตัวแปรจัดประเภทให้เป็นตัวแปรดัมมี (dummy) การตัดตัวแปรที่มีความแปรปรวนน้อยหรือความแปรปรวนเท่ากับ 0 ออกจากชุดข้อมูล (zv) การทดแทนค่าสูญหาย (impute) การแก้ปัญหา multicollinearity (decorrelate) การแปลงคะแนนตัวแปรให้อยู่ในสเกลมาตรฐาน (normalized) และการแปลงค่าของตัวแปรให้มีการแจกแจงที่สมมาตรหรือใกล้เคียง (transform)\n\nตารางต่อไปนี้แสดงตัวอย่าง checklist ของการจัดกระทำข้อมูลที่ควรดำเนินการในแต่ละอัลกอริทึมการเรียนรู้\n\n| อัลกอริทึม              | dummy | zv    | impute | decorrelate | normalized | transform |\n|----------------------|-------|-------|--------|-------------|------------|-----------|\n| linear regression    | yes   | yes   | yes    | yes         | no         | maybe     |\n| binary logistic      | yes   | yes   | yes    | yes         | no         | maybe     |\n| multinomial logistic | yes   | yes   | yes    | yes         | no         | maybe     |\n| K-NN                 | yes   | yes   | yes    | maybe       | yes        | yes       |\n| naive bayes          | no    | yes   | yes    | maybe       | no         | no        |\n| decision tree (CART) | no    | no    | no     | maybe       | no         | no        |\n| decision tree (C5)   | no    | no    | no     | no          | no         | no        |\n| pls regression       | yes   | yes   | yes    | no          | yes        | yes       |\n| MARS                 | yes   | no    | yes    | maybe       | no         | maybe     |\n| SVM                  | yes   | yes   | yes    | yes         | yes        | yes       |\n| random forest        | no    | maybe | yes    | maybe       | no         | no        |\n| bagging tree         | no    | no    | no     | maybe       | no         | no        |\n| bagging MARS         | yes   | no    | yes    | maybe       | no         | maybe     |\n| boosting tree        | no    | maybe | yes    | maybe       | no         | no        |\n\n: Checklist การจัดกระทำข้อมูลของอัลกอริทึมการเรียนรู้ต่าง ๆ\n\n**(2) การเตรียมเพื่อใช้ประโยชน์จากข้อมูลให้มีประสิทธิภาพสูงที่สุด** อาจกล่าวว่าเป็นขั้นตอนที่ทำภายหลังจากการเตรียมข้อมูลให้เป็นไปตามข้อตกลงเบื้องต้นของอัลกอริทึมแล้ว การเตรียมข้อมูลส่วนนี้ไม่ได้เป็นเงื่อนไขจำเป็นของการพัฒนาโมเดลทำนาย แต่อาจเป็นเงื่อนไขที่เพียงพอจะทำให้การพัฒนาโมเดลทำนายประสบความสำเร็จ กล่าวคือได้โมเดลทำนายที่มีประสิทธิภาพในการทำนายสูง การดำเนินการส่วนโดยปกติเป็นการจัดกระทำข้อมูลของตัวแปรอิสระ (independent variables) หรือที่นักวิทยาการข้อมูลมักใช้คำว่า features ให้มีความเหมาะสมกับบบริบทของปัญหาซึ่งจะช่วยให้การเรียนรู้ของโมเดลทำได้อย่างมีประสิทธิภาพมากขึ้น อาจเรียกการเตรียมข้อมูลประเภทนี้ว่า feature engineering\n\nการทำ feature engineering มีลักษณะเด่นที่สำคัญคือเป็นการดำเนินการที่ไม่ได้ขึ้นกับอัลกอริทึมการเรียนรู้แต่ขึ้นกับบริบทของปัญหาหรือข้อมูลที่ผู้วิเคราะห์มี ดังนั้นการที่ผู้วิเคราะห์จะตัดสินใจเลือกว่าจะใช้การจัดการข้อมูลแบบใดกับตัวแปรอิสระภายในชุดข้อมูลอาจต้องพิจารณาในหลายมิติร่วมกัน เช่น สภาพของข้อมูล ตัวเลือกทั้งหมดที่เป็นไปได้ในการจัดกระทำข้อมูลของตัวแปร ลักษณะ/รูปแบบของความสัมพันธ์ในธรรมชาติระหว่างตัวแปรตามกับตัวแปรอิสระ ในหลาย ๆ ครั้งอาจจะต้องใช้หลักเหตุผลรวมทั้งศึกษาค้นคว้าเอกสารงานวิจัยหรือทฤษฎีที่เกี่ยวข้องกับตัวแปรที่กำลังดำเนินงานอยู่ นอกจากนี้การสัมภาษณ์หรือเก็บรวบรวมข้อมูลจากผู้เกี่ยวข้อง เจ้าของข้อมูล หรือผู้มีส่วนได้ส่วนเสีย (stakeholder) อาจให้สารสนเทศที่เป็นประโยชน์ต่อการดำเนินงานในส่วนนี้ จะเห็นว่าการเตรียมข้อมูลลักษณะนี้ต้องใช้ทักษะมากกว่าการเตรียมข้อมูลประเภทแรกค่อนข้างมาก และมีลักษณะที่เป็น data-driven ซึ่งการดำเนินงานจะมีลักษณะทวนซ้ำเพื่อสังเกตผลลัพธ์และปรับแต่งการจัดกระทำตัวแปรเพื่อให้ประสิทธิภาพในการทำนายมีค่าสูงที่สุดเท่าที่จะเป็นไปได้ ทั้งนี้เพื่อให้เข้าใจลักษณะและประสิทธิภาพของการทำ feature engineering มากขึ้น ขอให้ผู้อ่านลองพิจารณาตัวอย่างต่อไปนี้\n\n\n::: {.cell}\n\n:::\n\n\nชุดข้อมูล `logistic.csv` ดาวน์โหลดได้จาก <https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week2/logistic.csv> ประกอบด้วยข้อมูลของตัวแปรตาม `y` คือสถานะการเลื่อนตำแหน่งของพนักงาน (promated และ not promoted) ส่วนตัวแปรอิสระมี 2 ตัวได้แก่ อายุของพนักงาน (`age`) และประสิทธิภาพในการทำงาน (`performance`) วัตถุประสงค์ของผู้วิเคราะห์คือพัฒนาโมเดลทำนายการได้เลื่อนตำแหน่งของพนักงานด้วยตัวแปรอิสระทั้งสองตัวดังกล่าว\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat<-read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week2/logistic.csv\")\nglimpse(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 2,000\nColumns: 4\n$ X           <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ age         <dbl> 35.73, 42.92, 57.10, 46.28, 59.89, 47.25, 58.40, 52.44, 55…\n$ performance <dbl> 8.57928964, 7.99899950, 7.10855428, 3.04652326, 6.25812906…\n$ y           <chr> \"not promoted\", \"not promoted\", \"promoted\", \"promoted\", \"p…\n```\n:::\n:::\n\n\nผลการสำรวจข้อมูลเบื้องต้นพบว่าชุดข้อมูล `dat` ที่นำเข้ามามีตัวแปรที่ไม่เกี่ยวข้องคือ `X` ซึ่งควรเอาออกจากชุดข้อมูล และตัวแปรตาม `y` อยู่ในรูปแบบของตัวแปรตัวอักษรซึ่งควรเปลี่ยนให้เป็นตัวแปรแบบ factor ก่อน การดำเนินการแก้ไขปัญหาดังกล่าวเป็นการจัดกระทำข้อมูลให้สอดคล้องกับการวิเคราะห์ด้วยอัลกอริทึม logistic regression ในโปรแกรม R จัดอยู่ในกลุ่มการเตรียมข้อมูลประเภทแรกดังที่ได้กล่าวไปแล้ว คำสั่งต่อไปนี้เป็นการเตรียมข้อมูลดังกล่าว\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- dat %>% dplyr::select(-X) %>%\n        mutate(y = factor(y, levels=c(\"promoted\",\"not promoted\")))\n```\n:::\n\n\nเมื่อจัดการกับข้อมูลดังกล่าวแล้ว ผู้วิเคราะห์ทำการแบ่งชุดข้อมูลออกเป็นสองชุด ได้แก่ ชุดข้อมูลฝึกหัด และชุดข้อมูลทดสอบ จากนั้นดำเนินการสำรวจความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระด้วยทัศนภาพข้อมูล\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_split <- initial_split(dat, prop = 0.7, strata = y)\ndat_split\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Training/Testing/Total>\n<1399/601/2000>\n```\n:::\n\n```{.r .cell-code}\ntrain <- dat_split %>% training()\ntest <- dat_split %>% testing()\n# data exploring\ntrain %>% ggplot(aes(x=age, y=performance))+\n            geom_point(aes(col=y))+\n            theme_minimal()\n```\n\n::: {.cell-output-display}\n![ผลการสำรวจข้อมูลเบื้องต้น](02MLProcess_files/figure-html/unnamed-chunk-37-1.png){width=576}\n:::\n:::\n\n\nผลการสำรวจความสัมพันธ์ระหว่างตัวแปรด้วยทัศนภาพข้อมูลข้างต้น จะเห็นว่าสามารถจำแนกพนักงานด้วยสายตาออกได้เป็น 3 กลุ่มอย่างค่อนข้างชัดเจน กลุ่มแรกคือกลุ่มที่มีประสิทธิภาพในการทำงานต่ำกว่า 0 คะแนน ซึ่งเกือบทั้งหมดไม่ได้รับการเลื่อนตำแหน่ง กลุ่มที่สองคือกลุ่มพนักงานที่ประสิทธิภาพการทำงานสูงกว่า 0 คะแนน แต่ไม่ได้รับการเลื่อนตำแหน่ง ในจำนวนนี้พบว่าส่วนใหญ่เป็นพนักงานที่มีอายุยังน้อย และกลุ่มที่สามคือกลุ่มพนักงานที่ประสิทธิภาพการทำงานสูงกว่า 0 และได้รับการเลื่อนตำแหน่ง ซึ่งในจำนวนนี้พบว่าส่วนใหญ่เป็นพนักงานที่มีอายุมาก\n\nขั้นตอนถัดมาผู้วิเคราะห์นำชุดข้อมูลฝึกหัดที่สร้างขึ้นไปให้อัลกอริทึมเรียนรู้จากนั้นทำการตรวจสอบประสิทธิภาพการทำนายของโมเดลในชุดข้อมูลทดสอบด้วย package parsnip ดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_logistic1 <- logistic_reg() %>%\n                    set_engine(\"glm\") %>%\n                    set_mode(\"classification\")%>%\n                    fit(y ~ ., data=train)\n# calculate predicted values\npred <- predict(fit_logistic1, \n                new_data = test,\n                type = \"class\")\npred_prob <- predict(fit_logistic1, \n                new_data = test,\n                type = \"prob\")\n\ntest_results <- test %>% dplyr::select(y)%>%\n                bind_cols(pred, pred_prob)\n# evaluate model\nconf_mat(data = test_results,\n         truth = y,\n         estimate = .pred_class)%>%\n        summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   <chr>                <chr>          <dbl>\n 1 accuracy             binary         0.812\n 2 kap                  binary         0.341\n 3 sens                 binary         0.324\n 4 spec                 binary         0.955\n 5 ppv                  binary         0.677\n 6 npv                  binary         0.828\n 7 mcc                  binary         0.375\n 8 j_index              binary         0.278\n 9 bal_accuracy         binary         0.639\n10 detection_prevalence binary         0.108\n11 precision            binary         0.677\n12 recall               binary         0.324\n13 f_meas               binary         0.438\n```\n:::\n\n```{.r .cell-code}\n# roc curve\ntest_results %>% \n  roc_curve(truth = y,\n            estimate = .pred_promoted)%>%\n  autoplot()\n```\n\n::: {.cell-output-display}\n![ROC Curve ของ logistic regression](02MLProcess_files/figure-html/unnamed-chunk-38-1.png){width=336}\n:::\n\n```{.r .cell-code}\ntest_results %>% \n    roc_auc(truth = y,\n            estimate = .pred_promoted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.752\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# decision boundary\nx1 <- seq(18,60,length=100)\nx2 <- seq(-10,10,length=100)\ngrid <- expand.grid(age = x1,performance = x2)\nbg.dat<-data.frame(grid) %>%\n          bind_cols(predict(fit_logistic1, grid, type=\"class\"),\n                    pred_prob = predict(fit_logistic1, grid, type=\"prob\"))\nggplot()+\n  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), \n             shape=3, size=1, alpha=0.5)+\n  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+\n  labs(col=\"test dataset\", fill=\"Decision Boundary\")+\n  theme(text=element_text(family=\"ChulaCharasNew\"))+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Decision Boundary ของ logistic regression](02MLProcess_files/figure-html/unnamed-chunk-39-1.png){width=528}\n:::\n:::\n\n\nผลการพัฒนาโมเดลทำนายด้วยอัลกอริทึม logistic regression ในข้างต้นจะเห็นว่ายังไม่ประสบความสำเร็จ โดยจากรูปจะเห็นว่าพื้นที่การตัดสินใจของโมเดลทำนายอยู่บริเวณมุมขวาบนของ feature space ซึ่งยังมีความคลาดเคลื่อนอยู่มาก เมื่อพิจารณาผลการวิเคราะห์จาก confusion matrix ประกอบพบว่าโมเดลมีความไว (sensitivity) ในการทำนายการเลื่อนตำแหน่งเท่ากับ .324 ซึ่งอยู่ในระดับต่ำ แต่มีความจำเพาะ (specificity) เท่ากับ .955 ซึ่งอยู่ในระดับสูงมาก อย่างไรก็ตามค่าความจำเพาะที่สูงดังกล่าวเป็นผลมาจากการที่โมเดลมี sensitivity ต่ำมากนั่นเอง นอกจากนี้เมื่อพิจารณา AUC ของ ROC curve พบว่ามีค่าเท่ากับ .752 แสดงว่าในภาพรวมโมเดลมีประสิทธิภาพการทำนายอยู่ในระดับพอใช้\n\nจากปัญหาที่พบเราสามารถแก้ปัญหาได้หลายวิธีการ วิธีการแรก ๆ ที่ควรดำเนินการคือการทำ feature engineering จากผลการสำรวจความสัมพันธ์ระหว่างตัวแปรตามกับตัวแปรอิสระในรูป 33 จะเห็นว่าการเลื่อนตำแหน่งของพนักงานไม่ได้ขึ้นกับอายุและประสิทธิภาพในการทำนายแบบเป็นเส้นตรง กล่าวคือพนักงานอายุเยอะไม่จำเป็นต้องได้เลื่อนตำแหน่งเสมอไป และพนักงานที่มีประสิทธิภาพการทำงานที่ดีก็ไม่จำเป็นที่จะต้องได้เลื่อนตำแหน่งเสมอไปเช่นกัน แต่พนักงานที่มีแนวโน้มจะได้เลื่อนตำแหน่งคือพนักงานที่มีประสิทธิภาพการทำงานดีและมีอายุ จากข้อสังเกตนี้แสดงให้เห็นว่ามีอิทธิพลปฏิสัมพันธ์ระหว่างอายุกับประสิทธิภาพการทำนายต่อการเลื่อนตำแหน่ง\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_logistic2 <- logistic_reg() %>%\n                    set_engine(\"glm\") %>%\n                    set_mode(\"classification\")%>%\n                    fit(y ~ . + age*performance, data=train)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.822\n2 sens     binary         0.375\n3 spec     binary         0.953\n```\n:::\n\n::: {.cell-output-display}\n![ROC Curve ของ logistic regression ที่มีอิทธิพลปฏิสัมพันธ์](02MLProcess_files/figure-html/unnamed-chunk-41-1.png){width=336}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.801\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# decision boundary\nx1 <- seq(18,60,length=100)\nx2 <- seq(-10,10,length=100)\ngrid <- expand.grid(age = x1,performance = x2)\nbg.dat<-data.frame(grid) %>%\n          bind_cols(predict(fit_logistic2, grid, type=\"class\"),\n                    pred_prob = predict(fit_logistic2, grid, type=\"prob\"))\nggplot()+\n  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), \n             shape=3, size=1, alpha=0.5)+\n  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+\n  labs(col=\"test dataset\", fill=\"Decision Boundary\")+\n  theme(text=element_text(family=\"ChulaCharasNew\"))+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Decision Boundary ของ logistic regression ที่มีอิทธิพลปฏิสัมพันธ์](02MLProcess_files/figure-html/unnamed-chunk-42-1.png){width=528}\n:::\n:::\n\n\nผลการทำนายของโมเดลที่มีเทอมปฏิสัมพันธ์ระหว่างอายุกับประสิทธิภาพการทำงานพบว่าดีขึ้นเล็กน้อย แต่ยังไม่ประสบความสำเร็จ คราวนี้เราลองพิจารณาทางเลือกในการแปลงค่าของตัวแปรในลักษณะอื่นบ้าง จากผลการสำรวจที่พบว่าการเลื่อนตำแหน่งขึ้นกับปัจจัยอายุและประสิทธิภาพการทำงานผู้วิเคราะห์สร้างตัวแปรใหม่ในชุดข้อมูลเป็นอัตราส่วนอายุต่อประสิทธิภาพการทำงาน (`ratio_age_performance`) จากนั้นดำเนินการ fit โมเดลเหมือนกับสองโมเดลแรกที่ผ่านมา\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- dat%>%\n        mutate(ratio_age_performance = age/performance)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n<Training/Testing/Total>\n<1399/601/2000>\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n              Truth\nPrediction     promoted not promoted\n  promoted          129            6\n  not promoted        7          459\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.978\n2 sens     binary         0.949\n3 spec     binary         0.987\n```\n:::\n\n::: {.cell-output-display}\n![ROC Curve ของ logistic regression ที่มีการทำ feature engineering](02MLProcess_files/figure-html/unnamed-chunk-44-1.png){width=336}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# decision boundary\nx1 <- seq(18,60,length=100)\nx2 <- seq(-10,10,length=100)\ngrid <- expand.grid(age = x1,performance = x2)%>%\n          mutate(ratio_age_performance = age/performance)\n\nbg.dat<-data.frame(grid) %>%\n          bind_cols(predict(fit_logistic3, grid, type=\"class\"),\n                    pred_prob = predict(fit_logistic3, grid, type=\"prob\"))\nggplot()+\n  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), \n             shape=3, size=1, alpha=0.5)+\n  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+\n  labs(col=\"test dataset\", fill=\"Decision Boundary\")+\n  theme(text=element_text(family=\"ChulaCharasNew\"))+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Decision Boundary ของ logistic regression ที่มีการทำ Feature Engineering](02MLProcess_files/figure-html/unnamed-chunk-45-1.png){width=528}\n:::\n:::\n\n\nคราวนี้ลองเปลี่ยนโมเดลทำนายข้างต้นเป็น decision tree แบบ CART ที่มีจุดเด่นคือเป็นโมเดลจำแนกแบบ nonlinear classification กล่าวคือโมเดล decision tree ควรมีประสิทธิภาพในการจำแนกพนักงานที่จะได้เลื่อนและไม่ได้เลื่อนตำแหน่งได้สูงกว่า logistic regression ที่ยังไม่ได้ทำ feature engineering\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_tree <- decision_tree() %>%\n                    set_engine(\"rpart\") %>%\n                    set_mode(\"classification\")%>%\n                    fit(y ~ . , data=train)\n\n# calculate predicted values\npred <- predict(fit_tree, \n                new_data = test,\n                type = \"class\")\npred_prob <- predict(fit_tree, \n                new_data = test,\n                type = \"prob\")\n\ntest_results <- test %>% dplyr::select(y)%>%\n                bind_cols(pred, pred_prob)\n# evaluate model\nconf_mat(data = test_results,\n         truth = y,\n         estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Truth\nPrediction     promoted not promoted\n  promoted          124            6\n  not promoted       12          459\n```\n:::\n\n```{.r .cell-code}\neval_metric <- metric_set(accuracy, sens, spec)\neval_metric(data = test_results,\n         truth = y,\n         estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.970\n2 sens     binary         0.912\n3 spec     binary         0.987\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# decision boundary\nx1 <- seq(18,60,length=100)\nx2 <- seq(-10,10,length=100)\ngrid <- expand.grid(age = x1,performance = x2)%>%\n          mutate(ratio_age_performance = age/performance)\n\nbg.dat<-data.frame(grid) %>%\n          bind_cols(predict(fit_tree, grid, type=\"class\"),\n                    pred_prob = predict(fit_tree, grid, type=\"prob\"))\nggplot()+\n  geom_point(data = bg.dat, aes(x=age, y=performance, col=.pred_class), \n             shape=3, size=1, alpha=0.5)+\n  geom_point(data = test, aes(x=age, y= performance, col=y), shape=16, size=1)+\n  labs(col=\"test dataset\", fill=\"Decision Boundary\")+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Decision Boundary ของ Decision Tree (CART algorithm)](02MLProcess_files/figure-html/unnamed-chunk-47-1.png){width=528}\n:::\n:::\n\n\nผู้อ่านจะเห็นว่าการทำ feature engineering โดยสร้างเทอมอัตราส่วนระหว่างอายุกับประสิทธิภาพการทำงานของพนักงานในการทำนายการเลื่อนตำแหน่งของพนักงานใน logistic regression ช่วยให้พื้นที่การตัดสินใจของโมเดลทำนายแบบ logistic regression พัฒนาขึ้นมาก จากเดิมที่เป็น linear classification เป็น nonlinear classification และมีประสิทธิภาพการทำนายบนชุดข้อมูลทดสอบที่สูงมากใกล้เคียงกับการใช้ decision tree ที่เป็น nonlinear classification (อย่างไรก็ตาม decision tree มี hyperparameter ที่สามารถปรับแต่งได้อีก ซึ่งอาจเพิ่มประสิทธิภาพในการทำนายได้มากขึ้นกว่านี้) ตัวอย่างนี้เป็นตัวอย่างหนึ่งที่แสดงให้เห็นว่าการทำ feature engineering ที่เหมาะสมนั้นช่วยเพิ่มประสิทธิภาพการทำนายให้กับโมเดลได้อย่างไร\n\n## 4.2 ประเภทของ Data Preprocessing\n\nดังที่ได้กล่าวในข้างต้นว่า data preprocessing เป็นกระบวนการจัดการข้อมูลที่มีลักษณะทวนซ้ำ และไม่ได้มีขั้นตอนการดำเนินการที่แน่นอน ขั้นตอนการดำเนินการจัดการข้อมูลในแต่ละงานขึ้นอยู่กับสภาพของข้อมูล และวัตถุประสงค์ของการวิเคราะห์ในแต่ละงาน โดยทั่วไปการจัดการข้อมูลอาจจำแนกเป็น 3 ประเภทได้แก่\n\n-   **การทำความสะอาดข้อมูล (data cleaning)**\n\n-   **การแปลงข้อมูล (data transformation)**\n\n-   **การคัดเลือกตัวแปร (feature selection)**\n\nรายละเอียดมีดังนี้\n\n### การทำความสะอาดข้อมูล (data cleaning)\n\nการทำความสะอาดข้อมูลเป็นกระบวนการเพื่อสำรวจ วินิจฉัย และแก้ไขความผิดปกติที่เกิดขึ้นในข้อมูล ความผิดปกติดังกล่าวสามารถเกิดขึ้นได้จากหลายสาเหตุ เช่น การจัดเก็บหรือบันทึกข้อมูลที่ผิดพลาด หรือการวัดข้อมูลมีความคลาดเคลื่อนจากการวัด ความผิดปกติดังกล่าวมีโอกาสเกิดขึ้นได้เป็นประจำ จึงเป็นหน้าที่ของนักวิทยาการข้อมูลที่จะต้องสำรวจ และวินิจฉัยความผิดปกติดังกล่าวในชุดข้อมูล จากนั้นจึงดำเนินการแก้ไขอย่างเหมาะสม วัตถุประสงค์ของการทำความสะอาดข้อมูลคือการได้มาซึ่งชุดข้อมูลใหม่ที่มีความพร้อมในการนำไปวิเคราะห์ได้โดยไม่มีความผิดพลาด การทำความสะอาดข้อมูลจัดอยู่ในกลุ่มการเตรียมข้อมูลให้สอดคล้องกับความต้องการหรือข้อตกลงเบื้องต้นของอัลกอริทึมการเรียนรู้ ซึ่งเกี่ยวข้องกับการดำเนินการหรือเทคนิควิธีการหลายอย่าง ได้แก่\n\n-   **การจัดระเบียบและจัดกระทำข้อมูล (tidying and manipulating data)** ซึ่งเกี่ยวข้องกับการจัดรูปแบบของตารางข้อมูลให้อยู่ในรูปแบบที่เหมาะสมสำหรับการวิเคราะห์ เช่นการเปลี่ยนรูปแบบตารางระหว่างตารางข้อมูลรูปแบบยาว (long format) กับรูปแบบกว้าง (wide format) การเปลี่ยนสถานะของตัวแปรในชุดข้อมูลให้เหมาะสม การแยกและยุบรวมคอลัมนท์ การจัดการกับข้อมูลซ้ำซ้อน การรวมชุดข้อมูล การคัดกรองข้อมูล เป็นต้น package ของ R ที่เกี่ยวข้องกับการดำเนินการส่วนนี้ ได้แก่ tidyr และ dplyr (รายละเอียดสามารถศึกษาได้จาก สิวะโชติ ศรีสุทธิยากร (2564)) \\<\\-\\-- ไม่พูดถึงแล้วในรายวิชานี้\n\n-   **การสำรวจและจัดการกับค่าผิดปกติ** เกี่ยวข้องกับการสำรวจข้อมูล วินิจฉัยความผิดปกติของข้อมูล และการแก้ไขปัญหาความผิดปกติของข้อมูล ข้อมูลที่ผิดปกติอาจจำแนกได้เป็นสามประเภทตามสาเหตุของการเกิด เช่น outlier, anomaly และ noisy data\n\n-   **การวิเคราะห์และทดแทนค่าสูญหาย** เป็นปกติที่ชุดข้อมูลจะมีข้อมูลที่สูญหายไม่ครบถ้วน หากค่าสูญหายดังกล่าวเกิดขึ้นเป็นจำนวนมากเกินไป และมีรูปแบบการเกิดที่เป็นระบบ อาจส่งผลให้การเรียนรู้ของเครื่องมีความลำเอียงหรือมีความน่าเชื่อถือที่ลดลงได้ การวิเคราะห์รูปแบบของค่าสูญหาย และการเลือกวิธีการทดแทนค่าสูญหายที่เหมาะสมจะช่วยลดทอนผลกระทบที่เกิดจากค่าสูญหายดังกล่าว\n\n### การแปลงข้อมูล (data transformation)\n\nการแปลงข้อมูลเป็นกระบวนการเปลี่ยนลักษณะหรือรูปแบบของข้อมูลจากรูปแบบหนึ่งไปเป็นอีกรูปแบบหนึ่ง เพื่อให้เหมาะกับความต้องการหรือข้อตกลงเบื้องต้นของการวิเคราะห์ที่เลือกใช้ ได้แก่ การแปลงข้อมูลจัดประเภทให้เป็นตัวแปรตัวเลข เช่น dummy encoding หรือ one-hot encoding การแปลงข้อมูลที่ไม่สมมาตรให้สมมาตร หรือการแปลงข้อมูลจากหน่วยใด ๆ ให้อยู่ในหน่วยมาตรฐานเพื่อให้สามารถเปรียบเทียบกันได้ หรือลดผลกระทบจากหน่วยข้อมูลที่มีต่อการเรียนรู้ของเครื่องในบางอัลกอริทึม นอกจากนี้การแปลงข้อมูลยังเป็นเทคนิคที่อาจช่วยให้การวิเคราะห์มีประสิทธิภาพสูงขึ้นดังตัวอย่างที่แสดงไว้ในส่วนนำของบทเรียนนี้\n\n### การคัดเลือกตัวแปร (feature selection)\n\nเป็นกระบวนการคัดเลือกตัวแปรอิสระภายในชุดข้อมูลที่มีประสิทธิภาพสำหรับการวิเคราะห์หรือพัฒนาโมเดลทำนาย กระบวนการนี้มีความสำคัญมากโดยเฉพาะในสถานการณ์ที่ผู้วิเคราะห์มีชุดข้อมูลขนาดใหญ่และมีตัวแปรจำนวนมาก การคัดเลือกตัวแปรจะช่วยลดขนาดของชุดข้อมูลและช่วยให้ผู้วิเคราะห์ทำงานได้ง่ายขึ้น โดยทั่วไปอาจจำแนกวิธีการคัดเลือกตัวแปรได้เป็น 3 ประเภทได้แก่ filter methods, wrapper methods และ embedded methods\n\n**Filter methods** เป็นวิธีการพื้นฐานสำหรับการคัดเลือกตัวแปรอิสระ วิธีการในกลุ่มนี้จะเป็นการใช้ค่าสถิติพื้นฐาน ได้แก่ สัมประสิทธิ์สหสัมพันธ์ และใช้ความรู้จากการทบทวนวรรณกรรม ประสบการณ์ของผู้วิเคราะห์ ความคิดเห็นของผู้เกี่ยวข้องหรือผู้ทรงคุณวุฒิ เข้ามาร่วมกันเพื่อคัดเลือกชุดของตัวแปรอิสระที่เหมาะสม\n\n**Wrapper methods** เป็นวิธีการที่คัดเลือกตัวแปรอิสระในโมเดลด้วยอัลกอริทึมสำหรับคัดเลือกตัวแปรได้แก่ forward selection, backward selection, stepwise selection หรือ recursive feature elimination เป็นต้น\n\n**Embedded methods** เป็นวิธีการคัดเลือกตัวแปรอิสระที่รวมไปกับกระบวนการเรียนรู้ของอัลกอริทึมบางตัว เช่น lasso regression และ decision tree\n\n## 4.3 พื้นฐาน `recipe` สำหรับทำ Data Preprocessing\n\n![](images/image-1527588902.png){width=\"30%\"}\n\nการทำ data preprocessing เป็นกระบวนการที่มีการใช้ทั้งการจัดกระทำข้อมูล สถิติและอัลกอริทึมการเรียนรู้ จริง ๆ แล้วการดำเนินการดังกล่าวสามารถทำได้โดยใช้คำสั่งพื้นฐานปกติใน R อย่างไรก็ตามในกระบวนการพัฒนาโมเดลที่มีการดำเนินการแบบทวนซ้ำแต่ละขั้นตอนไปมาซึ่งการเขียนคำสั่งแบบปกติอาจไม่สะดวกนัก โดยเฉพาะในกรณีที่ผู้วิเคราะห์มีการใช้เทคนิคการจัดการข้อมูลหลาย ๆ เทคนิคต่อเนื่องกัน เช่น การแปลงค่า --- \\>การทดแทนค่าสูญหาย ---\\> การสร้างองค์ประกอบด้วย PCA บทเรียนนี้จะกล่าวถึงการใช้ package recipe เพื่อใช้เป็นวิธีการทางเลือกสำหรับผู้วิเคราะห์ในการทำ data preprocessing ภายใต้ package นี้ผู้วิเคราะห์สามารถดำเนินการทำ data preprocessing ที่มีหลายขั้นตอนหลายเทคนิคได้อย่างต่อเนื่องโดยใช้ piping operator คล้ายกับการทำงานใน package dplyr นอกจากนี้ยังนำกระบวนการที่กำหนดไปทำซ้ำกับชุดข้อมูลอื่นได้โดยง่าย เนื้อหาในหัวข้อนี้จะกล่าวถึงพื้นฐานการใช้ package recipe ดังกล่าวรายละเอียดมีดังนี้\n\n### การดาวน์โหลดและติดตั้ง package\n\nกรณีที่ติดตั้ง package tidymodels จะดาวน์โหลดและติดตั้ง package recipe โดยอัตโนมัติ ส่วนในกรณีที่ต้องการติดตั้งแยกสามารถพิมพ์คำสั่งดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# CRAN version\ninstall.packages(\"recipe\")\nlibrary(recipe)\n# development version from GitHub\ndevtools::install_github(\"tidymodels/recipes\")\n```\n:::\n\n\n### ขั้นตอนการทำ data preprocessing ด้วย recipe\n\nการทำ data preprocessing ด้วย package recipe ประกอบด้วยขั้นตอนการดำเนินงานหลัก 4 ขั้นได้แก่\n\n1.  ขั้นตอนการกำหนดสถานะของตัวแปร ว่าภายในชุดข้อมูลที่ดำเนินการอยู่ ตัวแปรใดเป็นตัวแปรตามตัวแปรใดเป็นตัวแปรอิสระ รวมถึงพิจารณาประเภทของข้อมูลในแต่ละตัวแปรด้วย ซึ่งปกติสามารถจำแนกได้ 2 ประเภทได้แก่ ข้อมูลตัวเลข และข้อมูลแบบจัดประเภท การดำเนินการในขั้นนี้จะใช้ฟังก์ชัน `recipe()`\n\n2.  ขั้นตอนการกำหนดวิธีการจัดการข้อมูลที่ต้องการ โดยผู้วิเคราะห์สามารถกำหนดวิธีการจัดการข้อมูลที่ต้องการผ่านฟังก์ชัน `step_*()` ที่ครอบคลุมทั้งการแปลงค่าข้อมูล เช่น การแปลงให้เป็นคะแนนมาตรฐาน การแปลงด้วยฟังก์ชัน log การสร้างตัวแปรใหม่จากข้อมูลของตัวแปรเดิม หรือ การทดแทนค่าสูญหาย (missing data imputation) เป็นต้น ผู้อ่านสามารถศึกษารายละเอียดของฟังก์ชัน `step_*()` ทั้งหมดภายใต้ package recipe ได้จาก <https://recipes.tidymodels.org/reference/index.html>\n\n3.  การจัดการข้อมูลหลายตัวมีการใช้วิธีการทางสถิติหรืออัลกอริทึมการเรียนรู้ที่จะต้องใช้ผลการวิเคราะห์จากชุดข้อมูลฝึกหัดมาเป็นค่าพารามิเตอร์หรือค่าสถิติสำหรับจัดการข้อมูลที่กำหนด (แต่การจัดการข้อมูลบางตัวก็ไม่ต้องใช้) ดังนั้นเมื่อผู้วิเคราะห์กำหนดสถานะของตัวแปรและการจัดการข้อมูลเรียบร้อยแล้ว ขั้นตอนที่ 3 คือการนำตัวแปรจาก `recipe()` ข้างต้นมาผ่านการประมวลผลหรือวิเคราะห์โดยใช้ชุดข้อมูลฝึกหัดเป็นข้อมูลนำเข้า เช่น หากผู้วิเคราะห์กำหนดให้มีการแปลงคะแนนตัวแปรให้เป็นสเกลมาตรฐาน ขั้นตอนนี้จะเป็นการคำนวนค่าเฉลี่ย และส่วนเบี่ยงเบนมาตรฐานของตัวแปรในชุดข้อมูลฝึกหัดที่กำหนดเพื่อใช้ในการ centering และ scaling ตัวแปรในชุดข้อมูลที่ต้องการจะทำ data preprocessing ในอนาคต การดำเนินการใช้ขั้นตอนนี้จะใช้ฟังก์ชัน `prep()`\n\n4.  ขั้นตอนสุดท้ายคือการจัดการข้อมูลตามที่วางแผนไว้บนชุดข้อมูลที่กำหนด ซึ่งเป็นไปได้ทั้ง training dataset, test dataset หรือชุดข้อมูลอื่น ๆ ที่จะนำเข้าสู่โมเดลทำนายในอนาคต (เพราะ ML model ที่พัฒนาต้องจะต้องการข้อมูลที่มีการจัดการเหมือนกับชุดข้อมูลฝึกหัด) การดำเนินการในขั้นตอนนี้จะใช้ฟังก์ชัน `bake()`\n\nตัวอย่างต่อไปนี้แสดงทำ data preprocessing ด้วย package recipe ตามขั้นตอนข้างต้น จากชุดข้อมูล [`TeacherSalaryData.csv`](https://github.com/ssiwacho/2758688_ML/blob/main/week%201/TeacherSalaryData.csv) สมมุติว่าผู้วิจัยต้องการแปลงค่าของตัวแปร `salary` ด้วยฟังก์ชัน log สามารถดำเนินการได้ดังนี้\n\n**ขั้นที่ 0 : นำเข้าและแบ่งชุดข้อมูล**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- read.csv(\"https://raw.githubusercontent.com/ssiwacho/2758688_ML/main/week%201/TeacherSalaryData.csv\")\ndat <- dat[,-1] #remove X\ndat <- dat%>%mutate_if(is.character, factor)\n# data splitting\nsplit <- initial_split(data = dat, prop = 0.8)\nsalary_train <- split %>% training()\nsalary_test <- split %>% testing()\nsummary(salary_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        rank     discipline yrs.since.phd    yrs.service        sex     \n AssocProf: 55   A:141      Min.   : 1.00   Min.   : 0.00   Female: 35  \n AsstProf : 51   B:176      1st Qu.:12.00   1st Qu.: 7.00   Male  :282  \n Prof     :211              Median :22.00   Median :17.00               \n                            Mean   :22.57   Mean   :17.88               \n                            3rd Qu.:32.00   3rd Qu.:26.00               \n                            Max.   :56.00   Max.   :60.00               \n     salary      \n Min.   : 57800  \n 1st Qu.: 91000  \n Median :108200  \n Mean   :114839  \n 3rd Qu.:135027  \n Max.   :231545  \n```\n:::\n:::\n\n\n**ขั้น 1 : กำหนดสถานะของตัวแปร และพิจารณาความถูกต้องของประเภทข้อมูลในแต่ละตัวแปร**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary_rec <- recipe(salary ~., data = salary_train)\nsalary_rec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          5\n```\n:::\n\n```{.r .cell-code}\nsalary_rec %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n  variable      type    role      source  \n  <chr>         <chr>   <chr>     <chr>   \n1 rank          nominal predictor original\n2 discipline    nominal predictor original\n3 yrs.since.phd numeric predictor original\n4 yrs.service   numeric predictor original\n5 sex           nominal predictor original\n6 salary        numeric outcome   original\n```\n:::\n:::\n\n\nผลการวิเคราะห์ข้างต้นจะเห็นว่าภายในชุดข้อมูลประกอบด้วย 6 ตัวแปร มีตัวแปรตามคือ salary ซึ่งเป็นตัวแปรเชิงปริมาณ ตัวแปรที่เหลือเป็นตัวแปรอิสระที่ประกอบด้วยตัวแปรเชิงปริมาณจำนวน 2 ตัว และตัวแปรจัดประเภทจำนวน 3 ตัว\n\n**ขั้น 2 : กำหนดการจัดการข้อมูลให้กับตัวแปร `recipe` จากขั้นที่ 1**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary_rec <- salary_rec %>%\n  step_log(salary, base = 10)\nsalary_rec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          5\n\nOperations:\n\nLog transformation on salary\n```\n:::\n:::\n\n\nผลลัพธ์ในข้างต้นแสดงให้เห็นว่ามีการกำหนดให้แปลงค่าของตัวแปร `salary` ด้วยฟังก์ชัน log\n\n**ขั้น 3 : การประมวลผล preprocessing model**\n\nขั้นตอนนี้เป็นการนำกรอบการจัดการข้อมูลที่กำหนดให้ขั้นที่ 1 และ 2 มาประมวลผลบนชุดข้อมูลฝึกหัด ด้วยฟังก์ชัน `prep()` โดยฟังก์ชันดังกล่าวจะคำนวณค่าสถิติที่จำเป็นหรือให้อัลกอริทึมการเรียนรู้ทำการประมวลผลลัพธ์ที่จำเป็นสำหรับการจัดการข้อมูลตามที่กำหนดไว้ ฟังก์ชัน `prep()` มีอาร์กิวเมนท์ที่สำคัญคือ `training` ที่ใช้ระบุชุดข้อมูลฝึกหัดสำหรับการจัดการข้อมูล\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary_rec_prep <- salary_rec %>% prep(training = salary_train)\nsalary_rec_prep\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          5\n\nTraining data contained 317 data points and no missing data.\n\nOperations:\n\nLog transformation on salary [trained]\n```\n:::\n:::\n\n\nจะเห็นว่าเมื่อผ่านตัวแปรของ `recipe` เข้าสู่ฟังก์ชัน `prep` แล้วจะมีการขึ้นสถานะว่า `[trained]` ซึ่งหมายถึง package recipe ได้ประมวลผลที่จำเป็นสำหรับการจัดการข้อมูลตามที่กำหนดแล้ว และเก็บผลดังกล่าวเอาไว้ในตัวแปร `salary_rec_pre`\n\n**ขั้น 4 : การจัดการข้อมูล**\n\nอย่างที่กล่าวไว้แล้วว่าขั้นที่ 1 - 3 ถือเป็นขั้นตอนการวางแผนและเตรียมการจัดการข้อมูล ส่วนขั้นที่ 4 เป็นการจัดการข้อมูลบนชุดข้อมูลที่กำหนด ด้วยฟังก์ชัน `bake()` โดยจะใช้กรอบการจัดการข้อมูลที่กำหนดในขั้นตอนที่ 1 และ 2 และจะใช้ค่าสถิติที่จำเป็นสำหรับการจัดการข้อมูลที่ได้จากขั้นตอนที่ 3 ฟังก์ชัน `bake()` มีอาร์กิวเมนท์สำคัญหนึ่งตัวคือ `new_data` ที่ใช้ระบุชุดข้อมูลที่จะต้องการดำเนินการ ในกรณีที่ต้องการจัดการข้อมูลฝึกหัดที่ใช้เป็นชุดข้อมูลฝึกหัดในขั้นตอนที่ 3 ให้กำหนด `new_data = NULL` ดังตัวอย่างต่อไปนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary_train_baked <- salary_rec_prep %>% bake(new_data = NULL)\nsummary(salary_train_baked)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        rank     discipline yrs.since.phd    yrs.service        sex     \n AssocProf: 55   A:141      Min.   : 1.00   Min.   : 0.00   Female: 35  \n AsstProf : 51   B:176      1st Qu.:12.00   1st Qu.: 7.00   Male  :282  \n Prof     :211              Median :22.00   Median :17.00               \n                            Mean   :22.57   Mean   :17.88               \n                            3rd Qu.:32.00   3rd Qu.:26.00               \n                            Max.   :56.00   Max.   :60.00               \n     salary     \n Min.   :4.762  \n 1st Qu.:4.959  \n Median :5.034  \n Mean   :5.044  \n 3rd Qu.:5.130  \n Max.   :5.365  \n```\n:::\n:::\n\n\nในกรณีที่ต้องการนำการจัดการข้อมูลที่ train ไว้ในขั้นที่ 3 ไปใช้กับชุดข้อมูลอื่นเช่น `salary_test` สามารถเขียนคำสั่งได้ดังนี้\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary_test_baked <- salary_rec_prep %>% bake(new_data = salary_test)\nsalary_test_baked\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 80 × 6\n   rank     discipline yrs.since.phd yrs.service sex   salary\n   <fct>    <fct>              <int>       <int> <fct>  <dbl>\n 1 AsstProf B                      4           3 Male    4.90\n 2 Prof     A                     36          31 Male    5.01\n 3 AsstProf B                      5           3 Male    4.92\n 4 AsstProf B                     11           0 Male    4.89\n 5 Prof     B                     13           9 Male    5.07\n 6 AsstProf B                      4           2 Male    4.90\n 7 Prof     B                     40          27 Male    5.01\n 8 Prof     B                     12          11 Male    5.04\n 9 Prof     B                     16           9 Male    5.03\n10 AsstProf B                      8           3 Male    4.88\n# … with 70 more rows\n```\n:::\n:::\n\n\nจะเห็นว่าชุดข้อมูลทั้งสองมีการจัดการข้อมูลของตัวแปร salary ตามที่กำหนดไว้เรียบร้อยแล้ว เนื้อหาในส่วนต่อไปจะกล่าวถึงเทคนิคการทำ data preprocessing สำหรับสถานการณ์ต่าง ๆ โดยจะใช้ package recipe ในการดำเนินการ\n",
    "supporting": [
      "02MLProcess_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}